{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f4587e8",
   "metadata": {},
   "source": [
    "# Database Rebuild - Eliminate Fragmentation\n",
    "\n",
    "## Purpose\n",
    "This notebook creates a fresh copy of the database by copying all data row-by-row into a new database file. This eliminates:\n",
    "- **Fragmentation**: Empty space left behind by deleted records\n",
    "- **Inefficiencies**: Overhead from multiple deletions and updates\n",
    "- **Storage bloat**: Unused space that isn't reclaimed by VACUUM\n",
    "\n",
    "## Why This Approach?\n",
    "DuckDB's VACUUM command should theoretically reclaim space, but in practice we've seen cases where:\n",
    "1. The database file size increases after deletions instead of decreasing\n",
    "2. VACUUM doesn't fully reclaim fragmented space\n",
    "3. Multiple deletion operations leave behind structural inefficiencies\n",
    "\n",
    "**This brute-force approach** creates a completely fresh database with:\n",
    "- Clean table structures with no fragmentation\n",
    "- Optimal page layout and storage efficiency\n",
    "- Sequential row IDs with no gaps\n",
    "- Minimal file size for the actual data\n",
    "\n",
    "## Process Overview\n",
    "1. **Backup Check**: Verify the original database exists and log its statistics\n",
    "2. **Schema Creation**: Create a new database with the proper schema using `setup_database()`\n",
    "3. **Copy Players**: Copy all player records with their original IDs\n",
    "4. **Copy Openings**: Copy all opening records with their original IDs\n",
    "5. **Copy Stats**: Copy all player_opening_stats records to appropriate partitions\n",
    "6. **Verification**: Confirm all data was copied correctly\n",
    "7. **Comparison**: Show before/after file sizes and statistics\n",
    "\n",
    "## Important Notes\n",
    "- This creates a NEW database file, it does NOT modify the original\n",
    "- The original database remains untouched as a backup\n",
    "- You'll need to manually swap the files when you're satisfied with the rebuild\n",
    "- This can be run whenever you need to defragment the database\n",
    "\n",
    "## Better Way?\n",
    "There *should* be a better way using DuckDB's built-in maintenance commands, but after trying various approaches (VACUUM, CHECKPOINT, ANALYZE), this brute-force copy is the only reliable method we've found to truly reclaim space and eliminate fragmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8abe575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATABASE REBUILD CONFIGURATION\n",
      "================================================================================\n",
      "\n",
      "Original database: /Users/a/Documents/personalprojects/chess-opening-recommender/data/processed/chess_games.db\n",
      "New database: /Users/a/Documents/personalprojects/chess-opening-recommender/data/processed/chess_games_rebuilt.db\n",
      "\n",
      "Original database exists: True\n",
      "New database exists: False\n",
      "\n",
      "✓ New database path is clear - ready to create fresh database\n"
     ]
    }
   ],
   "source": [
    "# Configuration and setup\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from utils.database.db_utils import get_db_connection, setup_database\n",
    "\n",
    "# Define paths\n",
    "project_root = Path.cwd().parent if \"notebooks\" in str(Path.cwd()) else Path.cwd()\n",
    "original_db_path = project_root / \"data\" / \"processed\" / \"chess_games.db\"\n",
    "new_db_path = project_root / \"data\" / \"processed\" / \"chess_games_rebuilt.db\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATABASE REBUILD CONFIGURATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nOriginal database: {original_db_path}\")\n",
    "print(f\"New database: {new_db_path}\")\n",
    "print(f\"\\nOriginal database exists: {original_db_path.exists()}\")\n",
    "print(f\"New database exists: {new_db_path.exists()}\")\n",
    "\n",
    "if new_db_path.exists():\n",
    "    print(f\"\\n⚠️  WARNING: New database file already exists!\")\n",
    "    print(f\"   If you continue, it will be DELETED and recreated from scratch.\")\n",
    "    print(f\"   Press Ctrl+C to abort, or continue to proceed.\")\n",
    "else:\n",
    "    print(f\"\\n✓ New database path is clear - ready to create fresh database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e7ae1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ORIGINAL DATABASE STATISTICS\n",
      "================================================================================\n",
      "\n",
      "--- File Size ---\n",
      "Size: 2,781.5 MB (2.72 GB)\n",
      "Raw bytes: 2,916,626,432\n",
      "\n",
      "--- Record Counts ---\n",
      "Players: 50,000\n",
      "Openings: 3,568\n",
      "Player-Opening-Stats Records: 25,452,253\n",
      "\n",
      "--- Partition Distribution ---\n",
      "  Partition A: 5,854,225 (23.0%)\n",
      "  Partition B: 6,670,613 (26.2%)\n",
      "  Partition C: 8,472,867 (33.3%)\n",
      "  Partition D: 3,474,963 (13.7%)\n",
      "  Partition E: 979,585 (3.8%)\n",
      "  Partition other: 0 (0.0%)\n",
      "\n",
      "--- Game Statistics ---\n",
      "  Partition D: 3,474,963 (13.7%)\n",
      "  Partition E: 979,585 (3.8%)\n",
      "  Partition other: 0 (0.0%)\n",
      "\n",
      "--- Game Statistics ---\n",
      "Total Games: 475,054,388\n",
      "Average Games per Stats Record: 18.7\n",
      "Bytes per Stats Record: 114.6\n",
      "Bytes per Game: 6.14\n",
      "Total Games: 475,054,388\n",
      "Average Games per Stats Record: 18.7\n",
      "Bytes per Stats Record: 114.6\n",
      "Bytes per Game: 6.14\n",
      "\n",
      "✓ Original database statistics logged\n",
      "\n",
      "✓ Original database statistics logged\n"
     ]
    }
   ],
   "source": [
    "# Log original database statistics\n",
    "if not original_db_path.exists():\n",
    "    raise FileNotFoundError(f\"Original database not found at {original_db_path}\")\n",
    "\n",
    "original_size_bytes = os.path.getsize(original_db_path)\n",
    "original_size_mb = original_size_bytes / (1024 * 1024)\n",
    "original_size_gb = original_size_mb / 1024\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ORIGINAL DATABASE STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n--- File Size ---\")\n",
    "print(f\"Size: {original_size_mb:,.1f} MB ({original_size_gb:.2f} GB)\")\n",
    "print(f\"Raw bytes: {original_size_bytes:,}\")\n",
    "\n",
    "with get_db_connection(original_db_path) as con:\n",
    "    # Core table counts\n",
    "    print(f\"\\n--- Record Counts ---\")\n",
    "    player_count = con.execute('SELECT COUNT(*) FROM player').fetchone()[0]\n",
    "    opening_count = con.execute('SELECT COUNT(*) FROM opening').fetchone()[0]\n",
    "    total_stats = con.execute('SELECT COUNT(*) FROM player_opening_stats').fetchone()[0]\n",
    "    \n",
    "    print(f\"Players: {player_count:,}\")\n",
    "    print(f\"Openings: {opening_count:,}\")\n",
    "    print(f\"Player-Opening-Stats Records: {total_stats:,}\")\n",
    "    \n",
    "    # Partition distribution\n",
    "    print(f\"\\n--- Partition Distribution ---\")\n",
    "    partition_counts = {}\n",
    "    for letter in ['A', 'B', 'C', 'D', 'E', 'other']:\n",
    "        count = con.execute(f'SELECT COUNT(*) FROM player_opening_stats_{letter}').fetchone()[0]\n",
    "        partition_counts[letter] = count\n",
    "        percentage = (count / total_stats * 100) if total_stats > 0 else 0\n",
    "        print(f\"  Partition {letter}: {count:,} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Game statistics\n",
    "    print(f\"\\n--- Game Statistics ---\")\n",
    "    total_games = con.execute(\"\"\"\n",
    "        SELECT SUM(num_wins + num_draws + num_losses) as total_games\n",
    "        FROM player_opening_stats\n",
    "    \"\"\").fetchone()[0]\n",
    "    \n",
    "    print(f\"Total Games: {total_games:,}\")\n",
    "    print(f\"Average Games per Stats Record: {total_games/total_stats:.1f}\")\n",
    "    print(f\"Bytes per Stats Record: {original_size_bytes/total_stats:.1f}\")\n",
    "    print(f\"Bytes per Game: {original_size_bytes/total_games:.2f}\")\n",
    "\n",
    "# Store these for later comparison\n",
    "original_stats = {\n",
    "    'size_bytes': original_size_bytes,\n",
    "    'players': player_count,\n",
    "    'openings': opening_count,\n",
    "    'stats_records': total_stats,\n",
    "    'total_games': total_games,\n",
    "    'partition_counts': partition_counts\n",
    "}\n",
    "\n",
    "print(f\"\\n✓ Original database statistics logged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b626c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CREATING NEW DATABASE\n",
      "================================================================================\n",
      "\n",
      "📋 Creating fresh database with proper schema...\n",
      "Initializing database schema...\n",
      "Database tables and partitioned stats tables are ready.\n",
      "\n",
      "✅ New database created with proper schema at: /Users/a/Documents/personalprojects/chess-opening-recommender/data/processed/chess_games_rebuilt.db\n",
      "   File size: 274,432 bytes (empty database overhead)\n"
     ]
    }
   ],
   "source": [
    "# Delete existing new database if it exists, then create fresh schema\n",
    "print(\"=\" * 80)\n",
    "print(\"CREATING NEW DATABASE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if new_db_path.exists():\n",
    "    print(f\"\\n🗑️  Deleting existing new database file...\")\n",
    "    os.remove(new_db_path)\n",
    "    print(f\"   ✓ Deleted: {new_db_path}\")\n",
    "\n",
    "print(f\"\\n📋 Creating fresh database with proper schema...\")\n",
    "new_con = get_db_connection(new_db_path)\n",
    "setup_database(new_con)\n",
    "new_con.close()\n",
    "\n",
    "print(f\"\\n✅ New database created with proper schema at: {new_db_path}\")\n",
    "print(f\"   File size: {os.path.getsize(new_db_path):,} bytes (empty database overhead)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6824d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COPYING PLAYER TABLE\n",
      "================================================================================\n",
      "\n",
      "📊 Reading all players from original database...\n",
      "   Found 50,000 players to copy\n",
      "\n",
      "📝 Inserting players into new database...\n",
      "   This preserves original IDs to maintain referential integrity\n",
      "   Using batched transactions for better performance...\n",
      "   Progress: 10,000 / 50,000 players (20.0%)\n",
      "   Progress: 10,000 / 50,000 players (20.0%)\n",
      "   Progress: 20,000 / 50,000 players (40.0%)\n",
      "   Progress: 20,000 / 50,000 players (40.0%)\n",
      "   Progress: 30,000 / 50,000 players (60.0%)\n",
      "   Progress: 30,000 / 50,000 players (60.0%)\n",
      "   Progress: 40,000 / 50,000 players (80.0%)\n",
      "   Progress: 40,000 / 50,000 players (80.0%)\n",
      "   Progress: 50,000 / 50,000 players (100.0%)\n",
      "\n",
      "✅ Player table copied successfully\n",
      "   Original: 50,000 players\n",
      "   New: 50,000 players\n",
      "   Match: ✓ YES\n",
      "   Progress: 50,000 / 50,000 players (100.0%)\n",
      "\n",
      "✅ Player table copied successfully\n",
      "   Original: 50,000 players\n",
      "   New: 50,000 players\n",
      "   Match: ✓ YES\n"
     ]
    }
   ],
   "source": [
    "# Copy player table\n",
    "print(\"=\" * 80)\n",
    "print(\"COPYING PLAYER TABLE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "with get_db_connection(original_db_path) as source_con:\n",
    "    with get_db_connection(new_db_path) as dest_con:\n",
    "        print(f\"\\n📊 Reading all players from original database...\")\n",
    "        players = source_con.execute(\"\"\"\n",
    "            SELECT id, name, title\n",
    "            FROM player\n",
    "            ORDER BY id\n",
    "        \"\"\").fetchall()\n",
    "        \n",
    "        print(f\"   Found {len(players):,} players to copy\")\n",
    "        \n",
    "        print(f\"\\n📝 Inserting players into new database...\")\n",
    "        print(f\"   This preserves original IDs to maintain referential integrity\")\n",
    "        print(f\"   Using batched transactions for better performance...\")\n",
    "        \n",
    "        # Insert in batches with explicit transaction control\n",
    "        # The key issue: we need to wrap batches in transactions to avoid slowdowns\n",
    "        batch_size = 10_000\n",
    "        total_inserted = 0\n",
    "        \n",
    "        for i in range(0, len(players), batch_size):\n",
    "            batch = players[i:i+batch_size]\n",
    "            \n",
    "            # Use explicit transaction for this batch\n",
    "            dest_con.execute(\"BEGIN TRANSACTION\")\n",
    "            \n",
    "            # Insert the batch\n",
    "            dest_con.executemany(\"\"\"\n",
    "                INSERT INTO player (id, name, title)\n",
    "                VALUES (?, ?, ?)\n",
    "            \"\"\", batch)\n",
    "            \n",
    "            dest_con.execute(\"COMMIT\")\n",
    "            \n",
    "            total_inserted += len(batch)\n",
    "            print(f\"   Progress: {total_inserted:,} / {len(players):,} players ({total_inserted/len(players)*100:.1f}%)\")\n",
    "        \n",
    "        # Verify count\n",
    "        new_player_count = dest_con.execute('SELECT COUNT(*) FROM player').fetchone()[0]\n",
    "        \n",
    "        print(f\"\\n✅ Player table copied successfully\")\n",
    "        print(f\"   Original: {len(players):,} players\")\n",
    "        print(f\"   New: {new_player_count:,} players\")\n",
    "        print(f\"   Match: {'✓ YES' if new_player_count == len(players) else '✗ NO - ERROR!'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f7d2157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COPYING OPENING TABLE\n",
      "================================================================================\n",
      "\n",
      "📊 Reading all openings from original database...\n",
      "   Found 3,568 openings to copy\n",
      "\n",
      "📝 Inserting openings into new database...\n",
      "   This preserves original IDs to maintain referential integrity\n",
      "   Using batched transactions for better performance...\n",
      "   Progress: 3,568 / 3,568 openings (100.0%)\n",
      "\n",
      "✅ Opening table copied successfully\n",
      "   Original: 3,568 openings\n",
      "   New: 3,568 openings\n",
      "   Match: ✓ YES\n",
      "   Progress: 3,568 / 3,568 openings (100.0%)\n",
      "\n",
      "✅ Opening table copied successfully\n",
      "   Original: 3,568 openings\n",
      "   New: 3,568 openings\n",
      "   Match: ✓ YES\n"
     ]
    }
   ],
   "source": [
    "# Copy opening table\n",
    "print(\"=\" * 80)\n",
    "print(\"COPYING OPENING TABLE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "with get_db_connection(original_db_path) as source_con:\n",
    "    with get_db_connection(new_db_path) as dest_con:\n",
    "        print(f\"\\n📊 Reading all openings from original database...\")\n",
    "        openings = source_con.execute(\"\"\"\n",
    "            SELECT id, eco, name\n",
    "            FROM opening\n",
    "            ORDER BY id\n",
    "        \"\"\").fetchall()\n",
    "        \n",
    "        print(f\"   Found {len(openings):,} openings to copy\")\n",
    "        \n",
    "        print(f\"\\n📝 Inserting openings into new database...\")\n",
    "        print(f\"   This preserves original IDs to maintain referential integrity\")\n",
    "        print(f\"   Using batched transactions for better performance...\")\n",
    "        \n",
    "        # Insert in batches with explicit transaction control\n",
    "        batch_size = 1000\n",
    "        total_inserted = 0\n",
    "        \n",
    "        for i in range(0, len(openings), batch_size):\n",
    "            batch = openings[i:i+batch_size]\n",
    "            \n",
    "            # Use explicit transaction for this batch\n",
    "            dest_con.execute(\"BEGIN TRANSACTION\")\n",
    "            \n",
    "            # Insert batch\n",
    "            dest_con.executemany(\"\"\"\n",
    "                INSERT INTO opening (id, eco, name)\n",
    "                VALUES (?, ?, ?)\n",
    "            \"\"\", batch)\n",
    "            \n",
    "            dest_con.execute(\"COMMIT\")\n",
    "            \n",
    "            total_inserted += len(batch)\n",
    "            \n",
    "            if total_inserted % 5000 == 0 or total_inserted >= len(openings):\n",
    "                print(f\"   Progress: {total_inserted:,} / {len(openings):,} openings ({total_inserted/len(openings)*100:.1f}%)\")\n",
    "        \n",
    "        # Verify count\n",
    "        new_opening_count = dest_con.execute('SELECT COUNT(*) FROM opening').fetchone()[0]\n",
    "        \n",
    "        print(f\"\\n✅ Opening table copied successfully\")\n",
    "        print(f\"   Original: {len(openings):,} openings\")\n",
    "        print(f\"   New: {new_opening_count:,} openings\")\n",
    "        print(f\"   Match: {'✓ YES' if new_opening_count == len(openings) else '✗ NO - ERROR!'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e0cf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COPYING PLAYER_OPENING_STATS (PARTITIONED)\n",
      "================================================================================\n",
      "\n",
      "📊 Copying stats records partition by partition...\n",
      "   This ensures proper distribution across partitioned tables\n",
      "   Stats are copied WITH their ECO codes to enable partition routing\n",
      "   Using batched transactions for better performance\n",
      "\n",
      "\n",
      "============================================================\n",
      "PARTITION A\n",
      "============================================================\n",
      "\n",
      "📊 Reading from player_opening_stats_A...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63e76fa6d80491680d783167acf71f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Found 5,854,225 records in source partition\n",
      "\n",
      "📝 Inserting into player_opening_stats_A...\n",
      "\n",
      "📝 Inserting into player_opening_stats_A...\n",
      "   Progress: 100,000 / 5,854,225 (1.7%)\n",
      "   Progress: 100,000 / 5,854,225 (1.7%)\n",
      "   Progress: 200,000 / 5,854,225 (3.4%)\n",
      "   Progress: 200,000 / 5,854,225 (3.4%)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Query interrupted",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     20\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mother\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     22\u001b[39m partition_letters = [\u001b[33m'\u001b[39m\u001b[33mA\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mB\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mC\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mD\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mE\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mother\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_db_connection(original_db_path) \u001b[38;5;28;01mas\u001b[39;00m source_con:\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m get_db_connection(new_db_path) \u001b[38;5;28;01mas\u001b[39;00m dest_con:\n\u001b[32m     26\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m📊 Copying stats records partition by partition...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     22\u001b[39m partition_letters = [\u001b[33m'\u001b[39m\u001b[33mA\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mB\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mC\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mD\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mE\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mother\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_db_connection(original_db_path) \u001b[38;5;28;01mas\u001b[39;00m source_con:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m get_db_connection(new_db_path) \u001b[38;5;28;01mas\u001b[39;00m dest_con:\n\u001b[32m     26\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m📊 Copying stats records partition by partition...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     27\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   This ensures proper distribution across partitioned tables\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 93\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# Use explicit transaction for this batch\u001b[39;00m\n\u001b[32m     91\u001b[39m dest_con.execute(\u001b[33m\"\u001b[39m\u001b[33mBEGIN TRANSACTION\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[43mdest_con\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecutemany\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m     94\u001b[39m \u001b[33;43m    INSERT INTO \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdest_table\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m (player_id, opening_id, color, num_wins, num_draws, num_losses)\u001b[39;49m\n\u001b[32m     95\u001b[39m \u001b[33;43m    VALUES (?, ?, ?, ?, ?, ?)\u001b[39;49m\n\u001b[32m     96\u001b[39m \u001b[33;43m\u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m dest_con.execute(\u001b[33m\"\u001b[39m\u001b[33mCOMMIT\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    100\u001b[39m records_inserted += \u001b[38;5;28mlen\u001b[39m(batch)\n",
      "\u001b[31mRuntimeError\u001b[39m: Query interrupted"
     ]
    }
   ],
   "source": [
    "# Copy player_opening_stats to appropriate partitions\n",
    "print(\"=\" * 80)\n",
    "print(\"COPYING PLAYER_OPENING_STATS (PARTITIONED)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define partition mapping function\n",
    "def get_partition_letter(eco_code: str) -> str:\n",
    "    \"\"\"\n",
    "    Determines which partition a record belongs to based on ECO code.\n",
    "    ECO codes starting with A-E go to their respective partitions.\n",
    "    All others go to the 'other' partition.\n",
    "    \"\"\"\n",
    "    if not eco_code or len(eco_code) == 0:\n",
    "        return 'other'\n",
    "    \n",
    "    first_letter = eco_code[0].upper()\n",
    "    if first_letter in ['A', 'B', 'C', 'D', 'E']:\n",
    "        return first_letter\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "partition_letters = ['A', 'B', 'C', 'D', 'E', 'other']\n",
    "\n",
    "with get_db_connection(original_db_path) as source_con:\n",
    "    with get_db_connection(new_db_path) as dest_con:\n",
    "        print(f\"\\n📊 Copying stats records partition by partition...\")\n",
    "        print(f\"   This ensures proper distribution across partitioned tables\")\n",
    "        print(f\"   Stats are copied WITH their ECO codes to enable partition routing\")\n",
    "        print(f\"   Using batched transactions for better performance\\n\")\n",
    "        \n",
    "        total_copied = 0\n",
    "        partition_results = {}\n",
    "        \n",
    "        for letter in partition_letters:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"PARTITION {letter}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            source_table = f\"player_opening_stats_{letter}\"\n",
    "            dest_table = f\"player_opening_stats_{letter}\"\n",
    "            \n",
    "            print(f\"\\n📊 Reading from {source_table}...\")\n",
    "            \n",
    "            # Read all stats from this partition\n",
    "            # We need to join with opening to get ECO codes for verification\n",
    "            stats = source_con.execute(f\"\"\"\n",
    "                SELECT \n",
    "                    pos.player_id,\n",
    "                    pos.opening_id,\n",
    "                    pos.color,\n",
    "                    pos.num_wins,\n",
    "                    pos.num_draws,\n",
    "                    pos.num_losses,\n",
    "                    o.eco\n",
    "                FROM {source_table} pos\n",
    "                JOIN opening o ON pos.opening_id = o.id\n",
    "                ORDER BY pos.player_id, pos.opening_id, pos.color\n",
    "            \"\"\").fetchall()\n",
    "            \n",
    "            print(f\"   Found {len(stats):,} records in source partition\")\n",
    "            \n",
    "            if len(stats) == 0:\n",
    "                print(f\"   ⚠️  Empty partition - skipping\")\n",
    "                partition_results[letter] = {'source': 0, 'copied': 0, 'verified': 0}\n",
    "                continue\n",
    "            \n",
    "            # Verify all records belong in this partition\n",
    "            misplaced = 0\n",
    "            for record in stats:\n",
    "                eco = record[6]\n",
    "                expected_partition = get_partition_letter(eco)\n",
    "                if expected_partition != letter:\n",
    "                    misplaced += 1\n",
    "            \n",
    "            if misplaced > 0:\n",
    "                print(f\"   ⚠️  WARNING: {misplaced:,} records appear to be in wrong partition!\")\n",
    "            \n",
    "            print(f\"\\n📝 Inserting into {dest_table}...\")\n",
    "            \n",
    "            # Insert in batches with explicit transaction control (without ECO code, as it's not in the stats table)\n",
    "            batch_size = 1_000_000\n",
    "            records_inserted = 0\n",
    "            \n",
    "            for i in range(0, len(stats), batch_size):\n",
    "                batch = stats[i:i+batch_size]\n",
    "                \n",
    "                # Extract just the stats columns (exclude ECO)\n",
    "                batch_data = [(r[0], r[1], r[2], r[3], r[4], r[5]) for r in batch]\n",
    "                \n",
    "                # Use explicit transaction for this batch\n",
    "                dest_con.execute(\"BEGIN TRANSACTION\")\n",
    "                \n",
    "                dest_con.executemany(f\"\"\"\n",
    "                    INSERT INTO {dest_table} (player_id, opening_id, color, num_wins, num_draws, num_losses)\n",
    "                    VALUES (?, ?, ?, ?, ?, ?)\n",
    "                \"\"\", batch_data)\n",
    "                \n",
    "                dest_con.execute(\"COMMIT\")\n",
    "                \n",
    "                records_inserted += len(batch)\n",
    "                \n",
    "                if records_inserted % 100000 == 0 or records_inserted >= len(stats):\n",
    "                    print(f\"   Progress: {records_inserted:,} / {len(stats):,} ({records_inserted/len(stats)*100:.1f}%)\")\n",
    "            \n",
    "            # Verify count in new partition\n",
    "            new_count = dest_con.execute(f'SELECT COUNT(*) FROM {dest_table}').fetchone()[0]\n",
    "            \n",
    "            print(f\"\\n✅ Partition {letter} copied\")\n",
    "            print(f\"   Source: {len(stats):,} records\")\n",
    "            print(f\"   Destination: {new_count:,} records\")\n",
    "            print(f\"   Match: {'✓ YES' if new_count == len(stats) else '✗ NO - ERROR!'}\")\n",
    "            \n",
    "            partition_results[letter] = {\n",
    "                'source': len(stats),\n",
    "                'copied': records_inserted,\n",
    "                'verified': new_count\n",
    "            }\n",
    "            \n",
    "            total_copied += new_count\n",
    "        \n",
    "        # Overall summary\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"OVERALL STATS COPY SUMMARY\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        print(f\"\\nPartition-by-partition results:\")\n",
    "        for letter in partition_letters:\n",
    "            result = partition_results[letter]\n",
    "            status = '✓' if result['source'] == result['verified'] else '✗ ERROR'\n",
    "            print(f\"  {letter}: {result['source']:>10,} → {result['verified']:>10,}  {status}\")\n",
    "        \n",
    "        print(f\"\\nTotal stats records copied: {total_copied:,}\")\n",
    "        print(f\"Original total: {original_stats['stats_records']:,}\")\n",
    "        print(f\"Match: {'✓ YES' if total_copied == original_stats['stats_records'] else '✗ NO - ERROR!'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22d1e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive verification of the new database\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPREHENSIVE VERIFICATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "with get_db_connection(new_db_path) as con:\n",
    "    print(f\"\\n--- Record Counts Verification ---\")\n",
    "    \n",
    "    new_player_count = con.execute('SELECT COUNT(*) FROM player').fetchone()[0]\n",
    "    new_opening_count = con.execute('SELECT COUNT(*) FROM opening').fetchone()[0]\n",
    "    new_stats_count = con.execute('SELECT COUNT(*) FROM player_opening_stats').fetchone()[0]\n",
    "    \n",
    "    print(f\"Players:\")\n",
    "    print(f\"  Original: {original_stats['players']:,}\")\n",
    "    print(f\"  New:      {new_player_count:,}\")\n",
    "    print(f\"  Match:    {'✓ YES' if new_player_count == original_stats['players'] else '✗ NO'}\")\n",
    "    \n",
    "    print(f\"\\nOpenings:\")\n",
    "    print(f\"  Original: {original_stats['openings']:,}\")\n",
    "    print(f\"  New:      {new_opening_count:,}\")\n",
    "    print(f\"  Match:    {'✓ YES' if new_opening_count == original_stats['openings'] else '✗ NO'}\")\n",
    "    \n",
    "    print(f\"\\nPlayer-Opening-Stats:\")\n",
    "    print(f\"  Original: {original_stats['stats_records']:,}\")\n",
    "    print(f\"  New:      {new_stats_count:,}\")\n",
    "    print(f\"  Match:    {'✓ YES' if new_stats_count == original_stats['stats_records'] else '✗ NO'}\")\n",
    "    \n",
    "    # Verify partition distribution matches\n",
    "    print(f\"\\n--- Partition Distribution Verification ---\")\n",
    "    for letter in ['A', 'B', 'C', 'D', 'E', 'other']:\n",
    "        orig_count = original_stats['partition_counts'][letter]\n",
    "        new_count = con.execute(f'SELECT COUNT(*) FROM player_opening_stats_{letter}').fetchone()[0]\n",
    "        match = '✓' if orig_count == new_count else '✗'\n",
    "        print(f\"  Partition {letter}: {orig_count:>10,} → {new_count:>10,}  {match}\")\n",
    "    \n",
    "    # Verify game totals match\n",
    "    print(f\"\\n--- Game Statistics Verification ---\")\n",
    "    new_total_games = con.execute(\"\"\"\n",
    "        SELECT SUM(num_wins + num_draws + num_losses)\n",
    "        FROM player_opening_stats\n",
    "    \"\"\").fetchone()[0]\n",
    "    \n",
    "    print(f\"Total Games:\")\n",
    "    print(f\"  Original: {original_stats['total_games']:,}\")\n",
    "    print(f\"  New:      {new_total_games:,}\")\n",
    "    print(f\"  Match:    {'✓ YES' if new_total_games == original_stats['total_games'] else '✗ NO'}\")\n",
    "    \n",
    "    # Check for referential integrity\n",
    "    print(f\"\\n--- Referential Integrity Checks ---\")\n",
    "    \n",
    "    # Check for orphaned stats (player_id not in player table)\n",
    "    orphaned_players = con.execute(\"\"\"\n",
    "        SELECT COUNT(DISTINCT pos.player_id)\n",
    "        FROM player_opening_stats pos\n",
    "        LEFT JOIN player p ON pos.player_id = p.id\n",
    "        WHERE p.id IS NULL\n",
    "    \"\"\").fetchone()[0]\n",
    "    \n",
    "    print(f\"Orphaned player_ids in stats: {orphaned_players:,}\")\n",
    "    print(f\"  Status: {'✓ GOOD (none)' if orphaned_players == 0 else '✗ ERROR - orphaned records exist!'}\")\n",
    "    \n",
    "    # Check for orphaned stats (opening_id not in opening table)\n",
    "    orphaned_openings = con.execute(\"\"\"\n",
    "        SELECT COUNT(DISTINCT pos.opening_id)\n",
    "        FROM player_opening_stats pos\n",
    "        LEFT JOIN opening o ON pos.opening_id = o.id\n",
    "        WHERE o.id IS NULL\n",
    "    \"\"\").fetchone()[0]\n",
    "    \n",
    "    print(f\"\\nOrphaned opening_ids in stats: {orphaned_openings:,}\")\n",
    "    print(f\"  Status: {'✓ GOOD (none)' if orphaned_openings == 0 else '✗ ERROR - orphaned records exist!'}\")\n",
    "    \n",
    "    # Final verdict\n",
    "    all_checks_passed = (\n",
    "        new_player_count == original_stats['players'] and\n",
    "        new_opening_count == original_stats['openings'] and\n",
    "        new_stats_count == original_stats['stats_records'] and\n",
    "        new_total_games == original_stats['total_games'] and\n",
    "        orphaned_players == 0 and\n",
    "        orphaned_openings == 0\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    if all_checks_passed:\n",
    "        print(f\"✅ ALL VERIFICATION CHECKS PASSED\")\n",
    "        print(f\"   The new database is an exact copy of the original\")\n",
    "    else:\n",
    "        print(f\"❌ VERIFICATION FAILED\")\n",
    "        print(f\"   The new database does NOT match the original\")\n",
    "        print(f\"   DO NOT use the new database - investigate errors above\")\n",
    "    print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a05e76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File size comparison and efficiency gains\n",
    "print(\"=\" * 80)\n",
    "print(\"FILE SIZE COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "new_size_bytes = os.path.getsize(new_db_path)\n",
    "new_size_mb = new_size_bytes / (1024 * 1024)\n",
    "new_size_gb = new_size_mb / 1024\n",
    "\n",
    "size_difference_bytes = original_stats['size_bytes'] - new_size_bytes\n",
    "size_difference_mb = size_difference_bytes / (1024 * 1024)\n",
    "percentage_reduction = (size_difference_bytes / original_stats['size_bytes']) * 100\n",
    "\n",
    "print(f\"\\n--- Original Database ---\")\n",
    "print(f\"Size: {original_stats['size_bytes'] / (1024*1024):,.1f} MB ({original_stats['size_bytes'] / (1024*1024*1024):.2f} GB)\")\n",
    "print(f\"Raw bytes: {original_stats['size_bytes']:,}\")\n",
    "\n",
    "print(f\"\\n--- Rebuilt Database ---\")\n",
    "print(f\"Size: {new_size_mb:,.1f} MB ({new_size_gb:.2f} GB)\")\n",
    "print(f\"Raw bytes: {new_size_bytes:,}\")\n",
    "\n",
    "print(f\"\\n--- Comparison ---\")\n",
    "if size_difference_bytes > 0:\n",
    "    print(f\"✅ SIZE REDUCED by {size_difference_mb:,.1f} MB ({percentage_reduction:.1f}%)\")\n",
    "    print(f\"   Space reclaimed: {size_difference_bytes:,} bytes\")\n",
    "elif size_difference_bytes < 0:\n",
    "    print(f\"⚠️  Size INCREASED by {abs(size_difference_mb):,.1f} MB ({abs(percentage_reduction):.1f}%)\")\n",
    "    print(f\"   This is unexpected - the rebuild should not increase size\")\n",
    "else:\n",
    "    print(f\"Size is EXACTLY THE SAME\")\n",
    "    print(f\"   The original database was already fully optimized\")\n",
    "\n",
    "# Efficiency metrics\n",
    "print(f\"\\n--- Storage Efficiency ---\")\n",
    "bytes_per_record_old = original_stats['size_bytes'] / original_stats['stats_records']\n",
    "bytes_per_record_new = new_size_bytes / original_stats['stats_records']\n",
    "bytes_per_game_old = original_stats['size_bytes'] / original_stats['total_games']\n",
    "bytes_per_game_new = new_size_bytes / original_stats['total_games']\n",
    "\n",
    "print(f\"Bytes per stats record:\")\n",
    "print(f\"  Original: {bytes_per_record_old:.1f}\")\n",
    "print(f\"  New:      {bytes_per_record_new:.1f}\")\n",
    "print(f\"  Change:   {((bytes_per_record_new - bytes_per_record_old) / bytes_per_record_old * 100):+.1f}%\")\n",
    "\n",
    "print(f\"\\nBytes per game:\")\n",
    "print(f\"  Original: {bytes_per_game_old:.2f}\")\n",
    "print(f\"  New:      {bytes_per_game_new:.2f}\")\n",
    "print(f\"  Change:   {((bytes_per_game_new - bytes_per_game_old) / bytes_per_game_old * 100):+.1f}%\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"DATABASE REBUILD COMPLETE\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nOriginal database: {original_db_path}\")\n",
    "print(f\"New database:      {new_db_path}\")\n",
    "print(f\"\\nThe original database has NOT been modified.\")\n",
    "print(f\"If you're satisfied with the rebuild, you can:\")\n",
    "print(f\"  1. Rename the original as a backup\")\n",
    "print(f\"  2. Rename the rebuilt database to replace it\")\n",
    "print(f\"\\nExample commands:\")\n",
    "print(f\"  mv {original_db_path} {original_db_path}.backup\")\n",
    "print(f\"  mv {new_db_path} {original_db_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
