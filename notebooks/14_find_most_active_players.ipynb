{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5938f7b2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c657718",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "This notebook will find the 50k most active Lichess players (rapid blitz classical), measured by number of games.\n",
    "\n",
    "It does this by downloading and reading parquet files of raw game data.\n",
    "\n",
    "It's not practical to download the hundreds of 1GB parquet files; so we will download a certain number and extrapolate from there.\n",
    "\n",
    "We don't need to know exactly who is the *most* active, just need to find *very* active players.\n",
    "\n",
    "Then, we will process their games for data to feed in to our chess opening recommender AI model.\n",
    "\n",
    "# Reason\n",
    "\n",
    "Originally, we were just collecting data on millions of players without caring who was active or not.\n",
    "\n",
    "This grew impractical quickly, with a massive local DB. Games processing slowed down exponentially because SQL queries to the local duckdb got so slow due to the db's size.\n",
    "\n",
    "So I've decided to focus on the 50k most active players instead.\n",
    "\n",
    "# Method\n",
    "\n",
    "1. Get names of parquet files\n",
    "    - We will want to look at games data over the course of a year or so\n",
    "    - So, we'll download some 1GB raw game data parquet files (number TBD) from each month (there are about 60-70 total per month)\n",
    "    - To do this, we need the names of those files to get from the HuggingFace API\n",
    "    - Luckily we already have functionality elsewhere to do this; I'll import it here and update slightly for our needs\n",
    "\n",
    "2. Download parquet files\n",
    "    - Once we have the names of the needed files, we'll download them\n",
    "    - I already have functionality to do this elsewhere, just need to import it here\n",
    "\n",
    "3. Save game counts\n",
    "    - Once we have our parquet files downloaded, we'll count the number of games each username has\n",
    "    - There will be some filters; only Rapid/Blitz/Classical games, only players over 1200 rating\n",
    "    - Need to decide on a data saving method; probably in a CSV with username/num_games\n",
    "    - Wherever it's saved it needs to be persistent, as this processing will happen over multiple sessions.\n",
    "\n",
    "4. Get most active players\n",
    "    - Finally, we'll analyze our CSV to retrieve the usernames of the 50,000 most active Lichess players\n",
    "    - Profit\n",
    "\n",
    "\n",
    "- Note that all data for this will be saved in data/processed/find_most_active_players directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bac497",
   "metadata": {},
   "source": [
    "## Config\n",
    "\n",
    "Below, we'll define some important variables that we want to use in this notebook.\n",
    "\n",
    "I like to keep them in one place at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e15df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.downloading_raw_parquet_data.get_parquet_file_names import (\n",
    "    get_parquet_file_names,\n",
    ")\n",
    "\n",
    "# The year and month we want to download data for\n",
    "\n",
    "month_for_downloading = 6\n",
    "year_for_downloading = 2025\n",
    "\n",
    "max_files_to_download_per_month = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7070cdbc",
   "metadata": {},
   "source": [
    "## 1. Get file names\n",
    "\n",
    "Now, we'll get the file names for the month and year we want to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca8fa4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/year=2025/month=06/train-00000-of-00065.parquet\n",
      "data/year=2025/month=06/train-00001-of-00065.parquet\n",
      "data/year=2025/month=06/train-00002-of-00065.parquet\n"
     ]
    }
   ],
   "source": [
    "file_names_for_month = get_parquet_file_names(year_for_downloading, month_for_downloading)\n",
    "# print with line separations\n",
    "print(\"\\n\".join(file_names_for_month[:max_files_to_download_per_month]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fcbcc1",
   "metadata": {},
   "source": [
    "## Database Setup\n",
    "\n",
    "Now, we'll initialize our database.\n",
    "\n",
    "This is a small database that tracks the number of games played by a Lichess username, as well as which files have been checked so there are no duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "623816ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database file /Users/a/Documents/personalprojects/chess-opening-recommender/data/processed/find_most_active_players/player_game_counts.duckdb already exists. Skipping initialization.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from utils.database.db_utils import get_db_connection\n",
    "from utils.database.player_game_counts_db_utils import setup_player_game_counts_table\n",
    "\n",
    "# Define the project root\n",
    "project_root = Path.cwd().parent\n",
    "\n",
    "# Initialize the database\n",
    "DB_PATH = project_root / \"data\" / \"processed\" / \"find_most_active_players\" / \"player_game_counts.duckdb\"\n",
    "DB_DIR = DB_PATH.parent\n",
    "\n",
    "# Ensure the directory exists\n",
    "if not DB_DIR.exists():\n",
    "    DB_DIR.mkdir(parents=True)\n",
    "    print(f\"Created directory: {DB_DIR}\")\n",
    "\n",
    "# Ensure the database file exists\n",
    "if not DB_PATH.exists():\n",
    "    print(f\"Database file {DB_PATH} does not exist. Initializing...\")\n",
    "    con = get_db_connection(str(DB_PATH))\n",
    "    setup_player_game_counts_table(con)\n",
    "    con.close()\n",
    "    print(\"Database created and initialized.\")\n",
    "else:\n",
    "    print(f\"Database file {DB_PATH} already exists. Skipping initialization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae561e81",
   "metadata": {},
   "source": [
    "## Main Pipeline\n",
    "Now that we have the names of the files we need, we will do the following for each file name (until we've downloaded our predefined max number of files for the given month)\n",
    "\n",
    "1. Check our local db to make sure that we haven't already downloaded the file in question\n",
    "    - If we have, cycle through that month's list of files until we find one that hasn't been downloaded\n",
    "2. Download the file in question\n",
    "    - Note that HuggingFace's API is smart enough to not re-download files we already have on our local machine, which saves me a lot of headache when doing this repeatedly for testing.\n",
    "3. Mark the file as having been processed in our local db to avoid duplicates\n",
    "4. Process the file, recording each player's num_games in the local db\n",
    "5. Delete the file\n",
    "6. Move on to next file unless we've reached our maximum number of files\n",
    "\n",
    "Goals:\n",
    "\n",
    "- Thorough logging, especially for how long each step takes, including games per second while processing files\n",
    "- Each file is about 1.4 million rows so that helps when providing a file ETA\n",
    "- Also log which file number we're on out of the max total files to download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f527ca91",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61730001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checked file data/year=2025/month=06/train-00000-of-00065.parquet in 0.02 seconds.\n",
      "File data/year=2025/month=06/train-00000-of-00065.parquet has not been processed yet. Processing now.\n",
      "Checked file data/year=2025/month=06/train-00001-of-00065.parquet in 0.02 seconds.\n",
      "File data/year=2025/month=06/train-00001-of-00065.parquet has not been processed yet. Processing now.\n",
      "Checked file data/year=2025/month=06/train-00002-of-00065.parquet in 0.02 seconds.\n",
      "File data/year=2025/month=06/train-00002-of-00065.parquet has not been processed yet. Processing now.\n",
      "Checked file data/year=2025/month=06/train-00003-of-00065.parquet in 0.02 seconds.\n",
      "File data/year=2025/month=06/train-00003-of-00065.parquet has not been processed yet. Processing now.\n",
      "Checked file data/year=2025/month=06/train-00004-of-00065.parquet in 0.02 seconds.\n",
      "File data/year=2025/month=06/train-00004-of-00065.parquet has not been processed yet. Processing now.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from utils.database.player_game_counts_db_utils import is_file_already_downloaded\n",
    "from utils.downloading_raw_parquet_data.raw_parquet_data_file_downloader import (\n",
    "    download_single_parquet_file,\n",
    ")\n",
    "\n",
    "for file_name in file_names_for_month[:5]:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 1. Check in the local db whether the file has already been processed - if so, move on to next file\n",
    "    con = get_db_connection(str(DB_PATH))\n",
    "    is_already_downloaded = is_file_already_downloaded(con, file_name, year_for_downloading, month_for_downloading)\n",
    "    con.close()\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Checked file {file_name} in {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "    if is_already_downloaded:\n",
    "        print(f\"File {file_name} has already been processed. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"File {file_name} has not been processed yet. Processing now.\")\n",
    "\n",
    "    # 2. If it hasn't been processed, download the file\n",
    "    downloaded_file_path = download_single_parquet_file(\n",
    "        file_name, year_for_downloading, month_for_downloading\n",
    "    )\n",
    "\n",
    "\n",
    "    # 3. Mark the file as processed in the local db. Doing this part first because downloading is cheap and quick, we can just move on to the next file if something goes wrong\n",
    "\n",
    "    # 4. Process the file, updating player game counts in the local db\n",
    "\n",
    "    # 5. Delete the file\n",
    "\n",
    "    # 6. Move on to the next file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
