{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61d163cc",
   "metadata": {},
   "source": [
    "# Notebook 29 â€” Inference Pipeline: Predicting Opening Performance for New Players\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook demonstrates the complete inference pipeline for making opening recommendations to players **not** in our training set.\n",
    "We use the 1,000 holdout players (reserved in notebook 28) to validate our approach before deploying to production.\n",
    "\n",
    "**Production Use**: This pipeline will be used on the website to:\n",
    "- Fetch a player's game history from the Lichess API\n",
    "    - Note that for the testing in this notebook, we're just getting an untouched holdout player from our local DB.\n",
    "- Transform their opening statistics into model-ready features\n",
    "- Generate personalized opening recommendations\n",
    "- Display predictions with confidence scores\n",
    "\n",
    "**Development Focus**: We're building **granular, reusable functions** that can be easily adapted from local DB testing to production API integration.\n",
    "\n",
    "---\n",
    "\n",
    "## Pipeline Steps\n",
    "\n",
    "### 1. **Load Holdout Player Data**\n",
    "- Select a holdout player from the database (never seen during training)\n",
    "- Extract their complete opening statistics (wins, draws, losses per opening)\n",
    "- Retrieve player metadata (rating, name, etc.)\n",
    "- Verify data quality and completeness\n",
    "- Will use the same player every time this is run, for testing\n",
    "\n",
    "### 2. **Transform Data for Model Input**\n",
    "- Calculate raw performance scores: `(wins + 0.5 Ã— draws) / total_games`\n",
    "- Completely ignore openings not in training set\n",
    "    - We got rid of those for good reasons, not helpful/unrepresentative/too generic\n",
    "- Apply hierarchical Bayesian shrinkage toward opening-specific means\n",
    "- Normalize player rating using training set parameters (z-score)\n",
    "- Remap database IDs to training IDs (sequential 0-based indices)\n",
    "- Encode ECO codes into categorical features (letter and number)\n",
    "- Convert to PyTorch tensors\n",
    "    - player id (not sure this is needed), opening ids, eco letters and numbers, rating_z\n",
    "\n",
    "### 3. **Generate Predictions**\n",
    "- Load trained model and all required artifacts (mappings, normalization params, etc.)\n",
    "- Feed transformed data through the model\n",
    "- Generate predicted performance scores for all valid openings\n",
    "- Separate predictions into: openings player has played vs. new recommendations\n",
    "\n",
    "### 4. **Analyze and Display Results**\n",
    "- Compare predictions to actual performance (for openings player has played)\n",
    "- Rank and display top opening recommendations\n",
    "- Visualize prediction quality and confidence\n",
    "- Save predictions for later analysis\n",
    "\n",
    "---\n",
    "\n",
    "**Note**: This notebook only performs inferenceâ€”the model weights remain fixed. We are validating the deployment pipeline, not retraining.\n",
    "\n",
    "**Note about one possible issue**: I believe we will need opening statistics from the training data to perform Bayesian shrinkage on win rates. We may not have that readily available; I'll need to double check our artifacts. But it should be fairly easy to compile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d23f689",
   "metadata": {},
   "source": [
    "## Required Model Artifacts\n",
    "\n",
    "In this notebook (and in production), we will need to load various model artifact files to help in data processing.\n",
    "\n",
    "I currently believe that we only need very small files (< 1MB total), which is very doable on the client or server.\n",
    "\n",
    "From the trained model's artifact directory, we'll need:\n",
    "\n",
    "### **Core Model & Mappings**\n",
    "- **`best_model.pt`** (8.3 MB) - Trained PyTorch model weights for inference\n",
    "  - This will live on the HuggingFace space where we host our model, so we don't need to slow down production by loading it in.\n",
    "- **Note**: Need to make sure we're using a valid player id, if any. It might have to be the next sequential player id that the model's dataset would expect? Not sure, need to investigate.\n",
    "- **`opening_id_mappings.json`** (96 KB) - Maps database opening IDs â†’ training IDs (0-based sequential)\n",
    "  - *Why*: Same as above - embeddings require contiguous indices\n",
    "\n",
    "### **Normalization & Encoding**\n",
    "- **`rating_normalization.json`** (4 KB) - Contains `rating_mean` and `rating_std` from training\n",
    "  - *Why*: Must normalize new player ratings with exact same parameters: `z = (rating - mean) / std`\n",
    "- **`eco_encodings.json`** (4 KB) - Maps ECO codes to integers (letter: A-E â†’ 0-4, numbers â†’ sequential ints)\n",
    "  - *Why*: Model expects categorical integers, not raw ECO strings like \"B02\"\n",
    "\n",
    "### **Model Configuration**\n",
    "- **`hyperparameters.json`** (4 KB) - NUM_FACTORS (40), NUM_PLAYERS, NUM_OPENINGS, embedding dimensions\n",
    "  - *Why*: Need exact architecture specs to instantiate the model correctly\n",
    "- **`model_architecture.json`** (4 KB) - Complete model structure details\n",
    "  - *Why*: Documents the model class and layer configurations\n",
    "\n",
    "### **Reference Data**\n",
    "- **`opening_mappings.csv`** (168 KB) - Full opening metadata (db_id, training_id, eco, name)\n",
    "  - *Why*: Look up opening details when displaying recommendations\n",
    "- **`holdout_players.csv`** (24 KB) - List of 1,000 holdout player IDs for testing\n",
    "  - *Why*: Select test players that were never seen during training\n",
    "\n",
    "### **âš ï¸ Missing Artifact (Need to Create)**\n",
    "- **`opening_stats.json`** or **`.csv`** - Opening-specific statistics from training data\n",
    "  - Should contain: `opening_id`, `mean_score`, `total_games`, `num_players`\n",
    "  - *Why*: Required for hierarchical Bayesian shrinkage during inference\n",
    "  - *Status*: **Not currently saved** - we'll need to generate this from notebook 28's training data\n",
    "\n",
    "---\n",
    "\n",
    "**Total artifact size**: <1MB currently. I'm not sure if opening_stats.json will be large and unwieldy (assuming we even need it) but I don't think so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfc2a09",
   "metadata": {},
   "source": [
    "## Step 1: Load Test Player Data\n",
    "\n",
    "We'll:\n",
    "1. Load a player from the model artifacts (using training set for now - see note below)\n",
    "2. Select a deterministic player (using a fixed index)\n",
    "3. Extract their complete opening statistics from the database\n",
    "4. Retrieve their player metadata\n",
    "5. Display everything for verification\n",
    "\n",
    "**Note**: Using a TRAINING player (not holdout) for initial testing because the holdout players list appears to include players without Black games. In production, we'll use the Lichess API to fetch any player's data, so this distinction won't matter. For now, we just need to validate the inference pipeline works.\n",
    "\n",
    "**Deterministic Selection**: Using the same player index for consistency across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ab21d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Add project root to path for module imports\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from utils.database.db_utils import get_db_connection\n",
    "\n",
    "print(\"âœ“ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b278824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Verifying paths...\n",
      "   Database: True - /Users/a/Documents/personalprojects/chess-opening-recommender/data/processed/chess_games.db\n",
      "   Model artifacts: True - /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/20251212_152017_black\n",
      "âœ“ All paths verified\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "DB_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"chess_games.db\"\n",
    "MODEL_ARTIFACTS_DIR = PROJECT_ROOT / \"data\" / \"models\" / \"20251212_152017_black\"\n",
    "\n",
    "# Deterministic player selection\n",
    "# Note: We'll find a player with actual Black games data\n",
    "HOLDOUT_PLAYER_INDEX = 0  # Starting point, will find first player with Black games\n",
    "\n",
    "# Verify paths exist\n",
    "print(\" Verifying paths...\")\n",
    "print(f\"   Database: {DB_PATH.exists()} - {DB_PATH}\")\n",
    "print(f\"   Model artifacts: {MODEL_ARTIFACTS_DIR.exists()} - {MODEL_ARTIFACTS_DIR}\")\n",
    "\n",
    "if not DB_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Database not found at {DB_PATH}\")\n",
    "if not MODEL_ARTIFACTS_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Model artifacts not found at {MODEL_ARTIFACTS_DIR}\")\n",
    "\n",
    "print(\"âœ“ All paths verified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b111a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Loading holdout players...\n",
      "   Total holdout players: 1,000\n",
      "   Columns: ['db_id', 'name', 'title', 'rating']\n",
      "\n",
      "   First 5 holdout players:\n",
      "   db_id        name  title  rating\n",
      "0     53    AAashraf    NaN    1723\n",
      "1    129       AK988    NaN    1489\n",
      "2    187  ALexxxey89    NaN    1635\n",
      "3    425   Abgrenzer    NaN    1787\n",
      "4    498      Ac1000    NaN    2541\n",
      "\n",
      "âœ“ Selected holdout player #0:\n",
      "   Database ID: 53\n",
      "   Name: AAashraf\n",
      "   Rating: 1723\n"
     ]
    }
   ],
   "source": [
    "# Step 1.1: Load holdout players list\n",
    "print(\"Loading holdout players...\")\n",
    "\n",
    "holdout_players_path = MODEL_ARTIFACTS_DIR / \"holdout_players.csv\"\n",
    "holdout_players_df = pd.read_csv(holdout_players_path)\n",
    "\n",
    "print(f\"   Total holdout players: {len(holdout_players_df):,}\")\n",
    "print(f\"   Columns: {list(holdout_players_df.columns)}\")\n",
    "print(f\"\\n   First 5 holdout players:\")\n",
    "print(holdout_players_df.head())\n",
    "\n",
    "# Select our test player deterministically (always use the first player)\n",
    "test_player_db_id = int(holdout_players_df.iloc[HOLDOUT_PLAYER_INDEX]['db_id'])\n",
    "test_player_name = holdout_players_df.iloc[HOLDOUT_PLAYER_INDEX]['name']\n",
    "test_player_rating = int(holdout_players_df.iloc[HOLDOUT_PLAYER_INDEX]['rating'])\n",
    "\n",
    "print(f\"\\nâœ“ Selected holdout player #{HOLDOUT_PLAYER_INDEX}:\")\n",
    "print(f\"   Database ID: {test_player_db_id}\")\n",
    "print(f\"   Name: {test_player_name}\")\n",
    "print(f\"   Rating: {test_player_rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eda4ead1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying player is not in training set...\n",
      "   Total training players: 48,551\n",
      "   Columns: ['db_id', 'name', 'title', 'rating', 'training_id']\n",
      "âœ“ Verified: Player AAashraf (ID: 53) is NOT in training set\n",
      "   This is a true holdout player for testing inference\n"
     ]
    }
   ],
   "source": [
    "# Step 1.2: Verify player is NOT in training set\n",
    "print(\"Verifying player is not in training set...\")\n",
    "\n",
    "player_mappings_path = MODEL_ARTIFACTS_DIR / \"player_mappings.csv\"\n",
    "player_mappings_df = pd.read_csv(player_mappings_path)\n",
    "\n",
    "print(f\"   Total training players: {len(player_mappings_df):,}\")\n",
    "print(f\"   Columns: {list(player_mappings_df.columns)}\")\n",
    "\n",
    "# Check if our test player is in the training set\n",
    "is_in_training = test_player_db_id in player_mappings_df['db_id'].values\n",
    "\n",
    "if is_in_training:\n",
    "    raise ValueError(\n",
    "        f\"âŒ ERROR: Player {test_player_name} (ID: {test_player_db_id}) \"\n",
    "        f\"is in the training set! They should be a holdout player.\"\n",
    "    )\n",
    "\n",
    "print(f\"âœ“ Verified: Player {test_player_name} (ID: {test_player_db_id}) is NOT in training set\")\n",
    "print(f\"   This is a true holdout player for testing inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd9ea2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Extracting opening statistics for AAashraf...\n",
      "âœ“ Database query complete\n",
      "   Total openings played: 194\n",
      "   Total games: 3,502\n",
      "\n",
      "   Opening statistics columns: ['player_id', 'opening_id', 'eco', 'opening_name', 'num_games', 'wins', 'draws', 'losses']\n",
      "   Data types:\n",
      "player_id        int32\n",
      "opening_id       int32\n",
      "eco             object\n",
      "opening_name    object\n",
      "num_games        int32\n",
      "wins             int32\n",
      "draws            int32\n",
      "losses           int32\n",
      "dtype: object\n",
      "âœ“ Database query complete\n",
      "   Total openings played: 194\n",
      "   Total games: 3,502\n",
      "\n",
      "   Opening statistics columns: ['player_id', 'opening_id', 'eco', 'opening_name', 'num_games', 'wins', 'draws', 'losses']\n",
      "   Data types:\n",
      "player_id        int32\n",
      "opening_id       int32\n",
      "eco             object\n",
      "opening_name    object\n",
      "num_games        int32\n",
      "wins             int32\n",
      "draws            int32\n",
      "losses           int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Step 1.3: Extract player's opening statistics from database\n",
    "print(f\"Extracting opening statistics for {test_player_name}...\")\n",
    "\n",
    "conn = get_db_connection(DB_PATH)\n",
    "\n",
    "# Query to get all opening stats for this player (Black side, matching training data)\n",
    "# Note: The schema uses 'color' column with values 'w' or 'b' (not 'white'/'black')\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    pos.player_id,\n",
    "    pos.opening_id,\n",
    "    o.eco,\n",
    "    o.name as opening_name,\n",
    "    pos.num_wins + pos.num_draws + pos.num_losses as num_games,\n",
    "    pos.num_wins as wins,\n",
    "    pos.num_draws as draws,\n",
    "    pos.num_losses as losses\n",
    "FROM player_opening_stats pos\n",
    "JOIN opening o ON pos.opening_id = o.id\n",
    "WHERE pos.player_id = ?\n",
    "  AND pos.color = 'b'\n",
    "  AND (pos.num_wins + pos.num_draws + pos.num_losses) > 0\n",
    "ORDER BY (pos.num_wins + pos.num_draws + pos.num_losses) DESC\n",
    "\"\"\"\n",
    "\n",
    "# Convert numpy.int64 to regular Python int for DuckDB compatibility\n",
    "player_stats_df = conn.execute(query, [int(test_player_db_id)]).df()\n",
    "conn.close()\n",
    "\n",
    "print(f\"âœ“ Database query complete\")\n",
    "print(f\"   Total openings played: {len(player_stats_df)}\")\n",
    "print(f\"   Total games: {player_stats_df['num_games'].sum():,}\")\n",
    "print(f\"\\n   Opening statistics columns: {list(player_stats_df.columns)}\")\n",
    "print(f\"   Data types:\\n{player_stats_df.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90502146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPLETE DATA FOR TEST PLAYER: AAashraf\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ PLAYER METADATA:\n",
      "   Database ID: 53\n",
      "   Name: AAashraf\n",
      "   Rating: 1723\n",
      "   Status: HOLDOUT PLAYER (not in training set)\n",
      "\n",
      "ðŸ“Š OPENING STATISTICS SUMMARY:\n",
      "   Total openings played: 194\n",
      "   Total games: 3,502\n",
      "   Total wins: 1531\n",
      "   Total draws: 292\n",
      "   Total losses: 1679\n",
      "   Overall win rate: 43.7%\n",
      "\n",
      "ðŸ“ˆ TOP 10 MOST-PLAYED OPENINGS:\n",
      "                                                           opening_name eco  num_games  wins  draws  losses\n",
      "                                                       Philidor Defense C41       1450   642    119     689\n",
      "                           Queen's Pawn Game: Accelerated London System D00        206    99     20      87\n",
      "                                        Bishop's Opening: Boi Variation C23        136    64     11      61\n",
      "                                                            Vienna Game C25        127    61     13      53\n",
      "                                          Queen's Pawn Game: Anti-Torre D02         98    46      7      45\n",
      "                                 Queen's Gambit Accepted: Old Variation D20         96    33      9      54\n",
      "                         King's Gambit Accepted: King's Knight's Gambit C34         91    28      5      58\n",
      "            Queen's Gambit Accepted: Central Variation, Greco Variation D20         84    38      9      37\n",
      "                                                Queen's Gambit Accepted D20         54    22      0      32\n",
      "English Opening: King's English Variation, Kramnik-Shirov Counterattack A21         46    22      6      18\n",
      "\n",
      "ðŸ“‰ BOTTOM 10 LEAST-PLAYED OPENINGS:\n",
      "                                                                  opening_name eco  num_games  wins  draws  losses\n",
      "                                   Queen's Pawn Game: Colle System, Anti-Colle D04          1     0      0       1\n",
      "                 Queen's Gambit Declined: Chigorin Defense, Exchange Variation D07          1     0      0       1\n",
      "                                                     Slav Defense: Modern Line D11          1     0      0       1\n",
      "Semi-Slav Defense: Noteboom Variation, Anti-Noteboom Variation, Belyavsky Line D31          1     0      0       1\n",
      "                                 Nimzo-Indian Defense: Three Knights Variation E21          1     1      0       0\n",
      "                                 Italian Game: Scotch Gambit, Janowski Defense C56          1     0      0       1\n",
      "                                   Zukertort Opening: Reversed Mexican Defense A06          1     0      0       1\n",
      "                                     Scandinavian Defense: Valencian Variation B01          1     0      0       1\n",
      "                   King's Gambit Accepted: Bishop's Gambit, Bogoljubow Defense C33          1     1      0       0\n",
      "                                                       Englund Gambit Declined A40          1     0      0       1\n",
      "\n",
      "âœ… VERIFICATION COMPLETE\n",
      "   Player data extracted successfully for AAashraf\n",
      "   Ready to proceed to data transformation (Step 2)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 1.4: Display complete player data for verification\n",
    "print(\"=\"*80)\n",
    "print(f\"COMPLETE DATA FOR TEST PLAYER: {test_player_name}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nPLAYER METADATA:\")\n",
    "print(f\"   Database ID: {test_player_db_id}\")\n",
    "print(f\"   Name: {test_player_name}\")\n",
    "print(f\"   Rating: {test_player_rating}\")\n",
    "print(f\"   Status: HOLDOUT PLAYER (not in training set)\")\n",
    "\n",
    "print(\"\\nOPENING STATISTICS SUMMARY:\")\n",
    "print(f\"   Total openings played: {len(player_stats_df)}\")\n",
    "print(f\"   Total games: {player_stats_df['num_games'].sum():,}\")\n",
    "print(f\"   Total wins: {player_stats_df['wins'].sum()}\")\n",
    "print(f\"   Total draws: {player_stats_df['draws'].sum()}\")\n",
    "print(f\"   Total losses: {player_stats_df['losses'].sum()}\")\n",
    "print(f\"   Overall win rate: {player_stats_df['wins'].sum() / player_stats_df['num_games'].sum():.1%}\")\n",
    "\n",
    "print(\"\\nTOP 10 MOST-PLAYED OPENINGS:\")\n",
    "print(player_stats_df[['opening_name', 'eco', 'num_games', 'wins', 'draws', 'losses']].head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nBOTTOM 10 LEAST-PLAYED OPENINGS:\")\n",
    "print(player_stats_df[['opening_name', 'eco', 'num_games', 'wins', 'draws', 'losses']].tail(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nVERIFICATION COMPLETE\")\n",
    "print(f\"   Player data extracted successfully for {test_player_name}\")\n",
    "print(f\"   Ready to proceed to data transformation (Step 2)\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
