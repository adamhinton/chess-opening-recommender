{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61d163cc",
   "metadata": {},
   "source": [
    "# Notebook 29 â€” Inference Pipeline: Predicting Opening Performance for New Players\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook demonstrates the complete inference pipeline for making opening recommendations to players **not** in our training set.\n",
    "We use the 1,000 holdout players (reserved in notebook 28) to validate our approach before deploying to production.\n",
    "\n",
    "**Production Use**: This pipeline will be used on the website to:\n",
    "- Fetch a player's game history from the Lichess API\n",
    "    - Note that for the testing in this notebook, we're just getting an untouched holdout player from our local DB.\n",
    "- Transform their opening statistics into model-ready features\n",
    "- Generate personalized opening recommendations\n",
    "- Display predictions with confidence scores\n",
    "\n",
    "**Development Focus**: We're building **granular, reusable functions** that can be easily adapted from local DB testing to production API integration.\n",
    "\n",
    "---\n",
    "\n",
    "## Pipeline Steps\n",
    "\n",
    "### 1. **Load Holdout Player Data**\n",
    "- Select a holdout player from the database (never seen during training)\n",
    "- Extract their complete opening statistics (wins, draws, losses per opening)\n",
    "- Retrieve player metadata (rating, name, etc.)\n",
    "- Verify data quality and completeness\n",
    "- Will use the same player every time this is run, for testing\n",
    "\n",
    "### 2. **Transform Data for Model Input**\n",
    "- Calculate raw performance scores: `(wins + 0.5 Ã— draws) / total_games`\n",
    "- Completely ignore openings not in training set\n",
    "    - We got rid of those for good reasons, not helpful/unrepresentative/too generic\n",
    "- Apply hierarchical Bayesian shrinkage toward opening-specific means\n",
    "- Normalize player rating using training set parameters (z-score)\n",
    "- Remap database IDs to training IDs (sequential 0-based indices)\n",
    "- Encode ECO codes into categorical features (letter and number)\n",
    "- Convert to PyTorch tensors\n",
    "    - player id (not sure this is needed), opening ids, eco letters and numbers, rating_z\n",
    "\n",
    "### 3. **Generate Predictions**\n",
    "- Load trained model and all required artifacts (mappings, normalization params, etc.)\n",
    "- Feed transformed data through the model\n",
    "- Generate predicted performance scores for all valid openings\n",
    "- Separate predictions into: openings player has played vs. new recommendations\n",
    "\n",
    "### 4. **Analyze and Display Results**\n",
    "- Compare predictions to actual performance (for openings player has played)\n",
    "- Rank and display top opening recommendations\n",
    "- Visualize prediction quality and confidence\n",
    "- Save predictions for later analysis\n",
    "\n",
    "---\n",
    "\n",
    "**Note**: This notebook only performs inferenceâ€”the model weights remain fixed. We are validating the deployment pipeline, not retraining.\n",
    "\n",
    "**âœ“ Resolved**: Opening statistics files (`opening_stats_white.json`, `opening_stats_black.json`) have been created via notebook 30 to support hierarchical Bayesian shrinkage. These files contain opening-specific means calculated from training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d23f689",
   "metadata": {},
   "source": [
    "## Required Model Artifacts\n",
    "\n",
    "In this notebook (and in production), we will need to load various model artifact files to help in data processing.\n",
    "\n",
    "I currently believe that we only need very small files (< 1MB total), which is very doable on the client or server.\n",
    "\n",
    "From the trained model's artifact directory, we'll need:\n",
    "\n",
    "### **Core Model & Mappings**\n",
    "- **`best_model.pt`** (8.3 MB) - Trained PyTorch model weights for inference\n",
    "  - This will live on the HuggingFace space where we host our model, so we don't need to slow down production by loading it in.\n",
    "- **Note**: Need to make sure we're using a valid player id, if any. It might have to be the next sequential player id that the model's dataset would expect? Not sure, need to investigate.\n",
    "- **`opening_id_mappings.json`** (96 KB) - Maps database opening IDs â†’ training IDs (0-based sequential)\n",
    "  - *Why*: Same as above - embeddings require contiguous indices\n",
    "\n",
    "### **Normalization & Encoding**\n",
    "- **`rating_normalization.json`** (4 KB) - Contains `rating_mean` and `rating_std` from training\n",
    "  - *Why*: Must normalize new player ratings with exact same parameters: `z = (rating - mean) / std`\n",
    "- **`eco_encodings.json`** (4 KB) - Maps ECO codes to integers (letter: A-E â†’ 0-4, numbers â†’ sequential ints)\n",
    "  - *Why*: Model expects categorical integers, not raw ECO strings like \"B02\"\n",
    "\n",
    "### **Model Configuration**\n",
    "- **`hyperparameters.json`** (4 KB) - NUM_FACTORS (40), NUM_PLAYERS, NUM_OPENINGS, embedding dimensions\n",
    "  - *Why*: Need exact architecture specs to instantiate the model correctly\n",
    "- **`model_architecture.json`** (4 KB) - Complete model structure details\n",
    "  - *Why*: Documents the model class and layer configurations\n",
    "\n",
    "### **Reference Data**\n",
    "- **`opening_mappings.csv`** (168 KB) - Full opening metadata (db_id, training_id, eco, name)\n",
    "  - *Why*: Look up opening details when displaying recommendations\n",
    "- **`holdout_players.csv`** (24 KB) - List of 1,000 holdout player IDs for testing\n",
    "  - *Why*: Select test players that were never seen during training\n",
    "\n",
    "### **âœ“ Opening Statistics for Bayesian Shrinkage**\n",
    "- **`opening_stats_white.json`** (~50-100 KB) - White opening statistics (compact format)\n",
    "- **`opening_stats_black.json`** (~50-100 KB) - Black opening statistics (compact format)\n",
    "- **`opening_stats_white.csv`** (~200-300 KB) - Human-readable CSV with full columns\n",
    "- **`opening_stats_black.csv`** (~200-300 KB) - Human-readable CSV with full columns\n",
    "  - *Why*: Required for hierarchical Bayesian shrinkage during inference\n",
    "  - *Status*: **âœ“ Created via notebook 30** (`30_create_opening_stats.ipynb`)\n",
    "  - *Structure*: JSON uses compact array format `{training_id: [opening_mean, total_games, db_id]}`\n",
    "    - Index 0: `opening_mean` - Mean score for Bayesian shrinkage (float)\n",
    "    - Index 1: `total_games` - Total games across all players (int)\n",
    "    - Index 2: `db_id` - Database opening ID for reference (int)\n",
    "  - *Usage*: Load at startup, use `opening_stats[training_id][0]` for shrinkage target\n",
    "  - *CSV*: For manual inspection, contains full columns (training_id, db_id, eco, name, opening_mean, opening_total_games, opening_num_players)\n",
    "\n",
    "---\n",
    "\n",
    "**Total artifact size**: ~1MB for all files combined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfc2a09",
   "metadata": {},
   "source": [
    "## Step 1: Load Holdout Player Data\n",
    "\n",
    "We'll:\n",
    "1. Load the holdout players list from model artifacts\n",
    "2. Select a deterministic player (using fixed index from specs)\n",
    "3. Verify they're NOT in the training set\n",
    "4. Extract their complete opening statistics from database (for specified color)\n",
    "5. Retrieve their player metadata\n",
    "6. Display everything for verification\n",
    "\n",
    "**Deterministic Selection**: Using `HOLDOUT_PLAYER_INDEX` from specs for consistency across runs.\n",
    "\n",
    "**Color**: Extracting data for the color specified in pipeline specs (White='w' or Black='b')."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61d296e",
   "metadata": {},
   "source": [
    "## Pipeline Specifications\n",
    "\n",
    "Adjustable parameters for the inference pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172cf5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PIPELINE SPECIFICATIONS - Adjust these parameters as needed\n",
    "# ============================================================================\n",
    "\n",
    "# Color to analyze ('w' for White, 'b' for Black)\n",
    "COLOR = 'w'\n",
    "\n",
    "# Deterministic player selection (which holdout player to use)\n",
    "HOLDOUT_PLAYER_INDEX = 0\n",
    "\n",
    "# Model artifacts directory name\n",
    "MODEL_DIR_NAME = \"20251212_152017_black\"\n",
    "\n",
    "# ============================================================================\n",
    "\n",
    "# Derived display values\n",
    "COLOR_NAME = \"White\" if COLOR == 'w' else \"Black\"\n",
    "\n",
    "print(\" Pipeline Specifications:\")\n",
    "print(f\"   Color: {COLOR_NAME} ('{COLOR}')\")\n",
    "print(f\"   Holdout player index: {HOLDOUT_PLAYER_INDEX}\")\n",
    "print(f\"   Model directory: {MODEL_DIR_NAME}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ab21d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Add project root to path for module imports\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from utils.database.db_utils import get_db_connection\n",
    "\n",
    "print(\"âœ“ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b278824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - paths constructed from specifications\n",
    "DB_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"chess_games.db\"\n",
    "MODEL_ARTIFACTS_DIR = PROJECT_ROOT / \"data\" / \"models\" / MODEL_DIR_NAME\n",
    "\n",
    "# Verify paths exist\n",
    "print(\" Verifying paths...\")\n",
    "print(f\"   Database: {DB_PATH.exists()} - {DB_PATH}\")\n",
    "print(f\"   Model artifacts: {MODEL_ARTIFACTS_DIR.exists()} - {MODEL_ARTIFACTS_DIR}\")\n",
    "\n",
    "if not DB_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Database not found at {DB_PATH}\")\n",
    "if not MODEL_ARTIFACTS_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Model artifacts not found at {MODEL_ARTIFACTS_DIR}\")\n",
    "\n",
    "print(\"âœ“ All paths verified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b111a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.1: Load holdout players list\n",
    "print(\"Loading holdout players...\")\n",
    "\n",
    "holdout_players_path = MODEL_ARTIFACTS_DIR / \"holdout_players.csv\"\n",
    "holdout_players_df = pd.read_csv(holdout_players_path)\n",
    "\n",
    "print(f\"   Total holdout players: {len(holdout_players_df):,}\")\n",
    "print(f\"   Columns: {list(holdout_players_df.columns)}\")\n",
    "print(f\"\\n   First 5 holdout players:\")\n",
    "print(holdout_players_df.head())\n",
    "\n",
    "# Select our test player deterministically (always use the first player)\n",
    "test_player_db_id = int(holdout_players_df.iloc[HOLDOUT_PLAYER_INDEX]['db_id'])\n",
    "test_player_name = holdout_players_df.iloc[HOLDOUT_PLAYER_INDEX]['name']\n",
    "test_player_rating = int(holdout_players_df.iloc[HOLDOUT_PLAYER_INDEX]['rating'])\n",
    "\n",
    "print(f\"\\nâœ“ Selected holdout player #{HOLDOUT_PLAYER_INDEX}:\")\n",
    "print(f\"   Database ID: {test_player_db_id}\")\n",
    "print(f\"   Name: {test_player_name}\")\n",
    "print(f\"   Rating: {test_player_rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda4ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.2: Verify player is NOT in training set\n",
    "print(\"Verifying player is not in training set...\")\n",
    "\n",
    "player_mappings_path = MODEL_ARTIFACTS_DIR / \"player_mappings.csv\"\n",
    "player_mappings_df = pd.read_csv(player_mappings_path)\n",
    "\n",
    "print(f\"   Total training players: {len(player_mappings_df):,}\")\n",
    "print(f\"   Columns: {list(player_mappings_df.columns)}\")\n",
    "\n",
    "# Check if our test player is in the training set\n",
    "is_in_training = test_player_db_id in player_mappings_df['db_id'].values\n",
    "\n",
    "if is_in_training:\n",
    "    raise ValueError(\n",
    "        f\"âŒ ERROR: Player {test_player_name} (ID: {test_player_db_id}) \"\n",
    "        f\"is in the training set! They should be a holdout player.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd9ea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.3: Extract player's opening statistics and create PlayerData object\n",
    "print(f\" Extracting {COLOR_NAME} opening statistics for {test_player_name}...\")\n",
    "\n",
    "from utils.foldin_data_processing.types import PlayerData\n",
    "\n",
    "conn = get_db_connection(DB_PATH)\n",
    "\n",
    "# Query returns data matching OpeningStatsRow schema\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    pos.player_id,\n",
    "    pos.opening_id,\n",
    "    o.eco,\n",
    "    o.name as opening_name,\n",
    "    pos.num_wins + pos.num_draws + pos.num_losses as num_games,\n",
    "    pos.num_wins,\n",
    "    pos.num_draws,\n",
    "    pos.num_losses\n",
    "FROM player_opening_stats pos\n",
    "JOIN opening o ON pos.opening_id = o.id\n",
    "WHERE pos.player_id = ?\n",
    "  AND pos.color = ?\n",
    "  AND (pos.num_wins + pos.num_draws + pos.num_losses) > 0\n",
    "ORDER BY (pos.num_wins + pos.num_draws + pos.num_losses) DESC\n",
    "\"\"\"\n",
    "\n",
    "# Execute query and get DataFrame conforming to OpeningStatsRow schema\n",
    "opening_stats_df = conn.execute(query, [int(test_player_db_id), COLOR]).df()\n",
    "conn.close()\n",
    "\n",
    "# Immediately wrap in PlayerData object\n",
    "player_data = PlayerData(\n",
    "    player_id=test_player_db_id,\n",
    "    name=test_player_name,\n",
    "    rating=test_player_rating,\n",
    "    color=COLOR,\n",
    "    opening_stats_df=opening_stats_df\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Database query complete\")\n",
    "print(f\"   Total openings played: {len(player_data.opening_stats_df)}\")\n",
    "print(f\"   Total games: {player_data.total_games():,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90502146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.4: Display complete player data for verification\n",
    "print(\"=\"*80)\n",
    "print(f\"DATA FOR TEST PLAYER: {test_player_name} ({COLOR_NAME})\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n PLAYER METADATA:\")\n",
    "print(f\"   Database ID: {test_player_db_id}\")\n",
    "print(f\"   Name: {test_player_name}\")\n",
    "print(f\"   Rating: {test_player_rating}\")\n",
    "print(f\"   Color: {COLOR_NAME}\")\n",
    "print(f\"   Status: HOLDOUT PLAYER (not in training set)\")\n",
    "\n",
    "print(f\"\\n {COLOR_NAME.upper()} OPENING STATISTICS SUMMARY:\")\n",
    "print(f\"   Total openings played: {len(player_data.opening_stats_df)}\")\n",
    "print(f\"   Total games: {player_data.total_games():,}\")\n",
    "print(f\"   Total wins: {player_data.total_wins()}\")\n",
    "print(f\"   Total draws: {player_data.opening_stats_df['num_draws'].sum()}\")\n",
    "print(f\"   Total losses: {player_data.opening_stats_df['num_losses'].sum()}\")\n",
    "print(f\"   Overall win rate: {player_data.total_wins() / player_data.total_games():.1%}\")\n",
    "\n",
    "print(f\"\\n TOP 5 MOST-PLAYED {COLOR_NAME.upper()} OPENINGS:\")\n",
    "print(player_data.opening_stats_df[['opening_name', 'eco', 'num_games', 'num_wins', 'num_draws', 'num_losses']].head(5).to_string(index=False))\n",
    "\n",
    "print(f\"\\n {COLOR_NAME} opening data extracted successfully for {test_player_name}\")\n",
    "print(f\"   Ready to proceed to data transformation (Step 2)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe248fa8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# STEP 2: Transform Player Data for Model Inference\n",
    "\n",
    "This is the HEART of the production system. Every time a player visits the website, I'll:\n",
    "1. Download their games from Lichess API\n",
    "2. Process them through the pipeline below\n",
    "3. Send the result to HuggingFace for fold-in inference\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Transform raw player opening statistics into model-ready tensors that can be sent directly to HuggingFace.\n",
    "\n",
    "**Key Principle**: This transformation must be IDENTICAL whether data comes from:\n",
    "- Local DB (for notebook testing)\n",
    "- Lichess API (for production)\n",
    "\n",
    "---\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "PlayerData (from Step 1)\n",
    "    |\n",
    "    v\n",
    "[2.1] Define Type System\n",
    "    |\n",
    "    v\n",
    "[2.2] Load Model Artifacts (once at startup)\n",
    "    |\n",
    "    v\n",
    "[2.3] Filter & Validate Openings\n",
    "    |\n",
    "    v\n",
    "[2.4] Calculate Raw Scores\n",
    "    |\n",
    "    v\n",
    "[2.5] Apply Bayesian Shrinkage\n",
    "    |\n",
    "    v\n",
    "[2.6] Normalize Rating\n",
    "    |\n",
    "    v\n",
    "[2.7] Remap Database IDs -> Training IDs\n",
    "    |\n",
    "    v\n",
    "[2.8] Encode ECO Features\n",
    "    |\n",
    "    v\n",
    "[2.9] Convert to NumPy Arrays\n",
    "    |\n",
    "    v\n",
    "ModelInput -> HuggingFace API\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Implementation Steps\n",
    "\n",
    "### 2.1: Define Type System\n",
    "\n",
    "#### ACCOMPLISHED: Defined these types and stored them in notebooks/utils/foldin_data_processing/types.py\n",
    "\n",
    "**Goal**: Create strongly-typed dataclasses for all data structures\n",
    "\n",
    "**What I'll build**:\n",
    "- `RawOpeningStats`: Input from Step 1 (database/API)\n",
    "- `PlayerData`: Complete player profile\n",
    "- `ProcessedOpening`: After transformations\n",
    "- `ModelInput`: Final structure for HuggingFace\n",
    "\n",
    "**Why this matters**:\n",
    "- Catch type errors at development time\n",
    "- Self-documenting code\n",
    "- IDE autocomplete and type checking\n",
    "- Makes data flow crystal clear\n",
    "\n",
    "**Outputs**: Python dataclasses with type hints and docstrings\n",
    "\n",
    "---\n",
    "\n",
    "### 2.2: Load Model Artifacts\n",
    "\n",
    "**Goal**: Load all training artifacts into memory for fast lookup\n",
    "\n",
    "**Note that I will revisit this once I'm more sure what I need to load and when**\n",
    "\n",
    "**Required artifacts** (from training notebook 28):\n",
    "1. `opening_mappings.csv` - Database IDs to Training IDs\n",
    "2. `rating_normalization.json` - Rating mean/std\n",
    "3. `eco_encodings.json` - ECO letter/number mappings\n",
    "4. `opening_stats.json` - NEED TO CREATE THIS\n",
    "\n",
    "**Data structures to build**:\n",
    "- `valid_training_ids: Set[int]` - O(1) lookup for filtering\n",
    "- `db_to_training_id: Dict[int, int]` - O(1) ID remapping\n",
    "- `opening_means: Dict[int, float]` - Bayesian shrinkage targets\n",
    "- `eco_letter_map: Dict[str, int]` - ECO letter encoding\n",
    "- `eco_number_map: Dict[str, int]` - ECO number encoding\n",
    "\n",
    "**Critical**: Load ONCE at startup, cache in production\n",
    "\n",
    "**Outputs**: Dictionary of all artifacts plus fast lookup structures\n",
    "\n",
    "---\n",
    "\n",
    "### 2.3: Filter & Validate Openings\n",
    "\n",
    "**Goal**: Remove openings not in training set or below threshold\n",
    "\n",
    "**Filtering criteria**:\n",
    "1. Opening must be in training set (check against `valid_training_ids`)\n",
    "2. Player must have played >= `MIN_GAMES_THRESHOLD` with this opening (default: 10)\n",
    "\n",
    "**Edge case handling**:\n",
    "- What if player has 0 valid openings after filtering? -> Raise `ValueError`\n",
    "- What if opening ID not in mapping? -> Skip silently (expected)\n",
    "\n",
    "**Efficiency**: Use Set for O(1) membership testing\n",
    "\n",
    "**Outputs**: Filtered list of `RawOpeningStats`\n",
    "\n",
    "---\n",
    "\n",
    "### 2.4: Calculate Raw Scores\n",
    "\n",
    "**Goal**: Convert W/D/L to performance scores\n",
    "\n",
    "**Formula**: \n",
    "```\n",
    "raw_score = (wins + 0.5 * draws) / total_games\n",
    "```\n",
    "\n",
    "**Validation**:\n",
    "- Score must be in range [0.0, 1.0]\n",
    "- Handle edge case where `num_games = 0` (shouldn't happen after filtering)\n",
    "\n",
    "**Outputs**: Add `raw_score` property to each opening\n",
    "\n",
    "---\n",
    "\n",
    "### 2.5: Apply Bayesian Shrinkage\n",
    "\n",
    "**Goal**: Adjust scores toward opening-specific means (hierarchical Bayesian)\n",
    "\n",
    "**Formula**:\n",
    "```\n",
    "adjusted_score = (num_games * raw_score + k * opening_mean) / (num_games + k)\n",
    "confidence = num_games / (num_games + k)\n",
    "```\n",
    "\n",
    "**Constants** (must match training):\n",
    "- `k = 50` (shrinkage strength)\n",
    "- `opening_mean` from `opening_stats.json` (keyed by training_id, not db_id!)\n",
    "\n",
    "**Why this matters**:\n",
    "- Prevents overfitting to small sample sizes\n",
    "- Makes inference consistent with training\n",
    "- Different openings have different baseline win rates\n",
    "\n",
    "**Critical**: Use opening-specific means, NOT global mean\n",
    "\n",
    "**Outputs**: `ProcessedOpening` objects with `adjusted_score` and `confidence`\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ“Š Opening Stats Files Documentation\n",
    "\n",
    "The opening statistics files were created in **notebook 30** (`30_create_opening_stats.ipynb`) to support hierarchical Bayesian shrinkage during inference.\n",
    "\n",
    "**Files created for each color**:\n",
    "- `opening_stats_{color}.json` - Compact format for production (~50-100 KB per color)\n",
    "- `opening_stats_{color}.csv` - Human-readable format for inspection (~200-300 KB per color)\n",
    "\n",
    "**JSON Structure (Compact Array Format)**:\n",
    "```json\n",
    "{\n",
    "  \"training_id\": [opening_mean, total_games, db_id],\n",
    "  \"0\": [0.5234, 15847, 123],\n",
    "  \"1\": [0.4891, 8932, 456],\n",
    "  ...\n",
    "}\n",
    "```\n",
    "\n",
    "**Array indices**:\n",
    "- `[0]`: `opening_mean` (float) - Mean score for this opening across all training players. Use this for Bayesian shrinkage.\n",
    "- `[1]`: `total_games` (int) - Total games played with this opening across all players.\n",
    "- `[2]`: `db_id` (int) - Original database opening ID (for reference/debugging).\n",
    "\n",
    "**Usage in Step 2.5**:\n",
    "```python\n",
    "# Load at startup (once)\n",
    "with open(f'opening_stats_{color}.json', 'r') as f:\n",
    "    opening_stats = json.load(f)\n",
    "\n",
    "# During shrinkage (per opening)\n",
    "training_id = db_to_training_id[opening_db_id]\n",
    "opening_mean = opening_stats[str(training_id)][0]  # JSON keys are strings\n",
    "adjusted_score = (num_games * raw_score + k * opening_mean) / (num_games + k)\n",
    "```\n",
    "\n",
    "**CSV Structure** (for manual inspection):\n",
    "- Columns: `training_id`, `db_id`, `opening_id`, `eco`, `name`, `opening_mean`, `opening_total_games`, `opening_num_players`\n",
    "- Sorted by training_id for easy lookup\n",
    "- Contains full opening names and ECO codes for human readability\n",
    "\n",
    "**Data Source**:\n",
    "- Aggregated from `player_opening_stats` table in training database\n",
    "- Filtered to openings with â‰¥10 games per player (same threshold as training)\n",
    "- Calculated as: `mean((wins + 0.5 * draws) / total_games)` across all players\n",
    "\n",
    "**Why compact format?**:\n",
    "- Original verbose dict format was ~500 KB (too large for production)\n",
    "- Compact array format reduces size to ~50-100 KB per color\n",
    "- Faster to load and parse in production environment\n",
    "- Keys are training IDs (not db IDs) for O(1) lookup during inference\n",
    "\n",
    "---\n",
    "\n",
    "### 2.6: Normalize Rating\n",
    "\n",
    "**Goal**: Z-score normalize player rating\n",
    "\n",
    "**Formula**:\n",
    "```\n",
    "rating_z = (rating - RATING_MEAN) / RATING_STD\n",
    "```\n",
    "\n",
    "**Constants from artifacts**:\n",
    "- `RATING_MEAN` and `RATING_STD` from `rating_normalization.json`\n",
    "\n",
    "**Why this matters**:\n",
    "- Model was trained on normalized ratings\n",
    "- Keeps all features on similar scales\n",
    "\n",
    "**Outputs**: Single float `rating_z`\n",
    "\n",
    "---\n",
    "\n",
    "### 2.7: Remap Opening IDs\n",
    "\n",
    "**Goal**: Convert database IDs to training IDs (0-based sequential)\n",
    "\n",
    "**Why this is necessary**:\n",
    "- Database IDs are arbitrary (10, 15, 23, ...)\n",
    "- Model embedding layers expect 0-based sequential IDs (0, 1, 2, ...)\n",
    "- Training created this mapping during preprocessing\n",
    "\n",
    "**Lookup**: Use `db_to_training_id` dictionary (O(1))\n",
    "\n",
    "**Validation**: Ensure all remapped IDs are in valid range [0, num_openings)\n",
    "\n",
    "**Outputs**: Update `training_opening_id` in each `ProcessedOpening`\n",
    "\n",
    "---\n",
    "\n",
    "### 2.8: Encode ECO Features\n",
    "\n",
    "**Goal**: Convert ECO strings to categorical integers\n",
    "\n",
    "**ECO structure**: \"C21\" -> letter (\"C\") + number (\"21\")\n",
    "\n",
    "**Encoding**:\n",
    "- `eco_letter_cat`: \"A\"->0, \"B\"->1, \"C\"->2, \"D\"->3, \"E\"->4\n",
    "- `eco_number_cat`: \"00\"->0, \"01\"->1, ..., \"99\"->99 (sequential)\n",
    "\n",
    "**Edge case**: What if ECO not in mapping? -> Log warning, use default value\n",
    "\n",
    "**Why this matters**:\n",
    "- Model learns patterns by ECO category (e.g., all \"C\" openings share features)\n",
    "- Categorical encoding is more efficient than one-hot\n",
    "\n",
    "**Outputs**: Add `eco_letter_cat` and `eco_number_cat` to each `ProcessedOpening`\n",
    "\n",
    "---\n",
    "\n",
    "### 2.9: Build ModelInput Structure\n",
    "\n",
    "**Goal**: Convert processed openings to NumPy arrays for HuggingFace\n",
    "\n",
    "**Output structure**:\n",
    "```python\n",
    "ModelInput(\n",
    "    player_name: str,\n",
    "    rating_z: float,\n",
    "    color: str,\n",
    "    opening_ids: np.ndarray,      # shape (N,), dtype int64\n",
    "    eco_letter_cats: np.ndarray,  # shape (N,), dtype int64\n",
    "    eco_number_cats: np.ndarray,  # shape (N,), dtype int64\n",
    "    scores: np.ndarray,           # shape (N,), dtype float32\n",
    "    confidence: np.ndarray,       # shape (N,), dtype float32\n",
    "    opening_names: List[str],     # for display\n",
    "    num_openings_filtered: int,   # metadata\n",
    "    total_games: int              # metadata\n",
    ")\n",
    "```\n",
    "\n",
    "**Methods**:\n",
    "- `to_json_dict()` -> JSON for HuggingFace API\n",
    "- `to_tensors()` -> PyTorch tensors for local testing\n",
    "\n",
    "**Why NumPy not PyTorch**: \n",
    "- NumPy serializes to JSON easily\n",
    "- HuggingFace endpoint will convert to tensors on its side\n",
    "\n",
    "**Outputs**: Ready-to-send `ModelInput` object\n",
    "\n",
    "---\n",
    "\n",
    "### 2.10: Main Transformation Function\n",
    "\n",
    "**Goal**: Orchestrate all chunks into one reusable function\n",
    "\n",
    "**Signature**:\n",
    "```python\n",
    "def transform_player_for_inference(\n",
    "    player_data: PlayerData,\n",
    "    model_artifacts: Dict,\n",
    "    min_games_threshold: int = 10,\n",
    "    k_shrinkage: int = 50\n",
    ") -> ModelInput:\n",
    "    \"\"\"Production-ready transformation function.\"\"\"\n",
    "```\n",
    "\n",
    "**This function is the PUBLIC API** - it's what will be called in production\n",
    "\n",
    "**Error handling**:\n",
    "- Raise `ValueError` if no valid openings\n",
    "- Raise `FileNotFoundError` if artifacts missing\n",
    "- Log warnings for edge cases\n",
    "\n",
    "**Outputs**: Single `ModelInput` object ready for inference\n",
    "\n",
    "---\n",
    "\n",
    "### 2.11: Test & Validate\n",
    "\n",
    "**Goal**: Verify transformation on holdout player\n",
    "\n",
    "**Tests**:\n",
    "1. Run transformation on test player from Step 1\n",
    "2. Check ID ranges (0 <= opening_id < num_openings)\n",
    "3. Verify scores in [0, 1]\n",
    "4. Confirm ECO encodings are valid\n",
    "5. Validate rating normalization\n",
    "6. Check JSON serialization works\n",
    "7. Compare with training data format\n",
    "\n",
    "**Edge cases to test**:\n",
    "- Player with many openings\n",
    "- Player with few openings\n",
    "- Player near MIN_GAMES_THRESHOLD\n",
    "- High/low rated players\n",
    "\n",
    "**Outputs**: Validated `ModelInput` plus test results\n",
    "\n",
    "---\n",
    "\n",
    "## Critical Notes\n",
    "\n",
    "### ID Systems - PAY ATTENTION\n",
    "\n",
    "- **Database IDs**: What's in the DB and Lichess API (arbitrary integers)\n",
    "- **Training IDs**: 0-based sequential IDs used by model (0, 1, 2, ...)\n",
    "- **Transformation happens in 2.7**\n",
    "\n",
    "### Bayesian Shrinkage - MUST MATCH TRAINING\n",
    "\n",
    "- Training used opening-specific means (hierarchical)\n",
    "- Inference MUST use the same approach\n",
    "- Requires `opening_stats.json` (keyed by training_id)\n",
    "\n",
    "### Production vs Testing\n",
    "\n",
    "- Testing: Data from local DB (Step 1)\n",
    "- Production: Data from Lichess API (future code)\n",
    "- Transformation is IDENTICAL - that's the whole point\n",
    "\n",
    "### Performance Optimization\n",
    "\n",
    "- Load artifacts ONCE at startup\n",
    "- Use Sets for O(1) membership testing\n",
    "- Use Dicts for O(1) ID remapping\n",
    "- Vectorize NumPy operations (no loops)\n",
    "\n",
    "---\n",
    "\n",
    "## Before Starting Coding Checklist\n",
    "\n",
    "- [ ] Do I have all 4 artifact files?\n",
    "  - [ ] `opening_mappings.csv`\n",
    "  - [ ] `rating_normalization.json`\n",
    "  - [ ] `eco_encodings.json`\n",
    "  - [ ] `opening_stats.json` (NEED TO CREATE)\n",
    "\n",
    "- [ ] Have I reviewed the training preprocessing to match exactly?\n",
    "- [ ] Do I understand the ID remapping workflow?\n",
    "- [ ] Am I clear on hierarchical vs global Bayesian shrinkage?\n",
    "\n",
    "---\n",
    "\n",
    "## Success Criteria\n",
    "\n",
    "Step 2 is complete when:\n",
    "1. All type definitions are complete and well-documented\n",
    "2. All artifacts load successfully\n",
    "3. Transformation function runs without errors\n",
    "4. Output structure matches HuggingFace API expectations\n",
    "5. All validation checks pass\n",
    "6. Edge cases are handled gracefully\n",
    "7. Code is production-ready and reusable\n",
    "\n",
    "---\n",
    "\n",
    "Ready to implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9cd5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Define Tpes, Classes and Data Structures\n",
    "\n",
    "# We've done that in notebooks/utils/foldin_data_processing/types.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e7258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Load model artifacts\n",
    "# Placeholder: Will flesh this out more once we're sure what we need and when\n",
    "\n",
    "# Load artefacts here, not in individual cells below\n",
    "\n",
    "opening_mappings_df = pd.read_csv(MODEL_ARTIFACTS_DIR / \"opening_mappings.csv\")\n",
    "valid_training_opening_ids = set(opening_mappings_df[\"db_id\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1cc245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757a233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Filter and Validate Openings\n",
    "\n",
    "# I axed certain openings from the training data because they were unrepresentative, had weird scores, low sample size, etc\n",
    "\n",
    "# Resultingly, this pipeline will completely ignore those openings when making recommendations. This cell filters them out.\n",
    "\n",
    "\n",
    "def filter_valid_openings(\n",
    "    player_data: PlayerData,\n",
    "    valid_opening_local_db_ids: set[int],\n",
    "    min_num_games_threshold: int = 10,\n",
    ") -> PlayerData:\n",
    "    \"\"\"\n",
    "    Filter player's opening statistics to only include openings\n",
    "    that exist in the training set and meet minimum game threshold.\n",
    "\n",
    "    Args:\n",
    "        player_data: Complete player profile from Step 1\n",
    "        valid_opening_local_db_ids: Set of database opening IDs from training\n",
    "        min_num_games_threshold: Minimum games required per opening (default: 10)\n",
    "\n",
    "    Returns:\n",
    "        New PlayerData object with filtered opening_stats_df\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If no valid openings remain after filtering\n",
    "\n",
    "    Example:\n",
    "        >>> filtered_data = filter_valid_openings(player_data, valid_ids, min_num_games_threshold=10)\n",
    "        >>> print(f\"Kept {len(filtered_data.opening_stats_df)} / {len(player_data.opening_stats_df)} openings\")\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"STEP 2.3: Filtering Valid Openings\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    original_df = player_data.opening_stats_df\n",
    "    print(f\"\\nOriginal data:\")\n",
    "    print(f\"   Total openings: {len(original_df)}\")\n",
    "    print(f\"   Total games: {original_df['num_games'].sum():,}\")\n",
    "    print(f\"   Training set size: {len(valid_opening_local_db_ids):,} openings\")\n",
    "\n",
    "    # Filter 1: Opening must be in training set (O(1) lookup with set)\n",
    "    print(f\"\\nFilter 1: Must be in training set...\")\n",
    "    in_training_mask = original_df[\"opening_id\"].isin(valid_opening_local_db_ids)\n",
    "    after_training_filter = original_df[in_training_mask].copy()\n",
    "\n",
    "    dropped_not_in_training = len(original_df) - len(after_training_filter)\n",
    "    print(f\"   Kept: {len(after_training_filter)} openings\")\n",
    "    print(f\"   Dropped: {dropped_not_in_training} openings (not in training set)\")\n",
    "\n",
    "    if dropped_not_in_training > 0:\n",
    "        dropped_games = original_df[~in_training_mask][\"num_games\"].sum()\n",
    "        print(\n",
    "            f\"   Games in dropped openings: {dropped_games:,} ({dropped_games / original_df['num_games'].sum():.1%} of total)\"\n",
    "        )\n",
    "\n",
    "    # Filter 2: Must have minimum games\n",
    "    print(f\"\\nFilter 2: Must have >= {min_num_games_threshold} games...\")\n",
    "    games_mask = after_training_filter[\"num_games\"] >= min_num_games_threshold\n",
    "    filtered_df = after_training_filter[games_mask].copy()\n",
    "\n",
    "    dropped_low_games = len(after_training_filter) - len(filtered_df)\n",
    "    print(f\"   Kept: {len(filtered_df)} openings\")\n",
    "    print(f\"   Dropped: {dropped_low_games} openings (< {min_num_games_threshold} games)\")\n",
    "\n",
    "    if dropped_low_games > 0:\n",
    "        dropped_games = after_training_filter[~games_mask][\"num_games\"].sum()\n",
    "        print(f\"   Games in dropped openings: {dropped_games:,}\")\n",
    "\n",
    "    # Validation: Must have at least one opening remaining\n",
    "    if len(filtered_df) == 0:\n",
    "        total_dropped = dropped_not_in_training + dropped_low_games\n",
    "        raise ValueError(\n",
    "            f\"No valid openings remaining for player {player_data.name}!\\n\"\n",
    "            f\"   Original openings: {len(original_df)}\\n\"\n",
    "            f\"   Dropped (not in training): {dropped_not_in_training}\\n\"\n",
    "            f\"   Dropped (< {min_num_games_threshold} games): {dropped_low_games}\\n\"\n",
    "            f\"   Remaining: 0\\n\"\n",
    "            f\"Cannot make recommendations for this player.\"\n",
    "        )\n",
    "\n",
    "    # Create new PlayerData with filtered DataFrame\n",
    "    filtered_player_data = PlayerData(\n",
    "        player_id=player_data.player_id,\n",
    "        name=player_data.name,\n",
    "        rating=player_data.rating,\n",
    "        color=player_data.color,\n",
    "        opening_stats_df=filtered_df,\n",
    "    )\n",
    "\n",
    "    # Summary statistics\n",
    "    print(f\"\\nâœ“ Filtering complete:\")\n",
    "    print(\n",
    "        f\"   Final openings: {len(filtered_df)} ({len(filtered_df) / len(original_df):.1%} of original)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   Final games: {filtered_df['num_games'].sum():,} ({filtered_df['num_games'].sum() / original_df['num_games'].sum():.1%} of original)\"\n",
    "    )\n",
    "    print(f\"   Total dropped: {dropped_not_in_training + dropped_low_games} openings\")\n",
    "\n",
    "    # Show sample of kept openings\n",
    "    print(f\"\\n   Top 5 kept openings (by games):\")\n",
    "    top_5 = filtered_df.nlargest(5, \"num_games\")[[\"opening_name\", \"eco\", \"num_games\"]]\n",
    "    for idx, row in top_5.iterrows():\n",
    "        print(\n",
    "            f\"      {row['eco']:>3} | {row['opening_name']:<50} | {row['num_games']:>4} games\"\n",
    "        )\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    return filtered_player_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5642c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_valid_openings(\n",
    "    player_data,\n",
    "    valid_opening_local_db_ids=valid_training_opening_ids,\n",
    "    min_num_games_threshold=3,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
