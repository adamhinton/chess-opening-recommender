{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ecceed8",
   "metadata": {},
   "source": [
    "# Downloading Experiments\n",
    "\n",
    "This notebook is a proof of concept\n",
    "\n",
    "Right now, we have some flaws in our raw data download system. We want to make sure we get this right because we will be downloading and processing hundreds or thousands of GBs of raw data parquet files.\n",
    "\n",
    "So, we'll be messing around here with some implementations, and if they work, we'll be replacing parts of our original code with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5bdd03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install huggingface_hub --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dd6cc3",
   "metadata": {},
   "source": [
    "## Getting file names\n",
    "\n",
    "We want to use file names and other meta data to do dupe checks of what we've already processed, and see what we still need to download from a certain month. Let's run this code that gets all file names from the repo, to see what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82d1ccb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 files found for 2025-03\n",
      "data/year=2025/month=03/train-00000-of-00069.parquet\n",
      "data/year=2025/month=03/train-00001-of-00069.parquet\n",
      "data/year=2025/month=03/train-00002-of-00069.parquet\n",
      "data/year=2025/month=03/train-00003-of-00069.parquet\n",
      "data/year=2025/month=03/train-00004-of-00069.parquet\n",
      "data/year=2025/month=03/train-00005-of-00069.parquet\n",
      "data/year=2025/month=03/train-00006-of-00069.parquet\n",
      "data/year=2025/month=03/train-00007-of-00069.parquet\n",
      "data/year=2025/month=03/train-00008-of-00069.parquet\n",
      "data/year=2025/month=03/train-00009-of-00069.parquet\n",
      "data/year=2025/month=03/train-00010-of-00069.parquet\n",
      "data/year=2025/month=03/train-00011-of-00069.parquet\n",
      "data/year=2025/month=03/train-00012-of-00069.parquet\n",
      "data/year=2025/month=03/train-00013-of-00069.parquet\n",
      "data/year=2025/month=03/train-00014-of-00069.parquet\n",
      "data/year=2025/month=03/train-00015-of-00069.parquet\n",
      "data/year=2025/month=03/train-00016-of-00069.parquet\n",
      "data/year=2025/month=03/train-00017-of-00069.parquet\n",
      "data/year=2025/month=03/train-00018-of-00069.parquet\n",
      "data/year=2025/month=03/train-00019-of-00069.parquet\n"
     ]
    }
   ],
   "source": [
    "# Here we get a list of raw data files for the given month/year\n",
    "\n",
    "# File names in the remote repo are structured like:\n",
    "# data/year=2025/month=03/train-00001-of-00065.parquet\n",
    "# Obviously, there will be different amounts of them so it won't always be -00065.parquet\n",
    "\n",
    "from huggingface_hub import HfApi\n",
    "from pathlib import Path\n",
    "\n",
    "year = \"2025\"\n",
    "month = \"03\"  # <-- type manually\n",
    "\n",
    "api = HfApi()\n",
    "files = api.list_repo_files(\n",
    "    repo_id=\"Lichess/standard-chess-games\",\n",
    "    repo_type=\"dataset\"\n",
    ")\n",
    "\n",
    "# Filter for that year/month\n",
    "target_prefix = f\"data/year={year}/month={month}/\"\n",
    "all_file_names_in_month = [f for f in files if f.startswith(target_prefix)]\n",
    "\n",
    "print(len(all_file_names_in_month), f\"files found for {year}-{month}\")\n",
    "for f in all_file_names_in_month[:20]:  # preview first 20\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a3554f",
   "metadata": {},
   "source": [
    "## Dupe checks\n",
    "\n",
    "Now that we have the list of raw data file names for the given month and year, we'll perform our dupe checks. This parses through the list of file names to make sure we haven't already processed any of these files.\n",
    "\n",
    "Each file is a 1GB download, so it's obviously in our best interest not to download a file we've already processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d358efb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 new files to download\n"
     ]
    }
   ],
   "source": [
    "# Parse the list of raw data file names to make sure we haven't already processed any of these files, and skip downloading any dupes\n",
    "\n",
    "from huggingface_hub import get_hf_file_metadata, hf_hub_url\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current working directory (should be project root)\n",
    "project_root = Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from utils.file_processing.raw_data_file_dupe_checks import FileRegistry  # noqa: E402\n",
    "\n",
    "# Init registry\n",
    "registry = FileRegistry()\n",
    "\n",
    "# Remove files already processed\n",
    "non_dupe_files = []\n",
    "for f in all_file_names_in_month:\n",
    "    url = hf_hub_url(\n",
    "        repo_id=\"Lichess/standard-chess-games\",\n",
    "        repo_type=\"dataset\",\n",
    "        filename=f,\n",
    "    )\n",
    "    meta = get_hf_file_metadata(url=url)\n",
    "    size = meta.size\n",
    "    etag = meta.etag\n",
    "    if not registry.is_file_processed(f\"{year}-{month}\", Path(f).name, size, etag):\n",
    "        non_dupe_files.append(f)\n",
    "\n",
    "print(len(non_dupe_files), \"new files to download\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a040c3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to ../data/raw/better_downloading_experiments/2025-03-train-00000-of-00069.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "year, month = 2025, 3\n",
    "max_files_to_download = 1  # for testing; set to None to download all\n",
    "file_names_to_download = all_file_names_in_month[:max_files_to_download]\n",
    "\n",
    "local_dir = Path(\"../data/raw/better_downloading_experiments\")\n",
    "local_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for file_to_download in file_names_to_download:\n",
    "    # Download (HF handles caching)\n",
    "    downloaded_path = hf_hub_download(\n",
    "        repo_id=\"Lichess/standard-chess-games\",\n",
    "        repo_type=\"dataset\",\n",
    "        filename=file_to_download,\n",
    "    )\n",
    "\n",
    "    # Rename with prefix and move to flat folder\n",
    "    # HF sends it to me in a nested file structure; but we don't want that so here we reoganize it to the file structure we want locally\n",
    "\n",
    "    # Prefixing file name with year and month\n",
    "    # The file will be deleted immediately after processing, but this could still be helpful for debugging\n",
    "    target_filename = f\"{year}-{month:02d}-{Path(file_to_download).name}\"\n",
    "    target_path = local_dir / target_filename\n",
    "    shutil.copy(\n",
    "        downloaded_path, target_path\n",
    "    )  # or move() if you want to remove original\n",
    "    print(f\"File saved to {target_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
