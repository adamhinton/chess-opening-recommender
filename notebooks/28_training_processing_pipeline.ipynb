{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40e163a7",
   "metadata": {},
   "source": [
    "# Notebook 26 ‚Äî Opening Recommender Model: Training Pipeline\n",
    "\n",
    "### 0. Overview and Goals\n",
    "\n",
    "This notebook defines the full pipeline for training the chess opening recommender model.  \n",
    "The objective is to predict **player‚Äìopening performance scores** ((wins + (0.5 * draws) / num games)) for openings a player hasn‚Äôt yet played, based on their results in the openings they *have* played.  \n",
    "\n",
    "The model will use **matrix factorization** with **stochastic gradient descent (SGD)** to learn latent factors representing player and opening characteristics.  \n",
    "All computations will be implemented in **PyTorch**, with data loaded from my local **DuckDB** database.\n",
    "\n",
    "**High-level specs:**\n",
    "- Use only *White* openings initially (we‚Äôll extend to Black later).  \n",
    "- Data source: processed player‚Äìopening stats from local DuckDB.  \n",
    "- Predict: normalized ‚Äúscore‚Äù = win rate ((wins + 0.5 x draws) / total games).  \n",
    "- Filter: only include entries with ‚â• `MIN_GAMES_THRESHOLD` (default = 50).  \n",
    "- Ignore: rating differences, time controls, and other metadata.  \n",
    "- Model parameters (to be defined in appropriate places for easy editing):  \n",
    "  - `NUM_FACTORS`, `LEARNING_RATE`, `BATCH_SIZE`, `N_EPOCHS`, `NUM_PLAYERS_TO_PROCESS`  \n",
    "- Logging and checkpoints throughout for reproducibility.  \n",
    "- All random operations seeded for deterministic runs.  \n",
    "\n",
    "---\n",
    "\n",
    "### 1. Data Extraction\n",
    "- Connect to local DuckDB\n",
    "- Pull all processed player‚Äìopening statistics from\n",
    "- Verify schema consistency:  \n",
    "  - Required columns: `player_id`, `opening_id`, `eco`, `num_games`, `wins`, `draws`, `losses`.  \n",
    "- Include a row-count sanity check.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Data Sanitization & Normalization\n",
    "- Optionally normalize scores if needed for MF convergence.  \n",
    "- Drop players with no qualifying openings and openings with no qualifying players.  \n",
    "  - I believe there shouldn't be any but we'll double check.\n",
    "- Resequence player_id and opening_id to be sequential integers - right now there are gaps because of entries we deleted from the DB \n",
    "- Check for sparsity consistency (no implicit zeros yet).  \n",
    "- Note that this data has already been split in to white and black games further up the pipeline\n",
    "\n",
    "### Data Quality\n",
    "- Drop entries with fewer than `MIN_GAMES_THRESHOLD` games\n",
    "- Handle any duplicate `(player_id, opening_id)` combinations\n",
    "- Remove players with no qualifying openings\n",
    "- Remove openings with no qualifying players\n",
    "- Verify no null values remain\n",
    "\n",
    "### ECO Codes\n",
    "- Keep ECO codes for later categorical encoding (Step 4)\n",
    "- ECO will be used as opening side information (similar to rating for players)\n",
    "\n",
    "### Confidence Weighting\n",
    "- Use `MIN_GAMES_THRESHOLD = 10` to keep more data\n",
    "- Add a **confidence weight** column: `confidence = num_games / (num_games + K)` where K ‚âà 50\n",
    "- This weight will be used in the loss function to down-weight uncertain predictions\n",
    "- High-game-count entries ‚Üí high confidence ‚Üí larger loss impact\n",
    "- Low-game-count entries ‚Üí low confidence ‚Üí smaller loss impact\n",
    "\n",
    "### Player Rating (Side Information)\n",
    "- **Player ratings are side information** - they describe player characteristics, not individual player-opening interactions\n",
    "- Ratings will be stored separately and joined to player embeddings during training\n",
    "- We'll **normalize ratings** (likely z-score normalization) to avoid scaling issues with the embedding layer\n",
    "- Rating normalization will be done once after extraction, not per-row\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Data Splits\n",
    "- Split into train/test/val sets.  \n",
    "- Ensure every player and every opening appears at least once in the training data.  \n",
    "- Strategy:  \n",
    "  - Sample unique players and openings to guarantee coverage in train.  \n",
    "  - Remaining data ‚Üí stratified random split into train/test.  \n",
    "  - Deduplicate and merge unique IDs back into train if needed.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Enumerate Categorical Variables\n",
    "- Enumerate `eco` (if included) as an integer categorical variable.  \n",
    "- Confirm all columns are numeric and compatible with PyTorch tensors.  \n",
    "- Verify no missing or out-of-range IDs.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Training Data Structure\n",
    "- Each row: one `(player_id, opening_id, score)` record.\n",
    "- Include other fields- eco, num games etc\n",
    "- Convert DataFrame to PyTorch tensors (`torch.long` for IDs, `torch.float` for scores).  \n",
    "- Log dataset shapes and sparsity metrics.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Training Setup\n",
    "Define constants:\n",
    "- `LEARNING_RATE`, `BATCH_SIZE`, `N_EPOCHS`, `NUM_FACTORS`  \n",
    "- Loss functions: MSE and RMSE  \n",
    "- Activation: sigmoid or none (depending on score normalization)  \n",
    "- Optimizer: SGD  \n",
    "- Figure out if there's anything else we need to design or specify\n",
    "\n",
    "Implement helper functions:\n",
    "- `train_one_epoch()`\n",
    "- `evaluate_model()`\n",
    "- `calculate_rmse()`\n",
    "- `save_checkpoint()`  \n",
    "\n",
    "Ensure detailed logging, ETA reporting, and reproducible random seeds.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Training Loop\n",
    "- Initialize player and opening embeddings.  \n",
    "- Iterate through epochs with mini-batch SGD (`BATCH_SIZE = 1024`).  \n",
    "- Compute and log MSE/RMSE per epoch.  \n",
    "- Save model checkpoints locally after each epoch.\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Evaluation\n",
    "- Evaluate on test set.  \n",
    "- Report MSE, RMSE, and visual diagnostics (predicted vs actual score).  \n",
    "- Inspect a few player and opening latent factors for sanity.\n",
    "\n",
    "---\n",
    "\n",
    "### 9. Cross-Validation & Hyperparameter Tuning\n",
    "- Define ranges for:  \n",
    "  - `NUM_FACTORS`, `LEARNING_RATE`, `BATCH_SIZE`, `N_EPOCHS`  \n",
    "- Perform small-scale grid or random search for best configuration.  \n",
    "- Compare validation RMSE across runs.\n",
    "\n",
    "---\n",
    "\n",
    "### 10. Next Steps\n",
    "- Extend model to include Black openings.  \n",
    "- Experiment with hybrid inputs (player rating, ECO grouping).  \n",
    "- Consider implicit feedback handling (unplayed openings as zeros).  \n",
    "- Integrate trained model into API for recommendation output.\n",
    "\n",
    "---\n",
    "\n",
    "**Notes:**  \n",
    "- Every random seed and parameter definition will be explicit.  \n",
    "- Every major step includes row-count, schema, and type validation.  \n",
    "- Model artifacts and logs will be saved locally for reproducibility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc6d823",
   "metadata": {},
   "source": [
    "## Step 1: Data Extraction\n",
    "\n",
    "Connect to DuckDB and extract all player-opening statistics.\n",
    "Verify schema and perform sanity checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fcea569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 1: DATA EXTRACTION\n",
      "============================================================\n",
      "\n",
      "üìÅ Database: /Users/a/Documents/personalprojects/chess-opening-recommender/data/processed/chess_games.db\n",
      "üìÅ Database exists: True\n",
      "üé® Color filter: White\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# Add utils to path\n",
    "sys.path.append(str(Path.cwd() / 'utils'))\n",
    "from database.db_utils import get_db_connection\n",
    "\n",
    "# Configuration\n",
    "DB_PATH = Path.cwd().parent / \"data\" / \"processed\" / \"chess_games.db\"\n",
    "COLOR_FILTER = 'w'  # 'w' for white, 'b' for black\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 1: DATA EXTRACTION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüìÅ Database: {DB_PATH}\")\n",
    "print(f\"üìÅ Database exists: {DB_PATH.exists()}\")\n",
    "print(f\"üé® Color filter: {'White' if COLOR_FILTER == 'w' else 'Black'}\")\n",
    "\n",
    "if not DB_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Database not found at {DB_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9435033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1Ô∏è‚É£  Extracting player-opening statistics (color: 'w')...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678a20743be841ceaf28910e60315fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Extracted 11,877,700 rows\n",
      "\n",
      "2Ô∏è‚É£  Verifying schema...\n",
      "   ‚úì All required columns present: ['player_id', 'opening_id', 'num_games', 'score', 'eco']\n",
      "\n",
      "3Ô∏è‚É£  Checking data types...\n",
      "   ‚Ä¢ player_id: int32\n",
      "   ‚Ä¢ opening_id: int32\n",
      "   ‚Ä¢ num_games: int32\n",
      "   ‚Ä¢ score: float64\n",
      "   ‚Ä¢ eco: object\n",
      "\n",
      "4Ô∏è‚É£  Data statistics...\n",
      "   ‚Ä¢ Total rows: 11,877,700\n",
      "   ‚Ä¢ Unique players: 49,906\n",
      "   ‚Ä¢ Unique openings: 2,991\n",
      "   ‚Ä¢ Total games (sum): 235,152,459\n",
      "\n",
      "   Player ID range:\n",
      "   ‚Ä¢ Min: 1\n",
      "   ‚Ä¢ Max: 50000\n",
      "\n",
      "   Opening ID range:\n",
      "   ‚Ä¢ Min: 2\n",
      "   ‚Ä¢ Max: 3589\n",
      "\n",
      "   Games per entry:\n",
      "   ‚Ä¢ Min: 1\n",
      "   ‚Ä¢ Max: 13462\n",
      "   ‚Ä¢ Mean: 19.8\n",
      "   ‚Ä¢ Median: 3\n",
      "\n",
      "   Score distribution:\n",
      "   ‚Ä¢ Min: 0.0000\n",
      "   ‚Ä¢ Max: 1.0000\n",
      "   ‚Ä¢ Mean: 0.5006\n",
      "   ‚Ä¢ Median: 0.5000\n",
      "\n",
      "5Ô∏è‚É£  Checking for null values...\n",
      "   ‚úì No null values found\n",
      "\n",
      "6Ô∏è‚É£  Sample of extracted data (first 10 rows):\n",
      "   player_id  opening_id  num_games     score  eco\n",
      "0          1          39          6  0.666667  A00\n",
      "1          1          49          2  0.500000  A00\n",
      "2          1          53          1  0.000000  A00\n",
      "3          1         182          1  0.000000  A04\n",
      "4          1         187          1  1.000000  A04\n",
      "5          1         671          3  1.000000  B00\n",
      "6          1         675          3  0.000000  B00\n",
      "7          1         677          6  0.333333  B00\n",
      "8          1         688         25  0.620000  B00\n",
      "9          1         717          1  1.000000  B00\n",
      "\n",
      "============================================================\n",
      "‚úÖ DATA EXTRACTION COMPLETE\n",
      "============================================================\n",
      "\n",
      "Data shape: (11877700, 5)\n",
      "Columns: ['player_id', 'opening_id', 'num_games', 'score', 'eco']\n",
      "\n",
      "‚úì Database connection closed\n"
     ]
    }
   ],
   "source": [
    "# Connect to DuckDB and extract player-opening statistics\n",
    "con = get_db_connection(str(DB_PATH))\n",
    "\n",
    "try:\n",
    "    print(f\"\\n1Ô∏è‚É£  Extracting player-opening statistics (color: '{COLOR_FILTER}')...\")\n",
    "    \n",
    "    # Extract stats with calculated score and num_games\n",
    "    # Filter by color and calculate score in the database\n",
    "    query = f\"\"\"\n",
    "        SELECT \n",
    "            pos.player_id,\n",
    "            pos.opening_id,\n",
    "            pos.num_wins + pos.num_draws + pos.num_losses as num_games,\n",
    "            (pos.num_wins + (pos.num_draws * 0.5)) / \n",
    "                NULLIF(pos.num_wins + pos.num_draws + pos.num_losses, 0) as score,\n",
    "            o.eco\n",
    "        FROM player_opening_stats pos\n",
    "        JOIN opening o ON pos.opening_id = o.id\n",
    "        WHERE pos.color = '{COLOR_FILTER}'\n",
    "        ORDER BY pos.player_id, pos.opening_id\n",
    "    \"\"\"\n",
    "    \n",
    "    raw_data = pd.DataFrame(con.execute(query).df())\n",
    "    \n",
    "    print(f\"   ‚úì Extracted {len(raw_data):,} rows\")\n",
    "    \n",
    "    # Schema verification\n",
    "    print(\"\\n2Ô∏è‚É£  Verifying schema...\")\n",
    "    required_columns = ['player_id', 'opening_id', 'num_games', 'score', 'eco']\n",
    "    \n",
    "    for col in required_columns:\n",
    "        if col not in raw_data.columns:\n",
    "            raise ValueError(f\"Missing required column: {col}\")\n",
    "    \n",
    "    print(f\"   ‚úì All required columns present: {required_columns}\")\n",
    "    \n",
    "    # Data types verification\n",
    "    print(\"\\n3Ô∏è‚É£  Checking data types...\")\n",
    "    print(f\"   ‚Ä¢ player_id: {raw_data['player_id'].dtype}\")\n",
    "    print(f\"   ‚Ä¢ opening_id: {raw_data['opening_id'].dtype}\")\n",
    "    print(f\"   ‚Ä¢ num_games: {raw_data['num_games'].dtype}\")\n",
    "    print(f\"   ‚Ä¢ score: {raw_data['score'].dtype}\")\n",
    "    print(f\"   ‚Ä¢ eco: {raw_data['eco'].dtype}\")\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(\"\\n4Ô∏è‚É£  Data statistics...\")\n",
    "    print(f\"   ‚Ä¢ Total rows: {len(raw_data):,}\")\n",
    "    print(f\"   ‚Ä¢ Unique players: {raw_data['player_id'].nunique():,}\")\n",
    "    print(f\"   ‚Ä¢ Unique openings: {raw_data['opening_id'].nunique():,}\")\n",
    "    print(f\"   ‚Ä¢ Total games (sum): {raw_data['num_games'].sum():,}\")\n",
    "    \n",
    "    # Player ID range\n",
    "    print(f\"\\n   Player ID range:\")\n",
    "    print(f\"   ‚Ä¢ Min: {raw_data['player_id'].min()}\")\n",
    "    print(f\"   ‚Ä¢ Max: {raw_data['player_id'].max()}\")\n",
    "    \n",
    "    # Opening ID range\n",
    "    print(f\"\\n   Opening ID range:\")\n",
    "    print(f\"   ‚Ä¢ Min: {raw_data['opening_id'].min()}\")\n",
    "    print(f\"   ‚Ä¢ Max: {raw_data['opening_id'].max()}\")\n",
    "    \n",
    "    # Games per entry statistics\n",
    "    print(f\"\\n   Games per entry:\")\n",
    "    print(f\"   ‚Ä¢ Min: {raw_data['num_games'].min()}\")\n",
    "    print(f\"   ‚Ä¢ Max: {raw_data['num_games'].max()}\")\n",
    "    print(f\"   ‚Ä¢ Mean: {raw_data['num_games'].mean():.1f}\")\n",
    "    print(f\"   ‚Ä¢ Median: {raw_data['num_games'].median():.0f}\")\n",
    "    \n",
    "    # Score statistics\n",
    "    print(f\"\\n   Score distribution:\")\n",
    "    print(f\"   ‚Ä¢ Min: {raw_data['score'].min():.4f}\")\n",
    "    print(f\"   ‚Ä¢ Max: {raw_data['score'].max():.4f}\")\n",
    "    print(f\"   ‚Ä¢ Mean: {raw_data['score'].mean():.4f}\")\n",
    "    print(f\"   ‚Ä¢ Median: {raw_data['score'].median():.4f}\")\n",
    "    \n",
    "    # Check for null values\n",
    "    print(\"\\n5Ô∏è‚É£  Checking for null values...\")\n",
    "    null_counts = raw_data.isnull().sum()\n",
    "    if null_counts.sum() == 0:\n",
    "        print(\"   ‚úì No null values found\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  Found null values:\")\n",
    "        for col, count in null_counts[null_counts > 0].items():\n",
    "            print(f\"      ‚Ä¢ {col}: {count} nulls\")\n",
    "    \n",
    "    # Sample data\n",
    "    print(\"\\n6Ô∏è‚É£  Sample of extracted data (first 10 rows):\")\n",
    "    print(raw_data.head(10).to_string())\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úÖ DATA EXTRACTION COMPLETE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nData shape: {raw_data.shape}\")\n",
    "    print(f\"Columns: {list(raw_data.columns)}\")\n",
    "    \n",
    "finally:\n",
    "    con.close()\n",
    "    print(\"\\n‚úì Database connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad110b85",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "519d8f2f",
   "metadata": {},
   "source": [
    "## Step 2: Data Sanitization & Normalization\n",
    "\n",
    "Filter low-quality data, handle duplicates, and prepare for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e74f0b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 2: DATA SANITIZATION & NORMALIZATION\n",
      "============================================================\n",
      "\n",
      "‚öôÔ∏è  Configuration:\n",
      "   ‚Ä¢ MIN_GAMES_THRESHOLD: 10\n",
      "\n",
      "üìä Starting data shape: (11877700, 5)\n",
      "   ‚Ä¢ Rows: 11,877,700\n",
      "   ‚Ä¢ Unique players: 49,906\n",
      "   ‚Ä¢ Unique openings: 2,991\n",
      "\n",
      "1Ô∏è‚É£  Filtering entries with < 10 games...\n",
      "   ‚Ä¢ Before: 11,877,700 rows\n",
      "   ‚Ä¢ After: 2,975,888 rows\n",
      "   ‚Ä¢ Filtered out: 8,901,812 rows (74.9%)\n",
      "\n",
      "2Ô∏è‚É£  Checking for duplicate (player_id, opening_id) combinations...\n",
      "   ‚úì No duplicates found\n",
      "\n",
      "3Ô∏è‚É£  Removing players with no qualifying openings...\n",
      "   ‚Ä¢ Players before: 49,822\n",
      "   ‚Ä¢ Players after: 49,822\n",
      "   ‚Ä¢ Removed: 0\n",
      "\n",
      "4Ô∏è‚É£  Removing openings with no qualifying players...\n",
      "   ‚Ä¢ Openings before: 2,718\n",
      "   ‚Ä¢ Openings after: 2,718\n",
      "   ‚Ä¢ Removed: 0\n",
      "\n",
      "5Ô∏è‚É£  Verifying no null values...\n",
      "   ‚úì No null values found\n",
      "\n",
      "6Ô∏è‚É£  Final data statistics:\n",
      "   ‚Ä¢ Total rows: 2,975,888\n",
      "   ‚Ä¢ Unique players: 49,822\n",
      "   ‚Ä¢ Unique openings: 2,718\n",
      "   ‚Ä¢ Total games: 211,951,019\n",
      "   ‚Ä¢ Avg games per entry: 71.2\n",
      "   ‚Ä¢ Avg openings per player: 59.7\n",
      "   ‚Ä¢ Avg players per opening: 1094.9\n",
      "\n",
      "   Score statistics:\n",
      "   ‚Ä¢ Min: 0.0000\n",
      "   ‚Ä¢ 25th percentile: 0.4500\n",
      "   ‚Ä¢ Median: 0.5124\n",
      "   ‚Ä¢ 75th percentile: 0.5750\n",
      "   ‚Ä¢ Max: 1.0000\n",
      "   ‚Ä¢ Mean: 0.5110\n",
      "   ‚Ä¢ Std: 0.1083\n",
      "\n",
      "7Ô∏è‚É£  Sample of cleaned data (10 random rows):\n",
      "         player_id  opening_id  num_games     score  eco\n",
      "2125070      34968         510        173  0.569364  A48\n",
      "1386615      22887         976         83  0.487952  B15\n",
      "1321989      21826        3471         55  0.509091  C42\n",
      "1260087      20789         773         56  0.669643  B01\n",
      "2961460      49599        1314         82  0.487805  B90\n",
      "2172452      35757        3023         55  0.427273  E60\n",
      "588267        9614        1356         10  0.400000  C00\n",
      "2793184      46152        2462         98  0.530612  D02\n",
      "2412407      39701         799         58  0.439655  B02\n",
      "584193        9560         751         24  0.437500  B01\n",
      "\n",
      "============================================================\n",
      "‚úÖ DATA SANITIZATION COMPLETE\n",
      "============================================================\n",
      "\n",
      "Cleaned data shape: (2975888, 5)\n",
      "Data reduction: 74.9%\n"
     ]
    }
   ],
   "source": [
    "# 2a. Filter low-quality data, handle duplicates, and prepare for training.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Configuration\n",
    "MIN_GAMES_THRESHOLD = 10\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 2: DATA SANITIZATION & NORMALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n‚öôÔ∏è  Configuration:\")\n",
    "print(f\"   ‚Ä¢ MIN_GAMES_THRESHOLD: {MIN_GAMES_THRESHOLD}\")\n",
    "\n",
    "# Start with raw_data from Step 1\n",
    "print(f\"\\nüìä Starting data shape: {raw_data.shape}\")\n",
    "print(f\"   ‚Ä¢ Rows: {len(raw_data):,}\")\n",
    "print(f\"   ‚Ä¢ Unique players: {raw_data['player_id'].nunique():,}\")\n",
    "print(f\"   ‚Ä¢ Unique openings: {raw_data['opening_id'].nunique():,}\")\n",
    "\n",
    "# 1. Filter by minimum games threshold\n",
    "print(f\"\\n1Ô∏è‚É£  Filtering entries with < {MIN_GAMES_THRESHOLD} games...\")\n",
    "before_filter = len(raw_data)\n",
    "clean_data = raw_data.query(f'num_games >= {MIN_GAMES_THRESHOLD}').copy()\n",
    "num_rows_after_filter = len(clean_data)\n",
    "num_rows_filtered_out = before_filter - num_rows_after_filter\n",
    "\n",
    "print(f\"   ‚Ä¢ Before: {before_filter:,} rows\")\n",
    "print(f\"   ‚Ä¢ After: {num_rows_after_filter:,} rows\")\n",
    "print(f\"   ‚Ä¢ Filtered out: {num_rows_filtered_out:,} rows ({100*num_rows_filtered_out/before_filter:.1f}%)\")\n",
    "\n",
    "# 2. Check for duplicates\n",
    "print(f\"\\n2Ô∏è‚É£  Checking for duplicate (player_id, opening_id) combinations...\")\n",
    "num_duplicates = clean_data.duplicated(subset=['player_id', 'opening_id']).sum()\n",
    "\n",
    "if num_duplicates > 0:\n",
    "    print(f\"   ‚ö†Ô∏è  Found {num_duplicates} duplicate entries\")\n",
    "    dup_mask = clean_data.duplicated(subset=['player_id', 'opening_id'], keep=False)\n",
    "    print(\"\\n   Sample of duplicates:\")\n",
    "    print(clean_data[dup_mask].head(10).to_string())\n",
    "    \n",
    "    # Keep only first occurrence of any duplicate player-opening pair\n",
    "    print(\"\\n   Removing duplicates (keeping first occurrence)...\")\n",
    "    clean_data = pd.DataFrame.drop_duplicates(clean_data, subset=['player_id', 'opening_id'], keep='first')\n",
    "    print(f\"   ‚úì After deduplication: {len(clean_data):,} rows\")\n",
    "else:\n",
    "    print(f\"   ‚úì No duplicates found\")\n",
    "\n",
    "# 3. Remove players with no qualifying openings\n",
    "print(f\"\\n3Ô∏è‚É£  Removing players with no qualifying openings...\") # Note that a few players only play stuff like the Van't Kruijs which we've excluded, so a small numer of players will be excluded here\n",
    "players_before = clean_data['player_id'].nunique()\n",
    "\n",
    "# Count openings per player\n",
    "num_openings_per_player = pd.DataFrame(clean_data.groupby('player_id').size(), columns=['count'])\n",
    "players_with_data = num_openings_per_player[num_openings_per_player['count'] > 0].index.tolist()\n",
    "\n",
    "# Filter\n",
    "clean_data = clean_data[clean_data['player_id'].isin(players_with_data)]\n",
    "players_after = clean_data['player_id'].nunique()\n",
    "\n",
    "print(f\"   ‚Ä¢ Players before: {players_before:,}\")\n",
    "print(f\"   ‚Ä¢ Players after: {players_after:,}\")\n",
    "print(f\"   ‚Ä¢ Removed: {players_before - players_after}\")\n",
    "\n",
    "# 4. Remove openings with no qualifying players\n",
    "print(f\"\\n4Ô∏è‚É£  Removing openings with no qualifying players...\")\n",
    "num_openings_before = clean_data['opening_id'].nunique()\n",
    "\n",
    "# Use pd.DataFrame.groupby() to count players per opening\n",
    "num_players_per_opening = pd.DataFrame(clean_data.groupby('opening_id').size(), columns=['count'])\n",
    "openings_with_data = num_players_per_opening[num_players_per_opening['count'] > 0].index.tolist()\n",
    "\n",
    "# Filter using pd.DataFrame.isin()\n",
    "clean_data = clean_data[clean_data['opening_id'].isin(openings_with_data)]\n",
    "openings_after = clean_data['opening_id'].nunique()\n",
    "\n",
    "print(f\"   ‚Ä¢ Openings before: {num_openings_before:,}\")\n",
    "print(f\"   ‚Ä¢ Openings after: {openings_after:,}\")\n",
    "print(f\"   ‚Ä¢ Removed: {num_openings_before - openings_after}\")\n",
    "\n",
    "# 5. Verify no null values using pd.isna()\n",
    "print(f\"\\n5Ô∏è‚É£  Verifying no null values...\")\n",
    "null_counts = pd.DataFrame.isna(clean_data).sum()\n",
    "if null_counts.sum() == 0:\n",
    "    print(\"   ‚úì No null values found\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  Found null values:\")\n",
    "    for col, count in null_counts[null_counts > 0].items():\n",
    "        print(f\"      ‚Ä¢ {col}: {count} nulls\")\n",
    "    # Drop rows with nulls using pd.DataFrame.dropna()\n",
    "    clean_data = pd.DataFrame.dropna(clean_data)\n",
    "    print(f\"   ‚úì Dropped null rows. New shape: {clean_data.shape}\")\n",
    "\n",
    "# TODO: Add confidence weighting column\n",
    "# TODO: Extract and normalize player ratings (side information)\n",
    "\n",
    "# Reset index using pd.DataFrame.reset_index()\n",
    "clean_data = pd.DataFrame.reset_index(clean_data, drop=True)\n",
    "\n",
    "# Final statistics using pd functions\n",
    "print(f\"\\n6Ô∏è‚É£  Final data statistics:\")\n",
    "print(f\"   ‚Ä¢ Total rows: {len(clean_data):,}\")\n",
    "print(f\"   ‚Ä¢ Unique players: {pd.Series.nunique(clean_data['player_id']):,}\")\n",
    "print(f\"   ‚Ä¢ Unique openings: {pd.Series.nunique(clean_data['opening_id']):,}\")\n",
    "print(f\"   ‚Ä¢ Total games: {pd.Series.sum(clean_data['num_games']):,}\")\n",
    "print(f\"   ‚Ä¢ Avg games per entry: {pd.Series.mean(clean_data['num_games']):.1f}\")\n",
    "print(f\"   ‚Ä¢ Avg openings per player: {len(clean_data) / pd.Series.nunique(clean_data['player_id']):.1f}\")\n",
    "print(f\"   ‚Ä¢ Avg players per opening: {len(clean_data) / pd.Series.nunique(clean_data['opening_id']):.1f}\")\n",
    "\n",
    "# Score distribution using pd functions\n",
    "print(f\"\\n   Score statistics:\")\n",
    "print(f\"   ‚Ä¢ Min: {pd.Series.min(clean_data['score']):.4f}\")\n",
    "print(f\"   ‚Ä¢ 25th percentile: {pd.Series.quantile(clean_data['score'], 0.25):.4f}\")\n",
    "print(f\"   ‚Ä¢ Median: {pd.Series.median(clean_data['score']):.4f}\")\n",
    "print(f\"   ‚Ä¢ 75th percentile: {pd.Series.quantile(clean_data['score'], 0.75):.4f}\")\n",
    "print(f\"   ‚Ä¢ Max: {pd.Series.max(clean_data['score']):.4f}\")\n",
    "print(f\"   ‚Ä¢ Mean: {pd.Series.mean(clean_data['score']):.4f}\")\n",
    "print(f\"   ‚Ä¢ Std: {pd.Series.std(clean_data['score']):.4f}\")\n",
    "\n",
    "# Sample of cleaned data using pd.DataFrame.sample()\n",
    "print(f\"\\n7Ô∏è‚É£  Sample of cleaned data (10 random rows):\")\n",
    "print(pd.DataFrame.sample(clean_data, min(10, len(clean_data)), random_state=42).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ DATA SANITIZATION COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nCleaned data shape: {clean_data.shape}\")\n",
    "print(f\"Data reduction: {100 * (1 - len(clean_data)/len(raw_data)):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e671b6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 2B: HIERARCHICAL BAYESIAN SCORE ADJUSTMENT\n",
      "============================================================\n",
      "\n",
      "‚öôÔ∏è  Configuration:\n",
      "   ‚Ä¢ K_PLAYER (shrinkage constant): 50\n",
      "   ‚Ä¢ Method: Two-level empirical Bayes shrinkage\n",
      "   ‚Ä¢ Level 1: Calculate opening-specific means\n",
      "   ‚Ä¢ Level 2: Shrink player scores toward opening means\n",
      "\n",
      "üìä Global statistics:\n",
      "   ‚Ä¢ Global mean score: 0.5110\n",
      "   ‚Ä¢ Total entries: 2,975,888\n",
      "   ‚Ä¢ Unique openings: 2,718\n",
      "\n",
      "1Ô∏è‚É£  LEVEL 1: Calculating opening-specific means...\n",
      "   ‚úì Calculated means for 2,718 openings\n",
      "\n",
      "   Opening mean score distribution:\n",
      "   ‚Ä¢ Min: 0.1667\n",
      "   ‚Ä¢ 25th percentile: 0.4961\n",
      "   ‚Ä¢ Median: 0.5163\n",
      "   ‚Ä¢ 75th percentile: 0.5366\n",
      "   ‚Ä¢ Max: 1.0000\n",
      "   ‚Ä¢ Std: 0.0504\n",
      "\n",
      "   Opening sample size distribution:\n",
      "   ‚Ä¢ Total games per opening (median): 4913\n",
      "   ‚Ä¢ Players per opening (median): 160\n",
      "   ‚Ä¢ Total games range: [10, 5648567]\n",
      "   ‚Ä¢ Players range: [1, 44105]\n",
      "\n",
      "2Ô∏è‚É£  LEVEL 2: Shrinking player scores toward opening means...\n",
      "   Formula: adjusted_score = (num_games √ó player_score + 50 √ó opening_mean) / (num_games + 50)\n",
      "   ‚úì Scores adjusted for 2,975,888 entries\n",
      "\n",
      "3Ô∏è‚É£  Calculating confidence weights...\n",
      "   ‚úì Confidence weights calculated\n",
      "   ‚Ä¢ Formula: confidence = num_games / (num_games + 50)\n",
      "   ‚Ä¢ Range: [0.1667, 0.9963]\n",
      "\n",
      "4Ô∏è‚É£  Adjustment statistics:\n",
      "   ‚Ä¢ Mean adjustment: 0.000961\n",
      "   ‚Ä¢ Std adjustment: 0.076772\n",
      "   ‚Ä¢ Max adjustment: 0.457159\n",
      "   ‚Ä¢ Min adjustment: -0.457659\n",
      "\n",
      "   Adjustment by num_games quartiles:\n",
      "   ‚Ä¢ 25th percentile (n=15 games): avg adjustment = 0.003635\n",
      "   ‚Ä¢ 50th percentile (n=27 games): avg adjustment = 0.001803\n",
      "   ‚Ä¢ 75th percentile (n=66 games): avg adjustment = -0.000409\n",
      "   ‚Ä¢ >75th percentile (n>66 games): avg adjustment = -0.001361\n",
      "\n",
      "5Ô∏è‚É£  Adjusted score statistics:\n",
      "   ‚Ä¢ Min: 0.1003\n",
      "   ‚Ä¢ 25th percentile: 0.4849\n",
      "   ‚Ä¢ Median: 0.5117\n",
      "   ‚Ä¢ 75th percentile: 0.5384\n",
      "   ‚Ä¢ Max: 1.0000\n",
      "   ‚Ä¢ Mean: 0.5120\n",
      "   ‚Ä¢ Std: 0.0412\n",
      "\n",
      "6Ô∏è‚É£  Sample comparisons (showing effect of hierarchical shrinkage):\n",
      "\n",
      "   ========================================================================================================================\n",
      "   Low-game entries (10-20 games) - HIGH shrinkage toward opening mean:\n",
      "   ========================================================================================================================\n",
      "   Player 47413 | Opening 2495 | Games:  13 | Opening mean: 0.5403 | Original: 0.8462 ‚Üí Adjusted: 0.6034 | Diff: -0.2428 | Confidence: 0.206\n",
      "   Player 30621 | Opening 3471 | Games:  16 | Opening mean: 0.5101 | Original: 0.5312 ‚Üí Adjusted: 0.5152 | Diff: -0.0160 | Confidence: 0.242\n",
      "   Player 42014 | Opening  529 | Games:  15 | Opening mean: 0.4922 | Original: 0.3667 ‚Üí Adjusted: 0.4632 | Diff: +0.0966 | Confidence: 0.231\n",
      "   Player 23922 | Opening 2461 | Games:  20 | Opening mean: 0.5133 | Original: 0.4500 ‚Üí Adjusted: 0.4952 | Diff: +0.0452 | Confidence: 0.286\n",
      "   Player 34410 | Opening 1386 | Games:  15 | Opening mean: 0.4815 | Original: 0.5333 ‚Üí Adjusted: 0.4934 | Diff: -0.0399 | Confidence: 0.231\n",
      "   Player 39184 | Opening 2498 | Games:  13 | Opening mean: 0.5457 | Original: 0.4615 ‚Üí Adjusted: 0.5283 | Diff: +0.0668 | Confidence: 0.206\n",
      "   Player  4539 | Opening  744 | Games:  18 | Opening mean: 0.5132 | Original: 0.5278 ‚Üí Adjusted: 0.5171 | Diff: -0.0107 | Confidence: 0.265\n",
      "   Player 37644 | Opening 1167 | Games:  10 | Opening mean: 0.4961 | Original: 0.5000 ‚Üí Adjusted: 0.4968 | Diff: -0.0032 | Confidence: 0.167\n",
      "   Player 42056 | Opening 1580 | Games:  11 | Opening mean: 0.5570 | Original: 0.4545 ‚Üí Adjusted: 0.5385 | Diff: +0.0840 | Confidence: 0.180\n",
      "   Player  1673 | Opening  744 | Games:  16 | Opening mean: 0.5132 | Original: 0.4062 ‚Üí Adjusted: 0.4873 | Diff: +0.0810 | Confidence: 0.242\n",
      "\n",
      "   ========================================================================================================================\n",
      "   Medium-game entries (50-100 games) - MODERATE shrinkage:\n",
      "   ========================================================================================================================\n",
      "   Player 12843 | Opening 3212 | Games:  81 | Opening mean: 0.5150 | Original: 0.4568 ‚Üí Adjusted: 0.4790 | Diff: +0.0222 | Confidence: 0.618\n",
      "   Player  1532 | Opening 2495 | Games:  95 | Opening mean: 0.5403 | Original: 0.5368 ‚Üí Adjusted: 0.5380 | Diff: +0.0012 | Confidence: 0.655\n",
      "   Player 10321 | Opening 1046 | Games:  61 | Opening mean: 0.4828 | Original: 0.3934 ‚Üí Adjusted: 0.4337 | Diff: +0.0402 | Confidence: 0.550\n",
      "   Player 44124 | Opening  218 | Games:  61 | Opening mean: 0.4698 | Original: 0.4016 ‚Üí Adjusted: 0.4323 | Diff: +0.0307 | Confidence: 0.550\n",
      "   Player 30706 | Opening  509 | Games:  53 | Opening mean: 0.5058 | Original: 0.5849 ‚Üí Adjusted: 0.5465 | Diff: -0.0384 | Confidence: 0.515\n",
      "   Player  4681 | Opening 2465 | Games:  60 | Opening mean: 0.5182 | Original: 0.4667 ‚Üí Adjusted: 0.4901 | Diff: +0.0234 | Confidence: 0.545\n",
      "   Player 14017 | Opening 1664 | Games:  50 | Opening mean: 0.5147 | Original: 0.4100 ‚Üí Adjusted: 0.4623 | Diff: +0.0523 | Confidence: 0.500\n",
      "   Player 17497 | Opening 2052 | Games:  85 | Opening mean: 0.5378 | Original: 0.5471 ‚Üí Adjusted: 0.5436 | Diff: -0.0034 | Confidence: 0.630\n",
      "   Player 20864 | Opening  772 | Games:  96 | Opening mean: 0.5165 | Original: 0.5521 ‚Üí Adjusted: 0.5399 | Diff: -0.0122 | Confidence: 0.658\n",
      "   Player 10119 | Opening 2283 | Games:  74 | Opening mean: 0.5434 | Original: 0.4932 ‚Üí Adjusted: 0.5135 | Diff: +0.0202 | Confidence: 0.597\n",
      "\n",
      "   ========================================================================================================================\n",
      "   High-game entries (200+ games) - LOW shrinkage:\n",
      "   ========================================================================================================================\n",
      "   Player 20993 | Opening  309 | Games: 371 | Opening mean: 0.5169 | Original: 0.4757 ‚Üí Adjusted: 0.4806 | Diff: +0.0049 | Confidence: 0.881\n",
      "   Player 15842 | Opening 1475 | Games: 360 | Opening mean: 0.5166 | Original: 0.5292 ‚Üí Adjusted: 0.5276 | Diff: -0.0015 | Confidence: 0.878\n",
      "   Player  9283 | Opening 2052 | Games: 219 | Opening mean: 0.5378 | Original: 0.5525 ‚Üí Adjusted: 0.5498 | Diff: -0.0027 | Confidence: 0.814\n",
      "   Player 10494 | Opening  910 | Games: 312 | Opening mean: 0.5000 | Original: 0.4952 ‚Üí Adjusted: 0.4959 | Diff: +0.0007 | Confidence: 0.862\n",
      "   Player  8614 | Opening  146 | Games: 363 | Opening mean: 0.5034 | Original: 0.4862 ‚Üí Adjusted: 0.4883 | Diff: +0.0021 | Confidence: 0.879\n",
      "   Player  7203 | Opening 1968 | Games: 295 | Opening mean: 0.5534 | Original: 0.5780 ‚Üí Adjusted: 0.5744 | Diff: -0.0036 | Confidence: 0.855\n",
      "   Player 26298 | Opening  496 | Games: 267 | Opening mean: 0.5128 | Original: 0.5543 ‚Üí Adjusted: 0.5478 | Diff: -0.0065 | Confidence: 0.842\n",
      "   Player 29470 | Opening  474 | Games: 446 | Opening mean: 0.4896 | Original: 0.4798 ‚Üí Adjusted: 0.4808 | Diff: +0.0010 | Confidence: 0.899\n",
      "   Player 40324 | Opening 2216 | Games: 679 | Opening mean: 0.5324 | Original: 0.5479 ‚Üí Adjusted: 0.5468 | Diff: -0.0011 | Confidence: 0.931\n",
      "   Player 16641 | Opening 3214 | Games: 237 | Opening mean: 0.5144 | Original: 0.4789 ‚Üí Adjusted: 0.4851 | Diff: +0.0062 | Confidence: 0.826\n",
      "\n",
      "7Ô∏è‚É£  Extreme cases (showing why opening-specific shrinkage matters):\n",
      "\n",
      "   Openings with HIGHEST win rates (strong for White):\n",
      "   Opening 1811 (C39): mean = 1.0000 (+0.4890 vs global) | 1 player entries\n",
      "   Opening 3551 (C19): mean = 0.8000 (+0.2890 vs global) | 1 player entries\n",
      "   Opening 2881 (E10): mean = 0.8000 (+0.2890 vs global) | 1 player entries\n",
      "   Opening 2046 (C49): mean = 0.7857 (+0.2747 vs global) | 1 player entries\n",
      "   Opening 1659 (C30): mean = 0.7692 (+0.2582 vs global) | 1 player entries\n",
      "\n",
      "   Openings with LOWEST win rates (weak for White):\n",
      "   Opening 2593 (D26): mean = 0.1667 (-0.3443 vs global) | 1 player entries\n",
      "   Opening  636 (A83): mean = 0.2006 (-0.3104 vs global) | 2 player entries\n",
      "   Opening 3496 (A40): mean = 0.2273 (-0.2837 vs global) | 1 player entries\n",
      "   Opening 1763 (C37): mean = 0.2417 (-0.2693 vs global) | 2 player entries\n",
      "\n",
      "8Ô∏è‚É£  Examples showing hierarchical shrinkage benefit:\n",
      "\n",
      "   Strong opening + good player performance (shrunk toward HIGH opening mean):\n",
      "   Player 23562 | Opening 3292 (C54) | Games: 12 | Opening mean: 0.7297 | Original: 0.7500 ‚Üí 0.7336\n",
      "      If we'd shrunk to global mean: 0.5573 (would lose +0.1764 of deserved credit)\n",
      "   Player 14997 | Opening 3292 (C54) | Games: 13 | Opening mean: 0.7297 | Original: 0.9231 ‚Üí 0.7696\n",
      "      If we'd shrunk to global mean: 0.5960 (would lose +0.1736 of deserved credit)\n",
      "   Player  9893 | Opening 3292 (C54) | Games: 20 | Opening mean: 0.7297 | Original: 0.6500 ‚Üí 0.7069\n",
      "      If we'd shrunk to global mean: 0.5507 (would lose +0.1562 of deserved credit)\n",
      "\n",
      "   Weak opening + poor player performance (shrunk toward LOW opening mean):\n",
      "   Player  1857 | Opening 2293 (C71) | Games: 13 | Opening mean: 0.2665 | Original: 0.1538 ‚Üí 0.2433\n",
      "      If we'd shrunk to global mean: 0.4373 (would unfairly boost by +0.1940)\n",
      "   Player 19116 | Opening 1779 (C37) | Games: 10 | Opening mean: 0.3366 | Original: 0.2000 ‚Üí 0.3138\n",
      "      If we'd shrunk to global mean: 0.4592 (would unfairly boost by +0.1453)\n",
      "   Player  4605 | Opening 1779 (C37) | Games: 13 | Opening mean: 0.3366 | Original: 0.3846 ‚Üí 0.3465\n",
      "      If we'd shrunk to global mean: 0.4849 (would unfairly boost by +0.1384)\n",
      "\n",
      "9Ô∏è‚É£  Cleaning up...\n",
      "   ‚úì Removed temporary columns\n",
      "\n",
      "============================================================\n",
      "‚úÖ HIERARCHICAL BAYESIAN ADJUSTMENT COMPLETE\n",
      "============================================================\n",
      "\n",
      "Final data shape: (2975888, 6)\n",
      "Columns: ['player_id', 'opening_id', 'num_games', 'score', 'eco', 'confidence']\n",
      "\n",
      "New columns added:\n",
      "   ‚Ä¢ 'confidence': weight for loss function (range [0,1])\n",
      "   ‚Ä¢ 'score': adjusted using hierarchical Bayesian shrinkage\n",
      "\n",
      "Key improvement over simple shrinkage:\n",
      "   ‚Ä¢ Player scores now shrink toward OPENING-SPECIFIC means, not global mean\n",
      "   ‚Ä¢ Preserves opening difficulty differences\n",
      "   ‚Ä¢ More accurate for both strong and weak openings\n"
     ]
    }
   ],
   "source": [
    "# 2b. Apply hierarchical Bayesian shrinkage to adjust scores based on sample size confidence\n",
    "\n",
    "# A lot of our player-opening entries have a small number of games played, because openings are so specific.\n",
    "# This introduces sample size issues.\n",
    "\n",
    "# We'll use TWO-LEVEL shrinkage:\n",
    "# Level 1: Calculate opening-specific means (these are our \"ground truth\" for each opening)\n",
    "# Level 2: Shrink individual player-opening scores toward their opening's mean\n",
    "# This is better than shrinking toward global mean because different openings have different baseline win rates\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 2B: HIERARCHICAL BAYESIAN SCORE ADJUSTMENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Configuration for Bayesian shrinkage\n",
    "K_PLAYER = 50  # Shrinkage constant for player-opening scores\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è  Configuration:\")\n",
    "print(f\"   ‚Ä¢ K_PLAYER (shrinkage constant): {K_PLAYER}\")\n",
    "print(f\"   ‚Ä¢ Method: Two-level empirical Bayes shrinkage\")\n",
    "print(f\"   ‚Ä¢ Level 1: Calculate opening-specific means\")\n",
    "print(f\"   ‚Ä¢ Level 2: Shrink player scores toward opening means\")\n",
    "\n",
    "# Calculate global mean score for comparison\n",
    "global_mean_score = clean_data[\"score\"].mean()\n",
    "print(f\"\\nüìä Global statistics:\")\n",
    "print(f\"   ‚Ä¢ Global mean score: {global_mean_score:.4f}\")\n",
    "print(f\"   ‚Ä¢ Total entries: {len(clean_data):,}\")\n",
    "print(f\"   ‚Ä¢ Unique openings: {clean_data['opening_id'].nunique():,}\")\n",
    "\n",
    "# Store original scores for comparison\n",
    "clean_data = clean_data.copy()  # Best practice: work on a copy\n",
    "clean_data[\"score_original\"] = clean_data[\"score\"].copy()\n",
    "\n",
    "# LEVEL 1: Calculate opening-specific means and statistics\n",
    "print(f\"\\n1Ô∏è‚É£  LEVEL 1: Calculating opening-specific means...\")\n",
    "\n",
    "opening_stats = (\n",
    "    clean_data.groupby(\"opening_id\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"score\": \"mean\",\n",
    "            \"num_games\": \"sum\",\n",
    "            \"player_id\": \"count\",  # Number of players who played this opening\n",
    "        }\n",
    "    )\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"score\": \"opening_mean\",\n",
    "            \"num_games\": \"opening_total_games\",\n",
    "            \"player_id\": \"opening_num_players\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"   ‚úì Calculated means for {len(opening_stats):,} openings\")\n",
    "\n",
    "# Opening mean statistics\n",
    "print(f\"\\n   Opening mean score distribution:\")\n",
    "print(f\"   ‚Ä¢ Min: {opening_stats['opening_mean'].min():.4f}\")\n",
    "print(f\"   ‚Ä¢ 25th percentile: {opening_stats['opening_mean'].quantile(0.25):.4f}\")\n",
    "print(f\"   ‚Ä¢ Median: {opening_stats['opening_mean'].median():.4f}\")\n",
    "print(f\"   ‚Ä¢ 75th percentile: {opening_stats['opening_mean'].quantile(0.75):.4f}\")\n",
    "print(f\"   ‚Ä¢ Max: {opening_stats['opening_mean'].max():.4f}\")\n",
    "print(f\"   ‚Ä¢ Std: {opening_stats['opening_mean'].std():.4f}\")\n",
    "\n",
    "# Show distribution of opening sizes\n",
    "print(f\"\\n   Opening sample size distribution:\")\n",
    "print(\n",
    "    f\"   ‚Ä¢ Total games per opening (median): {opening_stats['opening_total_games'].median():.0f}\"\n",
    ")\n",
    "print(\n",
    "    f\"   ‚Ä¢ Players per opening (median): {opening_stats['opening_num_players'].median():.0f}\"\n",
    ")\n",
    "print(\n",
    "    f\"   ‚Ä¢ Total games range: [{opening_stats['opening_total_games'].min():.0f}, {opening_stats['opening_total_games'].max():.0f}]\"\n",
    ")\n",
    "print(\n",
    "    f\"   ‚Ä¢ Players range: [{opening_stats['opening_num_players'].min():.0f}, {opening_stats['opening_num_players'].max():.0f}]\"\n",
    ")\n",
    "\n",
    "# Merge opening means back into main dataframe\n",
    "clean_data = clean_data.merge(\n",
    "    opening_stats[[\"opening_mean\"]], left_on=\"opening_id\", right_index=True, how=\"left\"\n",
    ")\n",
    "\n",
    "# LEVEL 2: Shrink player-opening scores toward opening-specific means\n",
    "print(f\"\\n2Ô∏è‚É£  LEVEL 2: Shrinking player scores toward opening means...\")\n",
    "print(\n",
    "    f\"   Formula: adjusted_score = (num_games √ó player_score + {K_PLAYER} √ó opening_mean) / (num_games + {K_PLAYER})\"\n",
    ")\n",
    "\n",
    "numerator = (clean_data[\"num_games\"] * clean_data[\"score_original\"]) + (\n",
    "    K_PLAYER * clean_data[\"opening_mean\"]\n",
    ")\n",
    "denominator = clean_data[\"num_games\"] + K_PLAYER\n",
    "clean_data[\"score\"] = numerator / denominator\n",
    "\n",
    "print(f\"   ‚úì Scores adjusted for {len(clean_data):,} entries\")\n",
    "\n",
    "# Calculate confidence weights (will be used in loss function later)\n",
    "print(f\"\\n3Ô∏è‚É£  Calculating confidence weights...\")\n",
    "clean_data[\"confidence\"] = clean_data[\"num_games\"] / (\n",
    "    clean_data[\"num_games\"] + K_PLAYER\n",
    ")\n",
    "print(f\"   ‚úì Confidence weights calculated\")\n",
    "print(f\"   ‚Ä¢ Formula: confidence = num_games / (num_games + {K_PLAYER})\")\n",
    "print(\n",
    "    f\"   ‚Ä¢ Range: [{clean_data['confidence'].min():.4f}, {clean_data['confidence'].max():.4f}]\"\n",
    ")\n",
    "\n",
    "# Statistics on the adjustment\n",
    "score_diff = clean_data[\"score\"] - clean_data[\"score_original\"]\n",
    "print(f\"\\n4Ô∏è‚É£  Adjustment statistics:\")\n",
    "print(f\"   ‚Ä¢ Mean adjustment: {score_diff.mean():.6f}\")\n",
    "print(f\"   ‚Ä¢ Std adjustment: {score_diff.std():.6f}\")\n",
    "print(f\"   ‚Ä¢ Max adjustment: {score_diff.max():.6f}\")\n",
    "print(f\"   ‚Ä¢ Min adjustment: {score_diff.min():.6f}\")\n",
    "\n",
    "# Show distribution of adjustments\n",
    "print(f\"\\n   Adjustment by num_games quartiles:\")\n",
    "quartiles = clean_data[\"num_games\"].quantile([0.25, 0.5, 0.75])\n",
    "print(\n",
    "    f\"   ‚Ä¢ 25th percentile (n={quartiles[0.25]:.0f} games): avg adjustment = {score_diff[clean_data['num_games'] <= quartiles[0.25]].mean():.6f}\"\n",
    ")\n",
    "print(\n",
    "    f\"   ‚Ä¢ 50th percentile (n={quartiles[0.5]:.0f} games): avg adjustment = {score_diff[(clean_data['num_games'] > quartiles[0.25]) & (clean_data['num_games'] <= quartiles[0.5])].mean():.6f}\"\n",
    ")\n",
    "print(\n",
    "    f\"   ‚Ä¢ 75th percentile (n={quartiles[0.75]:.0f} games): avg adjustment = {score_diff[(clean_data['num_games'] > quartiles[0.5]) & (clean_data['num_games'] <= quartiles[0.75])].mean():.6f}\"\n",
    ")\n",
    "print(\n",
    "    f\"   ‚Ä¢ >75th percentile (n>{quartiles[0.75]:.0f} games): avg adjustment = {score_diff[clean_data['num_games'] > quartiles[0.75]].mean():.6f}\"\n",
    ")\n",
    "\n",
    "# New score distribution after adjustment\n",
    "print(f\"\\n5Ô∏è‚É£  Adjusted score statistics:\")\n",
    "print(f\"   ‚Ä¢ Min: {clean_data['score'].min():.4f}\")\n",
    "print(f\"   ‚Ä¢ 25th percentile: {clean_data['score'].quantile(0.25):.4f}\")\n",
    "print(f\"   ‚Ä¢ Median: {clean_data['score'].median():.4f}\")\n",
    "print(f\"   ‚Ä¢ 75th percentile: {clean_data['score'].quantile(0.75):.4f}\")\n",
    "print(f\"   ‚Ä¢ Max: {clean_data['score'].max():.4f}\")\n",
    "print(f\"   ‚Ä¢ Mean: {clean_data['score'].mean():.4f}\")\n",
    "print(f\"   ‚Ä¢ Std: {clean_data['score'].std():.4f}\")\n",
    "\n",
    "# Detailed sample showing the effect across different game counts\n",
    "print(f\"\\n6Ô∏è‚É£  Sample comparisons (showing effect of hierarchical shrinkage):\")\n",
    "print(f\"\\n   {'='*120}\")\n",
    "print(f\"   Low-game entries (10-20 games) - HIGH shrinkage toward opening mean:\")\n",
    "print(f\"   {'='*120}\")\n",
    "\n",
    "low_game_sample = clean_data[\n",
    "    (clean_data[\"num_games\"] >= 10) & (clean_data[\"num_games\"] <= 20)\n",
    "].sample(\n",
    "    min(\n",
    "        10,\n",
    "        len(\n",
    "            clean_data[\n",
    "                (clean_data[\"num_games\"] >= 10) & (clean_data[\"num_games\"] <= 20)\n",
    "            ]\n",
    "        ),\n",
    "    ),\n",
    "    random_state=42,\n",
    ")\n",
    "for idx, row in low_game_sample.iterrows():\n",
    "    adjustment = row[\"score\"] - row[\"score_original\"]\n",
    "    print(\n",
    "        f\"   Player {row['player_id']:>5} | Opening {row['opening_id']:>4} | Games: {row['num_games']:>3} | \"\n",
    "        f\"Opening mean: {row['opening_mean']:.4f} | Original: {row['score_original']:.4f} ‚Üí Adjusted: {row['score']:.4f} | \"\n",
    "        f\"Diff: {adjustment:>+.4f} | Confidence: {row['confidence']:.3f}\"\n",
    "    )\n",
    "\n",
    "print(f\"\\n   {'='*120}\")\n",
    "print(f\"   Medium-game entries (50-100 games) - MODERATE shrinkage:\")\n",
    "print(f\"   {'='*120}\")\n",
    "\n",
    "med_game_sample = clean_data[\n",
    "    (clean_data[\"num_games\"] >= 50) & (clean_data[\"num_games\"] <= 100)\n",
    "].sample(\n",
    "    min(\n",
    "        10,\n",
    "        len(\n",
    "            clean_data[\n",
    "                (clean_data[\"num_games\"] >= 50) & (clean_data[\"num_games\"] <= 100)\n",
    "            ]\n",
    "        ),\n",
    "    ),\n",
    "    random_state=42,\n",
    ")\n",
    "for idx, row in med_game_sample.iterrows():\n",
    "    adjustment = row[\"score\"] - row[\"score_original\"]\n",
    "    print(\n",
    "        f\"   Player {row['player_id']:>5} | Opening {row['opening_id']:>4} | Games: {row['num_games']:>3} | \"\n",
    "        f\"Opening mean: {row['opening_mean']:.4f} | Original: {row['score_original']:.4f} ‚Üí Adjusted: {row['score']:.4f} | \"\n",
    "        f\"Diff: {adjustment:>+.4f} | Confidence: {row['confidence']:.3f}\"\n",
    "    )\n",
    "\n",
    "print(f\"\\n   {'='*120}\")\n",
    "print(f\"   High-game entries (200+ games) - LOW shrinkage:\")\n",
    "print(f\"   {'='*120}\")\n",
    "\n",
    "high_game_sample = clean_data[clean_data[\"num_games\"] >= 200].sample(\n",
    "    min(10, len(clean_data[clean_data[\"num_games\"] >= 200])), random_state=42\n",
    ")\n",
    "for idx, row in high_game_sample.iterrows():\n",
    "    adjustment = row[\"score\"] - row[\"score_original\"]\n",
    "    print(\n",
    "        f\"   Player {row['player_id']:>5} | Opening {row['opening_id']:>4} | Games: {row['num_games']:>3} | \"\n",
    "        f\"Opening mean: {row['opening_mean']:.4f} | Original: {row['score_original']:.4f} ‚Üí Adjusted: {row['score']:.4f} | \"\n",
    "        f\"Diff: {adjustment:>+.4f} | Confidence: {row['confidence']:.3f}\"\n",
    "    )\n",
    "\n",
    "# Show extreme cases - comparing to both opening mean AND global mean\n",
    "print(f\"\\n7Ô∏è‚É£  Extreme cases (showing why opening-specific shrinkage matters):\")\n",
    "\n",
    "# Find entries where opening mean differs significantly from global mean\n",
    "clean_data[\"opening_deviation_from_global\"] = (\n",
    "    clean_data[\"opening_mean\"] - global_mean_score\n",
    ").abs()\n",
    "\n",
    "print(f\"\\n   Openings with HIGHEST win rates (strong for White):\")\n",
    "strong_openings = clean_data.nlargest(5, \"opening_mean\")[\n",
    "    [\"opening_id\", \"opening_mean\", \"eco\"]\n",
    "].drop_duplicates(\"opening_id\")\n",
    "for idx, row in strong_openings.iterrows():\n",
    "    num_entries = len(clean_data[clean_data[\"opening_id\"] == row[\"opening_id\"]])\n",
    "    deviation = row[\"opening_mean\"] - global_mean_score\n",
    "    print(\n",
    "        f\"   Opening {row['opening_id']:>4} ({row['eco']:>3}): mean = {row['opening_mean']:.4f} \"\n",
    "        f\"(+{deviation:.4f} vs global) | {num_entries} player entries\"\n",
    "    )\n",
    "\n",
    "print(f\"\\n   Openings with LOWEST win rates (weak for White):\")\n",
    "weak_openings = clean_data.nsmallest(5, \"opening_mean\")[\n",
    "    [\"opening_id\", \"opening_mean\", \"eco\"]\n",
    "].drop_duplicates(\"opening_id\")\n",
    "for idx, row in weak_openings.iterrows():\n",
    "    num_entries = len(clean_data[clean_data[\"opening_id\"] == row[\"opening_id\"]])\n",
    "    deviation = row[\"opening_mean\"] - global_mean_score\n",
    "    print(\n",
    "        f\"   Opening {row['opening_id']:>4} ({row['eco']:>3}): mean = {row['opening_mean']:.4f} \"\n",
    "        f\"({deviation:.4f} vs global) | {num_entries} player entries\"\n",
    "    )\n",
    "\n",
    "# Show specific examples where hierarchical shrinkage made a difference\n",
    "print(f\"\\n8Ô∏è‚É£  Examples showing hierarchical shrinkage benefit:\")\n",
    "\n",
    "# Find entries with strong openings where player did well\n",
    "strong_opening_ids = clean_data.nlargest(50, \"opening_mean\")[\"opening_id\"].unique()\n",
    "strong_examples = clean_data[\n",
    "    (clean_data[\"opening_id\"].isin(strong_opening_ids))\n",
    "    & (clean_data[\"num_games\"] <= 20)\n",
    "    & (clean_data[\"score_original\"] > 0.6)\n",
    "].sample(\n",
    "    min(\n",
    "        3,\n",
    "        len(\n",
    "            clean_data[\n",
    "                (clean_data[\"opening_id\"].isin(strong_opening_ids))\n",
    "                & (clean_data[\"num_games\"] <= 20)\n",
    "                & (clean_data[\"score_original\"] > 0.6)\n",
    "            ]\n",
    "        ),\n",
    "    ),\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\n   Strong opening + good player performance (shrunk toward HIGH opening mean):\"\n",
    ")\n",
    "for idx, row in strong_examples.iterrows():\n",
    "    adjustment = row[\"score\"] - row[\"score_original\"]\n",
    "    global_shrink_would_be = (\n",
    "        (row[\"num_games\"] * row[\"score_original\"]) + (K_PLAYER * global_mean_score)\n",
    "    ) / (row[\"num_games\"] + K_PLAYER)\n",
    "    difference = row[\"score\"] - global_shrink_would_be\n",
    "    print(\n",
    "        f\"   Player {row['player_id']:>5} | Opening {row['opening_id']:>4} ({row['eco']:>3}) | Games: {row['num_games']:>2} | \"\n",
    "        f\"Opening mean: {row['opening_mean']:.4f} | Original: {row['score_original']:.4f} ‚Üí {row['score']:.4f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"      If we'd shrunk to global mean: {global_shrink_would_be:.4f} (would lose {difference:+.4f} of deserved credit)\"\n",
    "    )\n",
    "\n",
    "# Find entries with weak openings where player did poorly\n",
    "weak_opening_ids = clean_data.nsmallest(50, \"opening_mean\")[\"opening_id\"].unique()\n",
    "weak_examples = clean_data[\n",
    "    (clean_data[\"opening_id\"].isin(weak_opening_ids))\n",
    "    & (clean_data[\"num_games\"] <= 20)\n",
    "    & (clean_data[\"score_original\"] < 0.45)\n",
    "].sample(\n",
    "    min(\n",
    "        3,\n",
    "        len(\n",
    "            clean_data[\n",
    "                (clean_data[\"opening_id\"].isin(weak_opening_ids))\n",
    "                & (clean_data[\"num_games\"] <= 20)\n",
    "                & (clean_data[\"score_original\"] < 0.45)\n",
    "            ]\n",
    "        ),\n",
    "    ),\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(f\"\\n   Weak opening + poor player performance (shrunk toward LOW opening mean):\")\n",
    "for idx, row in weak_examples.iterrows():\n",
    "    adjustment = row[\"score\"] - row[\"score_original\"]\n",
    "    global_shrink_would_be = (\n",
    "        (row[\"num_games\"] * row[\"score_original\"]) + (K_PLAYER * global_mean_score)\n",
    "    ) / (row[\"num_games\"] + K_PLAYER)\n",
    "    difference = row[\"score\"] - global_shrink_would_be\n",
    "    print(\n",
    "        f\"   Player {row['player_id']:>5} | Opening {row['opening_id']:>4} ({row['eco']:>3}) | Games: {row['num_games']:>2} | \"\n",
    "        f\"Opening mean: {row['opening_mean']:.4f} | Original: {row['score_original']:.4f} ‚Üí {row['score']:.4f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"      If we'd shrunk to global mean: {global_shrink_would_be:.4f} (would unfairly boost by {-difference:+.4f})\"\n",
    "    )\n",
    "\n",
    "# Drop temporary columns\n",
    "print(f\"\\n9Ô∏è‚É£  Cleaning up...\")\n",
    "clean_data = clean_data.drop(\n",
    "    columns=[\"score_original\", \"opening_mean\", \"opening_deviation_from_global\"]\n",
    ")\n",
    "print(f\"   ‚úì Removed temporary columns\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ HIERARCHICAL BAYESIAN ADJUSTMENT COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nFinal data shape: {clean_data.shape}\")\n",
    "print(f\"Columns: {list(clean_data.columns)}\")\n",
    "print(f\"\\nNew columns added:\")\n",
    "print(f\"   ‚Ä¢ 'confidence': weight for loss function (range [0,1])\")\n",
    "print(f\"   ‚Ä¢ 'score': adjusted using hierarchical Bayesian shrinkage\")\n",
    "print(f\"\\nKey improvement over simple shrinkage:\")\n",
    "print(f\"   ‚Ä¢ Player scores now shrink toward OPENING-SPECIFIC means, not global mean\")\n",
    "print(f\"   ‚Ä¢ Preserves opening difficulty differences\")\n",
    "print(f\"   ‚Ä¢ More accurate for both strong and weak openings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73319d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         player_id  opening_id  num_games     score  eco  confidence\n",
      "2975878      50000        1520         31  0.525188  C20    0.382716\n",
      "2975879      50000        1642         19  0.532716  C30    0.275362\n",
      "2975880      50000        1665         42  0.510040  C30    0.456522\n",
      "2975881      50000        1673         12  0.496546  C31    0.193548\n",
      "2975882      50000        1740         24  0.542961  C34    0.324324\n",
      "2975883      50000        1748         15  0.519497  C36    0.230769\n",
      "2975884      50000        2443         15  0.565022  D00    0.230769\n",
      "2975885      50000        2668         10  0.507630  D35    0.166667\n",
      "2975886      50000        3163         12  0.529981  B02    0.193548\n",
      "2975887      50000        3242         13  0.565552  C34    0.206349\n"
     ]
    }
   ],
   "source": [
    "print(clean_data.sample().to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
