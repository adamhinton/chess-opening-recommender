{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40e163a7",
   "metadata": {},
   "source": [
    "# Notebook 26 ‚Äî Opening Recommender Model: Training Pipeline\n",
    "\n",
    "### 0. Overview and Goals\n",
    "\n",
    "This notebook defines the full pipeline for training the chess opening recommender model.  \n",
    "The objective is to predict **player‚Äìopening performance scores** ((wins + (0.5 * draws) / num games)) for openings a player hasn‚Äôt yet played, based on their results in the openings they *have* played.  \n",
    "\n",
    "The model will use **matrix factorization** with **stochastic gradient descent (SGD)** to learn latent factors representing player and opening characteristics.  \n",
    "All computations will be implemented in **PyTorch**, with data loaded from my local **DuckDB** database.\n",
    "\n",
    "**High-level specs:**\n",
    "- Use only *White* openings initially (we‚Äôll extend to Black later).  \n",
    "- Data source: processed player‚Äìopening stats from local DuckDB.  \n",
    "- Predict: normalized ‚Äúscore‚Äù = win rate ((wins + 0.5 x draws) / total games).  \n",
    "- Filter: only include entries with ‚â• `MIN_GAMES_THRESHOLD` (default = 50).  \n",
    "- Ignore: rating differences, time controls, and other metadata.  \n",
    "- Model parameters (to be defined in appropriate places for easy editing):  \n",
    "  - `NUM_FACTORS`, `LEARNING_RATE`, `BATCH_SIZE`, `N_EPOCHS`, `NUM_PLAYERS_TO_PROCESS`  \n",
    "- Logging and checkpoints throughout for reproducibility.  \n",
    "- All random operations seeded for deterministic runs.  \n",
    "\n",
    "---\n",
    "\n",
    "### 1. Data Extraction\n",
    "- Connect to local DuckDB\n",
    "- Pull all processed player‚Äìopening statistics from\n",
    "- Verify schema consistency:  \n",
    "  - Required columns: `player_id`, `opening_id`, `eco`, `num_games`, `wins`, `draws`, `losses`.  \n",
    "- Include a row-count sanity check.\n",
    "- Only players with ratings above 1200\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Data Sanitization & Normalization\n",
    "- Optionally normalize scores if needed for MF convergence.  \n",
    "- Drop players with no qualifying openings and openings with no qualifying players.  \n",
    "  - I believe there shouldn't be any but we'll double check.\n",
    "- Resequence player_id and opening_id to be sequential integers - right now there are gaps because of entries we deleted from the DB \n",
    "- Check for sparsity consistency (no implicit zeros yet).  \n",
    "- Note that this data has already been split in to white and black games further up the pipeline\n",
    "\n",
    "### Data Quality\n",
    "- Drop entries with fewer than `MIN_GAMES_THRESHOLD` games\n",
    "- Handle any duplicate `(player_id, opening_id)` combinations\n",
    "- Remove players with no qualifying openings\n",
    "- Remove openings with no qualifying players\n",
    "- Verify no null values remain\n",
    "\n",
    "### ECO Codes\n",
    "- Keep ECO codes for later categorical encoding (Step 4)\n",
    "- ECO will be used as opening side information (similar to rating for players)\n",
    "\n",
    "### Confidence Weighting\n",
    "- Use `MIN_GAMES_THRESHOLD = 10` to keep more data\n",
    "- Add a **confidence weight** column: `confidence = num_games / (num_games + K)` where K ‚âà 50\n",
    "- This weight will be used in the loss function to down-weight uncertain predictions\n",
    "- High-game-count entries ‚Üí high confidence ‚Üí larger loss impact\n",
    "- Low-game-count entries ‚Üí low confidence ‚Üí smaller loss impact\n",
    "\n",
    "### Player Rating (Side Information)\n",
    "- **Player ratings are side information** - they describe player characteristics, not individual player-opening interactions\n",
    "- Ratings will be stored separately and joined to player embeddings during training\n",
    "- We'll **normalize ratings** (likely z-score normalization) to avoid scaling issues with the embedding layer\n",
    "- Rating normalization will be done once after extraction, not per-row\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Data Splits\n",
    "- Split into train/test/val sets.  \n",
    "- Ensure every player and every opening appears at least once in the training data.  \n",
    "- Strategy:  \n",
    "  - Sample unique players and openings to guarantee coverage in train.  \n",
    "  - Remaining data ‚Üí stratified random split into train/test.  \n",
    "  - Deduplicate and merge unique IDs back into train if needed.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Enumerate Categorical Variables\n",
    "- Enumerate `eco` (if included) as an integer categorical variable.  \n",
    "- Confirm all columns are numeric and compatible with PyTorch tensors.  \n",
    "- Verify no missing or out-of-range IDs.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Training Data Structure\n",
    "- Each row: one `(player_id, opening_id, score)` record.\n",
    "- Include other fields- eco, num games etc\n",
    "- Convert DataFrame to PyTorch tensors (`torch.long` for IDs, `torch.float` for scores).  \n",
    "- Log dataset shapes and sparsity metrics.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Training Setup\n",
    "Define constants:\n",
    "- `LEARNING_RATE`, `BATCH_SIZE`, `N_EPOCHS`, `NUM_FACTORS`  \n",
    "- Loss functions: MSE and RMSE  \n",
    "- Activation: sigmoid or none (depending on score normalization)  \n",
    "- Optimizer: SGD  \n",
    "- Figure out if there's anything else we need to design or specify\n",
    "\n",
    "Implement helper functions:\n",
    "- `train_one_epoch()`\n",
    "- `evaluate_model()`\n",
    "- `calculate_rmse()`\n",
    "- `save_checkpoint()`  \n",
    "\n",
    "Ensure detailed logging, ETA reporting, and reproducible random seeds.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Training Loop\n",
    "- Initialize player and opening embeddings.  \n",
    "- Iterate through epochs with mini-batch SGD (`BATCH_SIZE = 1024`).  \n",
    "- Compute and log MSE/RMSE per epoch.  \n",
    "- Save model checkpoints locally after each epoch.\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Evaluation\n",
    "- Evaluate on test set.  \n",
    "- Report MSE, RMSE, and visual diagnostics (predicted vs actual score).  \n",
    "- Inspect a few player and opening latent factors for sanity.\n",
    "\n",
    "---\n",
    "\n",
    "### 9. Cross-Validation & Hyperparameter Tuning\n",
    "- Define ranges for:  \n",
    "  - `NUM_FACTORS`, `LEARNING_RATE`, `BATCH_SIZE`, `N_EPOCHS`  \n",
    "- Perform small-scale grid or random search for best configuration.  \n",
    "- Compare validation RMSE across runs.\n",
    "\n",
    "---\n",
    "\n",
    "### 10. Next Steps\n",
    "- Extend model to include Black openings.  \n",
    "- Experiment with hybrid inputs (player rating, ECO grouping).  \n",
    "- Consider implicit feedback handling (unplayed openings as zeros).  \n",
    "- Integrate trained model into API for recommendation output.\n",
    "\n",
    "---\n",
    "\n",
    "**Notes:**  \n",
    "- Every random seed and parameter definition will be explicit.  \n",
    "- Every major step includes row-count, schema, and type validation.  \n",
    "- Model artifacts and logs will be saved locally for reproducibility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc6d823",
   "metadata": {},
   "source": [
    "## Step 1: Data Extraction\n",
    "\n",
    "Connect to DuckDB and extract all player-opening statistics.\n",
    "Verify schema and perform sanity checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fcea569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 1: DATA EXTRACTION\n",
      "============================================================\n",
      "\n",
      "üìÅ Database: /Users/a/Documents/personalprojects/chess-opening-recommender/data/processed/chess_games.db\n",
      "üìÅ Database exists: True\n",
      "üé® Color filter: White\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# Add utils to path\n",
    "sys.path.append(str(Path.cwd() / 'utils'))\n",
    "from database.db_utils import get_db_connection\n",
    "\n",
    "# Configuration\n",
    "DB_PATH = Path.cwd().parent / \"data\" / \"processed\" / \"chess_games.db\"\n",
    "COLOR_FILTER = 'w'  # 'w' for white, 'b' for black\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 1: DATA EXTRACTION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüìÅ Database: {DB_PATH}\")\n",
    "print(f\"üìÅ Database exists: {DB_PATH.exists()}\")\n",
    "print(f\"üé® Color filter: {'White' if COLOR_FILTER == 'w' else 'Black'}\")\n",
    "\n",
    "if not DB_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Database not found at {DB_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9435033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1Ô∏è‚É£  Extracting player-opening statistics (color: 'w')...\n",
      "   ‚Ä¢ Minimum rating filter: 1200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55af0ebb7194365bb2ac109f59ca8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Extracted 11,802,584 rows\n",
      "\n",
      "2Ô∏è‚É£  Verifying schema...\n",
      "   ‚úì All required columns present: ['player_id', 'opening_id', 'num_games', 'score', 'eco']\n",
      "\n",
      "3Ô∏è‚É£  Checking data types...\n",
      "   ‚Ä¢ player_id: int32\n",
      "   ‚Ä¢ opening_id: int32\n",
      "   ‚Ä¢ num_games: int32\n",
      "   ‚Ä¢ score: float64\n",
      "   ‚Ä¢ eco: object\n",
      "\n",
      "4Ô∏è‚É£  Data statistics...\n",
      "   ‚Ä¢ Total rows: 11,802,584\n",
      "   ‚Ä¢ Unique players: 49,551\n",
      "   ‚Ä¢ Unique openings: 2,991\n",
      "   ‚Ä¢ Total games (sum): 233,559,168\n",
      "\n",
      "   Player ID range:\n",
      "   ‚Ä¢ Min: 1\n",
      "   ‚Ä¢ Max: 50000\n",
      "\n",
      "   Opening ID range:\n",
      "   ‚Ä¢ Min: 2\n",
      "   ‚Ä¢ Max: 3589\n",
      "\n",
      "   Games per entry:\n",
      "   ‚Ä¢ Min: 1\n",
      "   ‚Ä¢ Max: 13462\n",
      "   ‚Ä¢ Mean: 19.8\n",
      "   ‚Ä¢ Median: 3\n",
      "\n",
      "   Score distribution:\n",
      "   ‚Ä¢ Min: 0.0000\n",
      "   ‚Ä¢ Max: 1.0000\n",
      "   ‚Ä¢ Mean: 0.5007\n",
      "   ‚Ä¢ Median: 3\n",
      "\n",
      "   Score distribution:\n",
      "   ‚Ä¢ Min: 0.0000\n",
      "   ‚Ä¢ Max: 1.0000\n",
      "   ‚Ä¢ Mean: 0.5007\n",
      "   ‚Ä¢ Median: 0.5000\n",
      "\n",
      "5Ô∏è‚É£  Checking for null values...\n",
      "   ‚Ä¢ Median: 0.5000\n",
      "\n",
      "5Ô∏è‚É£  Checking for null values...\n",
      "   ‚úì No null values found\n",
      "\n",
      "6Ô∏è‚É£  Sample of extracted data (first 10 rows):\n",
      "   player_id  opening_id  num_games     score  eco\n",
      "0          1          39          6  0.666667  A00\n",
      "1          1          49          2  0.500000  A00\n",
      "2          1          53          1  0.000000  A00\n",
      "3          1         182          1  0.000000  A04\n",
      "4          1         187          1  1.000000  A04\n",
      "5          1         671          3  1.000000  B00\n",
      "6          1         675          3  0.000000  B00\n",
      "7          1         677          6  0.333333  B00\n",
      "8          1         688         25  0.620000  B00\n",
      "9          1         717          1  1.000000  B00\n",
      "\n",
      "============================================================\n",
      "‚úÖ DATA EXTRACTION COMPLETE\n",
      "============================================================\n",
      "\n",
      "Data shape: (11802584, 5)\n",
      "Columns: ['player_id', 'opening_id', 'num_games', 'score', 'eco']\n",
      "\n",
      "‚úì Database connection closed\n",
      "   ‚úì No null values found\n",
      "\n",
      "6Ô∏è‚É£  Sample of extracted data (first 10 rows):\n",
      "   player_id  opening_id  num_games     score  eco\n",
      "0          1          39          6  0.666667  A00\n",
      "1          1          49          2  0.500000  A00\n",
      "2          1          53          1  0.000000  A00\n",
      "3          1         182          1  0.000000  A04\n",
      "4          1         187          1  1.000000  A04\n",
      "5          1         671          3  1.000000  B00\n",
      "6          1         675          3  0.000000  B00\n",
      "7          1         677          6  0.333333  B00\n",
      "8          1         688         25  0.620000  B00\n",
      "9          1         717          1  1.000000  B00\n",
      "\n",
      "============================================================\n",
      "‚úÖ DATA EXTRACTION COMPLETE\n",
      "============================================================\n",
      "\n",
      "Data shape: (11802584, 5)\n",
      "Columns: ['player_id', 'opening_id', 'num_games', 'score', 'eco']\n",
      "\n",
      "‚úì Database connection closed\n"
     ]
    }
   ],
   "source": [
    "# Connect to DuckDB and extract player-opening statistics\n",
    "con = get_db_connection(str(DB_PATH))\n",
    "\n",
    "try:\n",
    "    print(f\"\\n1Ô∏è‚É£  Extracting player-opening statistics (color: '{COLOR_FILTER}')...\")\n",
    "    \n",
    "    # Extract stats with calculated score and num_games\n",
    "    # Filter by color, minimum rating, and calculate score in the database\n",
    "    MIN_RATING = 1200\n",
    "    print(f\"   ‚Ä¢ Minimum rating filter: {MIN_RATING}\")\n",
    "    \n",
    "    query = f\"\"\"\n",
    "        SELECT \n",
    "            pos.player_id,\n",
    "            pos.opening_id,\n",
    "            pos.num_wins + pos.num_draws + pos.num_losses as num_games,\n",
    "            (pos.num_wins + (pos.num_draws * 0.5)) / \n",
    "                NULLIF(pos.num_wins + pos.num_draws + pos.num_losses, 0) as score,\n",
    "            o.eco\n",
    "        FROM player_opening_stats pos\n",
    "        JOIN opening o ON pos.opening_id = o.id\n",
    "        JOIN player p ON pos.player_id = p.id\n",
    "        WHERE pos.color = '{COLOR_FILTER}'\n",
    "        AND p.rating >= {MIN_RATING}\n",
    "        ORDER BY pos.player_id, pos.opening_id\n",
    "    \"\"\"\n",
    "    \n",
    "    raw_data = pd.DataFrame(con.execute(query).df())\n",
    "    \n",
    "    print(f\"   ‚úì Extracted {len(raw_data):,} rows\")\n",
    "    \n",
    "    # Schema verification\n",
    "    print(\"\\n2Ô∏è‚É£  Verifying schema...\")\n",
    "    required_columns = ['player_id', 'opening_id', 'num_games', 'score', 'eco']\n",
    "    \n",
    "    for col in required_columns:\n",
    "        if col not in raw_data.columns:\n",
    "            raise ValueError(f\"Missing required column: {col}\")\n",
    "    \n",
    "    print(f\"   ‚úì All required columns present: {required_columns}\")\n",
    "    \n",
    "    # Data types verification\n",
    "    print(\"\\n3Ô∏è‚É£  Checking data types...\")\n",
    "    print(f\"   ‚Ä¢ player_id: {raw_data['player_id'].dtype}\")\n",
    "    print(f\"   ‚Ä¢ opening_id: {raw_data['opening_id'].dtype}\")\n",
    "    print(f\"   ‚Ä¢ num_games: {raw_data['num_games'].dtype}\")\n",
    "    print(f\"   ‚Ä¢ score: {raw_data['score'].dtype}\")\n",
    "    print(f\"   ‚Ä¢ eco: {raw_data['eco'].dtype}\")\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(\"\\n4Ô∏è‚É£  Data statistics...\")\n",
    "    print(f\"   ‚Ä¢ Total rows: {len(raw_data):,}\")\n",
    "    print(f\"   ‚Ä¢ Unique players: {raw_data['player_id'].nunique():,}\")\n",
    "    print(f\"   ‚Ä¢ Unique openings: {raw_data['opening_id'].nunique():,}\")\n",
    "    print(f\"   ‚Ä¢ Total games (sum): {raw_data['num_games'].sum():,}\")\n",
    "    \n",
    "    # Player ID range\n",
    "    print(f\"\\n   Player ID range:\")\n",
    "    print(f\"   ‚Ä¢ Min: {raw_data['player_id'].min()}\")\n",
    "    print(f\"   ‚Ä¢ Max: {raw_data['player_id'].max()}\")\n",
    "    \n",
    "    # Opening ID range\n",
    "    print(f\"\\n   Opening ID range:\")\n",
    "    print(f\"   ‚Ä¢ Min: {raw_data['opening_id'].min()}\")\n",
    "    print(f\"   ‚Ä¢ Max: {raw_data['opening_id'].max()}\")\n",
    "    \n",
    "    # Games per entry statistics\n",
    "    print(f\"\\n   Games per entry:\")\n",
    "    print(f\"   ‚Ä¢ Min: {raw_data['num_games'].min()}\")\n",
    "    print(f\"   ‚Ä¢ Max: {raw_data['num_games'].max()}\")\n",
    "    print(f\"   ‚Ä¢ Mean: {raw_data['num_games'].mean():.1f}\")\n",
    "    print(f\"   ‚Ä¢ Median: {raw_data['num_games'].median():.0f}\")\n",
    "    \n",
    "    # Score statistics\n",
    "    print(f\"\\n   Score distribution:\")\n",
    "    print(f\"   ‚Ä¢ Min: {raw_data['score'].min():.4f}\")\n",
    "    print(f\"   ‚Ä¢ Max: {raw_data['score'].max():.4f}\")\n",
    "    print(f\"   ‚Ä¢ Mean: {raw_data['score'].mean():.4f}\")\n",
    "    print(f\"   ‚Ä¢ Median: {raw_data['score'].median():.4f}\")\n",
    "    \n",
    "    # Check for null values\n",
    "    print(\"\\n5Ô∏è‚É£  Checking for null values...\")\n",
    "    null_counts = raw_data.isnull().sum()\n",
    "    if null_counts.sum() == 0:\n",
    "        print(\"   ‚úì No null values found\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  Found null values:\")\n",
    "        for col, count in null_counts[null_counts > 0].items():\n",
    "            print(f\"      ‚Ä¢ {col}: {count} nulls\")\n",
    "    \n",
    "    # Sample data\n",
    "    print(\"\\n6Ô∏è‚É£  Sample of extracted data (first 10 rows):\")\n",
    "    print(raw_data.head(10).to_string())\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úÖ DATA EXTRACTION COMPLETE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nData shape: {raw_data.shape}\")\n",
    "    print(f\"Columns: {list(raw_data.columns)}\")\n",
    "    \n",
    "finally:\n",
    "    con.close()\n",
    "    print(\"\\n‚úì Database connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad110b85",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "519d8f2f",
   "metadata": {},
   "source": [
    "## Step 2: Data Sanitization & Normalization\n",
    "\n",
    "Filter low-quality data, handle duplicates, and prepare for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e74f0b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 2: DATA SANITIZATION & NORMALIZATION\n",
      "============================================================\n",
      "\n",
      "‚öôÔ∏è  Configuration:\n",
      "   ‚Ä¢ MIN_GAMES_THRESHOLD: 10\n",
      "\n",
      "üìä Starting data shape: (11802584, 5)\n",
      "   ‚Ä¢ Rows: 11,802,584\n",
      "   ‚Ä¢ Unique players: 49,551\n",
      "   ‚Ä¢ Unique openings: 2,991\n",
      "\n",
      "1Ô∏è‚É£  Filtering entries with < 10 games...\n",
      "   ‚Ä¢ Unique openings: 2,991\n",
      "\n",
      "1Ô∏è‚É£  Filtering entries with < 10 games...\n",
      "   ‚Ä¢ Before: 11,802,584 rows\n",
      "   ‚Ä¢ After: 2,956,680 rows\n",
      "   ‚Ä¢ Filtered out: 8,845,904 rows (74.9%)\n",
      "\n",
      "2Ô∏è‚É£  Checking for duplicate (player_id, opening_id) combinations...\n",
      "   ‚Ä¢ Before: 11,802,584 rows\n",
      "   ‚Ä¢ After: 2,956,680 rows\n",
      "   ‚Ä¢ Filtered out: 8,845,904 rows (74.9%)\n",
      "\n",
      "2Ô∏è‚É£  Checking for duplicate (player_id, opening_id) combinations...\n",
      "   ‚úì No duplicates found\n",
      "\n",
      "3Ô∏è‚É£  Removing players with no qualifying openings...\n",
      "   ‚úì No duplicates found\n",
      "\n",
      "3Ô∏è‚É£  Removing players with no qualifying openings...\n",
      "   ‚Ä¢ Players before: 49,467\n",
      "   ‚Ä¢ Players after: 49,467\n",
      "   ‚Ä¢ Removed: 0\n",
      "\n",
      "4Ô∏è‚É£  Removing openings with no qualifying players...\n",
      "   ‚Ä¢ Openings before: 2,717\n",
      "   ‚Ä¢ Openings after: 2,717\n",
      "   ‚Ä¢ Removed: 0\n",
      "\n",
      "5Ô∏è‚É£  Verifying no null values...\n",
      "   ‚Ä¢ Players before: 49,467\n",
      "   ‚Ä¢ Players after: 49,467\n",
      "   ‚Ä¢ Removed: 0\n",
      "\n",
      "4Ô∏è‚É£  Removing openings with no qualifying players...\n",
      "   ‚Ä¢ Openings before: 2,717\n",
      "   ‚Ä¢ Openings after: 2,717\n",
      "   ‚Ä¢ Removed: 0\n",
      "\n",
      "5Ô∏è‚É£  Verifying no null values...\n",
      "   ‚úì No null values found\n",
      "\n",
      "6Ô∏è‚É£  Final data statistics:\n",
      "   ‚Ä¢ Total rows: 2,956,680\n",
      "   ‚Ä¢ Unique players: 49,467\n",
      "   ‚Ä¢ Unique openings: 2,717\n",
      "   ‚Ä¢ Total games: 210,502,938\n",
      "   ‚Ä¢ Avg games per entry: 71.2\n",
      "   ‚Ä¢ Avg openings per player: 59.8\n",
      "   ‚Ä¢ Avg players per opening: 1088.2\n",
      "\n",
      "   Score statistics:\n",
      "   ‚Ä¢ Min: 0.0000\n",
      "   ‚úì No null values found\n",
      "\n",
      "6Ô∏è‚É£  Final data statistics:\n",
      "   ‚Ä¢ Total rows: 2,956,680\n",
      "   ‚Ä¢ Unique players: 49,467\n",
      "   ‚Ä¢ Unique openings: 2,717\n",
      "   ‚Ä¢ Total games: 210,502,938\n",
      "   ‚Ä¢ Avg games per entry: 71.2\n",
      "   ‚Ä¢ Avg openings per player: 59.8\n",
      "   ‚Ä¢ Avg players per opening: 1088.2\n",
      "\n",
      "   Score statistics:\n",
      "   ‚Ä¢ Min: 0.0000\n",
      "   ‚Ä¢ 25th percentile: 0.4500\n",
      "   ‚Ä¢ Median: 0.5125\n",
      "   ‚Ä¢ 75th percentile: 0.5750\n",
      "   ‚Ä¢ Max: 1.0000\n",
      "   ‚Ä¢ Mean: 0.5111\n",
      "   ‚Ä¢ Std: 0.1083\n",
      "\n",
      "7Ô∏è‚É£  Sample of cleaned data (10 random rows):\n",
      "         player_id  opening_id  num_games     score  eco\n",
      "1895626      31381         937         38  0.513158  B12\n",
      "304455        5028         439         15  0.600000  A43\n",
      "1467119      24344        3148         16  0.562500  A00\n",
      "629419       10369         400         10  0.600000  A40\n",
      "2563024      42505        2306         46  0.608696  C77\n",
      "2905339      48721        3238         18  0.472222  A53\n",
      "737637       12117         794        318  0.511006  B02\n",
      "285531        4712        2206         30  0.600000  C60\n",
      "1732664      28672        3214         15  0.566667  A40\n",
      "2776786      46177        2428         11  0.545455  D00\n",
      "\n",
      "============================================================\n",
      "‚úÖ DATA SANITIZATION COMPLETE\n",
      "============================================================\n",
      "\n",
      "Cleaned data shape: (2956680, 5)\n",
      "Data reduction: 74.9%\n",
      "   ‚Ä¢ 25th percentile: 0.4500\n",
      "   ‚Ä¢ Median: 0.5125\n",
      "   ‚Ä¢ 75th percentile: 0.5750\n",
      "   ‚Ä¢ Max: 1.0000\n",
      "   ‚Ä¢ Mean: 0.5111\n",
      "   ‚Ä¢ Std: 0.1083\n",
      "\n",
      "7Ô∏è‚É£  Sample of cleaned data (10 random rows):\n",
      "         player_id  opening_id  num_games     score  eco\n",
      "1895626      31381         937         38  0.513158  B12\n",
      "304455        5028         439         15  0.600000  A43\n",
      "1467119      24344        3148         16  0.562500  A00\n",
      "629419       10369         400         10  0.600000  A40\n",
      "2563024      42505        2306         46  0.608696  C77\n",
      "2905339      48721        3238         18  0.472222  A53\n",
      "737637       12117         794        318  0.511006  B02\n",
      "285531        4712        2206         30  0.600000  C60\n",
      "1732664      28672        3214         15  0.566667  A40\n",
      "2776786      46177        2428         11  0.545455  D00\n",
      "\n",
      "============================================================\n",
      "‚úÖ DATA SANITIZATION COMPLETE\n",
      "============================================================\n",
      "\n",
      "Cleaned data shape: (2956680, 5)\n",
      "Data reduction: 74.9%\n"
     ]
    }
   ],
   "source": [
    "# 2a. Filter low-quality data, handle duplicates, and prepare for training.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Configuration\n",
    "MIN_GAMES_THRESHOLD = 10\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 2: DATA SANITIZATION & NORMALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n‚öôÔ∏è  Configuration:\")\n",
    "print(f\"   ‚Ä¢ MIN_GAMES_THRESHOLD: {MIN_GAMES_THRESHOLD}\")\n",
    "\n",
    "# Start with raw_data from Step 1\n",
    "print(f\"\\nüìä Starting data shape: {raw_data.shape}\")\n",
    "print(f\"   ‚Ä¢ Rows: {len(raw_data):,}\")\n",
    "print(f\"   ‚Ä¢ Unique players: {raw_data['player_id'].nunique():,}\")\n",
    "print(f\"   ‚Ä¢ Unique openings: {raw_data['opening_id'].nunique():,}\")\n",
    "\n",
    "# 1. Filter by minimum games threshold\n",
    "print(f\"\\n1Ô∏è‚É£  Filtering entries with < {MIN_GAMES_THRESHOLD} games...\")\n",
    "before_filter = len(raw_data)\n",
    "clean_data = raw_data.query(f'num_games >= {MIN_GAMES_THRESHOLD}').copy()\n",
    "num_rows_after_filter = len(clean_data)\n",
    "num_rows_filtered_out = before_filter - num_rows_after_filter\n",
    "\n",
    "print(f\"   ‚Ä¢ Before: {before_filter:,} rows\")\n",
    "print(f\"   ‚Ä¢ After: {num_rows_after_filter:,} rows\")\n",
    "print(f\"   ‚Ä¢ Filtered out: {num_rows_filtered_out:,} rows ({100*num_rows_filtered_out/before_filter:.1f}%)\")\n",
    "\n",
    "# 2. Check for duplicates\n",
    "print(f\"\\n2Ô∏è‚É£  Checking for duplicate (player_id, opening_id) combinations...\")\n",
    "num_duplicates = clean_data.duplicated(subset=['player_id', 'opening_id']).sum()\n",
    "\n",
    "if num_duplicates > 0:\n",
    "    print(f\"   ‚ö†Ô∏è  Found {num_duplicates} duplicate entries\")\n",
    "    dup_mask = clean_data.duplicated(subset=['player_id', 'opening_id'], keep=False)\n",
    "    print(\"\\n   Sample of duplicates:\")\n",
    "    print(clean_data[dup_mask].head(10).to_string())\n",
    "    \n",
    "    # Keep only first occurrence of any duplicate player-opening pair\n",
    "    print(\"\\n   Removing duplicates (keeping first occurrence)...\")\n",
    "    clean_data = pd.DataFrame.drop_duplicates(clean_data, subset=['player_id', 'opening_id'], keep='first')\n",
    "    print(f\"   ‚úì After deduplication: {len(clean_data):,} rows\")\n",
    "else:\n",
    "    print(f\"   ‚úì No duplicates found\")\n",
    "\n",
    "# 3. Remove players with no qualifying openings\n",
    "print(f\"\\n3Ô∏è‚É£  Removing players with no qualifying openings...\") # Note that a few players only play stuff like the Van't Kruijs which we've excluded, so a small numer of players will be excluded here\n",
    "players_before = clean_data['player_id'].nunique()\n",
    "\n",
    "# Count openings per player\n",
    "num_openings_per_player = pd.DataFrame(clean_data.groupby('player_id').size(), columns=['count'])\n",
    "players_with_data = num_openings_per_player[num_openings_per_player['count'] > 0].index.tolist()\n",
    "\n",
    "# Filter\n",
    "clean_data = clean_data[clean_data['player_id'].isin(players_with_data)]\n",
    "players_after = clean_data['player_id'].nunique()\n",
    "\n",
    "print(f\"   ‚Ä¢ Players before: {players_before:,}\")\n",
    "print(f\"   ‚Ä¢ Players after: {players_after:,}\")\n",
    "print(f\"   ‚Ä¢ Removed: {players_before - players_after}\")\n",
    "\n",
    "# 4. Remove openings with no qualifying players\n",
    "print(f\"\\n4Ô∏è‚É£  Removing openings with no qualifying players...\")\n",
    "num_openings_before = clean_data['opening_id'].nunique()\n",
    "\n",
    "# Use pd.DataFrame.groupby() to count players per opening\n",
    "num_players_per_opening = pd.DataFrame(clean_data.groupby('opening_id').size(), columns=['count'])\n",
    "openings_with_data = num_players_per_opening[num_players_per_opening['count'] > 0].index.tolist()\n",
    "\n",
    "# Filter using pd.DataFrame.isin()\n",
    "clean_data = clean_data[clean_data['opening_id'].isin(openings_with_data)]\n",
    "openings_after = clean_data['opening_id'].nunique()\n",
    "\n",
    "print(f\"   ‚Ä¢ Openings before: {num_openings_before:,}\")\n",
    "print(f\"   ‚Ä¢ Openings after: {openings_after:,}\")\n",
    "print(f\"   ‚Ä¢ Removed: {num_openings_before - openings_after}\")\n",
    "\n",
    "# 5. Verify no null values using pd.isna()\n",
    "print(f\"\\n5Ô∏è‚É£  Verifying no null values...\")\n",
    "null_counts = pd.DataFrame.isna(clean_data).sum()\n",
    "if null_counts.sum() == 0:\n",
    "    print(\"   ‚úì No null values found\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  Found null values:\")\n",
    "    for col, count in null_counts[null_counts > 0].items():\n",
    "        print(f\"      ‚Ä¢ {col}: {count} nulls\")\n",
    "    # Drop rows with nulls using pd.DataFrame.dropna()\n",
    "    clean_data = pd.DataFrame.dropna(clean_data)\n",
    "    print(f\"   ‚úì Dropped null rows. New shape: {clean_data.shape}\")\n",
    "\n",
    "# TODO: Add confidence weighting column\n",
    "# TODO: Extract and normalize player ratings (side information)\n",
    "\n",
    "# Reset index using pd.DataFrame.reset_index()\n",
    "clean_data = pd.DataFrame.reset_index(clean_data, drop=True)\n",
    "\n",
    "# Final statistics using pd functions\n",
    "print(f\"\\n6Ô∏è‚É£  Final data statistics:\")\n",
    "print(f\"   ‚Ä¢ Total rows: {len(clean_data):,}\")\n",
    "print(f\"   ‚Ä¢ Unique players: {pd.Series.nunique(clean_data['player_id']):,}\")\n",
    "print(f\"   ‚Ä¢ Unique openings: {pd.Series.nunique(clean_data['opening_id']):,}\")\n",
    "print(f\"   ‚Ä¢ Total games: {pd.Series.sum(clean_data['num_games']):,}\")\n",
    "print(f\"   ‚Ä¢ Avg games per entry: {pd.Series.mean(clean_data['num_games']):.1f}\")\n",
    "print(f\"   ‚Ä¢ Avg openings per player: {len(clean_data) / pd.Series.nunique(clean_data['player_id']):.1f}\")\n",
    "print(f\"   ‚Ä¢ Avg players per opening: {len(clean_data) / pd.Series.nunique(clean_data['opening_id']):.1f}\")\n",
    "\n",
    "# Score distribution using pd functions\n",
    "print(f\"\\n   Score statistics:\")\n",
    "print(f\"   ‚Ä¢ Min: {pd.Series.min(clean_data['score']):.4f}\")\n",
    "print(f\"   ‚Ä¢ 25th percentile: {pd.Series.quantile(clean_data['score'], 0.25):.4f}\")\n",
    "print(f\"   ‚Ä¢ Median: {pd.Series.median(clean_data['score']):.4f}\")\n",
    "print(f\"   ‚Ä¢ 75th percentile: {pd.Series.quantile(clean_data['score'], 0.75):.4f}\")\n",
    "print(f\"   ‚Ä¢ Max: {pd.Series.max(clean_data['score']):.4f}\")\n",
    "print(f\"   ‚Ä¢ Mean: {pd.Series.mean(clean_data['score']):.4f}\")\n",
    "print(f\"   ‚Ä¢ Std: {pd.Series.std(clean_data['score']):.4f}\")\n",
    "\n",
    "# Sample of cleaned data using pd.DataFrame.sample()\n",
    "print(f\"\\n7Ô∏è‚É£  Sample of cleaned data (10 random rows):\")\n",
    "print(pd.DataFrame.sample(clean_data, min(10, len(clean_data)), random_state=42).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ DATA SANITIZATION COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nCleaned data shape: {clean_data.shape}\")\n",
    "print(f\"Data reduction: {100 * (1 - len(clean_data)/len(raw_data)):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e671b6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 2B: HIERARCHICAL BAYESIAN SCORE ADJUSTMENT\n",
      "============================================================\n",
      "\n",
      "‚öôÔ∏è  Configuration:\n",
      "   ‚Ä¢ K_PLAYER (shrinkage constant): 50\n",
      "   ‚Ä¢ Method: Two-level empirical Bayes shrinkage\n",
      "   ‚Ä¢ Level 1: Calculate opening-specific means\n",
      "   ‚Ä¢ Level 2: Shrink player scores toward opening means\n",
      "\n",
      "üìä Global statistics:\n",
      "   ‚Ä¢ Global mean score: 0.5111\n",
      "   ‚Ä¢ Total entries: 2,956,680\n",
      "   ‚Ä¢ Unique openings: 2,717\n",
      "\n",
      "1Ô∏è‚É£  LEVEL 1: Calculating opening-specific means...\n",
      "   ‚úì Calculated means for 2,717 openings\n",
      "\n",
      "   Opening mean score distribution:\n",
      "   ‚Ä¢ Min: 0.1667\n",
      "   ‚Ä¢ 25th percentile: 0.4962\n",
      "   ‚Ä¢ Median: 0.5163\n",
      "   ‚Ä¢ 75th percentile: 0.5365\n",
      "   ‚Ä¢ Max: 1.0000\n",
      "   ‚Ä¢ Std: 0.0504\n",
      "\n",
      "   Opening sample size distribution:\n",
      "   ‚Ä¢ Total games per opening (median): 4902\n",
      "   ‚Ä¢ Players per opening (median): 159\n",
      "   ‚Ä¢ Total games range: [10, 5613106]\n",
      "   ‚Ä¢ Players range: [1, 43778]\n",
      "   ‚úì Calculated means for 2,717 openings\n",
      "\n",
      "   Opening mean score distribution:\n",
      "   ‚Ä¢ Min: 0.1667\n",
      "   ‚Ä¢ 25th percentile: 0.4962\n",
      "   ‚Ä¢ Median: 0.5163\n",
      "   ‚Ä¢ 75th percentile: 0.5365\n",
      "   ‚Ä¢ Max: 1.0000\n",
      "   ‚Ä¢ Std: 0.0504\n",
      "\n",
      "   Opening sample size distribution:\n",
      "   ‚Ä¢ Total games per opening (median): 4902\n",
      "   ‚Ä¢ Players per opening (median): 159\n",
      "   ‚Ä¢ Total games range: [10, 5613106]\n",
      "   ‚Ä¢ Players range: [1, 43778]\n",
      "\n",
      "2Ô∏è‚É£  LEVEL 2: Shrinking player scores toward opening means...\n",
      "   Formula: adjusted_score = (num_games √ó player_score + 50 √ó opening_mean) / (num_games + 50)\n",
      "   ‚úì Scores adjusted for 2,956,680 entries\n",
      "\n",
      "3Ô∏è‚É£  Calculating confidence weights...\n",
      "   ‚úì Confidence weights calculated\n",
      "   ‚Ä¢ Formula: confidence = num_games / (num_games + 50)\n",
      "   ‚Ä¢ Range: [0.1667, 0.9963]\n",
      "\n",
      "4Ô∏è‚É£  Adjustment statistics:\n",
      "   ‚Ä¢ Mean adjustment: 0.000961\n",
      "   ‚Ä¢ Std adjustment: 0.076773\n",
      "   ‚Ä¢ Max adjustment: 0.457431\n",
      "   ‚Ä¢ Min adjustment: -0.457521\n",
      "\n",
      "   Adjustment by num_games quartiles:\n",
      "\n",
      "2Ô∏è‚É£  LEVEL 2: Shrinking player scores toward opening means...\n",
      "   Formula: adjusted_score = (num_games √ó player_score + 50 √ó opening_mean) / (num_games + 50)\n",
      "   ‚úì Scores adjusted for 2,956,680 entries\n",
      "\n",
      "3Ô∏è‚É£  Calculating confidence weights...\n",
      "   ‚úì Confidence weights calculated\n",
      "   ‚Ä¢ Formula: confidence = num_games / (num_games + 50)\n",
      "   ‚Ä¢ Range: [0.1667, 0.9963]\n",
      "\n",
      "4Ô∏è‚É£  Adjustment statistics:\n",
      "   ‚Ä¢ Mean adjustment: 0.000961\n",
      "   ‚Ä¢ Std adjustment: 0.076773\n",
      "   ‚Ä¢ Max adjustment: 0.457431\n",
      "   ‚Ä¢ Min adjustment: -0.457521\n",
      "\n",
      "   Adjustment by num_games quartiles:\n",
      "   ‚Ä¢ 25th percentile (n=15 games): avg adjustment = 0.003644\n",
      "   ‚Ä¢ 50th percentile (n=27 games): avg adjustment = 0.001794\n",
      "   ‚Ä¢ 75th percentile (n=65 games): avg adjustment = -0.000398\n",
      "   ‚Ä¢ >75th percentile (n>65 games): avg adjustment = -0.001362\n",
      "\n",
      "5Ô∏è‚É£  Adjusted score statistics:\n",
      "   ‚Ä¢ Min: 0.1004\n",
      "   ‚Ä¢ 25th percentile: 0.4850\n",
      "   ‚Ä¢ 25th percentile (n=15 games): avg adjustment = 0.003644\n",
      "   ‚Ä¢ 50th percentile (n=27 games): avg adjustment = 0.001794\n",
      "   ‚Ä¢ 75th percentile (n=65 games): avg adjustment = -0.000398\n",
      "   ‚Ä¢ >75th percentile (n>65 games): avg adjustment = -0.001362\n",
      "\n",
      "5Ô∏è‚É£  Adjusted score statistics:\n",
      "   ‚Ä¢ Min: 0.1004\n",
      "   ‚Ä¢ 25th percentile: 0.4850\n",
      "   ‚Ä¢ Median: 0.5118\n",
      "   ‚Ä¢ 75th percentile: 0.5385\n",
      "   ‚Ä¢ Max: 1.0000\n",
      "   ‚Ä¢ Mean: 0.5120\n",
      "   ‚Ä¢ Std: 0.0411\n",
      "\n",
      "6Ô∏è‚É£  Sample comparisons (showing effect of hierarchical shrinkage):\n",
      "\n",
      "   ========================================================================================================================\n",
      "   Low-game entries (10-20 games) - HIGH shrinkage toward opening mean:\n",
      "   ========================================================================================================================\n",
      "   ‚Ä¢ Median: 0.5118\n",
      "   ‚Ä¢ 75th percentile: 0.5385\n",
      "   ‚Ä¢ Max: 1.0000\n",
      "   ‚Ä¢ Mean: 0.5120\n",
      "   ‚Ä¢ Std: 0.0411\n",
      "\n",
      "6Ô∏è‚É£  Sample comparisons (showing effect of hierarchical shrinkage):\n",
      "\n",
      "   ========================================================================================================================\n",
      "   Low-game entries (10-20 games) - HIGH shrinkage toward opening mean:\n",
      "   ========================================================================================================================\n",
      "   Player 43088 | Opening 1591 | Games:  10 | Opening mean: 0.5110 | Original: 0.6000 ‚Üí Adjusted: 0.5258 | Diff: -0.0742 | Confidence: 0.167\n",
      "   Player  4506 | Opening 1026 | Games:  19 | Opening mean: 0.4951 | Original: 0.3684 ‚Üí Adjusted: 0.4602 | Diff: +0.0918 | Confidence: 0.275\n",
      "   Player 46013 | Opening 1167 | Games:  16 | Opening mean: 0.4962 | Original: 0.3750 ‚Üí Adjusted: 0.4668 | Diff: +0.0918 | Confidence: 0.242\n",
      "   Player 36777 | Opening 2061 | Games:  12 | Opening mean: 0.5060 | Original: 0.3333 ‚Üí Adjusted: 0.4725 | Diff: +0.1392 | Confidence: 0.194\n",
      "   Player 25319 | Opening  897 | Games:  17 | Opening mean: 0.5105 | Original: 0.5882 ‚Üí Adjusted: 0.5303 | Diff: -0.0580 | Confidence: 0.254\n",
      "   Player 21335 | Opening 3488 | Games:  10 | Opening mean: 0.5203 | Original: 0.5500 ‚Üí Adjusted: 0.5253 | Diff: -0.0247 | Confidence: 0.167\n",
      "   Player 16739 | Opening 1947 | Games:  10 | Opening mean: 0.5020 | Original: 0.6000 ‚Üí Adjusted: 0.5183 | Diff: -0.0817 | Confidence: 0.167\n",
      "   Player 35492 | Opening 2052 | Games:  10 | Opening mean: 0.5381 | Original: 0.5500 ‚Üí Adjusted: 0.5401 | Diff: -0.0099 | Confidence: 0.167\n",
      "   Player  6422 | Opening  392 | Games:  11 | Opening mean: 0.5175 | Original: 0.4545 ‚Üí Adjusted: 0.5061 | Diff: +0.0516 | Confidence: 0.180\n",
      "   Player 45272 | Opening 1062 | Games:  19 | Opening mean: 0.5170 | Original: 0.6842 ‚Üí Adjusted: 0.5631 | Diff: -0.1211 | Confidence: 0.275\n",
      "\n",
      "   ========================================================================================================================\n",
      "   Medium-game entries (50-100 games) - MODERATE shrinkage:\n",
      "   ========================================================================================================================\n",
      "   Player 18069 | Opening  730 | Games:  91 | Opening mean: 0.5185 | Original: 0.4670 ‚Üí Adjusted: 0.4853 | Diff: +0.0183 | Confidence: 0.645\n",
      "   Player 25696 | Opening  768 | Games:  83 | Opening mean: 0.4875 | Original: 0.4940 ‚Üí Adjusted: 0.4916 | Diff: -0.0024 | Confidence: 0.624\n",
      "   Player 24600 | Opening  897 | Games:  60 | Opening mean: 0.5105 | Original: 0.4833 ‚Üí Adjusted: 0.4957 | Diff: +0.0124 | Confidence: 0.545\n",
      "   Player 36487 | Opening 3181 | Games:  58 | Opening mean: 0.5210 | Original: 0.6552 ‚Üí Adjusted: 0.5930 | Diff: -0.0621 | Confidence: 0.537\n",
      "   Player 12032 | Opening 2451 | Games:  61 | Opening mean: 0.5335 | Original: 0.4262 ‚Üí Adjusted: 0.4746 | Diff: +0.0483 | Confidence: 0.550\n",
      "   Player 24695 | Opening 1531 | Games:  61 | Opening mean: 0.5072 | Original: 0.4508 ‚Üí Adjusted: 0.4762 | Diff: +0.0254 | Confidence: 0.550\n",
      "   Player 11022 | Opening  772 | Games:  74 | Opening mean: 0.5164 | Original: 0.4932 ‚Üí Adjusted: 0.5026 | Diff: +0.0093 | Confidence: 0.597\n",
      "   Player 48332 | Opening  937 | Games:  62 | Opening mean: 0.4749 | Original: 0.4758 ‚Üí Adjusted: 0.4754 | Diff: -0.0004 | Confidence: 0.554\n",
      "   Player 20100 | Opening 2231 | Games:  98 | Opening mean: 0.5029 | Original: 0.6071 ‚Üí Adjusted: 0.5719 | Diff: -0.0352 | Confidence: 0.662\n",
      "   Player 30545 | Opening 2155 | Games:  94 | Opening mean: 0.5204 | Original: 0.5319 ‚Üí Adjusted: 0.5279 | Diff: -0.0040 | Confidence: 0.653\n",
      "\n",
      "   ========================================================================================================================\n",
      "   High-game entries (200+ games) - LOW shrinkage:\n",
      "   ========================================================================================================================\n",
      "   Player 43088 | Opening 1591 | Games:  10 | Opening mean: 0.5110 | Original: 0.6000 ‚Üí Adjusted: 0.5258 | Diff: -0.0742 | Confidence: 0.167\n",
      "   Player  4506 | Opening 1026 | Games:  19 | Opening mean: 0.4951 | Original: 0.3684 ‚Üí Adjusted: 0.4602 | Diff: +0.0918 | Confidence: 0.275\n",
      "   Player 46013 | Opening 1167 | Games:  16 | Opening mean: 0.4962 | Original: 0.3750 ‚Üí Adjusted: 0.4668 | Diff: +0.0918 | Confidence: 0.242\n",
      "   Player 36777 | Opening 2061 | Games:  12 | Opening mean: 0.5060 | Original: 0.3333 ‚Üí Adjusted: 0.4725 | Diff: +0.1392 | Confidence: 0.194\n",
      "   Player 25319 | Opening  897 | Games:  17 | Opening mean: 0.5105 | Original: 0.5882 ‚Üí Adjusted: 0.5303 | Diff: -0.0580 | Confidence: 0.254\n",
      "   Player 21335 | Opening 3488 | Games:  10 | Opening mean: 0.5203 | Original: 0.5500 ‚Üí Adjusted: 0.5253 | Diff: -0.0247 | Confidence: 0.167\n",
      "   Player 16739 | Opening 1947 | Games:  10 | Opening mean: 0.5020 | Original: 0.6000 ‚Üí Adjusted: 0.5183 | Diff: -0.0817 | Confidence: 0.167\n",
      "   Player 35492 | Opening 2052 | Games:  10 | Opening mean: 0.5381 | Original: 0.5500 ‚Üí Adjusted: 0.5401 | Diff: -0.0099 | Confidence: 0.167\n",
      "   Player  6422 | Opening  392 | Games:  11 | Opening mean: 0.5175 | Original: 0.4545 ‚Üí Adjusted: 0.5061 | Diff: +0.0516 | Confidence: 0.180\n",
      "   Player 45272 | Opening 1062 | Games:  19 | Opening mean: 0.5170 | Original: 0.6842 ‚Üí Adjusted: 0.5631 | Diff: -0.1211 | Confidence: 0.275\n",
      "\n",
      "   ========================================================================================================================\n",
      "   Medium-game entries (50-100 games) - MODERATE shrinkage:\n",
      "   ========================================================================================================================\n",
      "   Player 18069 | Opening  730 | Games:  91 | Opening mean: 0.5185 | Original: 0.4670 ‚Üí Adjusted: 0.4853 | Diff: +0.0183 | Confidence: 0.645\n",
      "   Player 25696 | Opening  768 | Games:  83 | Opening mean: 0.4875 | Original: 0.4940 ‚Üí Adjusted: 0.4916 | Diff: -0.0024 | Confidence: 0.624\n",
      "   Player 24600 | Opening  897 | Games:  60 | Opening mean: 0.5105 | Original: 0.4833 ‚Üí Adjusted: 0.4957 | Diff: +0.0124 | Confidence: 0.545\n",
      "   Player 36487 | Opening 3181 | Games:  58 | Opening mean: 0.5210 | Original: 0.6552 ‚Üí Adjusted: 0.5930 | Diff: -0.0621 | Confidence: 0.537\n",
      "   Player 12032 | Opening 2451 | Games:  61 | Opening mean: 0.5335 | Original: 0.4262 ‚Üí Adjusted: 0.4746 | Diff: +0.0483 | Confidence: 0.550\n",
      "   Player 24695 | Opening 1531 | Games:  61 | Opening mean: 0.5072 | Original: 0.4508 ‚Üí Adjusted: 0.4762 | Diff: +0.0254 | Confidence: 0.550\n",
      "   Player 11022 | Opening  772 | Games:  74 | Opening mean: 0.5164 | Original: 0.4932 ‚Üí Adjusted: 0.5026 | Diff: +0.0093 | Confidence: 0.597\n",
      "   Player 48332 | Opening  937 | Games:  62 | Opening mean: 0.4749 | Original: 0.4758 ‚Üí Adjusted: 0.4754 | Diff: -0.0004 | Confidence: 0.554\n",
      "   Player 20100 | Opening 2231 | Games:  98 | Opening mean: 0.5029 | Original: 0.6071 ‚Üí Adjusted: 0.5719 | Diff: -0.0352 | Confidence: 0.662\n",
      "   Player 30545 | Opening 2155 | Games:  94 | Opening mean: 0.5204 | Original: 0.5319 ‚Üí Adjusted: 0.5279 | Diff: -0.0040 | Confidence: 0.653\n",
      "\n",
      "   ========================================================================================================================\n",
      "   High-game entries (200+ games) - LOW shrinkage:\n",
      "   ========================================================================================================================\n",
      "   Player 21111 | Opening 3203 | Games: 980 | Opening mean: 0.5246 | Original: 0.5577 ‚Üí Adjusted: 0.5560 | Diff: -0.0016 | Confidence: 0.951\n",
      "   Player 15853 | Opening  730 | Games: 209 | Opening mean: 0.5185 | Original: 0.5981 ‚Üí Adjusted: 0.5827 | Diff: -0.0154 | Confidence: 0.807\n",
      "   Player  8138 | Opening 3203 | Games: 1021 | Opening mean: 0.5246 | Original: 0.5500 ‚Üí Adjusted: 0.5488 | Diff: -0.0012 | Confidence: 0.953\n",
      "   Player  2858 | Opening 1582 | Games: 591 | Opening mean: 0.5281 | Original: 0.5736 ‚Üí Adjusted: 0.5701 | Diff: -0.0035 | Confidence: 0.922\n",
      "   Player 47038 | Opening 1167 | Games: 249 | Opening mean: 0.4962 | Original: 0.5422 ‚Üí Adjusted: 0.5345 | Diff: -0.0077 | Confidence: 0.833\n",
      "   Player 43708 | Opening  730 | Games: 231 | Opening mean: 0.5185 | Original: 0.5476 ‚Üí Adjusted: 0.5424 | Diff: -0.0052 | Confidence: 0.822\n",
      "   Player 40541 | Opening   89 | Games: 614 | Opening mean: 0.4888 | Original: 0.5024 ‚Üí Adjusted: 0.5014 | Diff: -0.0010 | Confidence: 0.925\n",
      "   Player 14586 | Opening 1357 | Games: 1093 | Opening mean: 0.4984 | Original: 0.5297 ‚Üí Adjusted: 0.5284 | Diff: -0.0014 | Confidence: 0.956\n",
      "   Player 17235 | Opening 1383 | Games: 233 | Opening mean: 0.5178 | Original: 0.5107 ‚Üí Adjusted: 0.5120 | Diff: +0.0012 | Confidence: 0.823\n",
      "   Player 23431 | Opening  838 | Games: 211 | Opening mean: 0.5096 | Original: 0.4147 ‚Üí Adjusted: 0.4329 | Diff: +0.0182 | Confidence: 0.808\n",
      "\n",
      "7Ô∏è‚É£  Extreme cases (showing why opening-specific shrinkage matters):\n",
      "\n",
      "   Openings with HIGHEST win rates (strong for White):\n",
      "   Player 21111 | Opening 3203 | Games: 980 | Opening mean: 0.5246 | Original: 0.5577 ‚Üí Adjusted: 0.5560 | Diff: -0.0016 | Confidence: 0.951\n",
      "   Player 15853 | Opening  730 | Games: 209 | Opening mean: 0.5185 | Original: 0.5981 ‚Üí Adjusted: 0.5827 | Diff: -0.0154 | Confidence: 0.807\n",
      "   Player  8138 | Opening 3203 | Games: 1021 | Opening mean: 0.5246 | Original: 0.5500 ‚Üí Adjusted: 0.5488 | Diff: -0.0012 | Confidence: 0.953\n",
      "   Player  2858 | Opening 1582 | Games: 591 | Opening mean: 0.5281 | Original: 0.5736 ‚Üí Adjusted: 0.5701 | Diff: -0.0035 | Confidence: 0.922\n",
      "   Player 47038 | Opening 1167 | Games: 249 | Opening mean: 0.4962 | Original: 0.5422 ‚Üí Adjusted: 0.5345 | Diff: -0.0077 | Confidence: 0.833\n",
      "   Player 43708 | Opening  730 | Games: 231 | Opening mean: 0.5185 | Original: 0.5476 ‚Üí Adjusted: 0.5424 | Diff: -0.0052 | Confidence: 0.822\n",
      "   Player 40541 | Opening   89 | Games: 614 | Opening mean: 0.4888 | Original: 0.5024 ‚Üí Adjusted: 0.5014 | Diff: -0.0010 | Confidence: 0.925\n",
      "   Player 14586 | Opening 1357 | Games: 1093 | Opening mean: 0.4984 | Original: 0.5297 ‚Üí Adjusted: 0.5284 | Diff: -0.0014 | Confidence: 0.956\n",
      "   Player 17235 | Opening 1383 | Games: 233 | Opening mean: 0.5178 | Original: 0.5107 ‚Üí Adjusted: 0.5120 | Diff: +0.0012 | Confidence: 0.823\n",
      "   Player 23431 | Opening  838 | Games: 211 | Opening mean: 0.5096 | Original: 0.4147 ‚Üí Adjusted: 0.4329 | Diff: +0.0182 | Confidence: 0.808\n",
      "\n",
      "7Ô∏è‚É£  Extreme cases (showing why opening-specific shrinkage matters):\n",
      "\n",
      "   Openings with HIGHEST win rates (strong for White):\n",
      "   Opening 1811 (C39): mean = 1.0000 (+0.4889 vs global) | 1 player entries\n",
      "   Opening 3551 (C19): mean = 0.8000 (+0.2889 vs global) | 1 player entries\n",
      "   Opening 2881 (E10): mean = 0.8000 (+0.2889 vs global) | 1 player entries\n",
      "   Opening 2046 (C49): mean = 0.7857 (+0.2747 vs global) | 1 player entries\n",
      "   Opening 1659 (C30): mean = 0.7692 (+0.2582 vs global) | 1 player entries\n",
      "\n",
      "   Openings with LOWEST win rates (weak for White):\n",
      "   Opening 1811 (C39): mean = 1.0000 (+0.4889 vs global) | 1 player entries\n",
      "   Opening 3551 (C19): mean = 0.8000 (+0.2889 vs global) | 1 player entries\n",
      "   Opening 2881 (E10): mean = 0.8000 (+0.2889 vs global) | 1 player entries\n",
      "   Opening 2046 (C49): mean = 0.7857 (+0.2747 vs global) | 1 player entries\n",
      "   Opening 1659 (C30): mean = 0.7692 (+0.2582 vs global) | 1 player entries\n",
      "\n",
      "   Openings with LOWEST win rates (weak for White):\n",
      "   Opening 2593 (D26): mean = 0.1667 (-0.3444 vs global) | 1 player entries\n",
      "   Opening  636 (A83): mean = 0.2006 (-0.3104 vs global) | 2 player entries\n",
      "   Opening 3496 (A40): mean = 0.2273 (-0.2838 vs global) | 1 player entries\n",
      "   Opening 1763 (C37): mean = 0.2417 (-0.2694 vs global) | 2 player entries\n",
      "\n",
      "8Ô∏è‚É£  Examples showing hierarchical shrinkage benefit:\n",
      "   Opening 2593 (D26): mean = 0.1667 (-0.3444 vs global) | 1 player entries\n",
      "   Opening  636 (A83): mean = 0.2006 (-0.3104 vs global) | 2 player entries\n",
      "   Opening 3496 (A40): mean = 0.2273 (-0.2838 vs global) | 1 player entries\n",
      "   Opening 1763 (C37): mean = 0.2417 (-0.2694 vs global) | 2 player entries\n",
      "\n",
      "8Ô∏è‚É£  Examples showing hierarchical shrinkage benefit:\n",
      "\n",
      "   Strong opening + good player performance (shrunk toward HIGH opening mean):\n",
      "   Player 23562 | Opening 3292 (C54) | Games: 12 | Opening mean: 0.7297 | Original: 0.7500 ‚Üí 0.7336\n",
      "      If we'd shrunk to global mean: 0.5573 (would lose +0.1763 of deserved credit)\n",
      "   Player 14997 | Opening 3292 (C54) | Games: 13 | Opening mean: 0.7297 | Original: 0.9231 ‚Üí 0.7696\n",
      "      If we'd shrunk to global mean: 0.5961 (would lose +0.1735 of deserved credit)\n",
      "   Player  9893 | Opening 3292 (C54) | Games: 20 | Opening mean: 0.7297 | Original: 0.6500 ‚Üí 0.7069\n",
      "      If we'd shrunk to global mean: 0.5508 (would lose +0.1562 of deserved credit)\n",
      "\n",
      "   Strong opening + good player performance (shrunk toward HIGH opening mean):\n",
      "   Player 23562 | Opening 3292 (C54) | Games: 12 | Opening mean: 0.7297 | Original: 0.7500 ‚Üí 0.7336\n",
      "      If we'd shrunk to global mean: 0.5573 (would lose +0.1763 of deserved credit)\n",
      "   Player 14997 | Opening 3292 (C54) | Games: 13 | Opening mean: 0.7297 | Original: 0.9231 ‚Üí 0.7696\n",
      "      If we'd shrunk to global mean: 0.5961 (would lose +0.1735 of deserved credit)\n",
      "   Player  9893 | Opening 3292 (C54) | Games: 20 | Opening mean: 0.7297 | Original: 0.6500 ‚Üí 0.7069\n",
      "      If we'd shrunk to global mean: 0.5508 (would lose +0.1562 of deserved credit)\n",
      "\n",
      "   Weak opening + poor player performance (shrunk toward LOW opening mean):\n",
      "   Player  1857 | Opening 2293 (C71) | Games: 13 | Opening mean: 0.2665 | Original: 0.1538 ‚Üí 0.2433\n",
      "      If we'd shrunk to global mean: 0.4373 (would unfairly boost by +0.1941)\n",
      "   Player 19116 | Opening 1779 (C37) | Games: 10 | Opening mean: 0.3366 | Original: 0.2000 ‚Üí 0.3138\n",
      "      If we'd shrunk to global mean: 0.4592 (would unfairly boost by +0.1454)\n",
      "   Player  4605 | Opening 1779 (C37) | Games: 13 | Opening mean: 0.3366 | Original: 0.3846 ‚Üí 0.3465\n",
      "      If we'd shrunk to global mean: 0.4850 (would unfairly boost by +0.1385)\n",
      "\n",
      "9Ô∏è‚É£  Cleaning up...\n",
      "   ‚úì Removed temporary columns\n",
      "\n",
      "============================================================\n",
      "‚úÖ HIERARCHICAL BAYESIAN ADJUSTMENT COMPLETE\n",
      "============================================================\n",
      "\n",
      "Final data shape: (2956680, 6)\n",
      "Columns: ['player_id', 'opening_id', 'num_games', 'score', 'eco', 'confidence']\n",
      "\n",
      "New columns added:\n",
      "   ‚Ä¢ 'confidence': weight for loss function (range [0,1])\n",
      "   ‚Ä¢ 'score': adjusted using hierarchical Bayesian shrinkage\n",
      "\n",
      "Key improvement over simple shrinkage:\n",
      "   ‚Ä¢ Player scores now shrink toward OPENING-SPECIFIC means, not global mean\n",
      "   ‚Ä¢ Preserves opening difficulty differences\n",
      "   ‚Ä¢ More accurate for both strong and weak openings\n",
      "\n",
      "   Weak opening + poor player performance (shrunk toward LOW opening mean):\n",
      "   Player  1857 | Opening 2293 (C71) | Games: 13 | Opening mean: 0.2665 | Original: 0.1538 ‚Üí 0.2433\n",
      "      If we'd shrunk to global mean: 0.4373 (would unfairly boost by +0.1941)\n",
      "   Player 19116 | Opening 1779 (C37) | Games: 10 | Opening mean: 0.3366 | Original: 0.2000 ‚Üí 0.3138\n",
      "      If we'd shrunk to global mean: 0.4592 (would unfairly boost by +0.1454)\n",
      "   Player  4605 | Opening 1779 (C37) | Games: 13 | Opening mean: 0.3366 | Original: 0.3846 ‚Üí 0.3465\n",
      "      If we'd shrunk to global mean: 0.4850 (would unfairly boost by +0.1385)\n",
      "\n",
      "9Ô∏è‚É£  Cleaning up...\n",
      "   ‚úì Removed temporary columns\n",
      "\n",
      "============================================================\n",
      "‚úÖ HIERARCHICAL BAYESIAN ADJUSTMENT COMPLETE\n",
      "============================================================\n",
      "\n",
      "Final data shape: (2956680, 6)\n",
      "Columns: ['player_id', 'opening_id', 'num_games', 'score', 'eco', 'confidence']\n",
      "\n",
      "New columns added:\n",
      "   ‚Ä¢ 'confidence': weight for loss function (range [0,1])\n",
      "   ‚Ä¢ 'score': adjusted using hierarchical Bayesian shrinkage\n",
      "\n",
      "Key improvement over simple shrinkage:\n",
      "   ‚Ä¢ Player scores now shrink toward OPENING-SPECIFIC means, not global mean\n",
      "   ‚Ä¢ Preserves opening difficulty differences\n",
      "   ‚Ä¢ More accurate for both strong and weak openings\n"
     ]
    }
   ],
   "source": [
    "# 2b. Apply hierarchical Bayesian shrinkage to adjust scores based on sample size confidence\n",
    "\n",
    "# Check if confidence already exists - if so, skip this processing\n",
    "if 'confidence' in clean_data.columns:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"‚è≠Ô∏è  SKIPPING STEP 2B: HIERARCHICAL BAYESIAN SCORE ADJUSTMENT\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\n‚úì 'confidence' column already exists in data\")\n",
    "    print(\"   This indicates hierarchical Bayesian processing has already been applied.\")\n",
    "    print(f\"\\nCurrent data shape: {clean_data.shape}\")\n",
    "    print(f\"Confidence range: [{clean_data['confidence'].min():.4f}, {clean_data['confidence'].max():.4f}]\")\n",
    "else:\n",
    "    # Define the processing function\n",
    "    # This is a long function, I recommend you fold it down in your editor\n",
    "    def apply_hierarchical_bayesian_shrinkage(data, k_player=50):\n",
    "        \"\"\"\n",
    "        Apply two-level hierarchical Bayesian shrinkage to adjust scores.\n",
    "        \n",
    "        A lot of our player-opening entries have a small number of games played, because openings are so specific.\n",
    "        This introduces sample size issues.\n",
    "        \n",
    "        We use TWO-LEVEL shrinkage:\n",
    "        Level 1: Calculate opening-specific means (these are our \"ground truth\" for each opening)\n",
    "        Level 2: Shrink individual player-opening scores toward their opening's mean\n",
    "        This is better than shrinking toward global mean because different openings have different baseline win rates\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        data : pd.DataFrame\n",
    "            Clean data with columns: player_id, opening_id, score, num_games, eco\n",
    "        k_player : int\n",
    "            Shrinkage constant for player-opening scores (default: 50)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame\n",
    "            Data with adjusted scores and new 'confidence' column\n",
    "        \"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"STEP 2B: HIERARCHICAL BAYESIAN SCORE ADJUSTMENT\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        print(f\"\\n‚öôÔ∏è  Configuration:\")\n",
    "        print(f\"   ‚Ä¢ K_PLAYER (shrinkage constant): {k_player}\")\n",
    "        print(f\"   ‚Ä¢ Method: Two-level empirical Bayes shrinkage\")\n",
    "        print(f\"   ‚Ä¢ Level 1: Calculate opening-specific means\")\n",
    "        print(f\"   ‚Ä¢ Level 2: Shrink player scores toward opening means\")\n",
    "        \n",
    "        # Calculate global mean score for comparison\n",
    "        global_mean_score = data[\"score\"].mean()\n",
    "        print(f\"\\nüìä Global statistics:\")\n",
    "        print(f\"   ‚Ä¢ Global mean score: {global_mean_score:.4f}\")\n",
    "        print(f\"   ‚Ä¢ Total entries: {len(data):,}\")\n",
    "        print(f\"   ‚Ä¢ Unique openings: {data['opening_id'].nunique():,}\")\n",
    "        \n",
    "        # Store original scores for comparison\n",
    "        data = data.copy()  # Best practice: work on a copy\n",
    "        data[\"score_original\"] = data[\"score\"].copy()\n",
    "        \n",
    "        # LEVEL 1: Calculate opening-specific means and statistics\n",
    "        print(f\"\\n1Ô∏è‚É£  LEVEL 1: Calculating opening-specific means...\")\n",
    "        \n",
    "        opening_stats = (\n",
    "            data.groupby(\"opening_id\")\n",
    "            .agg(\n",
    "                {\n",
    "                    \"score\": \"mean\",\n",
    "                    \"num_games\": \"sum\",\n",
    "                    \"player_id\": \"count\",  # Number of players who played this opening\n",
    "                }\n",
    "            )\n",
    "            .rename(\n",
    "                columns={\n",
    "                    \"score\": \"opening_mean\",\n",
    "                    \"num_games\": \"opening_total_games\",\n",
    "                    \"player_id\": \"opening_num_players\",\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        print(f\"   ‚úì Calculated means for {len(opening_stats):,} openings\")\n",
    "        \n",
    "        # Opening mean statistics\n",
    "        print(f\"\\n   Opening mean score distribution:\")\n",
    "        print(f\"   ‚Ä¢ Min: {opening_stats['opening_mean'].min():.4f}\")\n",
    "        print(f\"   ‚Ä¢ 25th percentile: {opening_stats['opening_mean'].quantile(0.25):.4f}\")\n",
    "        print(f\"   ‚Ä¢ Median: {opening_stats['opening_mean'].median():.4f}\")\n",
    "        print(f\"   ‚Ä¢ 75th percentile: {opening_stats['opening_mean'].quantile(0.75):.4f}\")\n",
    "        print(f\"   ‚Ä¢ Max: {opening_stats['opening_mean'].max():.4f}\")\n",
    "        print(f\"   ‚Ä¢ Std: {opening_stats['opening_mean'].std():.4f}\")\n",
    "        \n",
    "        # Show distribution of opening sizes\n",
    "        print(f\"\\n   Opening sample size distribution:\")\n",
    "        print(\n",
    "            f\"   ‚Ä¢ Total games per opening (median): {opening_stats['opening_total_games'].median():.0f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"   ‚Ä¢ Players per opening (median): {opening_stats['opening_num_players'].median():.0f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"   ‚Ä¢ Total games range: [{opening_stats['opening_total_games'].min():.0f}, {opening_stats['opening_total_games'].max():.0f}]\"\n",
    "        )\n",
    "        print(\n",
    "            f\"   ‚Ä¢ Players range: [{opening_stats['opening_num_players'].min():.0f}, {opening_stats['opening_num_players'].max():.0f}]\"\n",
    "        )\n",
    "        \n",
    "        # Merge opening means back into main dataframe\n",
    "        data = data.merge(\n",
    "            opening_stats[[\"opening_mean\"]], left_on=\"opening_id\", right_index=True, how=\"left\"\n",
    "        )\n",
    "        \n",
    "        # LEVEL 2: Shrink player-opening scores toward opening-specific means\n",
    "        print(f\"\\n2Ô∏è‚É£  LEVEL 2: Shrinking player scores toward opening means...\")\n",
    "        print(\n",
    "            f\"   Formula: adjusted_score = (num_games √ó player_score + {k_player} √ó opening_mean) / (num_games + {k_player})\"\n",
    "        )\n",
    "        \n",
    "        numerator = (data[\"num_games\"] * data[\"score_original\"]) + (\n",
    "            k_player * data[\"opening_mean\"]\n",
    "        )\n",
    "        denominator = data[\"num_games\"] + k_player\n",
    "        data[\"score\"] = numerator / denominator\n",
    "        \n",
    "        print(f\"   ‚úì Scores adjusted for {len(data):,} entries\")\n",
    "        \n",
    "        # Calculate confidence weights (will be used in loss function later)\n",
    "        print(f\"\\n3Ô∏è‚É£  Calculating confidence weights...\")\n",
    "        data[\"confidence\"] = data[\"num_games\"] / (\n",
    "            data[\"num_games\"] + k_player\n",
    "        )\n",
    "        print(f\"   ‚úì Confidence weights calculated\")\n",
    "        print(f\"   ‚Ä¢ Formula: confidence = num_games / (num_games + {k_player})\")\n",
    "        print(\n",
    "            f\"   ‚Ä¢ Range: [{data['confidence'].min():.4f}, {data['confidence'].max():.4f}]\"\n",
    "        )\n",
    "        \n",
    "        # Statistics on the adjustment\n",
    "        score_diff = data[\"score\"] - data[\"score_original\"]\n",
    "        print(f\"\\n4Ô∏è‚É£  Adjustment statistics:\")\n",
    "        print(f\"   ‚Ä¢ Mean adjustment: {score_diff.mean():.6f}\")\n",
    "        print(f\"   ‚Ä¢ Std adjustment: {score_diff.std():.6f}\")\n",
    "        print(f\"   ‚Ä¢ Max adjustment: {score_diff.max():.6f}\")\n",
    "        print(f\"   ‚Ä¢ Min adjustment: {score_diff.min():.6f}\")\n",
    "        \n",
    "        # Show distribution of adjustments\n",
    "        print(f\"\\n   Adjustment by num_games quartiles:\")\n",
    "        quartiles = data[\"num_games\"].quantile([0.25, 0.5, 0.75])\n",
    "        print(\n",
    "            f\"   ‚Ä¢ 25th percentile (n={quartiles[0.25]:.0f} games): avg adjustment = {score_diff[data['num_games'] <= quartiles[0.25]].mean():.6f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"   ‚Ä¢ 50th percentile (n={quartiles[0.5]:.0f} games): avg adjustment = {score_diff[(data['num_games'] > quartiles[0.25]) & (data['num_games'] <= quartiles[0.5])].mean():.6f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"   ‚Ä¢ 75th percentile (n={quartiles[0.75]:.0f} games): avg adjustment = {score_diff[(data['num_games'] > quartiles[0.5]) & (data['num_games'] <= quartiles[0.75])].mean():.6f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"   ‚Ä¢ >75th percentile (n>{quartiles[0.75]:.0f} games): avg adjustment = {score_diff[data['num_games'] > quartiles[0.75]].mean():.6f}\"\n",
    "        )\n",
    "        \n",
    "        # New score distribution after adjustment\n",
    "        print(f\"\\n5Ô∏è‚É£  Adjusted score statistics:\")\n",
    "        print(f\"   ‚Ä¢ Min: {data['score'].min():.4f}\")\n",
    "        print(f\"   ‚Ä¢ 25th percentile: {data['score'].quantile(0.25):.4f}\")\n",
    "        print(f\"   ‚Ä¢ Median: {data['score'].median():.4f}\")\n",
    "        print(f\"   ‚Ä¢ 75th percentile: {data['score'].quantile(0.75):.4f}\")\n",
    "        print(f\"   ‚Ä¢ Max: {data['score'].max():.4f}\")\n",
    "        print(f\"   ‚Ä¢ Mean: {data['score'].mean():.4f}\")\n",
    "        print(f\"   ‚Ä¢ Std: {data['score'].std():.4f}\")\n",
    "        \n",
    "        # Detailed sample showing the effect across different game counts\n",
    "        print(f\"\\n6Ô∏è‚É£  Sample comparisons (showing effect of hierarchical shrinkage):\")\n",
    "        print(f\"\\n   {'='*120}\")\n",
    "        print(f\"   Low-game entries (10-20 games) - HIGH shrinkage toward opening mean:\")\n",
    "        print(f\"   {'='*120}\")\n",
    "        \n",
    "        low_game_sample = data[\n",
    "            (data[\"num_games\"] >= 10) & (data[\"num_games\"] <= 20)\n",
    "        ].sample(\n",
    "            min(\n",
    "                10,\n",
    "                len(\n",
    "                    data[\n",
    "                        (data[\"num_games\"] >= 10) & (data[\"num_games\"] <= 20)\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            random_state=42,\n",
    "        )\n",
    "        for idx, row in low_game_sample.iterrows():\n",
    "            adjustment = row[\"score\"] - row[\"score_original\"]\n",
    "            print(\n",
    "                f\"   Player {row['player_id']:>5} | Opening {row['opening_id']:>4} | Games: {row['num_games']:>3} | \"\n",
    "                f\"Opening mean: {row['opening_mean']:.4f} | Original: {row['score_original']:.4f} ‚Üí Adjusted: {row['score']:.4f} | \"\n",
    "                f\"Diff: {adjustment:>+.4f} | Confidence: {row['confidence']:.3f}\"\n",
    "            )\n",
    "        \n",
    "        print(f\"\\n   {'='*120}\")\n",
    "        print(f\"   Medium-game entries (50-100 games) - MODERATE shrinkage:\")\n",
    "        print(f\"   {'='*120}\")\n",
    "        \n",
    "        med_game_sample = data[\n",
    "            (data[\"num_games\"] >= 50) & (data[\"num_games\"] <= 100)\n",
    "        ].sample(\n",
    "            min(\n",
    "                10,\n",
    "                len(\n",
    "                    data[\n",
    "                        (data[\"num_games\"] >= 50) & (data[\"num_games\"] <= 100)\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            random_state=42,\n",
    "        )\n",
    "        for idx, row in med_game_sample.iterrows():\n",
    "            adjustment = row[\"score\"] - row[\"score_original\"]\n",
    "            print(\n",
    "                f\"   Player {row['player_id']:>5} | Opening {row['opening_id']:>4} | Games: {row['num_games']:>3} | \"\n",
    "                f\"Opening mean: {row['opening_mean']:.4f} | Original: {row['score_original']:.4f} ‚Üí Adjusted: {row['score']:.4f} | \"\n",
    "                f\"Diff: {adjustment:>+.4f} | Confidence: {row['confidence']:.3f}\"\n",
    "            )\n",
    "        \n",
    "        print(f\"\\n   {'='*120}\")\n",
    "        print(f\"   High-game entries (200+ games) - LOW shrinkage:\")\n",
    "        print(f\"   {'='*120}\")\n",
    "        \n",
    "        high_game_sample = data[data[\"num_games\"] >= 200].sample(\n",
    "            min(10, len(data[data[\"num_games\"] >= 200])), random_state=42\n",
    "        )\n",
    "        for idx, row in high_game_sample.iterrows():\n",
    "            adjustment = row[\"score\"] - row[\"score_original\"]\n",
    "            print(\n",
    "                f\"   Player {row['player_id']:>5} | Opening {row['opening_id']:>4} | Games: {row['num_games']:>3} | \"\n",
    "                f\"Opening mean: {row['opening_mean']:.4f} | Original: {row['score_original']:.4f} ‚Üí Adjusted: {row['score']:.4f} | \"\n",
    "                f\"Diff: {adjustment:>+.4f} | Confidence: {row['confidence']:.3f}\"\n",
    "            )\n",
    "        \n",
    "        # Show extreme cases - comparing to both opening mean AND global mean\n",
    "        print(f\"\\n7Ô∏è‚É£  Extreme cases (showing why opening-specific shrinkage matters):\")\n",
    "        \n",
    "        # Find entries where opening mean differs significantly from global mean\n",
    "        data[\"opening_deviation_from_global\"] = (\n",
    "            data[\"opening_mean\"] - global_mean_score\n",
    "        ).abs()\n",
    "        \n",
    "        print(f\"\\n   Openings with HIGHEST win rates (strong for White):\")\n",
    "        strong_openings = data.nlargest(5, \"opening_mean\")[\n",
    "            [\"opening_id\", \"opening_mean\", \"eco\"]\n",
    "        ].drop_duplicates(\"opening_id\")\n",
    "        for idx, row in strong_openings.iterrows():\n",
    "            num_entries = len(data[data[\"opening_id\"] == row[\"opening_id\"]])\n",
    "            deviation = row[\"opening_mean\"] - global_mean_score\n",
    "            print(\n",
    "                f\"   Opening {row['opening_id']:>4} ({row['eco']:>3}): mean = {row['opening_mean']:.4f} \"\n",
    "                f\"(+{deviation:.4f} vs global) | {num_entries} player entries\"\n",
    "            )\n",
    "        \n",
    "        print(f\"\\n   Openings with LOWEST win rates (weak for White):\")\n",
    "        weak_openings = data.nsmallest(5, \"opening_mean\")[\n",
    "            [\"opening_id\", \"opening_mean\", \"eco\"]\n",
    "        ].drop_duplicates(\"opening_id\")\n",
    "        for idx, row in weak_openings.iterrows():\n",
    "            num_entries = len(data[data[\"opening_id\"] == row[\"opening_id\"]])\n",
    "            deviation = row[\"opening_mean\"] - global_mean_score\n",
    "            print(\n",
    "                f\"   Opening {row['opening_id']:>4} ({row['eco']:>3}): mean = {row['opening_mean']:.4f} \"\n",
    "                f\"({deviation:.4f} vs global) | {num_entries} player entries\"\n",
    "            )\n",
    "        \n",
    "        # Show specific examples where hierarchical shrinkage made a difference\n",
    "        print(f\"\\n8Ô∏è‚É£  Examples showing hierarchical shrinkage benefit:\")\n",
    "        \n",
    "        # Find entries with strong openings where player did well\n",
    "        strong_opening_ids = data.nlargest(50, \"opening_mean\")[\"opening_id\"].unique()\n",
    "        strong_examples = data[\n",
    "            (data[\"opening_id\"].isin(strong_opening_ids))\n",
    "            & (data[\"num_games\"] <= 20)\n",
    "            & (data[\"score_original\"] > 0.6)\n",
    "        ].sample(\n",
    "            min(\n",
    "                3,\n",
    "                len(\n",
    "                    data[\n",
    "                        (data[\"opening_id\"].isin(strong_opening_ids))\n",
    "                        & (data[\"num_games\"] <= 20)\n",
    "                        & (data[\"score_original\"] > 0.6)\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            random_state=42,\n",
    "        )\n",
    "        \n",
    "        print(\n",
    "            f\"\\n   Strong opening + good player performance (shrunk toward HIGH opening mean):\"\n",
    "        )\n",
    "        for idx, row in strong_examples.iterrows():\n",
    "            adjustment = row[\"score\"] - row[\"score_original\"]\n",
    "            global_shrink_would_be = (\n",
    "                (row[\"num_games\"] * row[\"score_original\"]) + (k_player * global_mean_score)\n",
    "            ) / (row[\"num_games\"] + k_player)\n",
    "            difference = row[\"score\"] - global_shrink_would_be\n",
    "            print(\n",
    "                f\"   Player {row['player_id']:>5} | Opening {row['opening_id']:>4} ({row['eco']:>3}) | Games: {row['num_games']:>2} | \"\n",
    "                f\"Opening mean: {row['opening_mean']:.4f} | Original: {row['score_original']:.4f} ‚Üí {row['score']:.4f}\"\n",
    "            )\n",
    "            print(\n",
    "                f\"      If we'd shrunk to global mean: {global_shrink_would_be:.4f} (would lose {difference:+.4f} of deserved credit)\"\n",
    "            )\n",
    "        \n",
    "        # Find entries with weak openings where player did poorly\n",
    "        weak_opening_ids = data.nsmallest(50, \"opening_mean\")[\"opening_id\"].unique()\n",
    "        weak_examples = data[\n",
    "            (data[\"opening_id\"].isin(weak_opening_ids))\n",
    "            & (data[\"num_games\"] <= 20)\n",
    "            & (data[\"score_original\"] < 0.45)\n",
    "        ].sample(\n",
    "            min(\n",
    "                3,\n",
    "                len(\n",
    "                    data[\n",
    "                        (data[\"opening_id\"].isin(weak_opening_ids))\n",
    "                        & (data[\"num_games\"] <= 20)\n",
    "                        & (data[\"score_original\"] < 0.45)\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            random_state=42,\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n   Weak opening + poor player performance (shrunk toward LOW opening mean):\")\n",
    "        for idx, row in weak_examples.iterrows():\n",
    "            adjustment = row[\"score\"] - row[\"score_original\"]\n",
    "            global_shrink_would_be = (\n",
    "                (row[\"num_games\"] * row[\"score_original\"]) + (k_player * global_mean_score)\n",
    "            ) / (row[\"num_games\"] + k_player)\n",
    "            difference = row[\"score\"] - global_shrink_would_be\n",
    "            print(\n",
    "                f\"   Player {row['player_id']:>5} | Opening {row['opening_id']:>4} ({row['eco']:>3}) | Games: {row['num_games']:>2} | \"\n",
    "                f\"Opening mean: {row['opening_mean']:.4f} | Original: {row['score_original']:.4f} ‚Üí {row['score']:.4f}\"\n",
    "            )\n",
    "            print(\n",
    "                f\"      If we'd shrunk to global mean: {global_shrink_would_be:.4f} (would unfairly boost by {-difference:+.4f})\"\n",
    "            )\n",
    "        \n",
    "        # Drop temporary columns\n",
    "        print(f\"\\n9Ô∏è‚É£  Cleaning up...\")\n",
    "        data = data.drop(\n",
    "            columns=[\"score_original\", \"opening_mean\", \"opening_deviation_from_global\"]\n",
    "        )\n",
    "        print(f\"   ‚úì Removed temporary columns\")\n",
    "        \n",
    "        print(f\"\\n\" + \"=\" * 60)\n",
    "        print(\"‚úÖ HIERARCHICAL BAYESIAN ADJUSTMENT COMPLETE\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"\\nFinal data shape: {data.shape}\")\n",
    "        print(f\"Columns: {list(data.columns)}\")\n",
    "        print(f\"\\nNew columns added:\")\n",
    "        print(f\"   ‚Ä¢ 'confidence': weight for loss function (range [0,1])\")\n",
    "        print(f\"   ‚Ä¢ 'score': adjusted using hierarchical Bayesian shrinkage\")\n",
    "        print(f\"\\nKey improvement over simple shrinkage:\")\n",
    "        print(f\"   ‚Ä¢ Player scores now shrink toward OPENING-SPECIFIC means, not global mean\")\n",
    "        print(f\"   ‚Ä¢ Preserves opening difficulty differences\")\n",
    "        print(f\"   ‚Ä¢ More accurate for both strong and weak openings\")\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    # Configuration for Bayesian shrinkage\n",
    "    K_PLAYER = 50  # Shrinkage constant for player-opening scores\n",
    "    \n",
    "    # Call the function\n",
    "    clean_data = apply_hierarchical_bayesian_shrinkage(clean_data, k_player=K_PLAYER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73319d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         player_id  opening_id  num_games     score  eco  confidence\n",
      "1906751      31564        1374         28  0.545827  C00    0.358974\n"
     ]
    }
   ],
   "source": [
    "print(clean_data.sample().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85a80e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 2C: PLAYER RATING STATISTICS\n",
      "============================================================\n",
      "\n",
      "1Ô∏è‚É£  Extracting player ratings from database...\n",
      "   ‚úì Retrieved ratings for 49,467 players\n",
      "   ‚úì Database connection closed\n",
      "\n",
      "2Ô∏è‚É£  Merging ratings with clean_data...\n",
      "   ‚úì Merged successfully\n",
      "   ‚úì All entries have ratings\n",
      "\n",
      "3Ô∏è‚É£  Basic rating statistics:\n",
      "   ‚Ä¢ Count: 49,467\n",
      "   ‚Ä¢ Missing: 0\n",
      "   ‚Ä¢ Min: 1200\n",
      "   ‚Ä¢ Max: 2823\n",
      "   ‚Ä¢ Mean: 1765.38\n",
      "   ‚Ä¢ Median: 1762\n",
      "   ‚Ä¢ Std Dev: 249.22\n",
      "\n",
      "4Ô∏è‚É£  Quartile statistics:\n",
      "   ‚Ä¢ 25th percentile: 1584\n",
      "   ‚Ä¢ 50th percentile (median): 1762\n",
      "   ‚Ä¢ 75th percentile: 1937\n",
      "\n",
      "5Ô∏è‚É£  Detailed percentile distribution (5% increments):\n",
      "\n",
      "   Percentile   Rating     Visual\n",
      "   ------------ ---------- ----------------------------------------\n",
      "       0%          1200    \n",
      "       5%          1359    ‚ñà‚ñà‚ñà\n",
      "      10%          1436    ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      15%          1494    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      20%          1541    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      25%          1584    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      30%          1623    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      35%          1660    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      40%          1696    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   ‚úì Retrieved ratings for 49,467 players\n",
      "   ‚úì Database connection closed\n",
      "\n",
      "2Ô∏è‚É£  Merging ratings with clean_data...\n",
      "   ‚úì Merged successfully\n",
      "   ‚úì All entries have ratings\n",
      "\n",
      "3Ô∏è‚É£  Basic rating statistics:\n",
      "   ‚Ä¢ Count: 49,467\n",
      "   ‚Ä¢ Missing: 0\n",
      "   ‚Ä¢ Min: 1200\n",
      "   ‚Ä¢ Max: 2823\n",
      "   ‚Ä¢ Mean: 1765.38\n",
      "   ‚Ä¢ Median: 1762\n",
      "   ‚Ä¢ Std Dev: 249.22\n",
      "\n",
      "4Ô∏è‚É£  Quartile statistics:\n",
      "   ‚Ä¢ 25th percentile: 1584\n",
      "   ‚Ä¢ 50th percentile (median): 1762\n",
      "   ‚Ä¢ 75th percentile: 1937\n",
      "\n",
      "5Ô∏è‚É£  Detailed percentile distribution (5% increments):\n",
      "\n",
      "   Percentile   Rating     Visual\n",
      "   ------------ ---------- ----------------------------------------\n",
      "       0%          1200    \n",
      "       5%          1359    ‚ñà‚ñà‚ñà\n",
      "      10%          1436    ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      15%          1494    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      20%          1541    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      25%          1584    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      30%          1623    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      35%          1660    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      40%          1696    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      45%          1729    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      50%          1762    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      55%          1798    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      60%          1830    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      65%          1864    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      70%          1901    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      75%          1937    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      80%          1980    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      85%          2027    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      90%          2089    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      95%          2184    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     100%          2823    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "6Ô∏è‚É£  Rating distribution by range:\n",
      "\n",
      "   Range           Count      Percentage   Visual\n",
      "   --------------- ---------- ------------ ----------------------------------------\n",
      "      0-1000           0      0.00%      \n",
      "   1000-1200           0      0.00%      \n",
      "   1200-1400       3,649      7.38%      ‚ñà‚ñà\n",
      "   1400-1600       9,611     19.43%      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   1600-1800      14,051     28.40%      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   1800-2000      13,155     26.59%      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2000-2200       6,751     13.65%      ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2200-2400       1,891      3.82%      ‚ñà\n",
      "   2400-2600         334      0.68%      \n",
      "   2600-3000          25      0.05%      \n",
      "\n",
      "7Ô∏è‚É£  Spread statistics:\n",
      "   ‚Ä¢ Range: 1623\n",
      "   ‚Ä¢ Interquartile Range (IQR): 353\n",
      "   ‚Ä¢ 10th-90th percentile range: 653\n",
      "\n",
      "8Ô∏è‚É£  Distribution shape:\n",
      "   ‚Ä¢ scipy not available for skewness/kurtosis calculation\n",
      "\n",
      "9Ô∏è‚É£  Sample players at different rating levels:\n",
      "\n",
      "   ~10th percentile (rating ‚âà 1436):\n",
      "      Player 36693: no_cry - Rating: 1436\n",
      "\n",
      "   ~25th percentile (rating ‚âà 1584):\n",
      "      Player 2672: Bala_Nuthulapati - Rating: 1584\n",
      "\n",
      "   ~50th percentile (rating ‚âà 1762):\n",
      "      Player 22846: aj2345 - Rating: 1762\n",
      "\n",
      "   ~75th percentile (rating ‚âà 1937):\n",
      "      Player 42: AAJ_88 - Rating: 1937\n",
      "\n",
      "   ~90th percentile (rating ‚âà 2089):\n",
      "      Player 7255: Finnja - Rating: 2089\n",
      "\n",
      "============================================================\n",
      "‚úÖ RATING STATISTICS COMPLETE\n",
      "============================================================\n",
      "\n",
      "Key takeaways:\n",
      "   ‚Ä¢ Total players: 49,467\n",
      "   ‚Ä¢ Rating range: [1200, 2823]\n",
      "   ‚Ä¢ Mean ¬± std: 1765 ¬± 249\n",
      "   ‚Ä¢ Median: 1762\n",
      "\n",
      "   Next steps: Normalize ratings for model input\n",
      "      45%          1729    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      50%          1762    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      55%          1798    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      60%          1830    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      65%          1864    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      70%          1901    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      75%          1937    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      80%          1980    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      85%          2027    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      90%          2089    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      95%          2184    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     100%          2823    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "6Ô∏è‚É£  Rating distribution by range:\n",
      "\n",
      "   Range           Count      Percentage   Visual\n",
      "   --------------- ---------- ------------ ----------------------------------------\n",
      "      0-1000           0      0.00%      \n",
      "   1000-1200           0      0.00%      \n",
      "   1200-1400       3,649      7.38%      ‚ñà‚ñà\n",
      "   1400-1600       9,611     19.43%      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   1600-1800      14,051     28.40%      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   1800-2000      13,155     26.59%      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2000-2200       6,751     13.65%      ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2200-2400       1,891      3.82%      ‚ñà\n",
      "   2400-2600         334      0.68%      \n",
      "   2600-3000          25      0.05%      \n",
      "\n",
      "7Ô∏è‚É£  Spread statistics:\n",
      "   ‚Ä¢ Range: 1623\n",
      "   ‚Ä¢ Interquartile Range (IQR): 353\n",
      "   ‚Ä¢ 10th-90th percentile range: 653\n",
      "\n",
      "8Ô∏è‚É£  Distribution shape:\n",
      "   ‚Ä¢ scipy not available for skewness/kurtosis calculation\n",
      "\n",
      "9Ô∏è‚É£  Sample players at different rating levels:\n",
      "\n",
      "   ~10th percentile (rating ‚âà 1436):\n",
      "      Player 36693: no_cry - Rating: 1436\n",
      "\n",
      "   ~25th percentile (rating ‚âà 1584):\n",
      "      Player 2672: Bala_Nuthulapati - Rating: 1584\n",
      "\n",
      "   ~50th percentile (rating ‚âà 1762):\n",
      "      Player 22846: aj2345 - Rating: 1762\n",
      "\n",
      "   ~75th percentile (rating ‚âà 1937):\n",
      "      Player 42: AAJ_88 - Rating: 1937\n",
      "\n",
      "   ~90th percentile (rating ‚âà 2089):\n",
      "      Player 7255: Finnja - Rating: 2089\n",
      "\n",
      "============================================================\n",
      "‚úÖ RATING STATISTICS COMPLETE\n",
      "============================================================\n",
      "\n",
      "Key takeaways:\n",
      "   ‚Ä¢ Total players: 49,467\n",
      "   ‚Ä¢ Rating range: [1200, 2823]\n",
      "   ‚Ä¢ Mean ¬± std: 1765 ¬± 249\n",
      "   ‚Ä¢ Median: 1762\n",
      "\n",
      "   Next steps: Normalize ratings for model input\n"
     ]
    }
   ],
   "source": [
    "# 2c. Gather player rating statistics (no mutation, just exploration)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 2C: PLAYER RATING STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Connect to database and extract player ratings\n",
    "con = get_db_connection(str(DB_PATH))\n",
    "\n",
    "try:\n",
    "    print(f\"\\n1Ô∏è‚É£  Extracting player ratings from database...\")\n",
    "    \n",
    "    # Get unique player IDs from our clean_data\n",
    "    unique_player_ids = clean_data['player_id'].unique()\n",
    "    player_ids_str = ','.join(map(str, unique_player_ids))\n",
    "    \n",
    "    # Query to get player ratings\n",
    "    rating_query = f\"\"\"\n",
    "        SELECT \n",
    "            id as player_id,\n",
    "            name,\n",
    "            title,\n",
    "            rating\n",
    "        FROM player\n",
    "        WHERE id IN ({player_ids_str})\n",
    "    \"\"\"\n",
    "    \n",
    "    player_ratings = pd.DataFrame(con.execute(rating_query).df())\n",
    "    print(f\"   ‚úì Retrieved ratings for {len(player_ratings):,} players\")\n",
    "    \n",
    "finally:\n",
    "    con.close()\n",
    "    print(\"   ‚úì Database connection closed\")\n",
    "\n",
    "# Merge ratings into clean_data for analysis\n",
    "print(f\"\\n2Ô∏è‚É£  Merging ratings with clean_data...\")\n",
    "clean_data_with_ratings = clean_data.merge(player_ratings[['player_id', 'rating']], on='player_id', how='left')\n",
    "print(f\"   ‚úì Merged successfully\")\n",
    "\n",
    "# Check for missing ratings\n",
    "num_missing_ratings = clean_data_with_ratings['rating'].isna().sum()\n",
    "if num_missing_ratings > 0:\n",
    "    print(f\"   ‚ö†Ô∏è  {num_missing_ratings:,} entries ({100*num_missing_ratings/len(clean_data_with_ratings):.2f}%) have missing ratings\")\n",
    "else:\n",
    "    print(f\"   ‚úì All entries have ratings\")\n",
    "\n",
    "# Basic rating statistics\n",
    "print(f\"\\n3Ô∏è‚É£  Basic rating statistics:\")\n",
    "print(f\"   ‚Ä¢ Count: {player_ratings['rating'].notna().sum():,}\")\n",
    "print(f\"   ‚Ä¢ Missing: {player_ratings['rating'].isna().sum():,}\")\n",
    "print(f\"   ‚Ä¢ Min: {player_ratings['rating'].min():.0f}\")\n",
    "print(f\"   ‚Ä¢ Max: {player_ratings['rating'].max():.0f}\")\n",
    "print(f\"   ‚Ä¢ Mean: {player_ratings['rating'].mean():.2f}\")\n",
    "print(f\"   ‚Ä¢ Median: {player_ratings['rating'].median():.0f}\")\n",
    "print(f\"   ‚Ä¢ Std Dev: {player_ratings['rating'].std():.2f}\")\n",
    "\n",
    "# Quartile statistics\n",
    "print(f\"\\n4Ô∏è‚É£  Quartile statistics:\")\n",
    "print(f\"   ‚Ä¢ 25th percentile: {player_ratings['rating'].quantile(0.25):.0f}\")\n",
    "print(f\"   ‚Ä¢ 50th percentile (median): {player_ratings['rating'].quantile(0.50):.0f}\")\n",
    "print(f\"   ‚Ä¢ 75th percentile: {player_ratings['rating'].quantile(0.75):.0f}\")\n",
    "\n",
    "# Granular percentile statistics (5% increments)\n",
    "print(f\"\\n5Ô∏è‚É£  Detailed percentile distribution (5% increments):\")\n",
    "percentiles = [0.00, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50,\n",
    "               0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 1.00]\n",
    "\n",
    "print(f\"\\n   {'Percentile':<12} {'Rating':<10} {'Visual'}\")\n",
    "print(f\"   {'-'*12} {'-'*10} {'-'*40}\")\n",
    "\n",
    "for p in percentiles:\n",
    "    rating_value = player_ratings['rating'].quantile(p)\n",
    "    # Create a simple bar visualization\n",
    "    bar_length = int((rating_value - player_ratings['rating'].min()) / \n",
    "                     (player_ratings['rating'].max() - player_ratings['rating'].min()) * 40)\n",
    "    bar = '‚ñà' * bar_length\n",
    "    print(f\"   {p*100:>5.0f}%       {rating_value:>7.0f}    {bar}\")\n",
    "\n",
    "# Rating ranges and counts\n",
    "print(f\"\\n6Ô∏è‚É£  Rating distribution by range:\")\n",
    "rating_ranges = [\n",
    "    (0, 1000), (1000, 1200), (1200, 1400), (1400, 1600), \n",
    "    (1600, 1800), (1800, 2000), (2000, 2200), (2200, 2400), \n",
    "    (2400, 2600), (2600, 3000)\n",
    "]\n",
    "\n",
    "print(f\"\\n   {'Range':<15} {'Count':<10} {'Percentage':<12} {'Visual'}\")\n",
    "print(f\"   {'-'*15} {'-'*10} {'-'*12} {'-'*40}\")\n",
    "\n",
    "for low, high in rating_ranges:\n",
    "    count = len(player_ratings[(player_ratings['rating'] >= low) & (player_ratings['rating'] < high)])\n",
    "    pct = 100 * count / len(player_ratings)\n",
    "    bar_length = int(pct * 0.4)  # Scale for visualization\n",
    "    bar = '‚ñà' * bar_length\n",
    "    print(f\"   {low:>4}-{high:<8} {count:>7,}    {pct:>6.2f}%      {bar}\")\n",
    "\n",
    "# Interquartile range\n",
    "iqr = player_ratings['rating'].quantile(0.75) - player_ratings['rating'].quantile(0.25)\n",
    "print(f\"\\n7Ô∏è‚É£  Spread statistics:\")\n",
    "print(f\"   ‚Ä¢ Range: {player_ratings['rating'].max() - player_ratings['rating'].min():.0f}\")\n",
    "print(f\"   ‚Ä¢ Interquartile Range (IQR): {iqr:.0f}\")\n",
    "print(f\"   ‚Ä¢ 10th-90th percentile range: {player_ratings['rating'].quantile(0.90) - player_ratings['rating'].quantile(0.10):.0f}\")\n",
    "\n",
    "# Skewness and kurtosis if available\n",
    "try:\n",
    "    from scipy.stats import skew, kurtosis\n",
    "    skewness = skew(player_ratings['rating'].dropna())\n",
    "    kurt = kurtosis(player_ratings['rating'].dropna())\n",
    "    print(f\"\\n8Ô∏è‚É£  Distribution shape:\")\n",
    "    print(f\"   ‚Ä¢ Skewness: {skewness:.4f} {'(right-skewed)' if skewness > 0 else '(left-skewed)' if skewness < 0 else '(symmetric)'}\")\n",
    "    print(f\"   ‚Ä¢ Kurtosis: {kurt:.4f} {'(heavy-tailed)' if kurt > 0 else '(light-tailed)' if kurt < 0 else '(normal)'}\")\n",
    "except ImportError:\n",
    "    print(f\"\\n8Ô∏è‚É£  Distribution shape:\")\n",
    "    print(f\"   ‚Ä¢ scipy not available for skewness/kurtosis calculation\")\n",
    "\n",
    "# Sample of players at different rating levels\n",
    "print(f\"\\n9Ô∏è‚É£  Sample players at different rating levels:\")\n",
    "sample_percentiles = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "for p in sample_percentiles:\n",
    "    rating_threshold = player_ratings['rating'].quantile(p)\n",
    "    # Get a player near this rating\n",
    "    sample_player = player_ratings.iloc[(player_ratings['rating'] - rating_threshold).abs().argsort()[:1]]\n",
    "    print(f\"\\n   ~{p*100:.0f}th percentile (rating ‚âà {rating_threshold:.0f}):\")\n",
    "    for idx, row in sample_player.iterrows():\n",
    "        # print(f\"      Player {row['player_id']}: {row['name']} - Rating: {row['rating']:.0f} {f'({row['title']})' if pd.notna(row['title']) else ''}\")\n",
    "        title_str = f\" ({row['title']})\" if pd.notna(row['title']) else \"\"\n",
    "        print(f\"      Player {row['player_id']}: {row['name']} - Rating: {row['rating']:.0f}{title_str}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ RATING STATISTICS COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nKey takeaways:\")\n",
    "print(f\"   ‚Ä¢ Total players: {len(player_ratings):,}\")\n",
    "print(f\"   ‚Ä¢ Rating range: [{player_ratings['rating'].min():.0f}, {player_ratings['rating'].max():.0f}]\")\n",
    "print(f\"   ‚Ä¢ Mean ¬± std: {player_ratings['rating'].mean():.0f} ¬± {player_ratings['rating'].std():.0f}\")\n",
    "print(f\"   ‚Ä¢ Median: {player_ratings['rating'].median():.0f}\")\n",
    "print(f\"\\n   Next steps: Normalize ratings for model input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ab6b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 2D: NORMALIZE PLAYER RATINGS\n",
      "============================================================\n",
      "\n",
      "‚öôÔ∏è  Normalization strategy: Z-score\n",
      "   ‚Ä¢ Formula: (rating - mean) / std\n",
      "   ‚Ä¢ Purpose: Scale ratings for use as side information in MF model\n",
      "   ‚Ä¢ Benefits: Prevents gradient dominance, matches embedding scale\n",
      "\n",
      "1Ô∏è‚É£  Normalization parameters (calculated from 49,467 players):\n",
      "   ‚Ä¢ Mean: 1765.38\n",
      "   ‚Ä¢ Std Dev: 249.22\n",
      "\n",
      "2Ô∏è‚É£  Normalized rating statistics:\n",
      "   ‚Ä¢ Min: -2.2686\n",
      "   ‚Ä¢ Max: 4.2437\n",
      "   ‚Ä¢ Mean: -0.000000 (should be ~0)\n",
      "   ‚Ä¢ Std: 1.000000 (should be ~1)\n",
      "   ‚Ä¢ Range: [-2.27, 4.24]\n",
      "\n",
      "3Ô∏è‚É£  Sample normalized ratings across skill levels:\n",
      "   ~10th percentile: no_cry               | Original: 1436 ‚Üí Normalized: -1.322\n",
      "   ~25th percentile: Bala_Nuthulapati     | Original: 1584 ‚Üí Normalized: -0.728\n",
      "   ~50th percentile: aj2345               | Original: 1762 ‚Üí Normalized: -0.014\n",
      "   ~75th percentile: AAJ_88               | Original: 1937 ‚Üí Normalized:  0.689\n",
      "   ~90th percentile: Finnja               | Original: 2089 ‚Üí Normalized:  1.299\n",
      "\n",
      "4Ô∏è‚É£  Interpretation guide:\n",
      "   ‚Ä¢ rating_z ‚âà -2.3: 1200 player (minimum)\n",
      "   ‚Ä¢ rating_z ‚âà -0.7: 1584 player (25th percentile)\n",
      "   ‚Ä¢ rating_z ‚âà  0.0: 1765 player (mean)\n",
      "   ‚Ä¢ rating_z ‚âà 0.7: 1937 player (75th percentile)\n",
      "   ‚Ä¢ rating_z ‚âà 4.2: 2823 player (maximum)\n",
      "\n",
      "5Ô∏è‚É£  Merging normalized ratings into clean_data...\n",
      "   ‚úì Merged successfully\n",
      "   ‚úì All entries have rating_z values\n",
      "\n",
      "6Ô∏è‚É£  Sample of data with normalized ratings (10 random entries):\n",
      "   Player 31381 | Opening  937 | Rating: 1595 ‚Üí Z-score: -0.684 | Score: 0.4914 | Games:  38\n",
      "   Player  5028 | Opening  439 | Rating: 1716 ‚Üí Z-score: -0.198 | Score: 0.5123 | Games:  15\n",
      "   Player 24344 | Opening 3148 | Rating: 2072 ‚Üí Z-score:  1.230 | Score: 0.4866 | Games:  16\n",
      "   Player 10369 | Opening  400 | Rating: 1557 ‚Üí Z-score: -0.836 | Score: 0.5353 | Games:  10\n",
      "   Player 42505 | Opening 2306 | Rating: 2005 ‚Üí Z-score:  0.961 | Score: 0.5767 | Games:  46\n",
      "   Player 48721 | Opening 3238 | Rating: 2180 ‚Üí Z-score:  1.664 | Score: 0.4942 | Games:  18\n",
      "   Player 12117 | Opening  794 | Rating: 2335 ‚Üí Z-score:  2.286 | Score: 0.5107 | Games: 318\n",
      "   Player  4712 | Opening 2206 | Rating: 1616 ‚Üí Z-score: -0.599 | Score: 0.5612 | Games:  30\n",
      "   Player 28672 | Opening 3214 | Rating: 1881 ‚Üí Z-score:  0.464 | Score: 0.5265 | Games:  15\n",
      "   Player 46177 | Opening 2428 | Rating: 1723 ‚Üí Z-score: -0.170 | Score: 0.5387 | Games:  11\n",
      "\n",
      "============================================================\n",
      "‚úÖ RATING NORMALIZATION COMPLETE\n",
      "============================================================\n",
      "\n",
      "Final data shape: (2956680, 8)\n",
      "New columns added:\n",
      "   ‚Ä¢ 'rating': original player rating (side information)\n",
      "   ‚Ä¢ 'rating_z': z-score normalized rating (for model input)\n",
      "\n",
      "‚ö†Ô∏è  CRITICAL: Save these parameters for inference!\n",
      "   RATING_MEAN = 1765.38\n",
      "   RATING_STD = 249.22\n",
      "\n",
      "   You'll need them to normalize ratings for new users at inference time.\n",
      "   ‚úì Merged successfully\n",
      "   ‚úì All entries have rating_z values\n",
      "\n",
      "6Ô∏è‚É£  Sample of data with normalized ratings (10 random entries):\n",
      "   Player 31381 | Opening  937 | Rating: 1595 ‚Üí Z-score: -0.684 | Score: 0.4914 | Games:  38\n",
      "   Player  5028 | Opening  439 | Rating: 1716 ‚Üí Z-score: -0.198 | Score: 0.5123 | Games:  15\n",
      "   Player 24344 | Opening 3148 | Rating: 2072 ‚Üí Z-score:  1.230 | Score: 0.4866 | Games:  16\n",
      "   Player 10369 | Opening  400 | Rating: 1557 ‚Üí Z-score: -0.836 | Score: 0.5353 | Games:  10\n",
      "   Player 42505 | Opening 2306 | Rating: 2005 ‚Üí Z-score:  0.961 | Score: 0.5767 | Games:  46\n",
      "   Player 48721 | Opening 3238 | Rating: 2180 ‚Üí Z-score:  1.664 | Score: 0.4942 | Games:  18\n",
      "   Player 12117 | Opening  794 | Rating: 2335 ‚Üí Z-score:  2.286 | Score: 0.5107 | Games: 318\n",
      "   Player  4712 | Opening 2206 | Rating: 1616 ‚Üí Z-score: -0.599 | Score: 0.5612 | Games:  30\n",
      "   Player 28672 | Opening 3214 | Rating: 1881 ‚Üí Z-score:  0.464 | Score: 0.5265 | Games:  15\n",
      "   Player 46177 | Opening 2428 | Rating: 1723 ‚Üí Z-score: -0.170 | Score: 0.5387 | Games:  11\n",
      "\n",
      "============================================================\n",
      "‚úÖ RATING NORMALIZATION COMPLETE\n",
      "============================================================\n",
      "\n",
      "Final data shape: (2956680, 8)\n",
      "New columns added:\n",
      "   ‚Ä¢ 'rating': original player rating (side information)\n",
      "   ‚Ä¢ 'rating_z': z-score normalized rating (for model input)\n",
      "\n",
      "‚ö†Ô∏è  CRITICAL: Save these parameters for inference!\n",
      "   RATING_MEAN = 1765.38\n",
      "   RATING_STD = 249.22\n",
      "\n",
      "   You'll need them to normalize ratings for new users at inference time.\n"
     ]
    }
   ],
   "source": [
    "# 2d. Normalize player ratings using z-score normalization (for use as side information in MF model)\n",
    "\n",
    "# TODO we'll need to save the mean and std for use during inference later. Copilot, you'll see later that I forgot this; remind me\n",
    "\n",
    "# Check if rating_z already exists - if so, skip processing but still show the statistics\n",
    "if 'rating_z' in clean_data.columns:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"‚è≠Ô∏è  SKIPPING STEP 2D: RATING NORMALIZATION\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\n‚úì 'rating_z' column already exists in data\")\n",
    "    print(\"   This indicates rating normalization has already been applied.\")\n",
    "    print(f\"\\nCurrent data shape: {clean_data.shape}\")\n",
    "    \n",
    "    # Still show statistics for review\n",
    "    print(f\"\\nüìä Existing normalized rating statistics:\")\n",
    "    print(f\"   ‚Ä¢ Min: {clean_data['rating_z'].min():.4f}\")\n",
    "    print(f\"   ‚Ä¢ Max: {clean_data['rating_z'].max():.4f}\")\n",
    "    print(f\"   ‚Ä¢ Mean: {clean_data['rating_z'].mean():.6f} (should be ~0)\")\n",
    "    print(f\"   ‚Ä¢ Std: {clean_data['rating_z'].std():.6f} (should be ~1)\")\n",
    "    \n",
    "    # Show sample with original and normalized ratings\n",
    "    print(f\"\\nüìã Sample of existing normalized ratings:\")\n",
    "    sample_data = clean_data[['player_id', 'rating', 'rating_z']].drop_duplicates('player_id').sample(10, random_state=42)\n",
    "    for idx, row in sample_data.iterrows():\n",
    "        print(f\"   Player {row['player_id']:>5} | Original: {row['rating']:>4.0f} ‚Üí Normalized: {row['rating_z']:>6.3f}\")\n",
    "else:\n",
    "    # Define the normalization function\n",
    "    def normalize_player_ratings(data, player_ratings_df):\n",
    "        \"\"\"\n",
    "        Apply z-score normalization to player ratings for use as side information.\n",
    "        \n",
    "        Why z-score normalization?\n",
    "        - Puts ratings on similar scale as embedding initialization (typically N(0, 0.1))\n",
    "        - Prevents gradient scale mismatch during training\n",
    "        - Standard practice for side information in matrix factorization\n",
    "        - Preserves relative differences between players\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        data : pd.DataFrame\n",
    "            Clean data with player_id column\n",
    "        player_ratings_df : pd.DataFrame\n",
    "            Player ratings with columns: player_id, rating\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame\n",
    "            Data with 'rating' and 'rating_z' columns added\n",
    "        \"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"STEP 2D: NORMALIZE PLAYER RATINGS\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        print(f\"\\n‚öôÔ∏è  Normalization strategy: Z-score\")\n",
    "        print(f\"   ‚Ä¢ Formula: (rating - mean) / std\")\n",
    "        print(f\"   ‚Ä¢ Purpose: Scale ratings for use as side information in MF model\")\n",
    "        print(f\"   ‚Ä¢ Benefits: Prevents gradient dominance, matches embedding scale\")\n",
    "        \n",
    "        # Calculate normalization parameters from player_ratings\n",
    "        RATING_MEAN = player_ratings_df['rating'].mean()\n",
    "        RATING_STD = player_ratings_df['rating'].std()\n",
    "        \n",
    "        print(f\"\\n1Ô∏è‚É£  Normalization parameters (calculated from {len(player_ratings_df):,} players):\")\n",
    "        print(f\"   ‚Ä¢ Mean: {RATING_MEAN:.2f}\")\n",
    "        print(f\"   ‚Ä¢ Std Dev: {RATING_STD:.2f}\")\n",
    "        \n",
    "        # Apply z-score normalization to player_ratings\n",
    "        player_ratings_df = player_ratings_df.copy()\n",
    "        player_ratings_df['rating_z'] = (player_ratings_df['rating'] - RATING_MEAN) / RATING_STD\n",
    "        \n",
    "        print(f\"\\n2Ô∏è‚É£  Normalized rating statistics:\")\n",
    "        print(f\"   ‚Ä¢ Min: {player_ratings_df['rating_z'].min():.4f}\")\n",
    "        print(f\"   ‚Ä¢ Max: {player_ratings_df['rating_z'].max():.4f}\")\n",
    "        print(f\"   ‚Ä¢ Mean: {player_ratings_df['rating_z'].mean():.6f} (should be ~0)\")\n",
    "        print(f\"   ‚Ä¢ Std: {player_ratings_df['rating_z'].std():.6f} (should be ~1)\")\n",
    "        print(f\"   ‚Ä¢ Range: [{player_ratings_df['rating_z'].min():.2f}, {player_ratings_df['rating_z'].max():.2f}]\")\n",
    "        \n",
    "        print(f\"\\n3Ô∏è‚É£  Sample normalized ratings across skill levels:\")\n",
    "        sample_percentiles = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "        for p in sample_percentiles:\n",
    "            rating_threshold = player_ratings_df['rating'].quantile(p)\n",
    "            sample_player = player_ratings_df.iloc[(player_ratings_df['rating'] - rating_threshold).abs().argsort()[:1]]\n",
    "            for idx, row in sample_player.iterrows():\n",
    "                print(f\"   ~{p*100:.0f}th percentile: {row['name']:<20} | \"\n",
    "                      f\"Original: {row['rating']:>4.0f} ‚Üí Normalized: {row['rating_z']:>6.3f}\")\n",
    "        \n",
    "        print(f\"\\n4Ô∏è‚É£  Interpretation guide:\")\n",
    "        print(f\"   ‚Ä¢ rating_z ‚âà {(1200 - RATING_MEAN)/RATING_STD:.1f}: 1200 player (minimum)\")\n",
    "        print(f\"   ‚Ä¢ rating_z ‚âà {(player_ratings_df['rating'].quantile(0.25) - RATING_MEAN)/RATING_STD:.1f}: {player_ratings_df['rating'].quantile(0.25):.0f} player (25th percentile)\")\n",
    "        print(f\"   ‚Ä¢ rating_z ‚âà  0.0: {RATING_MEAN:.0f} player (mean)\")\n",
    "        print(f\"   ‚Ä¢ rating_z ‚âà {(player_ratings_df['rating'].quantile(0.75) - RATING_MEAN)/RATING_STD:.1f}: {player_ratings_df['rating'].quantile(0.75):.0f} player (75th percentile)\")\n",
    "        print(f\"   ‚Ä¢ rating_z ‚âà {(player_ratings_df['rating'].max() - RATING_MEAN)/RATING_STD:.1f}: {player_ratings_df['rating'].max():.0f} player (maximum)\")\n",
    "        \n",
    "        # Merge rating and rating_z into the main data\n",
    "        print(f\"\\n5Ô∏è‚É£  Merging normalized ratings into clean_data...\")\n",
    "        data = data.merge(\n",
    "            player_ratings_df[['player_id', 'rating', 'rating_z']], \n",
    "            on='player_id', \n",
    "            how='left'\n",
    "        )\n",
    "        print(f\"   ‚úì Merged successfully\")\n",
    "        \n",
    "        # Verify no missing values\n",
    "        missing_ratings = data['rating_z'].isna().sum()\n",
    "        if missing_ratings > 0:\n",
    "            print(f\"   ‚ö†Ô∏è  Warning: {missing_ratings} entries have missing rating_z values\")\n",
    "        else:\n",
    "            print(f\"   ‚úì All entries have rating_z values\")\n",
    "        \n",
    "        # Show sample of merged data\n",
    "        print(f\"\\n6Ô∏è‚É£  Sample of data with normalized ratings (10 random entries):\")\n",
    "        sample_data = data.sample(min(10, len(data)), random_state=42)\n",
    "        for idx, row in sample_data.iterrows():\n",
    "            print(f\"   Player {row['player_id']:>5} | Opening {row['opening_id']:>4} | \"\n",
    "                  f\"Rating: {row['rating']:>4.0f} ‚Üí Z-score: {row['rating_z']:>6.3f} | \"\n",
    "                  f\"Score: {row['score']:.4f} | Games: {row['num_games']:>3}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"‚úÖ RATING NORMALIZATION COMPLETE\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"\\nFinal data shape: {data.shape}\")\n",
    "        print(f\"New columns added:\")\n",
    "        print(f\"   ‚Ä¢ 'rating': original player rating (side information)\")\n",
    "        print(f\"   ‚Ä¢ 'rating_z': z-score normalized rating (for model input)\")\n",
    "        \n",
    "        print(f\"\\n‚ö†Ô∏è  CRITICAL: Save these parameters for inference!\")\n",
    "        print(f\"   RATING_MEAN = {RATING_MEAN:.2f}\")\n",
    "        print(f\"   RATING_STD = {RATING_STD:.2f}\")\n",
    "        print(f\"\\n   You'll need them to normalize ratings for new users at inference time.\")\n",
    "        \n",
    "        return data, RATING_MEAN, RATING_STD\n",
    "    \n",
    "    # Call the function\n",
    "    clean_data, RATING_MEAN, RATING_STD = normalize_player_ratings(clean_data, player_ratings)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
