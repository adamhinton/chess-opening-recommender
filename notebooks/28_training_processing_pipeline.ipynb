{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40e163a7",
   "metadata": {},
   "source": [
    "# Notebook 26 ‚Äî Opening Recommender Model: Training Pipeline\n",
    "\n",
    "### 0. Overview and Goals\n",
    "\n",
    "This notebook defines the full pipeline for training the chess opening recommender model.  \n",
    "The objective is to predict **player‚Äìopening performance scores** ((wins + (0.5 * draws) / num games)) for openings a player hasn‚Äôt yet played, based on their results in the openings they *have* played.  \n",
    "\n",
    "The model will use **matrix factorization** with **stochastic gradient descent (SGD)** to learn latent factors representing player and opening characteristics.  \n",
    "All computations will be implemented in **PyTorch**, with data loaded from my local **DuckDB** database.\n",
    "\n",
    "**High-level specs:**\n",
    "- Use only *White* openings initially (we‚Äôll extend to Black later).  \n",
    "- Data source: processed player‚Äìopening stats from local DuckDB.  \n",
    "- Predict: normalized ‚Äúscore‚Äù = win rate ((wins + 0.5 x draws) / total games).  \n",
    "- Filter: only include entries with ‚â• `MIN_GAMES_THRESHOLD` (default = 50).  \n",
    "- Ignore: rating differences, time controls, and other metadata.  \n",
    "- Model parameters (to be defined in appropriate places for easy editing):  \n",
    "  - `NUM_FACTORS`, `LEARNING_RATE`, `BATCH_SIZE`, `N_EPOCHS`, `NUM_PLAYERS_TO_PROCESS`  \n",
    "- Logging and checkpoints throughout for reproducibility.  \n",
    "- All random operations seeded for deterministic runs.  \n",
    "\n",
    "---\n",
    "\n",
    "### 1. Data Extraction\n",
    "- Connect to local DuckDB\n",
    "- Pull all processed player‚Äìopening statistics from\n",
    "- Verify schema consistency:  \n",
    "  - Required columns: `player_id`, `opening_id`, `eco`, `num_games`, `wins`, `draws`, `losses`.  \n",
    "- Include a row-count sanity check.\n",
    "- Only players with ratings above 1200\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Data Sanitization & Normalization\n",
    "- Optionally normalize scores if needed for MF convergence.  \n",
    "- Drop players with no qualifying openings and openings with no qualifying players.  \n",
    "  - I believe there shouldn't be any but we'll double check.\n",
    "- Resequence player_id and opening_id to be sequential integers - right now there are gaps because of entries we deleted from the DB \n",
    "- Check for sparsity consistency (no implicit zeros yet).  \n",
    "- Note that this data has already been split in to white and black games further up the pipeline\n",
    "\n",
    "### Data Quality\n",
    "- Drop entries with fewer than `MIN_GAMES_THRESHOLD` games\n",
    "- Handle any duplicate `(player_id, opening_id)` combinations\n",
    "- Remove players with no qualifying openings\n",
    "- Remove openings with no qualifying players\n",
    "- Verify no null values remain\n",
    "\n",
    "### ECO Codes\n",
    "- Keep ECO codes for later categorical encoding (Step 4)\n",
    "- ECO will be used as opening side information (similar to rating for players)\n",
    "\n",
    "### Confidence Weighting\n",
    "- Use `MIN_GAMES_THRESHOLD = 10` to keep more data\n",
    "- Add a **confidence weight** column: `confidence = num_games / (num_games + K)` where K ‚âà 50\n",
    "- This weight will be used in the loss function to down-weight uncertain predictions\n",
    "- High-game-count entries ‚Üí high confidence ‚Üí larger loss impact\n",
    "- Low-game-count entries ‚Üí low confidence ‚Üí smaller loss impact\n",
    "\n",
    "### Player Rating (Side Information)\n",
    "- **Player ratings are side information** - they describe player characteristics, not individual player-opening interactions\n",
    "- Ratings will be stored separately and joined to player embeddings during training\n",
    "- We'll **normalize ratings** (likely z-score normalization) to avoid scaling issues with the embedding layer\n",
    "- Rating normalization will be done once after extraction, not per-row\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Data Splits\n",
    "- Split into train/test/val sets.  \n",
    "- Ensure every player and every opening appears at least once in the training data.  \n",
    "- Strategy:  \n",
    "  - Sample unique players and openings to guarantee coverage in train.  \n",
    "  - Remaining data ‚Üí stratified random split into train/test.  \n",
    "  - Deduplicate and merge unique IDs back into train if needed.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Enumerate Categorical Variables\n",
    "- Enumerate `eco` (if included) as an integer categorical variable.  \n",
    "- Confirm all columns are numeric and compatible with PyTorch tensors.  \n",
    "- Verify no missing or out-of-range IDs.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Training Data Structure\n",
    "- Each row: one `(player_id, opening_id, score)` record.\n",
    "- Include other fields- eco, num games etc\n",
    "- Convert DataFrame to PyTorch tensors (`torch.long` for IDs, `torch.float` for scores).  \n",
    "- Log dataset shapes and sparsity metrics.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Training Setup\n",
    "Define constants:\n",
    "- `LEARNING_RATE`, `BATCH_SIZE`, `N_EPOCHS`, `NUM_FACTORS`  \n",
    "- Loss functions: MSE and RMSE  \n",
    "- Activation: sigmoid or none (depending on score normalization)  \n",
    "- Optimizer: SGD  \n",
    "- Figure out if there's anything else we need to design or specify\n",
    "\n",
    "Implement helper functions:\n",
    "- `train_one_epoch()`\n",
    "- `evaluate_model()`\n",
    "- `calculate_rmse()`\n",
    "- `save_checkpoint()`  \n",
    "\n",
    "Ensure detailed logging, ETA reporting, and reproducible random seeds.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Training Loop\n",
    "- Initialize player and opening embeddings.  \n",
    "- Iterate through epochs with mini-batch SGD (`BATCH_SIZE = 1024`).  \n",
    "- Compute and log MSE/RMSE per epoch.  \n",
    "- Save model checkpoints locally after each epoch.\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Evaluation\n",
    "- Evaluate on test set.  \n",
    "- Report MSE, RMSE, and visual diagnostics (predicted vs actual score).  \n",
    "- Inspect a few player and opening latent factors for sanity.\n",
    "\n",
    "---\n",
    "\n",
    "### 9. Cross-Validation & Hyperparameter Tuning\n",
    "- Define ranges for:  \n",
    "  - `NUM_FACTORS`, `LEARNING_RATE`, `BATCH_SIZE`, `N_EPOCHS`  \n",
    "- Perform small-scale grid or random search for best configuration.  \n",
    "- Compare validation RMSE across runs.\n",
    "\n",
    "---\n",
    "\n",
    "### 10. Next Steps\n",
    "- Extend model to include Black openings.  \n",
    "- Experiment with hybrid inputs (player rating, ECO grouping).  \n",
    "- Consider implicit feedback handling (unplayed openings as zeros).  \n",
    "- Integrate trained model into API for recommendation output.\n",
    "\n",
    "---\n",
    "\n",
    "**Notes:**  \n",
    "- Every random seed and parameter definition will be explicit.  \n",
    "- Every major step includes row-count, schema, and type validation.  \n",
    "- Model artifacts and logs will be saved locally for reproducibility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc6d823",
   "metadata": {},
   "source": [
    "## Step 1: Data Extraction\n",
    "\n",
    "Connect to DuckDB and extract all player-opening statistics.\n",
    "Verify schema and perform sanity checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcea569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# Add utils to path\n",
    "sys.path.append(str(Path.cwd() / 'utils'))\n",
    "from database.db_utils import get_db_connection\n",
    "\n",
    "# Configuration\n",
    "DB_PATH = Path.cwd().parent / \"data\" / \"processed\" / \"chess_games.db\"\n",
    "COLOR_FILTER = 'w'  # 'w' for white, 'b' for black\n",
    "MIN_HOLDOUT_PLAYERS = 1000  # Minimum number of players to reserve for fold-in verification. These will not be used at all in this notebook for training, test/val or anything else.\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 1: DATA EXTRACTION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüìÅ Database: {DB_PATH}\")\n",
    "print(f\"üìÅ Database exists: {DB_PATH.exists()}\")\n",
    "print(f\"üé® Color filter: {'White' if COLOR_FILTER == 'w' else 'Black'}\")\n",
    "print(f\"üîí Minimum holdout players: {MIN_HOLDOUT_PLAYERS:,}\")\n",
    "\n",
    "if not DB_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Database not found at {DB_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9435033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DuckDB and extract player-opening statistics\n",
    "con = get_db_connection(str(DB_PATH))\n",
    "\n",
    "try:\n",
    "    print(f\"\\n1Ô∏è‚É£  Extracting player-opening statistics (color: '{COLOR_FILTER}')...\")\n",
    "    \n",
    "    # Extract stats with calculated score and num_games\n",
    "    # Filter by color, minimum rating, and calculate score in the database\n",
    "    MIN_RATING = 1200\n",
    "    print(f\"   ‚Ä¢ Minimum rating filter: {MIN_RATING}\")\n",
    "    \n",
    "    # First, get all eligible players and randomly select holdout set\n",
    "    print(f\"\\n2Ô∏è‚É£  Selecting holdout players for fold-in verification...\")\n",
    "    print(f\"   ‚Ä¢ Holdout size: {MIN_HOLDOUT_PLAYERS:,} players minimum\")\n",
    "    \n",
    "    # Get all players with sufficient data\n",
    "    player_query = f\"\"\"\n",
    "        SELECT DISTINCT p.id as player_id\n",
    "        FROM player p\n",
    "        JOIN player_opening_stats pos ON p.id = pos.player_id\n",
    "        WHERE p.rating >= {MIN_RATING}\n",
    "        AND pos.color = '{COLOR_FILTER}'\n",
    "    \"\"\"\n",
    "    \n",
    "    all_eligible_players = pd.DataFrame(con.execute(player_query).df())\n",
    "    total_eligible = len(all_eligible_players)\n",
    "    print(f\"   ‚Ä¢ Total eligible players: {total_eligible:,}\")\n",
    "    \n",
    "    if total_eligible < MIN_HOLDOUT_PLAYERS:\n",
    "        raise ValueError(f\"Not enough eligible players ({total_eligible:,}) to create holdout set of {MIN_HOLDOUT_PLAYERS:,}\")\n",
    "    \n",
    "    # Randomly sample holdout players (deterministic with seed)\n",
    "    import numpy as np\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    \n",
    "    holdout_player_ids = np.random.choice(\n",
    "        all_eligible_players['player_id'].values,\n",
    "        size=MIN_HOLDOUT_PLAYERS,\n",
    "        replace=False\n",
    "    )\n",
    "    \n",
    "    training_player_ids = set(all_eligible_players['player_id'].values) - set(holdout_player_ids)\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Holdout players selected: {len(holdout_player_ids):,}\")\n",
    "    print(f\"   ‚Ä¢ Training players available: {len(training_player_ids):,}\")\n",
    "    print(f\"   ‚Ä¢ Holdout percentage: {100 * len(holdout_player_ids) / total_eligible:.1f}%\")\n",
    "    \n",
    "    # Convert training player IDs to SQL-friendly string\n",
    "    training_player_ids_str = ','.join(map(str, training_player_ids))\n",
    "    \n",
    "    # Extract data ONLY for training players\n",
    "    print(f\"\\n3Ô∏è‚É£  Extracting training data (excluding holdout players)...\")\n",
    "    \n",
    "    query = f\"\"\"\n",
    "        SELECT \n",
    "            pos.player_id,\n",
    "            pos.opening_id,\n",
    "            pos.num_wins + pos.num_draws + pos.num_losses as num_games,\n",
    "            (pos.num_wins + (pos.num_draws * 0.5)) / \n",
    "                NULLIF(pos.num_wins + pos.num_draws + pos.num_losses, 0) as score,\n",
    "            o.eco\n",
    "        FROM player_opening_stats pos\n",
    "        JOIN opening o ON pos.opening_id = o.id\n",
    "        JOIN player p ON pos.player_id = p.id\n",
    "        WHERE pos.color = '{COLOR_FILTER}'\n",
    "        AND p.rating >= {MIN_RATING}\n",
    "        AND pos.player_id IN ({training_player_ids_str})\n",
    "        ORDER BY pos.player_id, pos.opening_id\n",
    "    \"\"\"\n",
    "    \n",
    "    raw_data = pd.DataFrame(con.execute(query).df())\n",
    "    \n",
    "    print(f\"   ‚úì Extracted {len(raw_data):,} rows\")\n",
    "    \n",
    "    # Also save holdout player IDs for later use\n",
    "    holdout_players_df = pd.DataFrame({'player_id': holdout_player_ids})\n",
    "    print(f\"\\n   üíæ Saved holdout_players_df with {len(holdout_players_df):,} player IDs\")\n",
    "    print(f\"   ‚Ä¢ These players are COMPLETELY UNSEEN by the training process\")\n",
    "    print(f\"   ‚Ä¢ Use them later for fold-in verification\")\n",
    "    \n",
    "    # Schema verification\n",
    "    print(\"\\n4Ô∏è‚É£  Verifying schema...\")\n",
    "    required_columns = ['player_id', 'opening_id', 'num_games', 'score', 'eco']\n",
    "    \n",
    "    for col in required_columns:\n",
    "        if col not in raw_data.columns:\n",
    "            raise ValueError(f\"Missing required column: {col}\")\n",
    "    \n",
    "    print(f\"   ‚úì All required columns present: {required_columns}\")\n",
    "    \n",
    "    # Data types verification\n",
    "    print(\"\\n5Ô∏è‚É£  Checking data types...\")\n",
    "    print(f\"   ‚Ä¢ player_id: {raw_data['player_id'].dtype}\")\n",
    "    print(f\"   ‚Ä¢ opening_id: {raw_data['opening_id'].dtype}\")\n",
    "    print(f\"   ‚Ä¢ num_games: {raw_data['num_games'].dtype}\")\n",
    "    print(f\"   ‚Ä¢ score: {raw_data['score'].dtype}\")\n",
    "    print(f\"   ‚Ä¢ eco: {raw_data['eco'].dtype}\")\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(\"\\n6Ô∏è‚É£  Data statistics...\")\n",
    "    print(f\"   ‚Ä¢ Total rows: {len(raw_data):,}\")\n",
    "    print(f\"   ‚Ä¢ Unique players: {raw_data['player_id'].nunique():,}\")\n",
    "    print(f\"   ‚Ä¢ Unique openings: {raw_data['opening_id'].nunique():,}\")\n",
    "    print(f\"   ‚Ä¢ Total games (sum): {raw_data['num_games'].sum():,}\")\n",
    "    \n",
    "    # Player ID range\n",
    "    print(f\"\\n   Player ID range:\")\n",
    "    print(f\"   ‚Ä¢ Min: {raw_data['player_id'].min()}\")\n",
    "    print(f\"   ‚Ä¢ Max: {raw_data['player_id'].max()}\")\n",
    "    \n",
    "    # Opening ID range\n",
    "    print(f\"\\n   Opening ID range:\")\n",
    "    print(f\"   ‚Ä¢ Min: {raw_data['opening_id'].min()}\")\n",
    "    print(f\"   ‚Ä¢ Max: {raw_data['opening_id'].max()}\")\n",
    "    \n",
    "    # Games per entry statistics\n",
    "    print(f\"\\n   Games per entry:\")\n",
    "    print(f\"   ‚Ä¢ Min: {raw_data['num_games'].min()}\")\n",
    "    print(f\"   ‚Ä¢ Max: {raw_data['num_games'].max()}\")\n",
    "    print(f\"   ‚Ä¢ Mean: {raw_data['num_games'].mean():.1f}\")\n",
    "    print(f\"   ‚Ä¢ Median: {raw_data['num_games'].median():.0f}\")\n",
    "    \n",
    "    # Score statistics\n",
    "    print(f\"\\n   Score distribution:\")\n",
    "    print(f\"   ‚Ä¢ Min: {raw_data['score'].min():.4f}\")\n",
    "    print(f\"   ‚Ä¢ Max: {raw_data['score'].max():.4f}\")\n",
    "    print(f\"   ‚Ä¢ Mean: {raw_data['score'].mean():.4f}\")\n",
    "    print(f\"   ‚Ä¢ Median: {raw_data['score'].median():.4f}\")\n",
    "    \n",
    "    # Check for null values\n",
    "    print(\"\\n7Ô∏è‚É£  Checking for null values...\")\n",
    "    null_counts = raw_data.isnull().sum()\n",
    "    if null_counts.sum() == 0:\n",
    "        print(\"   ‚úì No null values found\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  Found null values:\")\n",
    "        for col, count in null_counts[null_counts > 0].items():\n",
    "            print(f\"      ‚Ä¢ {col}: {count} nulls\")\n",
    "    \n",
    "    # Sample data\n",
    "    print(\"\\n8Ô∏è‚É£  Sample of extracted data (first 10 rows):\")\n",
    "    print(raw_data.head(10).to_string())\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úÖ DATA EXTRACTION COMPLETE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nData shape: {raw_data.shape}\")\n",
    "    print(f\"Columns: {list(raw_data.columns)}\")\n",
    "    print(f\"\\n‚ö†Ô∏è  IMPORTANT: {len(holdout_player_ids):,} players held out for fold-in verification\")\n",
    "    print(f\"   ‚Ä¢ Access via: holdout_players_df\")\n",
    "    print(f\"   ‚Ä¢ These players will NOT appear in any training, validation, or test splits\")\n",
    "    \n",
    "finally:\n",
    "    con.close()\n",
    "    print(\"\\n‚úì Database connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad110b85",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "519d8f2f",
   "metadata": {},
   "source": [
    "## Step 2: Data Sanitization & Normalization\n",
    "\n",
    "Filter low-quality data, handle duplicates, and prepare for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74f0b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2a. Filter low-quality data, handle duplicates, and prepare for training.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Configuration\n",
    "MIN_GAMES_THRESHOLD = 10\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 2: DATA SANITIZATION & NORMALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n‚öôÔ∏è  Configuration:\")\n",
    "print(f\"   ‚Ä¢ MIN_GAMES_THRESHOLD: {MIN_GAMES_THRESHOLD}\")\n",
    "\n",
    "# Start with raw_data from Step 1\n",
    "print(f\"\\nüìä Starting data shape: {raw_data.shape}\")\n",
    "print(f\"   ‚Ä¢ Rows: {len(raw_data):,}\")\n",
    "print(f\"   ‚Ä¢ Unique players: {raw_data['player_id'].nunique():,}\")\n",
    "print(f\"   ‚Ä¢ Unique openings: {raw_data['opening_id'].nunique():,}\")\n",
    "\n",
    "# 1. Filter by minimum games threshold\n",
    "print(f\"\\n1Ô∏è‚É£  Filtering entries with < {MIN_GAMES_THRESHOLD} games...\")\n",
    "before_filter = len(raw_data)\n",
    "clean_data = raw_data.query(f'num_games >= {MIN_GAMES_THRESHOLD}').copy()\n",
    "num_rows_after_filter = len(clean_data)\n",
    "num_rows_filtered_out = before_filter - num_rows_after_filter\n",
    "\n",
    "print(f\"   ‚Ä¢ Before: {before_filter:,} rows\")\n",
    "print(f\"   ‚Ä¢ After: {num_rows_after_filter:,} rows\")\n",
    "print(f\"   ‚Ä¢ Filtered out: {num_rows_filtered_out:,} rows ({100*num_rows_filtered_out/before_filter:.1f}%)\")\n",
    "\n",
    "# 2. Check for duplicates\n",
    "print(f\"\\n2Ô∏è‚É£  Checking for duplicate (player_id, opening_id) combinations...\")\n",
    "num_duplicates = clean_data.duplicated(subset=['player_id', 'opening_id']).sum()\n",
    "\n",
    "if num_duplicates > 0:\n",
    "    print(f\"   ‚ö†Ô∏è  Found {num_duplicates} duplicate entries\")\n",
    "    dup_mask = clean_data.duplicated(subset=['player_id', 'opening_id'], keep=False)\n",
    "    print(\"\\n   Sample of duplicates:\")\n",
    "    print(clean_data[dup_mask].head(10).to_string())\n",
    "    \n",
    "    # Keep only first occurrence of any duplicate player-opening pair\n",
    "    print(\"\\n   Removing duplicates (keeping first occurrence)...\")\n",
    "    clean_data = pd.DataFrame.drop_duplicates(clean_data, subset=['player_id', 'opening_id'], keep='first')\n",
    "    print(f\"   ‚úì After deduplication: {len(clean_data):,} rows\")\n",
    "else:\n",
    "    print(f\"   ‚úì No duplicates found\")\n",
    "\n",
    "# 3. Remove players with no qualifying openings\n",
    "print(f\"\\n3Ô∏è‚É£  Removing players with no qualifying openings...\") # Note that a few players only play stuff like the Van't Kruijs which we've excluded, so a small numer of players will be excluded here\n",
    "players_before = clean_data['player_id'].nunique()\n",
    "\n",
    "# Count openings per player\n",
    "num_openings_per_player = pd.DataFrame(clean_data.groupby('player_id').size(), columns=['count'])\n",
    "players_with_data = num_openings_per_player[num_openings_per_player['count'] > 0].index.tolist()\n",
    "\n",
    "# Filter\n",
    "clean_data = clean_data[clean_data['player_id'].isin(players_with_data)]\n",
    "players_after = clean_data['player_id'].nunique()\n",
    "\n",
    "print(f\"   ‚Ä¢ Players before: {players_before:,}\")\n",
    "print(f\"   ‚Ä¢ Players after: {players_after:,}\")\n",
    "print(f\"   ‚Ä¢ Removed: {players_before - players_after}\")\n",
    "\n",
    "# 4. Remove openings with no qualifying players\n",
    "print(f\"\\n4Ô∏è‚É£  Removing openings with no qualifying players...\")\n",
    "num_openings_before = clean_data['opening_id'].nunique()\n",
    "\n",
    "# Use pd.DataFrame.groupby() to count players per opening\n",
    "num_players_per_opening = pd.DataFrame(clean_data.groupby('opening_id').size(), columns=['count'])\n",
    "openings_with_data = num_players_per_opening[num_players_per_opening['count'] > 0].index.tolist()\n",
    "\n",
    "# Filter using pd.DataFrame.isin()\n",
    "clean_data = clean_data[clean_data['opening_id'].isin(openings_with_data)]\n",
    "openings_after = clean_data['opening_id'].nunique()\n",
    "\n",
    "print(f\"   ‚Ä¢ Openings before: {num_openings_before:,}\")\n",
    "print(f\"   ‚Ä¢ Openings after: {openings_after:,}\")\n",
    "print(f\"   ‚Ä¢ Removed: {num_openings_before - openings_after}\")\n",
    "\n",
    "# 5. Verify no null values using pd.isna()\n",
    "print(f\"\\n5Ô∏è‚É£  Verifying no null values...\")\n",
    "null_counts = pd.DataFrame.isna(clean_data).sum()\n",
    "if null_counts.sum() == 0:\n",
    "    print(\"   ‚úì No null values found\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  Found null values:\")\n",
    "    for col, count in null_counts[null_counts > 0].items():\n",
    "        print(f\"      ‚Ä¢ {col}: {count} nulls\")\n",
    "    # Drop rows with nulls using pd.DataFrame.dropna()\n",
    "    clean_data = pd.DataFrame.dropna(clean_data)\n",
    "    print(f\"   ‚úì Dropped null rows. New shape: {clean_data.shape}\")\n",
    "\n",
    "# TODO: Add confidence weighting column\n",
    "# TODO: Extract and normalize player ratings (side information)\n",
    "\n",
    "# Reset index using pd.DataFrame.reset_index()\n",
    "clean_data = pd.DataFrame.reset_index(clean_data, drop=True)\n",
    "\n",
    "# Final statistics using pd functions\n",
    "print(f\"\\n6Ô∏è‚É£  Final data statistics:\")\n",
    "print(f\"   ‚Ä¢ Total rows: {len(clean_data):,}\")\n",
    "print(f\"   ‚Ä¢ Unique players: {pd.Series.nunique(clean_data['player_id']):,}\")\n",
    "print(f\"   ‚Ä¢ Unique openings: {pd.Series.nunique(clean_data['opening_id']):,}\")\n",
    "print(f\"   ‚Ä¢ Total games: {pd.Series.sum(clean_data['num_games']):,}\")\n",
    "print(f\"   ‚Ä¢ Avg games per entry: {pd.Series.mean(clean_data['num_games']):.1f}\")\n",
    "print(f\"   ‚Ä¢ Avg openings per player: {len(clean_data) / pd.Series.nunique(clean_data['player_id']):.1f}\")\n",
    "print(f\"   ‚Ä¢ Avg players per opening: {len(clean_data) / pd.Series.nunique(clean_data['opening_id']):.1f}\")\n",
    "\n",
    "# Score distribution using pd functions\n",
    "print(f\"\\n   Score statistics:\")\n",
    "print(f\"   ‚Ä¢ Min: {pd.Series.min(clean_data['score']):.4f}\")\n",
    "print(f\"   ‚Ä¢ 25th percentile: {pd.Series.quantile(clean_data['score'], 0.25):.4f}\")\n",
    "print(f\"   ‚Ä¢ Median: {pd.Series.median(clean_data['score']):.4f}\")\n",
    "print(f\"   ‚Ä¢ 75th percentile: {pd.Series.quantile(clean_data['score'], 0.75):.4f}\")\n",
    "print(f\"   ‚Ä¢ Max: {pd.Series.max(clean_data['score']):.4f}\")\n",
    "print(f\"   ‚Ä¢ Mean: {pd.Series.mean(clean_data['score']):.4f}\")\n",
    "print(f\"   ‚Ä¢ Std: {pd.Series.std(clean_data['score']):.4f}\")\n",
    "\n",
    "# Sample of cleaned data using pd.DataFrame.sample()\n",
    "print(f\"\\n7Ô∏è‚É£  Sample of cleaned data (10 random rows):\")\n",
    "print(pd.DataFrame.sample(clean_data, min(10, len(clean_data)), random_state=42).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ DATA SANITIZATION COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nCleaned data shape: {clean_data.shape}\")\n",
    "print(f\"Data reduction: {100 * (1 - len(clean_data)/len(raw_data)):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e671b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2b. Apply hierarchical Bayesian shrinkage to adjust scores based on sample size confidence\n",
    "\n",
    "# Check if confidence already exists - if so, skip this processing\n",
    "if 'confidence' in clean_data.columns:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"‚è≠Ô∏è  SKIPPING STEP 2B: HIERARCHICAL BAYESIAN SCORE ADJUSTMENT\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\n‚úì 'confidence' column already exists in data\")\n",
    "    print(\"   This indicates hierarchical Bayesian processing has already been applied.\")\n",
    "    print(f\"\\nCurrent data shape: {clean_data.shape}\")\n",
    "    print(f\"Confidence range: [{clean_data['confidence'].min():.4f}, {clean_data['confidence'].max():.4f}]\")\n",
    "else:\n",
    "    # Define the processing function\n",
    "    # This is a long function, I recommend you fold it down in your editor\n",
    "    def apply_hierarchical_bayesian_shrinkage(data, k_player=50):\n",
    "        \"\"\"\n",
    "        Apply two-level hierarchical Bayesian shrinkage to adjust scores.\n",
    "        \n",
    "        A lot of our player-opening entries have a small number of games played, because openings are so specific.\n",
    "        This introduces sample size issues.\n",
    "        \n",
    "        We use TWO-LEVEL shrinkage:\n",
    "        Level 1: Calculate opening-specific means (these are our \"ground truth\" for each opening)\n",
    "        Level 2: Shrink individual player-opening scores toward their opening's mean\n",
    "        This is better than shrinking toward global mean because different openings have different baseline win rates\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        data : pd.DataFrame\n",
    "            Clean data with columns: player_id, opening_id, score, num_games, eco\n",
    "        k_player : int\n",
    "            Shrinkage constant for player-opening scores (default: 50)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame\n",
    "            Data with adjusted scores and new 'confidence' column\n",
    "        \"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"STEP 2B: HIERARCHICAL BAYESIAN SCORE ADJUSTMENT\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        print(f\"\\n‚öôÔ∏è  Configuration:\")\n",
    "        print(f\"   ‚Ä¢ K_PLAYER (shrinkage constant): {k_player}\")\n",
    "        print(f\"   ‚Ä¢ Method: Two-level empirical Bayes shrinkage\")\n",
    "        print(f\"   ‚Ä¢ Level 1: Calculate opening-specific means\")\n",
    "        print(f\"   ‚Ä¢ Level 2: Shrink player scores toward opening means\")\n",
    "        \n",
    "        # Calculate global mean score for comparison\n",
    "        global_mean_score = data[\"score\"].mean()\n",
    "        print(f\"\\nüìä Global statistics:\")\n",
    "        print(f\"   ‚Ä¢ Global mean score: {global_mean_score:.4f}\")\n",
    "        print(f\"   ‚Ä¢ Total entries: {len(data):,}\")\n",
    "        print(f\"   ‚Ä¢ Unique openings: {data['opening_id'].nunique():,}\")\n",
    "        \n",
    "        # Store original scores for comparison\n",
    "        data = data.copy()  # Best practice: work on a copy\n",
    "        data[\"score_original\"] = data[\"score\"].copy()\n",
    "        \n",
    "        # LEVEL 1: Calculate opening-specific means and statistics\n",
    "        print(f\"\\n1Ô∏è‚É£  LEVEL 1: Calculating opening-specific means...\")\n",
    "        \n",
    "        opening_stats = (\n",
    "            data.groupby(\"opening_id\")\n",
    "            .agg(\n",
    "                {\n",
    "                    \"score\": \"mean\",\n",
    "                    \"num_games\": \"sum\",\n",
    "                    \"player_id\": \"count\",  # Number of players who played this opening\n",
    "                }\n",
    "            )\n",
    "            .rename(\n",
    "                columns={\n",
    "                    \"score\": \"opening_mean\",\n",
    "                    \"num_games\": \"opening_total_games\",\n",
    "                    \"player_id\": \"opening_num_players\",\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        print(f\"   ‚úì Calculated means for {len(opening_stats):,} openings\")\n",
    "        \n",
    "        # Opening mean statistics\n",
    "        print(f\"\\n   Opening mean score distribution:\")\n",
    "        print(f\"   ‚Ä¢ Min: {opening_stats['opening_mean'].min():.4f}\")\n",
    "        print(f\"   ‚Ä¢ 25th percentile: {opening_stats['opening_mean'].quantile(0.25):.4f}\")\n",
    "        print(f\"   ‚Ä¢ Median: {opening_stats['opening_mean'].median():.4f}\")\n",
    "        print(f\"   ‚Ä¢ 75th percentile: {opening_stats['opening_mean'].quantile(0.75):.4f}\")\n",
    "        print(f\"   ‚Ä¢ Max: {opening_stats['opening_mean'].max():.4f}\")\n",
    "        print(f\"   ‚Ä¢ Std: {opening_stats['opening_mean'].std():.4f}\")\n",
    "        \n",
    "        # Show distribution of opening sizes\n",
    "        print(f\"\\n   Opening sample size distribution:\")\n",
    "        print(\n",
    "            f\"   ‚Ä¢ Total games per opening (median): {opening_stats['opening_total_games'].median():.0f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"   ‚Ä¢ Players per opening (median): {opening_stats['opening_num_players'].median():.0f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"   ‚Ä¢ Total games range: [{opening_stats['opening_total_games'].min():.0f}, {opening_stats['opening_total_games'].max():.0f}]\"\n",
    "        )\n",
    "        print(\n",
    "            f\"   ‚Ä¢ Players range: [{opening_stats['opening_num_players'].min():.0f}, {opening_stats['opening_num_players'].max():.0f}]\"\n",
    "        )\n",
    "        \n",
    "        # Merge opening means back into main dataframe\n",
    "        data = data.merge(\n",
    "            opening_stats[[\"opening_mean\"]], left_on=\"opening_id\", right_index=True, how=\"left\"\n",
    "        )\n",
    "        \n",
    "        # LEVEL 2: Shrink player-opening scores toward opening-specific means\n",
    "        print(f\"\\n2Ô∏è‚É£  LEVEL 2: Shrinking player scores toward opening means...\")\n",
    "        print(\n",
    "            f\"   Formula: adjusted_score = (num_games √ó player_score + {k_player} √ó opening_mean) / (num_games + {k_player})\"\n",
    "        )\n",
    "        \n",
    "        numerator = (data[\"num_games\"] * data[\"score_original\"]) + (\n",
    "            k_player * data[\"opening_mean\"]\n",
    "        )\n",
    "        denominator = data[\"num_games\"] + k_player\n",
    "        data[\"score\"] = numerator / denominator\n",
    "        \n",
    "        print(f\"   ‚úì Scores adjusted for {len(data):,} entries\")\n",
    "        \n",
    "        # Calculate confidence weights (will be used in loss function later)\n",
    "        print(f\"\\n3Ô∏è‚É£  Calculating confidence weights...\")\n",
    "        data[\"confidence\"] = data[\"num_games\"] / (\n",
    "            data[\"num_games\"] + k_player\n",
    "        )\n",
    "        print(f\"   ‚úì Confidence weights calculated\")\n",
    "        print(f\"   ‚Ä¢ Formula: confidence = num_games / (num_games + {k_player})\")\n",
    "        print(\n",
    "            f\"   ‚Ä¢ Range: [{data['confidence'].min():.4f}, {data['confidence'].max():.4f}]\"\n",
    "        )\n",
    "        \n",
    "        # Statistics on the adjustment\n",
    "        score_diff = data[\"score\"] - data[\"score_original\"]\n",
    "        print(f\"\\n4Ô∏è‚É£  Adjustment statistics:\")\n",
    "        print(f\"   ‚Ä¢ Mean adjustment: {score_diff.mean():.6f}\")\n",
    "        print(f\"   ‚Ä¢ Std adjustment: {score_diff.std():.6f}\")\n",
    "        print(f\"   ‚Ä¢ Max adjustment: {score_diff.max():.6f}\")\n",
    "        print(f\"   ‚Ä¢ Min adjustment: {score_diff.min():.6f}\")\n",
    "        \n",
    "        # Show distribution of adjustments\n",
    "        print(f\"\\n   Adjustment by num_games quartiles:\")\n",
    "        quartiles = data[\"num_games\"].quantile([0.25, 0.5, 0.75])\n",
    "        print(\n",
    "            f\"   ‚Ä¢ 25th percentile (n={quartiles[0.25]:.0f} games): avg adjustment = {score_diff[data['num_games'] <= quartiles[0.25]].mean():.6f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"   ‚Ä¢ 50th percentile (n={quartiles[0.5]:.0f} games): avg adjustment = {score_diff[(data['num_games'] > quartiles[0.25]) & (data['num_games'] <= quartiles[0.5])].mean():.6f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"   ‚Ä¢ 75th percentile (n={quartiles[0.75]:.0f} games): avg adjustment = {score_diff[(data['num_games'] > quartiles[0.5]) & (data['num_games'] <= quartiles[0.75])].mean():.6f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"   ‚Ä¢ >75th percentile (n>{quartiles[0.75]:.0f} games): avg adjustment = {score_diff[data['num_games'] > quartiles[0.75]].mean():.6f}\"\n",
    "        )\n",
    "        \n",
    "        # New score distribution after adjustment\n",
    "        print(f\"\\n5Ô∏è‚É£  Adjusted score statistics:\")\n",
    "        print(f\"   ‚Ä¢ Min: {data['score'].min():.4f}\")\n",
    "        print(f\"   ‚Ä¢ 25th percentile: {data['score'].quantile(0.25):.4f}\")\n",
    "        print(f\"   ‚Ä¢ Median: {data['score'].median():.4f}\")\n",
    "        print(f\"   ‚Ä¢ 75th percentile: {data['score'].quantile(0.75):.4f}\")\n",
    "        print(f\"   ‚Ä¢ Max: {data['score'].max():.4f}\")\n",
    "        print(f\"   ‚Ä¢ Mean: {data['score'].mean():.4f}\")\n",
    "        print(f\"   ‚Ä¢ Std: {data['score'].std():.4f}\")\n",
    "        \n",
    "        # Detailed sample showing the effect across different game counts\n",
    "        print(f\"\\n6Ô∏è‚É£  Sample comparisons (showing effect of hierarchical shrinkage):\")\n",
    "        print(f\"\\n   {'='*120}\")\n",
    "        print(f\"   Low-game entries (10-20 games) - HIGH shrinkage toward opening mean:\")\n",
    "        print(f\"   {'='*120}\")\n",
    "        \n",
    "        low_game_sample = data[\n",
    "            (data[\"num_games\"] >= 10) & (data[\"num_games\"] <= 20)\n",
    "        ].sample(\n",
    "            min(\n",
    "                10,\n",
    "                len(\n",
    "                    data[\n",
    "                        (data[\"num_games\"] >= 10) & (data[\"num_games\"] <= 20)\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            random_state=42,\n",
    "        )\n",
    "        for idx, row in low_game_sample.iterrows():\n",
    "            adjustment = row[\"score\"] - row[\"score_original\"]\n",
    "            print(\n",
    "                f\"   Player {row['player_id']:>5} | Opening {row['opening_id']:>4} | Games: {row['num_games']:>3} | \"\n",
    "                f\"Opening mean: {row['opening_mean']:.4f} | Original: {row['score_original']:.4f} ‚Üí Adjusted: {row['score']:.4f} | \"\n",
    "                f\"Diff: {adjustment:>+.4f} | Confidence: {row['confidence']:.3f}\"\n",
    "            )\n",
    "        \n",
    "        print(f\"\\n   {'='*120}\")\n",
    "        print(f\"   Medium-game entries (50-100 games) - MODERATE shrinkage:\")\n",
    "        print(f\"   {'='*120}\")\n",
    "        \n",
    "        med_game_sample = data[\n",
    "            (data[\"num_games\"] >= 50) & (data[\"num_games\"] <= 100)\n",
    "        ].sample(\n",
    "            min(\n",
    "                10,\n",
    "                len(\n",
    "                    data[\n",
    "                        (data[\"num_games\"] >= 50) & (data[\"num_games\"] <= 100)\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            random_state=42,\n",
    "        )\n",
    "        for idx, row in med_game_sample.iterrows():\n",
    "            adjustment = row[\"score\"] - row[\"score_original\"]\n",
    "            print(\n",
    "                f\"   Player {row['player_id']:>5} | Opening {row['opening_id']:>4} | Games: {row['num_games']:>3} | \"\n",
    "                f\"Opening mean: {row['opening_mean']:.4f} | Original: {row['score_original']:.4f} ‚Üí Adjusted: {row['score']:.4f} | \"\n",
    "                f\"Diff: {adjustment:>+.4f} | Confidence: {row['confidence']:.3f}\"\n",
    "            )\n",
    "        \n",
    "        print(f\"\\n   {'='*120}\")\n",
    "        print(f\"   High-game entries (200+ games) - LOW shrinkage:\")\n",
    "        print(f\"   {'='*120}\")\n",
    "        \n",
    "        high_game_sample = data[data[\"num_games\"] >= 200].sample(\n",
    "            min(10, len(data[data[\"num_games\"] >= 200])), random_state=42\n",
    "        )\n",
    "        for idx, row in high_game_sample.iterrows():\n",
    "            adjustment = row[\"score\"] - row[\"score_original\"]\n",
    "            print(\n",
    "                f\"   Player {row['player_id']:>5} | Opening {row['opening_id']:>4} | Games: {row['num_games']:>3} | \"\n",
    "                f\"Opening mean: {row['opening_mean']:.4f} | Original: {row['score_original']:.4f} ‚Üí Adjusted: {row['score']:.4f} | \"\n",
    "                f\"Diff: {adjustment:>+.4f} | Confidence: {row['confidence']:.3f}\"\n",
    "            )\n",
    "        \n",
    "        # Show extreme cases - comparing to both opening mean AND global mean\n",
    "        print(f\"\\n7Ô∏è‚É£  Extreme cases (showing why opening-specific shrinkage matters):\")\n",
    "        \n",
    "        # Find entries where opening mean differs significantly from global mean\n",
    "        data[\"opening_deviation_from_global\"] = (\n",
    "            data[\"opening_mean\"] - global_mean_score\n",
    "        ).abs()\n",
    "        \n",
    "        print(f\"\\n   Openings with HIGHEST win rates (strong for White):\")\n",
    "        strong_openings = data.nlargest(5, \"opening_mean\")[\n",
    "            [\"opening_id\", \"opening_mean\", \"eco\"]\n",
    "        ].drop_duplicates(\"opening_id\")\n",
    "        for idx, row in strong_openings.iterrows():\n",
    "            num_entries = len(data[data[\"opening_id\"] == row[\"opening_id\"]])\n",
    "            deviation = row[\"opening_mean\"] - global_mean_score\n",
    "            print(\n",
    "                f\"   Opening {row['opening_id']:>4} ({row['eco']:>3}): mean = {row['opening_mean']:.4f} \"\n",
    "                f\"(+{deviation:.4f} vs global) | {num_entries} player entries\"\n",
    "            )\n",
    "        \n",
    "        print(f\"\\n   Openings with LOWEST win rates (weak for White):\")\n",
    "        weak_openings = data.nsmallest(5, \"opening_mean\")[\n",
    "            [\"opening_id\", \"opening_mean\", \"eco\"]\n",
    "        ].drop_duplicates(\"opening_id\")\n",
    "        for idx, row in weak_openings.iterrows():\n",
    "            num_entries = len(data[data[\"opening_id\"] == row[\"opening_id\"]])\n",
    "            deviation = row[\"opening_mean\"] - global_mean_score\n",
    "            print(\n",
    "                f\"   Opening {row['opening_id']:>4} ({row['eco']:>3}): mean = {row['opening_mean']:.4f} \"\n",
    "                f\"({deviation:.4f} vs global) | {num_entries} player entries\"\n",
    "            )\n",
    "        \n",
    "        # Show specific examples where hierarchical shrinkage made a difference\n",
    "        print(f\"\\n8Ô∏è‚É£  Examples showing hierarchical shrinkage benefit:\")\n",
    "        \n",
    "        # Find entries with strong openings where player did well\n",
    "        strong_opening_ids = data.nlargest(50, \"opening_mean\")[\"opening_id\"].unique()\n",
    "        strong_examples = data[\n",
    "            (data[\"opening_id\"].isin(strong_opening_ids))\n",
    "            & (data[\"num_games\"] <= 20)\n",
    "            & (data[\"score_original\"] > 0.6)\n",
    "        ].sample(\n",
    "            min(\n",
    "                3,\n",
    "                len(\n",
    "                    data[\n",
    "                        (data[\"opening_id\"].isin(strong_opening_ids))\n",
    "                        & (data[\"num_games\"] <= 20)\n",
    "                        & (data[\"score_original\"] > 0.6)\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            random_state=42,\n",
    "        )\n",
    "        \n",
    "        print(\n",
    "            f\"\\n   Strong opening + good player performance (shrunk toward HIGH opening mean):\"\n",
    "        )\n",
    "        for idx, row in strong_examples.iterrows():\n",
    "            adjustment = row[\"score\"] - row[\"score_original\"]\n",
    "            global_shrink_would_be = (\n",
    "                (row[\"num_games\"] * row[\"score_original\"]) + (k_player * global_mean_score)\n",
    "            ) / (row[\"num_games\"] + k_player)\n",
    "            difference = row[\"score\"] - global_shrink_would_be\n",
    "            print(\n",
    "                f\"   Player {row['player_id']:>5} | Opening {row['opening_id']:>4} ({row['eco']:>3}) | Games: {row['num_games']:>2} | \"\n",
    "                f\"Opening mean: {row['opening_mean']:.4f} | Original: {row['score_original']:.4f} ‚Üí {row['score']:.4f}\"\n",
    "            )\n",
    "            print(\n",
    "                f\"      If we'd shrunk to global mean: {global_shrink_would_be:.4f} (would lose {difference:+.4f} of deserved credit)\"\n",
    "            )\n",
    "        \n",
    "        # Find entries with weak openings where player did poorly\n",
    "        weak_opening_ids = data.nsmallest(50, \"opening_mean\")[\"opening_id\"].unique()\n",
    "        weak_examples = data[\n",
    "            (data[\"opening_id\"].isin(weak_opening_ids))\n",
    "            & (data[\"num_games\"] <= 20)\n",
    "            & (data[\"score_original\"] < 0.45)\n",
    "        ].sample(\n",
    "            min(\n",
    "                3,\n",
    "                len(\n",
    "                    data[\n",
    "                        (data[\"opening_id\"].isin(weak_opening_ids))\n",
    "                        & (data[\"num_games\"] <= 20)\n",
    "                        & (data[\"score_original\"] < 0.45)\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            random_state=42,\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n   Weak opening + poor player performance (shrunk toward LOW opening mean):\")\n",
    "        for idx, row in weak_examples.iterrows():\n",
    "            adjustment = row[\"score\"] - row[\"score_original\"]\n",
    "            global_shrink_would_be = (\n",
    "                (row[\"num_games\"] * row[\"score_original\"]) + (k_player * global_mean_score)\n",
    "            ) / (row[\"num_games\"] + k_player)\n",
    "            difference = row[\"score\"] - global_shrink_would_be\n",
    "            print(\n",
    "                f\"   Player {row['player_id']:>5} | Opening {row['opening_id']:>4} ({row['eco']:>3}) | Games: {row['num_games']:>2} | \"\n",
    "                f\"Opening mean: {row['opening_mean']:.4f} | Original: {row['score_original']:.4f} ‚Üí {row['score']:.4f}\"\n",
    "            )\n",
    "            print(\n",
    "                f\"      If we'd shrunk to global mean: {global_shrink_would_be:.4f} (would unfairly boost by {-difference:+.4f})\"\n",
    "            )\n",
    "        \n",
    "        # Drop temporary columns\n",
    "        print(f\"\\n9Ô∏è‚É£  Cleaning up...\")\n",
    "        data = data.drop(\n",
    "            columns=[\"score_original\", \"opening_mean\", \"opening_deviation_from_global\"]\n",
    "        )\n",
    "        print(f\"   ‚úì Removed temporary columns\")\n",
    "        \n",
    "        print(f\"\\n\" + \"=\" * 60)\n",
    "        print(\"‚úÖ HIERARCHICAL BAYESIAN ADJUSTMENT COMPLETE\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"\\nFinal data shape: {data.shape}\")\n",
    "        print(f\"Columns: {list(data.columns)}\")\n",
    "        print(f\"\\nNew columns added:\")\n",
    "        print(f\"   ‚Ä¢ 'confidence': weight for loss function (range [0,1])\")\n",
    "        print(f\"   ‚Ä¢ 'score': adjusted using hierarchical Bayesian shrinkage\")\n",
    "        print(f\"\\nKey improvement over simple shrinkage:\")\n",
    "        print(f\"   ‚Ä¢ Player scores now shrink toward OPENING-SPECIFIC means, not global mean\")\n",
    "        print(f\"   ‚Ä¢ Preserves opening difficulty differences\")\n",
    "        print(f\"   ‚Ä¢ More accurate for both strong and weak openings\")\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    # Configuration for Bayesian shrinkage\n",
    "    K_PLAYER = 50  # Shrinkage constant for player-opening scores\n",
    "    \n",
    "    # Call the function\n",
    "    clean_data = apply_hierarchical_bayesian_shrinkage(clean_data, k_player=K_PLAYER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73319d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_data.sample().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a80e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2c. Gather player rating statistics (no mutation, just exploration)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 2C: PLAYER RATING STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Connect to database and extract player ratings\n",
    "con = get_db_connection(str(DB_PATH))\n",
    "\n",
    "try:\n",
    "    print(f\"\\n1Ô∏è‚É£  Extracting player ratings from database...\")\n",
    "    \n",
    "    # Get unique player IDs from our clean_data\n",
    "    unique_player_ids = clean_data['player_id'].unique()\n",
    "    player_ids_str = ','.join(map(str, unique_player_ids))\n",
    "    \n",
    "    # Query to get player ratings\n",
    "    rating_query = f\"\"\"\n",
    "        SELECT \n",
    "            id as player_id,\n",
    "            name,\n",
    "            title,\n",
    "            rating\n",
    "        FROM player\n",
    "        WHERE id IN ({player_ids_str})\n",
    "    \"\"\"\n",
    "    \n",
    "    player_ratings = pd.DataFrame(con.execute(rating_query).df())\n",
    "    print(f\"   ‚úì Retrieved ratings for {len(player_ratings):,} players\")\n",
    "    \n",
    "finally:\n",
    "    con.close()\n",
    "    print(\"   ‚úì Database connection closed\")\n",
    "\n",
    "# Merge ratings into clean_data for analysis\n",
    "print(f\"\\n2Ô∏è‚É£  Merging ratings with clean_data...\")\n",
    "clean_data_with_ratings = clean_data.merge(player_ratings[['player_id', 'rating']], on='player_id', how='left')\n",
    "print(f\"   ‚úì Merged successfully\")\n",
    "\n",
    "# Check for missing ratings\n",
    "num_missing_ratings = clean_data_with_ratings['rating'].isna().sum()\n",
    "if num_missing_ratings > 0:\n",
    "    print(f\"   ‚ö†Ô∏è  {num_missing_ratings:,} entries ({100*num_missing_ratings/len(clean_data_with_ratings):.2f}%) have missing ratings\")\n",
    "else:\n",
    "    print(f\"   ‚úì All entries have ratings\")\n",
    "\n",
    "# Basic rating statistics\n",
    "print(f\"\\n3Ô∏è‚É£  Basic rating statistics:\")\n",
    "print(f\"   ‚Ä¢ Count: {player_ratings['rating'].notna().sum():,}\")\n",
    "print(f\"   ‚Ä¢ Missing: {player_ratings['rating'].isna().sum():,}\")\n",
    "print(f\"   ‚Ä¢ Min: {player_ratings['rating'].min():.0f}\")\n",
    "print(f\"   ‚Ä¢ Max: {player_ratings['rating'].max():.0f}\")\n",
    "print(f\"   ‚Ä¢ Mean: {player_ratings['rating'].mean():.2f}\")\n",
    "print(f\"   ‚Ä¢ Median: {player_ratings['rating'].median():.0f}\")\n",
    "print(f\"   ‚Ä¢ Std Dev: {player_ratings['rating'].std():.2f}\")\n",
    "\n",
    "# Quartile statistics\n",
    "print(f\"\\n4Ô∏è‚É£  Quartile statistics:\")\n",
    "print(f\"   ‚Ä¢ 25th percentile: {player_ratings['rating'].quantile(0.25):.0f}\")\n",
    "print(f\"   ‚Ä¢ 50th percentile (median): {player_ratings['rating'].quantile(0.50):.0f}\")\n",
    "print(f\"   ‚Ä¢ 75th percentile: {player_ratings['rating'].quantile(0.75):.0f}\")\n",
    "\n",
    "# Granular percentile statistics (5% increments)\n",
    "print(f\"\\n5Ô∏è‚É£  Detailed percentile distribution (5% increments):\")\n",
    "percentiles = [0.00, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50,\n",
    "               0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 1.00]\n",
    "\n",
    "print(f\"\\n   {'Percentile':<12} {'Rating':<10} {'Visual'}\")\n",
    "print(f\"   {'-'*12} {'-'*10} {'-'*40}\")\n",
    "\n",
    "for p in percentiles:\n",
    "    rating_value = player_ratings['rating'].quantile(p)\n",
    "    # Create a simple bar visualization\n",
    "    bar_length = int((rating_value - player_ratings['rating'].min()) / \n",
    "                     (player_ratings['rating'].max() - player_ratings['rating'].min()) * 40)\n",
    "    bar = '‚ñà' * bar_length\n",
    "    print(f\"   {p*100:>5.0f}%       {rating_value:>7.0f}    {bar}\")\n",
    "\n",
    "# Rating ranges and counts\n",
    "print(f\"\\n6Ô∏è‚É£  Rating distribution by range:\")\n",
    "rating_ranges = [\n",
    "    (0, 1000), (1000, 1200), (1200, 1400), (1400, 1600), \n",
    "    (1600, 1800), (1800, 2000), (2000, 2200), (2200, 2400), \n",
    "    (2400, 2600), (2600, 3000)\n",
    "]\n",
    "\n",
    "print(f\"\\n   {'Range':<15} {'Count':<10} {'Percentage':<12} {'Visual'}\")\n",
    "print(f\"   {'-'*15} {'-'*10} {'-'*12} {'-'*40}\")\n",
    "\n",
    "for low, high in rating_ranges:\n",
    "    count = len(player_ratings[(player_ratings['rating'] >= low) & (player_ratings['rating'] < high)])\n",
    "    pct = 100 * count / len(player_ratings)\n",
    "    bar_length = int(pct * 0.4)  # Scale for visualization\n",
    "    bar = '‚ñà' * bar_length\n",
    "    print(f\"   {low:>4}-{high:<8} {count:>7,}    {pct:>6.2f}%      {bar}\")\n",
    "\n",
    "# Interquartile range\n",
    "iqr = player_ratings['rating'].quantile(0.75) - player_ratings['rating'].quantile(0.25)\n",
    "print(f\"\\n7Ô∏è‚É£  Spread statistics:\")\n",
    "print(f\"   ‚Ä¢ Range: {player_ratings['rating'].max() - player_ratings['rating'].min():.0f}\")\n",
    "print(f\"   ‚Ä¢ Interquartile Range (IQR): {iqr:.0f}\")\n",
    "print(f\"   ‚Ä¢ 10th-90th percentile range: {player_ratings['rating'].quantile(0.90) - player_ratings['rating'].quantile(0.10):.0f}\")\n",
    "\n",
    "# Skewness and kurtosis if available\n",
    "try:\n",
    "    from scipy.stats import skew, kurtosis\n",
    "    skewness = skew(player_ratings['rating'].dropna())\n",
    "    kurt = kurtosis(player_ratings['rating'].dropna())\n",
    "    print(f\"\\n8Ô∏è‚É£  Distribution shape:\")\n",
    "    print(f\"   ‚Ä¢ Skewness: {skewness:.4f} {'(right-skewed)' if skewness > 0 else '(left-skewed)' if skewness < 0 else '(symmetric)'}\")\n",
    "    print(f\"   ‚Ä¢ Kurtosis: {kurt:.4f} {'(heavy-tailed)' if kurt > 0 else '(light-tailed)' if kurt < 0 else '(normal)'}\")\n",
    "except ImportError:\n",
    "    print(f\"\\n8Ô∏è‚É£  Distribution shape:\")\n",
    "    print(f\"   ‚Ä¢ scipy not available for skewness/kurtosis calculation\")\n",
    "\n",
    "# Sample of players at different rating levels\n",
    "print(f\"\\n9Ô∏è‚É£  Sample players at different rating levels:\")\n",
    "sample_percentiles = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "for p in sample_percentiles:\n",
    "    rating_threshold = player_ratings['rating'].quantile(p)\n",
    "    # Get a player near this rating\n",
    "    sample_player = player_ratings.iloc[(player_ratings['rating'] - rating_threshold).abs().argsort()[:1]]\n",
    "    print(f\"\\n   ~{p*100:.0f}th percentile (rating ‚âà {rating_threshold:.0f}):\")\n",
    "    for idx, row in sample_player.iterrows():\n",
    "        # print(f\"      Player {row['player_id']}: {row['name']} - Rating: {row['rating']:.0f} {f'({row['title']})' if pd.notna(row['title']) else ''}\")\n",
    "        title_str = f\" ({row['title']})\" if pd.notna(row['title']) else \"\"\n",
    "        print(f\"      Player {row['player_id']}: {row['name']} - Rating: {row['rating']:.0f}{title_str}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ RATING STATISTICS COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nKey takeaways:\")\n",
    "print(f\"   ‚Ä¢ Total players: {len(player_ratings):,}\")\n",
    "print(f\"   ‚Ä¢ Rating range: [{player_ratings['rating'].min():.0f}, {player_ratings['rating'].max():.0f}]\")\n",
    "print(f\"   ‚Ä¢ Mean ¬± std: {player_ratings['rating'].mean():.0f} ¬± {player_ratings['rating'].std():.0f}\")\n",
    "print(f\"   ‚Ä¢ Median: {player_ratings['rating'].median():.0f}\")\n",
    "print(f\"\\n   Next steps: Normalize ratings for model input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ab6b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d. Normalize player ratings using z-score normalization (for use as side information in MF model)\n",
    "\n",
    "# Check if we've already created the player_side_info table\n",
    "if 'player_side_info' in globals() and 'rating_z' in player_side_info.columns:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"‚è≠Ô∏è  SKIPPING STEP 2D: RATING NORMALIZATION\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\n‚úì 'player_side_info' table already exists\")\n",
    "    print(\"   This indicates rating normalization has already been applied.\")\n",
    "    print(f\"\\nPlayer side info shape: {player_side_info.shape}\")\n",
    "    \n",
    "    # Show statistics\n",
    "    print(f\"\\nüìä Existing normalized rating statistics:\")\n",
    "    print(f\"   ‚Ä¢ Min: {player_side_info['rating_z'].min():.4f}\")\n",
    "    print(f\"   ‚Ä¢ Max: {player_side_info['rating_z'].max():.4f}\")\n",
    "    print(f\"   ‚Ä¢ Mean: {player_side_info['rating_z'].mean():.6f} (should be ~0)\")\n",
    "    print(f\"   ‚Ä¢ Std: {player_side_info['rating_z'].std():.6f} (should be ~1)\")\n",
    "    \n",
    "    print(f\"\\nüìã Sample of existing normalized ratings:\")\n",
    "    sample_data = player_side_info.sample(min(10, len(player_side_info)), random_state=42)\n",
    "    for idx, row in sample_data.iterrows():\n",
    "        print(f\"   Player {idx:>5} | {row['name']:<20} | \"\n",
    "              f\"Rating: {row['rating']:>4.0f} ‚Üí Z-score: {row['rating_z']:>6.3f}\")\n",
    "else:\n",
    "    def normalize_player_ratings(player_ratings_df):\n",
    "        \"\"\"\n",
    "        Apply z-score normalization to player ratings for use as side information.\n",
    "        \n",
    "        This creates a SEPARATE table of player-level features, NOT merged into clean_data.\n",
    "        Rating is side information - it describes the player, not the player-opening interaction.\n",
    "        \n",
    "        During training, the model will LOOK UP each player's rating_z from this table.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        player_ratings_df : pd.DataFrame\n",
    "            Player ratings with columns: player_id, name, title, rating\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        tuple: (player_side_info DataFrame, RATING_MEAN, RATING_STD)\n",
    "        \"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"STEP 2D: NORMALIZE PLAYER RATINGS (SIDE INFORMATION)\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        print(f\"\\n‚öôÔ∏è  Normalization strategy: Z-score\")\n",
    "        print(f\"   ‚Ä¢ Formula: (rating - mean) / std\")\n",
    "        print(f\"   ‚Ä¢ Purpose: Scale ratings for use as side information in MF model\")\n",
    "        print(f\"   ‚Ä¢ Storage: SEPARATE lookup table, NOT merged into clean_data\")\n",
    "        print(f\"   ‚Ä¢ Usage: Model will lookup player_id ‚Üí rating_z during training\")\n",
    "        \n",
    "        # Calculate normalization parameters\n",
    "        RATING_MEAN = player_ratings_df['rating'].mean()\n",
    "        RATING_STD = player_ratings_df['rating'].std()\n",
    "        \n",
    "        print(f\"\\n1Ô∏è‚É£  Normalization parameters (calculated from {len(player_ratings_df):,} players):\")\n",
    "        print(f\"   ‚Ä¢ Mean: {RATING_MEAN:.2f}\")\n",
    "        print(f\"   ‚Ä¢ Std Dev: {RATING_STD:.2f}\")\n",
    "        \n",
    "        # Create side information table - only keep player_id and rating for now\n",
    "        player_side_info = player_ratings_df[['player_id', 'rating']].copy()\n",
    "        player_side_info['rating_z'] = (player_side_info['rating'] - RATING_MEAN) / RATING_STD\n",
    "        \n",
    "        print(f\"\\n2Ô∏è‚É£  Normalized rating statistics:\")\n",
    "        print(f\"   ‚Ä¢ Min: {player_side_info['rating_z'].min():.4f}\")\n",
    "        print(f\"   ‚Ä¢ Max: {player_side_info['rating_z'].max():.4f}\")\n",
    "        print(f\"   ‚Ä¢ Mean: {player_side_info['rating_z'].mean():.6f} (should be ~0)\")\n",
    "        print(f\"   ‚Ä¢ Std: {player_side_info['rating_z'].std():.6f} (should be ~1)\")\n",
    "        print(f\"   ‚Ä¢ Range: [{player_side_info['rating_z'].min():.2f}, {player_side_info['rating_z'].max():.2f}]\")\n",
    "        \n",
    "        print(f\"\\n3Ô∏è‚É£  Sample normalized ratings across skill levels:\")\n",
    "        sample_percentiles = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "        for p in sample_percentiles:\n",
    "            rating_threshold = player_side_info['rating'].quantile(p)\n",
    "            sample_player = player_side_info.iloc[(player_side_info['rating'] - rating_threshold).abs().argsort()[:1]]\n",
    "            for idx, row in sample_player.iterrows():\n",
    "                print(f\"   ~{p*100:.0f}th percentile: Player {idx} | \"\n",
    "                      f\"Rating: {row['rating']:>4.0f} ‚Üí Z-score: {row['rating_z']:>6.3f}\")\n",
    "        \n",
    "        print(f\"\\n4Ô∏è‚É£  Interpretation guide:\")\n",
    "        print(f\"   ‚Ä¢ rating_z ‚âà {(1200 - RATING_MEAN)/RATING_STD:.1f}: 1200 player (minimum)\")\n",
    "        print(f\"   ‚Ä¢ rating_z ‚âà {(player_side_info['rating'].quantile(0.25) - RATING_MEAN)/RATING_STD:.1f}: {player_side_info['rating'].quantile(0.25):.0f} player (25th percentile)\")\n",
    "        print(f\"   ‚Ä¢ rating_z ‚âà  0.0: {RATING_MEAN:.0f} player (mean)\")\n",
    "        print(f\"   ‚Ä¢ rating_z ‚âà {(player_side_info['rating'].quantile(0.75) - RATING_MEAN)/RATING_STD:.1f}: {player_side_info['rating'].quantile(0.75):.0f} player (75th percentile)\")\n",
    "        print(f\"   ‚Ä¢ rating_z ‚âà {(player_side_info['rating'].max() - RATING_MEAN)/RATING_STD:.1f}: {player_side_info['rating'].max():.0f} player (maximum)\")\n",
    "        \n",
    "        print(f\"\\n5Ô∏è‚É£  Side information table structure:\")\n",
    "        print(f\"   ‚Ä¢ Shape: {player_side_info.shape}\")\n",
    "        print(f\"   ‚Ä¢ Columns: {list(player_side_info.columns)}\")\n",
    "        print(f\"   ‚Ä¢ Indexing: Setting player_id as index for O(1) lookups\")\n",
    "        \n",
    "        # Set player_id as index for fast lookups\n",
    "        player_side_info = player_side_info.set_index('player_id')\n",
    "        \n",
    "        print(f\"\\n6Ô∏è‚É£  Sample entries from side information table:\")\n",
    "        sample_data = player_side_info.sample(min(10, len(player_side_info)), random_state=42)\n",
    "        for idx, row in sample_data.iterrows():\n",
    "            print(f\"   Player {idx:>5} | Rating: {row['rating']:>4.0f} ‚Üí Z-score: {row['rating_z']:>6.3f}\")\n",
    "        \n",
    "        print(f\"\\n7Ô∏è‚É£  Removing unnecessary columns...\")\n",
    "        # Drop rating column - we only need rating_z for the model\n",
    "        player_side_info = player_side_info.drop(columns=['rating'])\n",
    "        print(f\"   ‚úì Dropped 'rating' column (only keeping 'rating_z')\")\n",
    "        print(f\"   ‚Ä¢ Final columns: {list(player_side_info.columns)}\")\n",
    "        \n",
    "        print(f\"\\n8Ô∏è‚É£  Verifying all clean_data players have ratings:\")\n",
    "        # This is important - make sure every player in clean_data has a rating\n",
    "        missing_players = set(clean_data['player_id'].unique()) - set(player_side_info.index)\n",
    "        if len(missing_players) > 0:\n",
    "            print(f\"   ‚ö†Ô∏è  WARNING: {len(missing_players)} players in clean_data are missing from side_info!\")\n",
    "            print(f\"   Missing player IDs: {sorted(list(missing_players))[:10]}...\")\n",
    "        else:\n",
    "            print(f\"   ‚úì All {len(player_side_info):,} players in clean_data have side information\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"‚úÖ RATING NORMALIZATION COMPLETE\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"\\nCreated: player_side_info\")\n",
    "        print(f\"   ‚Ä¢ Shape: {player_side_info.shape}\")\n",
    "        print(f\"   ‚Ä¢ Index: player_id\")\n",
    "        print(f\"   ‚Ä¢ Columns: {list(player_side_info.columns)}\")\n",
    "        \n",
    "        print(f\"\\nüìä Data structure summary:\")\n",
    "        print(f\"   ‚Ä¢ clean_data: {clean_data.shape[0]:,} rows (player-opening interactions)\")\n",
    "        print(f\"   ‚Ä¢ player_side_info: {len(player_side_info):,} rows (one per player)\")\n",
    "        print(f\"   ‚Ä¢ Rating storage: ONE value per player (not duplicated per interaction)\")\n",
    "        \n",
    "        print(f\"\\n‚ö†Ô∏è  CRITICAL: Save these parameters for inference!\")\n",
    "        print(f\"   RATING_MEAN = {RATING_MEAN:.2f}\")\n",
    "        print(f\"   RATING_STD = {RATING_STD:.2f}\")\n",
    "        print(f\"\\n   You'll need them to normalize ratings for new users at inference time.\")\n",
    "        \n",
    "        return player_side_info, RATING_MEAN, RATING_STD\n",
    "    \n",
    "    # Call the function\n",
    "    player_side_info, RATING_MEAN, RATING_STD = normalize_player_ratings(player_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eba9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_data.sample(20).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac119ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(player_side_info.sample(10).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30280db",
   "metadata": {},
   "source": [
    "## Step 3: Train/Test/Val splits\n",
    "\n",
    "Here, I split my data and drop columns that are no longer needed. We're very close to being able to train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf3849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train/Validation/Test Split (75/15/10) - OPTIMIZED\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 3: TRAIN/VALIDATION/TEST SPLIT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è  Configuration:\")\n",
    "print(f\"   ‚Ä¢ Train: 75%\")\n",
    "print(f\"   ‚Ä¢ Validation: 15%\")\n",
    "print(f\"   ‚Ä¢ Test: 10%\")\n",
    "print(f\"   ‚Ä¢ Random seed: 42 (for reproducibility)\")\n",
    "\n",
    "# Prepare the data\n",
    "print(f\"\\n1Ô∏è‚É£  Preparing data for split...\")\n",
    "\n",
    "# Drop num_games from clean_data - we don't need it for training\n",
    "# Keep: player_id, opening_id, score, eco, confidence\n",
    "X = clean_data[[\"player_id\", \"opening_id\", \"eco\", \"confidence\"]].copy()\n",
    "y = clean_data[\"score\"].copy()\n",
    "\n",
    "print(f\"   ‚Ä¢ Features (X): {X.shape}\")\n",
    "print(f\"   ‚Ä¢ Target (y): {y.shape}\")\n",
    "print(f\"   ‚Ä¢ Feature columns: {list(X.columns)}\")\n",
    "\n",
    "# Clean up player_side_info - only keep rating_z\n",
    "print(f\"\\n2Ô∏è‚É£  Cleaning player side information...\")\n",
    "player_side_info_clean = player_side_info[[\"rating_z\"]].copy()\n",
    "print(f\"   ‚Ä¢ Original player_side_info shape: {player_side_info.shape}\")\n",
    "print(f\"   ‚Ä¢ Cleaned player_side_info shape: {player_side_info_clean.shape}\")\n",
    "print(f\"   ‚Ä¢ Columns: {list(player_side_info_clean.columns)}\")\n",
    "\n",
    "# OPTIMIZED: Use index-based splitting to avoid DataFrame copies\n",
    "print(f\"\\n3Ô∏è‚É£  Splitting data (optimized approach)...\")\n",
    "idx = np.arange(len(X))\n",
    "\n",
    "# First split: separate out test set (10%)\n",
    "idx_temp, idx_test = train_test_split(idx, test_size=0.10, random_state=42, shuffle=True)\n",
    "\n",
    "# Second split: split remaining into train (75%) and val (15%)\n",
    "# 15% of original = 15/90 ‚âà 0.1667 of temp\n",
    "idx_train, idx_val = train_test_split(idx_temp, test_size=15/90, random_state=42, shuffle=True)\n",
    "\n",
    "# Create splits using iloc (view, not copy)\n",
    "X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n",
    "X_val, y_val = X.iloc[idx_val], y.iloc[idx_val]\n",
    "X_test, y_test = X.iloc[idx_test], y.iloc[idx_test]\n",
    "\n",
    "print(f\"   ‚Ä¢ Train: {len(X_train):,} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Validation: {len(X_val):,} samples ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Test: {len(X_test):,} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Verify the split\n",
    "print(f\"\\n4Ô∏è‚É£  Verification:\")\n",
    "total = len(X_train) + len(X_val) + len(X_test)\n",
    "print(f\"   ‚Ä¢ Total samples: {total:,} (should equal {len(X):,})\")\n",
    "print(f\"   ‚Ä¢ Train %: {len(X_train)/total*100:.2f}% (target: 75%)\")\n",
    "print(f\"   ‚Ä¢ Val %: {len(X_val)/total*100:.2f}% (target: 15%)\")\n",
    "print(f\"   ‚Ä¢ Test %: {len(X_test)/total*100:.2f}% (target: 10%)\")\n",
    "\n",
    "# OPTIMIZED: Pre-compute unique arrays once\n",
    "print(f\"\\n5Ô∏è‚É£  Computing coverage statistics (cached)...\")\n",
    "players_train = X_train[\"player_id\"].unique()\n",
    "players_val = X_val[\"player_id\"].unique()\n",
    "players_test = X_test[\"player_id\"].unique()\n",
    "\n",
    "openings_train = X_train[\"opening_id\"].unique()\n",
    "openings_val = X_val[\"opening_id\"].unique()\n",
    "openings_test = X_test[\"opening_id\"].unique()\n",
    "\n",
    "print(f\"\\n   Players:\")\n",
    "print(f\"   ‚Ä¢ Train: {len(players_train):,} unique players\")\n",
    "print(f\"   ‚Ä¢ Val: {len(players_val):,} unique players\")\n",
    "print(f\"   ‚Ä¢ Test: {len(players_test):,} unique players\")\n",
    "print(f\"   ‚Ä¢ Total unique: {X['player_id'].nunique():,} players\")\n",
    "\n",
    "print(f\"\\n   Openings:\")\n",
    "print(f\"   ‚Ä¢ Train: {len(openings_train):,} unique openings\")\n",
    "print(f\"   ‚Ä¢ Val: {len(openings_val):,} unique openings\")\n",
    "print(f\"   ‚Ä¢ Test: {len(openings_test):,} unique openings\")\n",
    "print(f\"   ‚Ä¢ Total unique: {X['opening_id'].nunique():,} openings\")\n",
    "\n",
    "# OPTIMIZED: Use NumPy setdiff1d for cold-start analysis (C-speed)\n",
    "print(f\"\\n6Ô∏è‚É£  Cold start analysis (vectorized)...\")\n",
    "\n",
    "val_cold_players = np.setdiff1d(players_val, players_train, assume_unique=True)\n",
    "val_cold_openings = np.setdiff1d(openings_val, openings_train, assume_unique=True)\n",
    "\n",
    "test_cold_players = np.setdiff1d(players_test, players_train, assume_unique=True)\n",
    "test_cold_openings = np.setdiff1d(openings_test, openings_train, assume_unique=True)\n",
    "\n",
    "print(f\"\\n   Validation set:\")\n",
    "print(f\"   ‚Ä¢ Players not in train: {len(val_cold_players):,} ({len(val_cold_players)/len(players_val)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Openings not in train: {len(val_cold_openings):,} ({len(val_cold_openings)/len(openings_val)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n   Test set:\")\n",
    "print(f\"   ‚Ä¢ Players not in train: {len(test_cold_players):,} ({len(test_cold_players)/len(players_test)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Openings not in train: {len(test_cold_openings):,} ({len(test_cold_openings)/len(openings_test)*100:.1f}%)\")\n",
    "\n",
    "# OPTIMIZED: Compute stats in one pass using describe()\n",
    "print(f\"\\n7Ô∏è‚É£  Score distribution across splits:\")\n",
    "\n",
    "y_train_stats = y_train.describe()\n",
    "y_val_stats = y_val.describe()\n",
    "y_test_stats = y_test.describe()\n",
    "\n",
    "print(f\"\\n   Train:\")\n",
    "print(f\"   ‚Ä¢ Mean: {y_train_stats['mean']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Std: {y_train_stats['std']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Min: {y_train_stats['min']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Max: {y_train_stats['max']:.4f}\")\n",
    "\n",
    "print(f\"\\n   Validation:\")\n",
    "print(f\"   ‚Ä¢ Mean: {y_val_stats['mean']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Std: {y_val_stats['std']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Min: {y_val_stats['min']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Max: {y_val_stats['max']:.4f}\")\n",
    "\n",
    "print(f\"\\n   Test:\")\n",
    "print(f\"   ‚Ä¢ Mean: {y_test_stats['mean']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Std: {y_test_stats['std']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Min: {y_test_stats['min']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Max: {y_test_stats['max']:.4f}\")\n",
    "\n",
    "# OPTIMIZED: Compute confidence stats in one pass\n",
    "print(f\"\\n8Ô∏è‚É£  Confidence distribution across splits:\")\n",
    "\n",
    "conf_train_stats = X_train['confidence'].describe()\n",
    "conf_val_stats = X_val['confidence'].describe()\n",
    "conf_test_stats = X_test['confidence'].describe()\n",
    "\n",
    "print(f\"\\n   Train:\")\n",
    "print(f\"   ‚Ä¢ Mean: {conf_train_stats['mean']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Median: {conf_train_stats['50%']:.4f}\")\n",
    "\n",
    "print(f\"\\n   Validation:\")\n",
    "print(f\"   ‚Ä¢ Mean: {conf_val_stats['mean']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Median: {conf_val_stats['50%']:.4f}\")\n",
    "\n",
    "print(f\"\\n   Test:\")\n",
    "print(f\"   ‚Ä¢ Mean: {conf_test_stats['mean']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Median: {conf_test_stats['50%']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ DATA SPLIT COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä Summary:\")\n",
    "print(f\"   ‚Ä¢ Training data: {len(X_train):,} samples (75%)\")\n",
    "print(f\"   ‚Ä¢ Validation data: {len(X_val):,} samples (15%)\")\n",
    "print(f\"   ‚Ä¢ Test data: {len(X_test):,} samples (10%)\")\n",
    "print(f\"   ‚Ä¢ Player side info: {len(player_side_info_clean):,} players\")\n",
    "print(f\"   ‚Ä¢ Side info columns: {list(player_side_info_clean.columns)}\")\n",
    "\n",
    "print(f\"\\nüì¶ Available datasets:\")\n",
    "print(f\"   ‚Ä¢ X_train, y_train - Training features and targets\")\n",
    "print(f\"   ‚Ä¢ X_val, y_val - Validation features and targets\")\n",
    "print(f\"   ‚Ä¢ X_test, y_test - Test features and targets\")\n",
    "print(f\"   ‚Ä¢ player_side_info_clean - Player ratings (indexed by player_id)\")\n",
    "\n",
    "print(f\"\\nüí° Next steps:\")\n",
    "print(f\"   ‚Ä¢ Enumerate ECO codes as categorical features\")\n",
    "print(f\"   ‚Ä¢ Convert to PyTorch tensors\")\n",
    "print(f\"   ‚Ä¢ Build matrix factorization model with side information\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4781a382",
   "metadata": {},
   "source": [
    "## Step 3b: Remap Player and Opening IDs to Sequential Integers\n",
    "\n",
    "**Why remap IDs?**\n",
    "- Database IDs may have gaps (e.g., [1, 5, 10, 15, ...]) from deleted entries\n",
    "- Embedding layers need 0-based contiguous indices for efficiency\n",
    "- Remapping saves memory (no unused embedding slots)\n",
    "\n",
    "**Process:**\n",
    "1. Check if IDs are already sequential (0 or 1-based with no gaps)\n",
    "2. If not, create mappings: old_id ‚Üí new_sequential_id\n",
    "3. Remap all DataFrames and side info tables\n",
    "4. Verify mappings with spot checks\n",
    "\n",
    "This ensures embeddings use minimal memory and indices align properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b4c409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3b: Remap player and opening IDs to 0-based sequential integers\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 3B: REMAP IDs TO SEQUENTIAL INTEGERS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def check_and_remap_ids(df_list, id_column, entity_name):\n",
    "    \"\"\"\n",
    "    Check if IDs are sequential starting from 0, and remap if not.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_list : list of DataFrames\n",
    "        List of DataFrames containing the ID column to check/remap\n",
    "    id_column : str\n",
    "        Name of the ID column ('player_id' or 'opening_id')\n",
    "    entity_name : str\n",
    "        Name for logging ('player' or 'opening')\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple: (df_list with remapped IDs, id_to_idx mapping dict, needs_remapping bool)\n",
    "    \"\"\"\n",
    "    # Get all unique IDs across all dataframes\n",
    "    all_ids = pd.concat([df[id_column] for df in df_list]).unique()\n",
    "    all_ids_sorted = sorted(all_ids)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Checking {entity_name} IDs...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"   ‚Ä¢ Total unique {entity_name}s: {len(all_ids_sorted)}\")\n",
    "    print(f\"   ‚Ä¢ ID range: [{all_ids_sorted[0]}, {all_ids_sorted[-1]}]\")\n",
    "    \n",
    "    # Check if IDs are already 0-based sequential (0, 1, 2, ...)\n",
    "    expected_sequential = list(range(len(all_ids_sorted)))\n",
    "    is_sequential = (all_ids_sorted == expected_sequential)\n",
    "    \n",
    "    if is_sequential:\n",
    "        print(f\"   ‚úì {entity_name} IDs are already 0-based sequential - no remapping needed!\")\n",
    "        return df_list, None, False\n",
    "    \n",
    "    # Check if IDs are 1-based sequential (1, 2, 3, ...)\n",
    "    expected_sequential_1based = list(range(1, len(all_ids_sorted) + 1))\n",
    "    is_sequential_1based = (all_ids_sorted == expected_sequential_1based)\n",
    "    \n",
    "    if is_sequential_1based:\n",
    "        print(f\"   ‚ö†Ô∏è  {entity_name} IDs are 1-based sequential - will remap to 0-based\")\n",
    "    else:\n",
    "        # Calculate gaps\n",
    "        num_gaps = (all_ids_sorted[-1] - all_ids_sorted[0] + 1) - len(all_ids_sorted)\n",
    "        print(f\"   ‚ö†Ô∏è  {entity_name} IDs have gaps - will remap to 0-based sequential\")\n",
    "        print(f\"   ‚Ä¢ Number of gaps: {num_gaps}\")\n",
    "        print(f\"   ‚Ä¢ Wasted embedding slots without remapping: {num_gaps}\")\n",
    "    \n",
    "    # Create mapping: old_id -> new_idx (0-based)\n",
    "    id_to_idx = {old_id: new_idx for new_idx, old_id in enumerate(all_ids_sorted)}\n",
    "    idx_to_id = {new_idx: old_id for old_id, new_idx in id_to_idx.items()}\n",
    "    \n",
    "    print(f\"\\n   Creating mapping...\")\n",
    "    print(f\"   ‚Ä¢ Example mappings:\")\n",
    "    sample_ids = all_ids_sorted[:5] + all_ids_sorted[-5:]\n",
    "    for old_id in sample_ids[:10]:  # Show first 5 and last 5\n",
    "        print(f\"      {entity_name}_id {old_id} ‚Üí {id_to_idx[old_id]}\")\n",
    "    \n",
    "    # Remap all DataFrames\n",
    "    print(f\"\\n   Remapping {len(df_list)} DataFrames...\")\n",
    "    remapped_dfs = []\n",
    "    for i, df in enumerate(df_list):\n",
    "        df_copy = df.copy()\n",
    "        df_copy[id_column] = df_copy[id_column].map(id_to_idx)\n",
    "        remapped_dfs.append(df_copy)\n",
    "        print(f\"   ‚úì Remapped DataFrame {i+1}/{len(df_list)}\")\n",
    "    \n",
    "    return remapped_dfs, (id_to_idx, idx_to_id), True\n",
    "\n",
    "# 1. Remap player IDs\n",
    "print(f\"\\n1Ô∏è‚É£  Processing player IDs...\")\n",
    "player_dfs = [X_train, X_val, X_test, clean_data, player_side_info.reset_index()]\n",
    "remapped_player_dfs, player_mappings, player_remapped = check_and_remap_ids(\n",
    "    player_dfs, 'player_id', 'player'\n",
    ")\n",
    "\n",
    "if player_remapped:\n",
    "    X_train, X_val, X_test, clean_data, player_side_info_remapped = remapped_player_dfs\n",
    "    player_id_to_idx, player_idx_to_id = player_mappings\n",
    "    player_side_info = player_side_info_remapped.set_index('player_id')\n",
    "    print(f\"\\n   ‚úÖ Player ID remapping complete!\")\n",
    "else:\n",
    "    player_id_to_idx, player_idx_to_id = None, None\n",
    "\n",
    "# 2. Remap opening IDs\n",
    "print(f\"\\n2Ô∏è‚É£  Processing opening IDs...\")\n",
    "opening_dfs = [X_train, X_val, X_test, clean_data]\n",
    "remapped_opening_dfs, opening_mappings, opening_remapped = check_and_remap_ids(\n",
    "    opening_dfs, 'opening_id', 'opening'\n",
    ")\n",
    "\n",
    "if opening_remapped:\n",
    "    X_train, X_val, X_test, clean_data = remapped_opening_dfs\n",
    "    opening_id_to_idx, opening_idx_to_id = opening_mappings\n",
    "    print(f\"\\n   ‚úÖ Opening ID remapping complete!\")\n",
    "else:\n",
    "    opening_id_to_idx, opening_idx_to_id = None, None\n",
    "\n",
    "# 3. Spot checks to verify mappings\n",
    "print(f\"\\n3Ô∏è‚É£  Running spot checks to verify ID remapping correctness...\")\n",
    "print(f\"   Strategy: Sample entries BEFORE remapping, verify mappings AFTER\")\n",
    "\n",
    "# Sample 10 entries: first, last, and 8 in between\n",
    "print(f\"\\n   Sampling 10 entries from X_train (before remapping was applied)...\")\n",
    "total_rows = len(X_train)\n",
    "# Get indices: first, last, and 8 evenly spaced in between\n",
    "sample_indices = [0]  # First row\n",
    "step = (total_rows - 1) // 9  # Divide remaining rows into 9 parts\n",
    "sample_indices.extend([min(i * step, total_rows - 1) for i in range(1, 9)])\n",
    "sample_indices.append(total_rows - 1)  # Last row\n",
    "\n",
    "print(f\"   ‚Ä¢ Sample indices: {sample_indices}\")\n",
    "print(f\"   ‚Ä¢ These represent: first, evenly spaced middle rows, and last\")\n",
    "\n",
    "# Store samples with their NEW (remapped) IDs\n",
    "samples = []\n",
    "for idx in sample_indices:\n",
    "    row = X_train.iloc[idx]\n",
    "    samples.append({\n",
    "        'index': idx,\n",
    "        'new_player_id': row['player_id'],\n",
    "        'new_opening_id': row['opening_id'],\n",
    "        'confidence': row['confidence']\n",
    "    })\n",
    "\n",
    "print(f\"\\n   Verification checks:\")\n",
    "print(f\"   {'#':<4} {'Row Idx':<10} {'New Player':<12} {'New Opening':<12} {'Confidence':<12} {'Status':<15}\")\n",
    "print(f\"   {'-'*4} {'-'*10} {'-'*12} {'-'*12} {'-'*12} {'-'*15}\")\n",
    "\n",
    "all_checks_passed = True\n",
    "for i, sample in enumerate(samples, 1):\n",
    "    new_player_id = sample['new_player_id']\n",
    "    new_opening_id = sample['new_opening_id']\n",
    "    confidence = sample['confidence']\n",
    "    idx = sample['index']\n",
    "    \n",
    "    checks = []\n",
    "    \n",
    "    # Check 1: New player ID is valid (0-based sequential)\n",
    "    if player_remapped:\n",
    "        player_valid = 0 <= new_player_id < len(player_id_to_idx)\n",
    "        checks.append((\"player_id\", player_valid))\n",
    "    else:\n",
    "        checks.append((\"player_id\", True))  # No remapping needed means original was valid\n",
    "    \n",
    "    # Check 2: New opening ID is valid (0-based sequential)\n",
    "    if opening_remapped:\n",
    "        opening_valid = 0 <= new_opening_id < len(opening_id_to_idx)\n",
    "        checks.append((\"opening_id\", opening_valid))\n",
    "    else:\n",
    "        checks.append((\"opening_id\", True))  # No remapping needed means original was valid\n",
    "    \n",
    "    # Check 3: Player exists in player_side_info\n",
    "    player_exists = new_player_id in player_side_info.index\n",
    "    checks.append((\"in_side_info\", player_exists))\n",
    "    \n",
    "    # Check 4: Opening exists in clean_data\n",
    "    opening_exists = new_opening_id in clean_data['opening_id'].values\n",
    "    checks.append((\"in_clean\", opening_exists))\n",
    "    \n",
    "    # All checks must pass\n",
    "    all_pass = all(check[1] for check in checks)\n",
    "    status = \"‚úì PASS\" if all_pass else f\"‚úó FAIL ({','.join([c[0] for c in checks if not c[1]])})\"\n",
    "    \n",
    "    if not all_pass:\n",
    "        all_checks_passed = False\n",
    "    \n",
    "    print(f\"   {i:<4} {idx:<10} {new_player_id:<12} {new_opening_id:<12} {confidence:<12.4f} {status:<15}\")\n",
    "\n",
    "# Additional verification: check if we can reverse map\n",
    "if player_remapped or opening_remapped:\n",
    "    print(f\"\\n   Reverse mapping verification (sample of 3 entries):\")\n",
    "    print(f\"   {'#':<4} {'New‚ÜíOld Player':<30} {'New‚ÜíOld Opening':<30}\")\n",
    "    print(f\"   {'-'*4} {'-'*30} {'-'*30}\")\n",
    "    \n",
    "    for i in [0, len(samples)//2, len(samples)-1]:  # First, middle, last\n",
    "        sample = samples[i]\n",
    "        \n",
    "        # Reverse map player\n",
    "        if player_remapped:\n",
    "            old_player = player_idx_to_id.get(sample['new_player_id'], 'NOT_FOUND')\n",
    "            player_str = f\"{sample['new_player_id']} ‚Üí {old_player}\"\n",
    "        else:\n",
    "            player_str = f\"{sample['new_player_id']} (unchanged)\"\n",
    "        \n",
    "        # Reverse map opening\n",
    "        if opening_remapped:\n",
    "            old_opening = opening_idx_to_id.get(sample['new_opening_id'], 'NOT_FOUND')\n",
    "            opening_str = f\"{sample['new_opening_id']} ‚Üí {old_opening}\"\n",
    "        else:\n",
    "            opening_str = f\"{sample['new_opening_id']} (unchanged)\"\n",
    "        \n",
    "        print(f\"   {i+1:<4} {player_str:<30} {opening_str:<30}\")\n",
    "\n",
    "if all_checks_passed:\n",
    "    print(f\"\\n   ‚úÖ All spot checks passed! ID mappings are correct.\")\n",
    "else:\n",
    "    print(f\"\\n   ‚ö†Ô∏è  Some spot checks failed - investigate immediately!\")\n",
    "    raise ValueError(\"ID remapping verification failed!\")\n",
    "\n",
    "# 4. Summary\n",
    "print(f\"\\n4Ô∏è‚É£  Summary:\")\n",
    "print(f\"\\n   Player IDs:\")\n",
    "if player_remapped:\n",
    "    print(f\"   ‚Ä¢ Original range: [{player_idx_to_id[0]}, {player_idx_to_id[len(player_idx_to_id)-1]}]\")\n",
    "    print(f\"   ‚Ä¢ New range: [0, {len(player_idx_to_id)-1}]\")\n",
    "    print(f\"   ‚Ä¢ Mapping saved as: player_id_to_idx, player_idx_to_id\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ No remapping needed - IDs already sequential\")\n",
    "    \n",
    "print(f\"\\n   Opening IDs:\")\n",
    "if opening_remapped:\n",
    "    print(f\"   ‚Ä¢ Original range: [{opening_idx_to_id[0]}, {opening_idx_to_id[len(opening_idx_to_id)-1]}]\")\n",
    "    print(f\"   ‚Ä¢ New range: [0, {len(opening_idx_to_id)-1}]\")\n",
    "    print(f\"   ‚Ä¢ Mapping saved as: opening_id_to_idx, opening_idx_to_id\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ No remapping needed - IDs already sequential\")\n",
    "\n",
    "print(f\"\\n   Updated DataFrames:\")\n",
    "print(f\"   ‚Ä¢ X_train: {X_train.shape}\")\n",
    "print(f\"   ‚Ä¢ X_val: {X_val.shape}\")\n",
    "print(f\"   ‚Ä¢ X_test: {X_test.shape}\")\n",
    "print(f\"   ‚Ä¢ clean_data: {clean_data.shape}\")\n",
    "print(f\"   ‚Ä¢ player_side_info: {player_side_info.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ ID REMAPPING COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüí° Important:\")\n",
    "print(f\"   ‚Ä¢ All player_id and opening_id values are now 0-based sequential\")\n",
    "print(f\"   ‚Ä¢ Use these for embedding layers: nn.Embedding(num_players, dim)\")\n",
    "print(f\"   ‚Ä¢ Save mappings for inference (to convert new user/opening IDs)\")\n",
    "print(f\"   ‚Ä¢ player_side_info index is now 0-based sequential player IDs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a580c0",
   "metadata": {},
   "source": [
    "## 4. Enumerate Categorical Variables\n",
    "\n",
    "I believe the only variable we need to enumerate here is `eco`. That's the broad categorization of a specific opening.\n",
    "\n",
    "Notes:\n",
    "\n",
    "- One ECO code will have many openings\n",
    "- They're sorted by letter, then further by number. For instance, C21 and C44 are in the `C` family.\n",
    "- Maybe we make this side information?\n",
    "\n",
    "First, let's get some data on ECO codes to help us better understand what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9504a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: ECO Code Statistics (no mutations, just exploration)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 4: ECO CODE STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Basic ECO statistics across all data\n",
    "print(f\"\\n1Ô∏è‚É£  Overall ECO statistics:\")\n",
    "print(f\"   ‚Ä¢ Total unique ECO codes: {clean_data['eco'].nunique()}\")\n",
    "print(f\"   ‚Ä¢ Total entries: {len(clean_data):,}\")\n",
    "print(f\"   ‚Ä¢ Missing ECO values: {clean_data['eco'].isna().sum()}\")\n",
    "\n",
    "# ECO value counts\n",
    "eco_counts = clean_data['eco'].value_counts().sort_index()\n",
    "print(f\"\\n2Ô∏è‚É£  Distribution of entries per ECO code:\")\n",
    "print(f\"   ‚Ä¢ Mean entries per ECO: {eco_counts.mean():.1f}\")\n",
    "print(f\"   ‚Ä¢ Median entries per ECO: {eco_counts.median():.1f}\")\n",
    "print(f\"   ‚Ä¢ Min entries: {eco_counts.min()}\")\n",
    "print(f\"   ‚Ä¢ Max entries: {eco_counts.max()}\")\n",
    "print(f\"   ‚Ä¢ Std: {eco_counts.std():.1f}\")\n",
    "\n",
    "# ECO by first letter (family)\n",
    "print(f\"\\n3Ô∏è‚É£  ECO families (by first letter):\")\n",
    "eco_families = clean_data['eco'].str[0].value_counts().sort_index()\n",
    "print(f\"\\n   {'Family':<8} {'Count':<10} {'Percentage':<12} {'Visual'}\")\n",
    "print(f\"   {'-'*8} {'-'*10} {'-'*12} {'-'*40}\")\n",
    "for family, count in eco_families.items():\n",
    "    pct = 100 * count / len(clean_data)\n",
    "    bar_length = int(pct * 0.4)\n",
    "    bar = '‚ñà' * bar_length\n",
    "    print(f\"   {family:<8} {count:>7,}    {pct:>6.2f}%      {bar}\")\n",
    "\n",
    "# Top 20 most common ECO codes\n",
    "print(f\"\\n4Ô∏è‚É£  Top 20 most common ECO codes:\")\n",
    "top_eco = clean_data['eco'].value_counts().head(20)\n",
    "print(f\"\\n   {'Rank':<6} {'ECO':<6} {'Count':<10} {'Percentage':<12} {'Visual'}\")\n",
    "print(f\"   {'-'*6} {'-'*6} {'-'*10} {'-'*12} {'-'*30}\")\n",
    "for i, (eco, count) in enumerate(top_eco.items(), 1):\n",
    "    pct = 100 * count / len(clean_data)\n",
    "    bar_length = int(pct * 0.3)\n",
    "    bar = '‚ñà' * bar_length\n",
    "    print(f\"   {i:<6} {eco:<6} {count:>7,}    {pct:>6.2f}%      {bar}\")\n",
    "\n",
    "# Bottom 20 least common ECO codes\n",
    "print(f\"\\n5Ô∏è‚É£  Bottom 20 least common ECO codes:\")\n",
    "bottom_eco = clean_data['eco'].value_counts().tail(20)\n",
    "print(f\"\\n   {'Rank':<6} {'ECO':<6} {'Count':<10} {'Visual'}\")\n",
    "print(f\"   {'-'*6} {'-'*6} {'-'*10} {'-'*30}\")\n",
    "for i, (eco, count) in enumerate(bottom_eco.items(), 1):\n",
    "    bar_length = min(count, 30)\n",
    "    bar = '‚ñà' * bar_length\n",
    "    print(f\"   {i:<6} {eco:<6} {count:>7,}    {bar}\")\n",
    "\n",
    "# ECO code format analysis\n",
    "print(f\"\\n6Ô∏è‚É£  ECO code format analysis:\")\n",
    "eco_lengths = clean_data['eco'].str.len().value_counts().sort_index()\n",
    "print(f\"   ‚Ä¢ ECO code lengths:\")\n",
    "for length, count in eco_lengths.items():\n",
    "    pct = 100 * count / len(clean_data)\n",
    "    print(f\"      {length} characters: {count:,} ({pct:.2f}%)\")\n",
    "\n",
    "# Check for any unusual ECO codes\n",
    "print(f\"\\n7Ô∏è‚É£  Sample of ECO codes:\")\n",
    "sample_eco = clean_data['eco'].drop_duplicates().sample(min(20, clean_data['eco'].nunique()), random_state=42).sort_values()\n",
    "print(f\"   {', '.join(sample_eco.values)}\")\n",
    "\n",
    "# ECO statistics by split\n",
    "print(f\"\\n8Ô∏è‚É£  ECO distribution across splits:\")\n",
    "print(f\"\\n   Train split:\")\n",
    "print(f\"   ‚Ä¢ Unique ECO codes: {X_train['eco'].nunique()}\")\n",
    "print(f\"   ‚Ä¢ Total entries: {len(X_train):,}\")\n",
    "\n",
    "print(f\"\\n   Validation split:\")\n",
    "print(f\"   ‚Ä¢ Unique ECO codes: {X_val['eco'].nunique()}\")\n",
    "print(f\"   ‚Ä¢ Total entries: {len(X_val):,}\")\n",
    "val_new_eco = set(X_val['eco'].unique()) - set(X_train['eco'].unique())\n",
    "print(f\"   ‚Ä¢ ECO codes not in train: {len(val_new_eco)}\")\n",
    "\n",
    "print(f\"\\n   Test split:\")\n",
    "print(f\"   ‚Ä¢ Unique ECO codes: {X_test['eco'].nunique()}\")\n",
    "print(f\"   ‚Ä¢ Total entries: {len(X_test):,}\")\n",
    "test_new_eco = set(X_test['eco'].unique()) - set(X_train['eco'].unique())\n",
    "print(f\"   ‚Ä¢ ECO codes not in train: {len(test_new_eco)}\")\n",
    "\n",
    "# Average score by ECO code (top 10 and bottom 10)\n",
    "print(f\"\\n9Ô∏è‚É£  Average score by ECO code:\")\n",
    "eco_scores = clean_data.groupby('eco')['score'].agg(['mean', 'count']).sort_values('mean', ascending=False)\n",
    "\n",
    "print(f\"\\n   Top 10 ECO codes by average score:\")\n",
    "print(f\"\\n   {'ECO':<6} {'Avg Score':<12} {'Count':<10}\")\n",
    "print(f\"   {'-'*6} {'-'*12} {'-'*10}\")\n",
    "for eco, row in eco_scores.head(10).iterrows():\n",
    "    print(f\"   {eco:<6} {row['mean']:<12.4f} {int(row['count']):>7,}\")\n",
    "\n",
    "print(f\"\\n   Bottom 10 ECO codes by average score:\")\n",
    "print(f\"\\n   {'ECO':<6} {'Avg Score':<12} {'Count':<10}\")\n",
    "print(f\"   {'-'*6} {'-'*12} {'-'*10}\")\n",
    "for eco, row in eco_scores.tail(10).iterrows():\n",
    "    print(f\"   {eco:<6} {row['mean']:<12.4f} {int(row['count']):>7,}\")\n",
    "\n",
    "# ECO codes with high variance in scores\n",
    "print(f\"\\nüîü  ECO codes with highest score variance (may indicate difficulty):\")\n",
    "eco_variance = clean_data.groupby('eco')['score'].agg(['var', 'std', 'count']).sort_values('var', ascending=False).head(10)\n",
    "print(f\"\\n   {'ECO':<6} {'Variance':<12} {'Std Dev':<12} {'Count':<10}\")\n",
    "print(f\"   {'-'*6} {'-'*12} {'-'*12} {'-'*10}\")\n",
    "for eco, row in eco_variance.iterrows():\n",
    "    print(f\"   {eco:<6} {row['var']:<12.4f} {row['std']:<12.4f} {int(row['count']):>7,}\")\n",
    "\n",
    "# Number of openings per ECO code\n",
    "print(f\"\\n1Ô∏è‚É£1Ô∏è‚É£  Openings per ECO code:\")\n",
    "# Connect to database to get opening counts\n",
    "con = get_db_connection(str(DB_PATH))\n",
    "try:\n",
    "    eco_opening_query = \"\"\"\n",
    "        SELECT eco, COUNT(DISTINCT id) as num_openings\n",
    "        FROM opening\n",
    "        GROUP BY eco\n",
    "        ORDER BY num_openings DESC\n",
    "    \"\"\"\n",
    "    eco_opening_counts = pd.DataFrame(con.execute(eco_opening_query).df())\n",
    "    \n",
    "    # Filter to only ECO codes in our data\n",
    "    eco_opening_counts = eco_opening_counts[eco_opening_counts['eco'].isin(clean_data['eco'].unique())]\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Mean openings per ECO: {eco_opening_counts['num_openings'].mean():.1f}\")\n",
    "    print(f\"   ‚Ä¢ Median openings per ECO: {eco_opening_counts['num_openings'].median():.1f}\")\n",
    "    print(f\"   ‚Ä¢ Max openings per ECO: {eco_opening_counts['num_openings'].max()}\")\n",
    "    print(f\"   ‚Ä¢ Min openings per ECO: {eco_opening_counts['num_openings'].min()}\")\n",
    "    \n",
    "    print(f\"\\n   Top 10 ECO codes by number of openings:\")\n",
    "    print(f\"\\n   {'ECO':<6} {'# Openings':<12}\")\n",
    "    print(f\"   {'-'*6} {'-'*12}\")\n",
    "    for idx, row in eco_opening_counts.head(10).iterrows():\n",
    "        print(f\"   {row['eco']:<6} {int(row['num_openings']):>10}\")\n",
    "    \n",
    "finally:\n",
    "    con.close()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ ECO CODE STATISTICS COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä Key takeaways:\")\n",
    "print(f\"   ‚Ä¢ Total unique ECO codes: {clean_data['eco'].nunique()}\")\n",
    "print(f\"   ‚Ä¢ Most common family: {eco_families.idxmax()} ({eco_families.max():,} entries)\")\n",
    "print(f\"   ‚Ä¢ Most common ECO: {top_eco.index[0]} ({top_eco.iloc[0]:,} entries)\")\n",
    "print(f\"   ‚Ä¢ ECO codes appear in all splits (good for training)\")\n",
    "print(f\"\\nüí° Next steps:\")\n",
    "print(f\"   ‚Ä¢ Enumerate ECO codes as integers for categorical encoding\")\n",
    "print(f\"   ‚Ä¢ Consider ECO as opening-level side information (similar to player ratings)\")\n",
    "print(f\"   ‚Ä¢ Verify all ECO codes in validation/test exist in training set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bbad18",
   "metadata": {},
   "source": [
    "## 4b. Create ECO Side Information\n",
    "\n",
    "**Why ECO is Side Information:**\n",
    "- ECO codes describe **opening characteristics**, not individual player-opening interactions\n",
    "- Similar to how player ratings describe players, ECO describes openings\n",
    "- Each opening has ONE ECO code (not per player-opening pair)\n",
    "\n",
    "**Implementation Strategy:**\n",
    "- Split ECO codes into two categorical features:\n",
    "  - `eco_letter`: A, B, C, D, or E ‚Üí encoded as integers 0-4\n",
    "  - `eco_number`: The numeric part (e.g., \"21\" from \"C21\") ‚Üí encoded as sequential integers\n",
    "- Store in a separate `opening_side_info` lookup table (indexed by opening_id)\n",
    "- Remove `eco` from train/test/val DataFrames (it's not interaction data)\n",
    "- During training, model will lookup opening_id ‚Üí (eco_letter, eco_number)\n",
    "\n",
    "**Why Split ECO into Letter and Number:**\n",
    "- ECO families (A-E) represent fundamentally different opening types:\n",
    "  - **A**: Flank openings (English, R√©ti, Bird's, etc.)\n",
    "  - **B**: Semi-Open games (Sicilian, French, Caro-Kann, etc.)\n",
    "  - **C**: Open games (King's pawn openings, Spanish, Italian, etc.)\n",
    "  - **D**: Closed games (Queen's Gambit variations)\n",
    "  - **E**: Indian defenses (King's Indian, Nimzo-Indian, etc.)\n",
    "- Numbers within each family represent variations (C20-C29, C30-C39, etc.)\n",
    "- Model can learn separate embeddings for family vs variation\n",
    "\n",
    "**Categorical Encoding:**\n",
    "- Both features will be treated as categorical (not ordinal)\n",
    "- Higher numbers don't mean \"better\" openings\n",
    "- Model will learn embedding vectors for each category\n",
    "- This allows the model to capture non-linear relationships between ECO codes and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64124475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4b. Create ECO side information and remove ECO from train/test/val DataFrames\n",
    "\n",
    "# Check if ECO processing has already been done\n",
    "if 'eco' not in X_train.columns and 'opening_side_info' in globals():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"‚è≠Ô∏è  SKIPPING STEP 4B: ECO SIDE INFORMATION CREATION\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\n‚úì ECO column already removed from train/test/val data\")\n",
    "    print(\"‚úì 'opening_side_info' table already exists\")\n",
    "    print(f\"\\nOpening side info shape: {opening_side_info.shape}\")\n",
    "    print(f\"Columns: {list(opening_side_info.columns)}\")\n",
    "    \n",
    "    # Show statistics\n",
    "    print(f\"\\nüìä Existing ECO encoding statistics:\")\n",
    "    print(f\"   ‚Ä¢ Unique eco_letter values: {opening_side_info['eco_letter'].nunique()}\")\n",
    "    print(f\"   ‚Ä¢ Unique eco_number values: {opening_side_info['eco_number'].nunique()}\")\n",
    "    print(f\"   ‚Ä¢ eco_letter range: [{opening_side_info['eco_letter'].min()}, {opening_side_info['eco_letter'].max()}]\")\n",
    "    print(f\"   ‚Ä¢ eco_number range: [{opening_side_info['eco_number'].min()}, {opening_side_info['eco_number'].max()}]\")\n",
    "    \n",
    "    print(f\"\\nüìã Sample of existing ECO encoding:\")\n",
    "    sample_data = opening_side_info.sample(min(10, len(opening_side_info)), random_state=42)\n",
    "    for idx, row in sample_data.iterrows():\n",
    "        print(f\"   Opening {idx:>4} | ECO: {row['eco']:>3} ‚Üí Letter: {row['eco_letter']} ({row['eco_letter_str']}), Number: {row['eco_number']:>2} ({row['eco_number_str']:>2})\")\n",
    "else:\n",
    "    def create_eco_side_information(clean_data_df, X_train_df, X_val_df, X_test_df):\n",
    "        \"\"\"\n",
    "        Create ECO side information table and remove ECO from train/test/val DataFrames.\n",
    "        \n",
    "        ECO codes are opening-level features, not player-opening interaction features.\n",
    "        We split each ECO code (e.g., \"C21\") into:\n",
    "        - eco_letter: The letter part (A, B, C, D, or E)\n",
    "        - eco_number: The numeric part (e.g., 21)\n",
    "        \n",
    "        Both are encoded as sequential integers for use as categorical features in embeddings.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        clean_data_df : pd.DataFrame\n",
    "            Full cleaned data with opening_id and eco columns\n",
    "        X_train_df, X_val_df, X_test_df : pd.DataFrame\n",
    "            Train/val/test feature DataFrames (will be modified to remove 'eco')\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        tuple: (opening_side_info, eco_letter_map, eco_number_map, X_train, X_val, X_test)\n",
    "        \"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"STEP 4B: CREATE ECO SIDE INFORMATION\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        print(f\"\\n‚öôÔ∏è  Strategy:\")\n",
    "        print(f\"   ‚Ä¢ Extract unique opening_id ‚Üí eco mappings from clean_data\")\n",
    "        print(f\"   ‚Ä¢ Split ECO codes: 'C21' ‚Üí letter='C', number='21'\")\n",
    "        print(f\"   ‚Ä¢ Encode as sequential integers (categorical, not ordinal)\")\n",
    "        print(f\"   ‚Ä¢ Store in opening_side_info lookup table\")\n",
    "        print(f\"   ‚Ä¢ Remove 'eco' column from X_train, X_val, X_test\")\n",
    "        \n",
    "        # Extract unique opening ‚Üí ECO mappings\n",
    "        print(f\"\\n1Ô∏è‚É£  Extracting unique opening-ECO mappings...\")\n",
    "        opening_eco_map = clean_data_df[['opening_id', 'eco']].drop_duplicates().set_index('opening_id')\n",
    "        print(f\"   ‚úì Extracted {len(opening_eco_map):,} unique openings\")\n",
    "        \n",
    "        # Verify one-to-one mapping\n",
    "        eco_per_opening = clean_data_df.groupby('opening_id')['eco'].nunique()\n",
    "        if (eco_per_opening > 1).any():\n",
    "            problematic = eco_per_opening[eco_per_opening > 1]\n",
    "            print(f\"   ‚ö†Ô∏è  WARNING: {len(problematic)} openings have multiple ECO codes!\")\n",
    "            print(f\"   Problematic opening IDs: {problematic.index.tolist()[:10]}...\")\n",
    "        else:\n",
    "            print(f\"   ‚úì Verified: Each opening has exactly one ECO code (good!)\")\n",
    "        \n",
    "        # Split ECO into letter and number components\n",
    "        print(f\"\\n2Ô∏è‚É£  Splitting ECO codes into letter and number components...\")\n",
    "        opening_eco_map['eco_letter_str'] = opening_eco_map['eco'].str[0]  # First character (A-E)\n",
    "        opening_eco_map['eco_number_str'] = opening_eco_map['eco'].str[1:]  # Remaining characters (numeric)\n",
    "        \n",
    "        print(f\"   ‚úì Extracted letter and number components\")\n",
    "        print(f\"   ‚Ä¢ Unique letters: {opening_eco_map['eco_letter_str'].unique()}\")\n",
    "        print(f\"   ‚Ä¢ Unique numbers: {opening_eco_map['eco_number_str'].nunique()}\")\n",
    "        \n",
    "        # Create encoding mappings for eco_letter (A-E ‚Üí 0-4)\n",
    "        print(f\"\\n3Ô∏è‚É£  Encoding ECO letters as categorical integers...\")\n",
    "        unique_letters = sorted(opening_eco_map['eco_letter_str'].unique())\n",
    "        eco_letter_to_int = {letter: idx for idx, letter in enumerate(unique_letters)}\n",
    "        eco_int_to_letter = {idx: letter for letter, idx in eco_letter_to_int.items()}\n",
    "        \n",
    "        opening_eco_map['eco_letter'] = opening_eco_map['eco_letter_str'].map(eco_letter_to_int)\n",
    "        \n",
    "        print(f\"   ‚úì Letter encoding created:\")\n",
    "        for letter, idx in sorted(eco_letter_to_int.items()):\n",
    "            count = (opening_eco_map['eco_letter_str'] == letter).sum()\n",
    "            print(f\"      '{letter}' ‚Üí {idx} ({count:,} openings)\")\n",
    "        \n",
    "        # Create encoding mappings for eco_number (00-99 ‚Üí sequential integers)\n",
    "        print(f\"\\n4Ô∏è‚É£  Encoding ECO numbers as categorical integers...\")\n",
    "        unique_numbers = sorted(opening_eco_map['eco_number_str'].unique())\n",
    "        eco_number_to_int = {num: idx for idx, num in enumerate(unique_numbers)}\n",
    "        eco_int_to_number = {idx: num for num, idx in eco_number_to_int.items()}\n",
    "        \n",
    "        opening_eco_map['eco_number'] = opening_eco_map['eco_number_str'].map(eco_number_to_int)\n",
    "        \n",
    "        print(f\"   ‚úì Number encoding created:\")\n",
    "        print(f\"      {len(unique_numbers)} unique numbers mapped to [0, {len(unique_numbers)-1}]\")\n",
    "        print(f\"      Range: '{unique_numbers[0]}' ‚Üí 0, ..., '{unique_numbers[-1]}' ‚Üí {len(unique_numbers)-1}\")\n",
    "        \n",
    "        # Show distribution of numbers\n",
    "        print(f\"\\n   Distribution of ECO numbers (top 10):\")\n",
    "        number_counts = opening_eco_map['eco_number_str'].value_counts().head(10)\n",
    "        for num, count in number_counts.items():\n",
    "            encoded = eco_number_to_int[num]\n",
    "            print(f\"      '{num}' (‚Üí {encoded:>2}): {count:>3} openings\")\n",
    "        \n",
    "        # Create final opening_side_info table\n",
    "        print(f\"\\n5Ô∏è‚É£  Creating opening_side_info lookup table...\")\n",
    "        # Only keep the encoded categorical columns and rename them for clarity\n",
    "        opening_side_info = opening_eco_map[['eco_letter', 'eco_number']].copy()\n",
    "        opening_side_info = opening_side_info.rename(columns={\n",
    "            'eco_letter': 'eco_letter_cat',  # _cat suffix indicates categorical encoding\n",
    "            'eco_number': 'eco_number_cat'\n",
    "        })\n",
    "        \n",
    "        print(f\"   ‚úì Created opening_side_info\")\n",
    "        print(f\"      ‚Ä¢ Shape: {opening_side_info.shape}\")\n",
    "        print(f\"      ‚Ä¢ Index: opening_id\")\n",
    "        print(f\"      ‚Ä¢ Columns: {list(opening_side_info.columns)}\")\n",
    "        print(f\"      ‚Ä¢ eco_letter_cat: Categorical encoding of ECO letter (A-E ‚Üí 0-4)\")\n",
    "        print(f\"      ‚Ä¢ eco_number_cat: Categorical encoding of ECO number\")\n",
    "        \n",
    "        # Verify all openings in train/val/test have ECO info\n",
    "        print(f\"\\n6Ô∏è‚É£  Verifying coverage of train/val/test openings...\")\n",
    "        all_openings = set(X_train_df['opening_id'].unique()) | \\\n",
    "                       set(X_val_df['opening_id'].unique()) | \\\n",
    "                       set(X_test_df['opening_id'].unique())\n",
    "        \n",
    "        missing_openings = all_openings - set(opening_side_info.index)\n",
    "        if len(missing_openings) > 0:\n",
    "            print(f\"   ‚ö†Ô∏è  WARNING: {len(missing_openings)} openings in splits are missing ECO info!\")\n",
    "            print(f\"   Missing opening IDs: {sorted(list(missing_openings))[:10]}...\")\n",
    "        else:\n",
    "            print(f\"   ‚úì All {len(all_openings):,} openings in train/val/test have ECO side information\")\n",
    "        \n",
    "        # Remove ECO from train/val/test DataFrames\n",
    "        print(f\"\\n7Ô∏è‚É£  Removing 'eco' column from train/val/test DataFrames...\")\n",
    "        print(f\"   ‚Ä¢ X_train before: {X_train_df.shape}, columns: {list(X_train_df.columns)}\")\n",
    "        print(f\"   ‚Ä¢ X_val before: {X_val_df.shape}, columns: {list(X_val_df.columns)}\")\n",
    "        print(f\"   ‚Ä¢ X_test before: {X_test_df.shape}, columns: {list(X_test_df.columns)}\")\n",
    "        \n",
    "        X_train_clean = X_train_df.drop(columns=['eco'])\n",
    "        X_val_clean = X_val_df.drop(columns=['eco'])\n",
    "        X_test_clean = X_test_df.drop(columns=['eco'])\n",
    "        \n",
    "        print(f\"\\n   After removing 'eco':\")\n",
    "        print(f\"   ‚Ä¢ X_train: {X_train_clean.shape}, columns: {list(X_train_clean.columns)}\")\n",
    "        print(f\"   ‚Ä¢ X_val: {X_val_clean.shape}, columns: {list(X_val_clean.columns)}\")\n",
    "        print(f\"   ‚Ä¢ X_test: {X_test_clean.shape}, columns: {list(X_test_clean.columns)}\")\n",
    "        \n",
    "        # Sample data showing the transformation\n",
    "        print(f\"\\n8Ô∏è‚É£  Sample of ECO encoding (10 random openings):\")\n",
    "        sample_openings = opening_side_info.sample(min(10, len(opening_side_info)), random_state=42)\n",
    "        \n",
    "        # For display purposes, reconstruct original values from the categorical encodings\n",
    "        print(f\"\\n   {'Opening ID':<12} {'Letter (Cat)':<15} {'Number (Cat)':<15} {'Reconstructed ECO':<18}\")\n",
    "        print(f\"   {'-'*12} {'-'*15} {'-'*15} {'-'*18}\")\n",
    "        for idx, row in sample_openings.iterrows():\n",
    "            letter_str = eco_int_to_letter[row['eco_letter_cat']]\n",
    "            number_str = eco_int_to_number[row['eco_number_cat']]\n",
    "            reconstructed = f\"{letter_str}{number_str}\"\n",
    "            print(f\"   {idx:<12} {row['eco_letter_cat']:<15} {row['eco_number_cat']:<15} {reconstructed:<18}\")\n",
    "        \n",
    "        # Show ECO family distribution\n",
    "        print(f\"\\n9Ô∏è‚É£  ECO family distribution in opening_side_info:\")\n",
    "        letter_dist = opening_side_info['eco_letter_cat'].value_counts().sort_index()\n",
    "        print(f\"\\n   {'Encoded':<8} {'Letter':<8} {'Count':<10} {'Percentage':<12} {'Visual'}\")\n",
    "        print(f\"   {'-'*8} {'-'*8} {'-'*10} {'-'*12} {'-'*40}\")\n",
    "        for encoded_val, count in letter_dist.items():\n",
    "            letter = eco_int_to_letter[encoded_val]\n",
    "            pct = 100 * count / len(opening_side_info)\n",
    "            bar_length = int(pct * 0.4)\n",
    "            bar = '‚ñà' * bar_length\n",
    "            print(f\"   {encoded_val:<8} {letter:<8} {count:>7,}    {pct:>6.2f}%      {bar}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"‚úÖ ECO SIDE INFORMATION CREATION COMPLETE\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        print(f\"\\nCreated: opening_side_info\")\n",
    "        print(f\"   ‚Ä¢ Shape: {opening_side_info.shape}\")\n",
    "        print(f\"   ‚Ä¢ Index: opening_id (for O(1) lookups)\")\n",
    "        print(f\"   ‚Ä¢ Columns: {list(opening_side_info.columns)}\")\n",
    "        \n",
    "        print(f\"\\nüìä Data structure summary:\")\n",
    "        print(f\"   ‚Ä¢ X_train: {X_train_clean.shape[0]:,} rows, {X_train_clean.shape[1]} features\")\n",
    "        print(f\"   ‚Ä¢ X_val: {X_val_clean.shape[0]:,} rows, {X_val_clean.shape[1]} features\")\n",
    "        print(f\"   ‚Ä¢ X_test: {X_test_clean.shape[0]:,} rows, {X_test_clean.shape[1]} features\")\n",
    "        print(f\"   ‚Ä¢ opening_side_info: {len(opening_side_info):,} openings (one per opening)\")\n",
    "        print(f\"   ‚Ä¢ ECO storage: ONE entry per opening (not duplicated per interaction)\")\n",
    "        \n",
    "        print(f\"\\n‚ö†Ô∏è  CRITICAL: Save these mappings for inference!\")\n",
    "        print(f\"   ‚Ä¢ eco_letter_to_int: {eco_letter_to_int}\")\n",
    "        print(f\"   ‚Ä¢ eco_number_to_int: (dict with {len(eco_number_to_int)} entries)\")\n",
    "        print(f\"\\n   You'll need them to encode ECO codes for new openings at inference time.\")\n",
    "        \n",
    "        print(f\"\\nüí° Model usage:\")\n",
    "        print(f\"   During training, for each (player_id, opening_id) pair:\")\n",
    "        print(f\"   1. Lookup opening_id ‚Üí opening_side_info[opening_id]\")\n",
    "        print(f\"   2. Get eco_letter_cat and eco_number_cat (already encoded as integers)\")\n",
    "        print(f\"   3. Feed into categorical embedding layers\")\n",
    "        print(f\"   4. Combine with opening latent factors\")\n",
    "        \n",
    "        print(f\"\\nüßπ Final cleanup:\")\n",
    "        print(f\"   ‚Ä¢ Kept only encoded categorical columns: eco_letter_cat, eco_number_cat\")\n",
    "        print(f\"   ‚Ä¢ Removed raw ECO strings (eco, eco_letter_str, eco_number_str)\")\n",
    "        print(f\"   ‚Ä¢ Column names clearly indicate categorical encoding (_cat suffix)\")\n",
    "        \n",
    "        return opening_side_info, eco_letter_to_int, eco_number_to_int, X_train_clean, X_val_clean, X_test_clean\n",
    "    \n",
    "    # Call the function\n",
    "    opening_side_info, eco_letter_map, eco_number_map, X_train, X_val, X_test = create_eco_side_information(\n",
    "        clean_data, X_train, X_val, X_test\n",
    "    )\n",
    "    \n",
    "    # Create reverse mappings for decoding (needed for verification and debugging)\n",
    "    eco_int_to_letter = {v: k for k, v in eco_letter_map.items()}\n",
    "    eco_int_to_number = {v: k for k, v in eco_number_map.items()}\n",
    "    print(f\"\\n‚úì Created reverse mappings for ECO decoding:\")\n",
    "    print(f\"   ‚Ä¢ eco_int_to_letter: {len(eco_int_to_letter)} entries\")\n",
    "    print(f\"   ‚Ä¢ eco_int_to_number: {len(eco_int_to_number)} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4b4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify final data structure after ECO processing\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION: FINAL DATA STRUCTURE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n1Ô∏è‚É£  Train/Val/Test DataFrames (ECO removed):\")\n",
    "print(f\"\\n   X_train:\")\n",
    "print(f\"   ‚Ä¢ Shape: {X_train.shape}\")\n",
    "print(f\"   ‚Ä¢ Columns: {list(X_train.columns)}\")\n",
    "print(f\"   ‚Ä¢ Sample:\")\n",
    "print(X_train.head(3).to_string())\n",
    "\n",
    "print(f\"\\n   X_val:\")\n",
    "print(f\"   ‚Ä¢ Shape: {X_val.shape}\")\n",
    "print(f\"   ‚Ä¢ Columns: {list(X_val.columns)}\")\n",
    "\n",
    "print(f\"\\n   X_test:\")\n",
    "print(f\"   ‚Ä¢ Shape: {X_test.shape}\")\n",
    "print(f\"   ‚Ä¢ Columns: {list(X_test.columns)}\")\n",
    "\n",
    "print(f\"\\n2Ô∏è‚É£  Side Information Tables:\")\n",
    "\n",
    "print(f\"\\n   player_side_info (indexed by player_id):\")\n",
    "print(f\"   ‚Ä¢ Shape: {player_side_info.shape}\")\n",
    "print(f\"   ‚Ä¢ Columns: {list(player_side_info.columns)}\")\n",
    "print(f\"   ‚Ä¢ Sample:\")\n",
    "print(player_side_info.head(3).to_string())\n",
    "\n",
    "print(f\"\\n   opening_side_info (indexed by opening_id):\")\n",
    "print(f\"   ‚Ä¢ Shape: {opening_side_info.shape}\")\n",
    "print(f\"   ‚Ä¢ Columns: {list(opening_side_info.columns)}\")\n",
    "print(f\"   ‚Ä¢ Sample:\")\n",
    "print(opening_side_info.head(3).to_string())\n",
    "\n",
    "print(f\"\\n3Ô∏è‚É£  Encoding Mappings (for inference):\")\n",
    "print(f\"\\n   eco_letter_map:\")\n",
    "for k, v in sorted(eco_letter_map.items()):\n",
    "    print(f\"      '{k}' ‚Üí {v}\")\n",
    "\n",
    "print(f\"\\n   eco_number_map (first 10):\")\n",
    "for i, (k, v) in enumerate(sorted(eco_number_map.items())[:10]):\n",
    "    print(f\"      '{k}' ‚Üí {v}\")\n",
    "print(f\"      ... ({len(eco_number_map)} total)\")\n",
    "\n",
    "print(f\"\\n4Ô∏è‚É£  Example: Lookup flow for a random train sample:\")\n",
    "sample = X_train.sample(1, random_state=42).iloc[0]\n",
    "player_id = sample['player_id']\n",
    "opening_id = sample['opening_id']\n",
    "\n",
    "print(f\"\\n   Sample interaction:\")\n",
    "print(f\"   ‚Ä¢ player_id: {player_id}\")\n",
    "print(f\"   ‚Ä¢ opening_id: {opening_id}\")\n",
    "print(f\"   ‚Ä¢ confidence: {sample['confidence']:.4f}\")\n",
    "\n",
    "print(f\"\\n   Player side info lookup:\")\n",
    "player_info = player_side_info.loc[player_id]\n",
    "print(f\"   ‚Ä¢ rating_z: {player_info['rating_z']:.4f}\")\n",
    "\n",
    "print(f\"\\n   Opening side info lookup:\")\n",
    "opening_info = opening_side_info.loc[opening_id]\n",
    "print(f\"   ‚Ä¢ eco_letter_cat: {opening_info['eco_letter_cat']} (letter: {eco_int_to_letter[opening_info['eco_letter_cat']]})\")\n",
    "print(f\"   ‚Ä¢ eco_number_cat: {opening_info['eco_number_cat']} (number: {eco_int_to_number[opening_info['eco_number_cat']]})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ VERIFICATION COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüì¶ Ready for PyTorch tensor conversion:\")\n",
    "print(f\"   ‚Ä¢ Features: player_id, opening_id, confidence\")\n",
    "print(f\"   ‚Ä¢ Target: score (in y_train, y_val, y_test)\")\n",
    "print(f\"   ‚Ä¢ Player side info: rating_z\")\n",
    "print(f\"   ‚Ä¢ Opening side info: eco_letter_cat, eco_number_cat\")\n",
    "print(f\"\\n   All ECO and rating data is now properly separated as side information!\")\n",
    "print(f\"\\n   Side info tables are clean - only contain necessary model inputs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017515d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification: Sample 100 player-opening pairs with reconstructed ECO codes and opening names\n",
    "# Doing this to make sure that our ECO encoding/decoding is correct\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"VERIFICATION: ECO RECONSTRUCTION AND OPENING NAMES\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Sample 100 random player-opening pairs from training data\n",
    "sample_size = 100\n",
    "sample_data = X_train.sample(min(sample_size, len(X_train)), random_state=42)\n",
    "\n",
    "print(f\"\\nSampling {len(sample_data)} player-opening pairs for verification...\\n\")\n",
    "\n",
    "# Get unique opening IDs from sample\n",
    "opening_ids = sample_data['opening_id'].unique()\n",
    "opening_ids_str = ','.join(map(str, opening_ids.astype(int)))\n",
    "\n",
    "# Query database for opening names\n",
    "con = get_db_connection(str(DB_PATH))\n",
    "try:\n",
    "    opening_query = f\"\"\"\n",
    "        SELECT id, name, eco\n",
    "        FROM opening\n",
    "        WHERE id IN ({opening_ids_str})\n",
    "    \"\"\"\n",
    "    opening_names = pd.DataFrame(con.execute(opening_query).df()).set_index('id')\n",
    "finally:\n",
    "    con.close()\n",
    "\n",
    "# Create reverse mappings for ECO decoding\n",
    "eco_int_to_letter = {v: k for k, v in eco_letter_map.items()}\n",
    "eco_int_to_number = {v: k for k, v in eco_number_map.items()}\n",
    "\n",
    "# Build verification table\n",
    "print(f\"{'#':<4} {'Player':<8} {'Opening':<9} {'ECO (DB)':<10} {'Reconstructed':<13} {'Match':<6} {'Opening Name':<50}\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "matches = 0\n",
    "for i, (idx, row) in enumerate(sample_data.iterrows(), 1):\n",
    "    player_id = int(row['player_id'])\n",
    "    opening_id = int(row['opening_id'])\n",
    "    \n",
    "    # Lookup opening side info\n",
    "    opening_info = opening_side_info.loc[opening_id]\n",
    "    \n",
    "    # Reconstruct ECO from encoded categorical values\n",
    "    eco_letter_encoded = opening_info['eco_letter_cat']\n",
    "    eco_number_encoded = opening_info['eco_number_cat']\n",
    "    \n",
    "    eco_letter_decoded = eco_int_to_letter[eco_letter_encoded]\n",
    "    eco_number_decoded = eco_int_to_number[eco_number_encoded]\n",
    "    \n",
    "    reconstructed_eco = f\"{eco_letter_decoded}{eco_number_decoded}\"\n",
    "    \n",
    "    # Get original ECO from database\n",
    "    db_eco = opening_names.loc[opening_id, 'eco']\n",
    "    opening_name = opening_names.loc[opening_id, 'name']\n",
    "    \n",
    "    # Check if they match\n",
    "    match = \"‚úì\" if reconstructed_eco == db_eco else \"‚úó\"\n",
    "    if reconstructed_eco == db_eco:\n",
    "        matches += 1\n",
    "    \n",
    "    # Truncate opening name if too long\n",
    "    if len(opening_name) > 48:\n",
    "        opening_name = opening_name[:45] + \"...\"\n",
    "    \n",
    "    print(f\"{i:<4} {player_id:<8} {opening_id:<9} {db_eco:<10} {reconstructed_eco:<13} {match:<6} {opening_name:<50}\")\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(f\"\\n‚úÖ Verification Results:\")\n",
    "print(f\"   ‚Ä¢ Total samples: {len(sample_data)}\")\n",
    "print(f\"   ‚Ä¢ Matches: {matches}/{len(sample_data)} ({100*matches/len(sample_data):.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Mismatches: {len(sample_data) - matches}\")\n",
    "\n",
    "if matches == len(sample_data):\n",
    "    print(f\"\\nüéâ Perfect! All ECO codes reconstructed correctly!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Warning: Some ECO codes did not match. Investigate mismatches above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcf4878",
   "metadata": {},
   "source": [
    "## 5. Data Verification and Examination\n",
    "We're almost there. Let's examine our data structures to check for any obvious flaws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f76afbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"X_train \\n\", X_train.head())\n",
    "print(\"=\"*60)\n",
    "print(\"X_val \\n\", X_val.head())\n",
    "print(\"=\" * 60)\n",
    "print(\"X_test \\n\", X_test.head())\n",
    "print(\"=\" * 60)\n",
    "print(\"y_train \\n\", y_train.head())\n",
    "print(\"=\" * 60)\n",
    "print(\"y_val \\n\", y_val.head())\n",
    "print(\"=\" * 60) \n",
    "print(\"y_test \\n\", y_test.head())\n",
    "\n",
    "# Now side information\n",
    "print(\"player_side_info \\n\", player_side_info.head())\n",
    "print(\"=\" * 60)\n",
    "print(\"opening_side_info \\n\", opening_side_info.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f00d8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52936cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final verification: Display cleaned side info tables\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CLEANED SIDE INFORMATION TABLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä player_side_info (cleaned):\")\n",
    "print(f\"   ‚Ä¢ Shape: {player_side_info.shape}\")\n",
    "print(f\"   ‚Ä¢ Columns: {list(player_side_info.columns)}\")\n",
    "print(f\"   ‚Ä¢ Index: player_id\")\n",
    "print(f\"\\n   Sample (5 rows):\")\n",
    "print(player_side_info.head().to_string())\n",
    "\n",
    "print(f\"\\nüìä opening_side_info (cleaned):\")\n",
    "print(f\"   ‚Ä¢ Shape: {opening_side_info.shape}\")\n",
    "print(f\"   ‚Ä¢ Columns: {list(opening_side_info.columns)}\")\n",
    "print(f\"   ‚Ä¢ Index: opening_id\")\n",
    "print(f\"\\n   Sample (5 rows):\")\n",
    "print(opening_side_info.head().to_string())\n",
    "\n",
    "print(f\"\\n‚úÖ Both side info tables contain ONLY the necessary model inputs:\")\n",
    "print(f\"   ‚Ä¢ player_side_info: rating_z (normalized rating)\")\n",
    "print(f\"   ‚Ä¢ opening_side_info: eco_letter_cat, eco_number_cat (categorical encodings)\")\n",
    "print(f\"   ‚Ä¢ No unnecessary columns (names, titles, raw strings, etc.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19883cba",
   "metadata": {},
   "source": [
    "## Step 5: Convert to PyTorch Tensors\n",
    "\n",
    "**What are tensors?**\n",
    "Tensors are PyTorch's version of arrays - just multi-dimensional data structures optimized for deep learning. Think of them like fancy NumPy arrays that can run on GPUs.\n",
    "\n",
    "**What we need to convert:**\n",
    "\n",
    "1. **Main features** (X_train, X_val, X_test):\n",
    "   - `player_id` ‚Üí long tensor (integer IDs)\n",
    "   - `opening_id` ‚Üí long tensor (integer IDs)\n",
    "   - `confidence` ‚Üí float tensor (weights for loss function)\n",
    "\n",
    "2. **Targets** (y_train, y_val, y_test):\n",
    "   - `score` ‚Üí float tensor (what we're predicting)\n",
    "\n",
    "3. **Player side info** (player_side_info):\n",
    "   - `rating_z` ‚Üí float tensor (normalized ratings)\n",
    "   - Indexed by player_id for fast lookup\n",
    "\n",
    "4. **Opening side info** (opening_side_info):\n",
    "   - `eco_letter_cat` ‚Üí long tensor (categorical)\n",
    "   - `eco_number_cat` ‚Üí long tensor (categorical)\n",
    "   - Indexed by opening_id for fast lookup\n",
    "\n",
    "**Why these data types?**\n",
    "- `long` (int64): For IDs and categorical features that will be embedded\n",
    "- `float` (float32): For continuous values like scores, confidence, and normalized ratings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350be514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch (if not already installed)\n",
    "import sys\n",
    "import subprocess\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda01b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Convert all data to PyTorch tensors\n",
    "\n",
    "import torch\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 5: CONVERT TO PYTORCH TENSORS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è  Configuration:\")\n",
    "print(f\"   ‚Ä¢ PyTorch version: {torch.__version__}\")\n",
    "print(f\"   ‚Ä¢ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   ‚Ä¢ CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"   ‚Ä¢ Default dtype: float32 for continuous, int64 for IDs/categorical\")\n",
    "\n",
    "# 0. Index alignment sanity checks\n",
    "print(f\"\\n0Ô∏è‚É£  Index alignment sanity checks...\")\n",
    "\n",
    "# Check player_side_info is properly indexed\n",
    "print(f\"   Checking player_side_info index alignment...\")\n",
    "player_ids_sorted = sorted(player_side_info.index.values)\n",
    "if player_ids_sorted != list(player_side_info.index.values):\n",
    "    print(f\"   ‚ö†Ô∏è  player_side_info index is not sorted - this is OK, we'll use index values directly\")\n",
    "else:\n",
    "    print(f\"   ‚úì player_side_info index is sorted\")\n",
    "print(f\"   ‚Ä¢ Index range: [{player_side_info.index.min()}, {player_side_info.index.max()}]\")\n",
    "print(f\"   ‚Ä¢ Index dtype: {player_side_info.index.dtype}\")\n",
    "\n",
    "# Check opening_side_info is properly indexed\n",
    "print(f\"\\n   Checking opening_side_info index alignment...\")\n",
    "opening_ids_sorted = sorted(opening_side_info.index.values)\n",
    "if opening_ids_sorted != list(opening_side_info.index.values):\n",
    "    print(f\"   ‚ö†Ô∏è  opening_side_info index is not sorted - this is OK, we'll use index values directly\")\n",
    "else:\n",
    "    print(f\"   ‚úì opening_side_info index is sorted\")\n",
    "print(f\"   ‚Ä¢ Index range: [{opening_side_info.index.min()}, {opening_side_info.index.max()}]\")\n",
    "print(f\"   ‚Ä¢ Index dtype: {opening_side_info.index.dtype}\")\n",
    "\n",
    "# CRITICAL: Check if indices are contiguous 0-based\n",
    "# If opening_side_info.index = [0, 1, 2, ..., N-1], then we can use opening_id as direct array index\n",
    "# If not (e.g., [10, 15, 23, ...]), we'll need a mapping dictionary\n",
    "print(f\"\\n   Checking if indices are contiguous 0-based...\")\n",
    "player_contiguous = (player_side_info.index == range(len(player_side_info))).all()\n",
    "opening_contiguous = (opening_side_info.index == range(len(opening_side_info))).all()\n",
    "\n",
    "print(f\"   ‚Ä¢ player_side_info contiguous 0-based: {player_contiguous}\")\n",
    "print(f\"   ‚Ä¢ opening_side_info contiguous 0-based: {opening_contiguous}\")\n",
    "\n",
    "if not player_contiguous:\n",
    "    print(f\"   ‚ÑπÔ∏è  Player IDs are NOT 0-based contiguous - will need mapping for embedding lookup\")\n",
    "if not opening_contiguous:\n",
    "    print(f\"   ‚ÑπÔ∏è  Opening IDs are NOT 0-based contiguous - will need mapping for embedding lookup\")\n",
    "\n",
    "# 1. Convert main features (train/val/test)\n",
    "print(f\"\\n1Ô∏è‚É£  Converting main features (X_train, X_val, X_test)...\")\n",
    "\n",
    "# Train set\n",
    "player_ids_train = torch.tensor(X_train['player_id'].values, dtype=torch.long)\n",
    "opening_ids_train = torch.tensor(X_train['opening_id'].values, dtype=torch.long)\n",
    "confidence_train = torch.tensor(X_train['confidence'].values, dtype=torch.float32)\n",
    "\n",
    "print(f\"   Train tensors:\")\n",
    "print(f\"   ‚Ä¢ player_ids_train: {player_ids_train.shape}, dtype={player_ids_train.dtype}\")\n",
    "print(f\"   ‚Ä¢ opening_ids_train: {opening_ids_train.shape}, dtype={opening_ids_train.dtype}\")\n",
    "print(f\"   ‚Ä¢ confidence_train: {confidence_train.shape}, dtype={confidence_train.dtype}\")\n",
    "\n",
    "# Validation set\n",
    "player_ids_val = torch.tensor(X_val['player_id'].values, dtype=torch.long)\n",
    "opening_ids_val = torch.tensor(X_val['opening_id'].values, dtype=torch.long)\n",
    "confidence_val = torch.tensor(X_val['confidence'].values, dtype=torch.float32)\n",
    "\n",
    "print(f\"\\n   Validation tensors:\")\n",
    "print(f\"   ‚Ä¢ player_ids_val: {player_ids_val.shape}, dtype={player_ids_val.dtype}\")\n",
    "print(f\"   ‚Ä¢ opening_ids_val: {opening_ids_val.shape}, dtype={opening_ids_val.dtype}\")\n",
    "print(f\"   ‚Ä¢ confidence_val: {confidence_val.shape}, dtype={confidence_val.dtype}\")\n",
    "\n",
    "# Test set\n",
    "player_ids_test = torch.tensor(X_test['player_id'].values, dtype=torch.long)\n",
    "opening_ids_test = torch.tensor(X_test['opening_id'].values, dtype=torch.long)\n",
    "confidence_test = torch.tensor(X_test['confidence'].values, dtype=torch.float32)\n",
    "\n",
    "print(f\"\\n   Test tensors:\")\n",
    "print(f\"   ‚Ä¢ player_ids_test: {player_ids_test.shape}, dtype={player_ids_test.dtype}\")\n",
    "print(f\"   ‚Ä¢ opening_ids_test: {opening_ids_test.shape}, dtype={opening_ids_test.dtype}\")\n",
    "print(f\"   ‚Ä¢ confidence_test: {confidence_test.shape}, dtype={confidence_test.dtype}\")\n",
    "\n",
    "# 2. Convert targets (scores)\n",
    "print(f\"\\n2Ô∏è‚É£  Converting target scores (y_train, y_val, y_test)...\")\n",
    "\n",
    "scores_train = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "scores_val = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "scores_test = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "print(f\"   ‚Ä¢ scores_train: {scores_train.shape}, dtype={scores_train.dtype}\")\n",
    "print(f\"   ‚Ä¢ scores_val: {scores_val.shape}, dtype={scores_val.dtype}\")\n",
    "print(f\"   ‚Ä¢ scores_test: {scores_test.shape}, dtype={scores_test.dtype}\")\n",
    "\n",
    "print(f\"\\n   Score ranges (sanity check):\")\n",
    "print(f\"   ‚Ä¢ Train: [{scores_train.min():.4f}, {scores_train.max():.4f}]\")\n",
    "print(f\"   ‚Ä¢ Val: [{scores_val.min():.4f}, {scores_val.max():.4f}]\")\n",
    "print(f\"   ‚Ä¢ Test: [{scores_test.min():.4f}, {scores_test.max():.4f}]\")\n",
    "\n",
    "# 3. Convert player side information\n",
    "print(f\"\\n3Ô∏è‚É£  Converting player side information...\")\n",
    "\n",
    "# Create tensor of all player ratings (indexed by player_id)\n",
    "# Since player_side_info is indexed by player_id, we need to ensure coverage\n",
    "player_ratings_tensor = torch.tensor(player_side_info['rating_z'].values, dtype=torch.float32)\n",
    "player_ids_in_side_info = torch.tensor(player_side_info.index.values, dtype=torch.long)\n",
    "\n",
    "print(f\"   ‚Ä¢ player_ratings_tensor: {player_ratings_tensor.shape}, dtype={player_ratings_tensor.dtype}\")\n",
    "print(f\"   ‚Ä¢ player_ids_in_side_info: {player_ids_in_side_info.shape}, dtype={player_ids_in_side_info.dtype}\")\n",
    "print(f\"   ‚Ä¢ Rating range: [{player_ratings_tensor.min():.4f}, {player_ratings_tensor.max():.4f}]\")\n",
    "\n",
    "# Verify all player IDs in train/val/test are covered\n",
    "all_player_ids = torch.cat([player_ids_train, player_ids_val, player_ids_test]).unique()\n",
    "missing_players = set(all_player_ids.tolist()) - set(player_ids_in_side_info.tolist())\n",
    "if len(missing_players) > 0:\n",
    "    print(f\"   ‚ö†Ô∏è  WARNING: {len(missing_players)} players in splits missing from side_info!\")\n",
    "else:\n",
    "    print(f\"   ‚úì All {len(all_player_ids)} unique players in splits have side information\")\n",
    "\n",
    "# 4. Convert opening side information\n",
    "print(f\"\\n4Ô∏è‚É£  Converting opening side information...\")\n",
    "\n",
    "# Verify column names exist (using eco_letter_cat and eco_number_cat consistently)\n",
    "if 'eco_letter_cat' not in opening_side_info.columns:\n",
    "    raise ValueError(f\"Column 'eco_letter_cat' not found. Available: {opening_side_info.columns.tolist()}\")\n",
    "if 'eco_number_cat' not in opening_side_info.columns:\n",
    "    raise ValueError(f\"Column 'eco_number_cat' not found. Available: {opening_side_info.columns.tolist()}\")\n",
    "\n",
    "# Create tensors for opening ECO features (indexed by opening_id)\n",
    "opening_eco_letter_tensor = torch.tensor(opening_side_info['eco_letter_cat'].values, dtype=torch.long)\n",
    "opening_eco_number_tensor = torch.tensor(opening_side_info['eco_number_cat'].values, dtype=torch.long)\n",
    "opening_ids_in_side_info = torch.tensor(opening_side_info.index.values, dtype=torch.long)\n",
    "\n",
    "print(f\"   ‚Ä¢ opening_eco_letter_tensor: {opening_eco_letter_tensor.shape}, dtype={opening_eco_letter_tensor.dtype}\")\n",
    "print(f\"   ‚Ä¢ opening_eco_number_tensor: {opening_eco_number_tensor.shape}, dtype={opening_eco_number_tensor.dtype}\")\n",
    "print(f\"   ‚Ä¢ opening_ids_in_side_info: {opening_ids_in_side_info.shape}, dtype={opening_ids_in_side_info.dtype}\")\n",
    "print(f\"   ‚Ä¢ ECO letter range: [{opening_eco_letter_tensor.min()}, {opening_eco_letter_tensor.max()}]\")\n",
    "print(f\"   ‚Ä¢ ECO number range: [{opening_eco_number_tensor.min()}, {opening_eco_number_tensor.max()}]\")\n",
    "\n",
    "# Verify all opening IDs in train/val/test are covered\n",
    "all_opening_ids = torch.cat([opening_ids_train, opening_ids_val, opening_ids_test]).unique()\n",
    "missing_openings = set(all_opening_ids.tolist()) - set(opening_ids_in_side_info.tolist())\n",
    "if len(missing_openings) > 0:\n",
    "    print(f\"   ‚ö†Ô∏è  WARNING: {len(missing_openings)} openings in splits missing from side_info!\")\n",
    "else:\n",
    "    print(f\"   ‚úì All {len(all_opening_ids)} unique openings in splits have side information\")\n",
    "\n",
    "# 5. Summary statistics\n",
    "print(f\"\\n5Ô∏è‚É£  Summary statistics:\")\n",
    "print(f\"\\n   Dataset sizes:\")\n",
    "print(f\"   ‚Ä¢ Train: {len(scores_train):,} samples\")\n",
    "print(f\"   ‚Ä¢ Val: {len(scores_val):,} samples\")\n",
    "print(f\"   ‚Ä¢ Test: {len(scores_test):,} samples\")\n",
    "\n",
    "print(f\"\\n   Unique entities:\")\n",
    "print(f\"   ‚Ä¢ Players: {len(player_ids_in_side_info):,}\")\n",
    "print(f\"   ‚Ä¢ Openings: {len(opening_ids_in_side_info):,}\")\n",
    "\n",
    "print(f\"\\n   Vocabulary sizes (for embedding layers):\")\n",
    "print(f\"   ‚Ä¢ num_players: {player_ids_in_side_info.max() + 1} (max player_id + 1)\")\n",
    "print(f\"   ‚Ä¢ num_openings: {opening_ids_in_side_info.max() + 1} (max opening_id + 1)\")\n",
    "print(f\"   ‚Ä¢ num_eco_letters: {opening_eco_letter_tensor.max() + 1} (max eco_letter_cat + 1)\")\n",
    "print(f\"   ‚Ä¢ num_eco_numbers: {opening_eco_number_tensor.max() + 1} (max eco_number_cat + 1)\")\n",
    "\n",
    "# 6. Memory usage (approximate - using simple calculation)\n",
    "print(f\"\\n6Ô∏è‚É£  Approximate memory usage:\")\n",
    "# More efficient calculation: element_size * nelement for each tensor\n",
    "# Using list comprehension with helper function for cleaner code\n",
    "def tensor_memory_mb(t):\n",
    "    \"\"\"Calculate tensor memory in MB\"\"\"\n",
    "    return (t.element_size() * t.nelement()) / (1024 * 1024)\n",
    "\n",
    "tensors = [\n",
    "    player_ids_train, opening_ids_train, confidence_train, scores_train,\n",
    "    player_ids_val, opening_ids_val, confidence_val, scores_val,\n",
    "    player_ids_test, opening_ids_test, confidence_test, scores_test,\n",
    "    player_ratings_tensor, opening_eco_letter_tensor, opening_eco_number_tensor\n",
    "]\n",
    "total_memory_mb = sum(tensor_memory_mb(t) for t in tensors)\n",
    "print(f\"   ‚Ä¢ Total tensor memory: {total_memory_mb:.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ TENSOR CONVERSION COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüì¶ Available tensors for training:\")\n",
    "print(f\"\\n   Main features (train/val/test):\")\n",
    "print(f\"   ‚Ä¢ player_ids_train, player_ids_val, player_ids_test\")\n",
    "print(f\"   ‚Ä¢ opening_ids_train, opening_ids_val, opening_ids_test\")\n",
    "print(f\"   ‚Ä¢ confidence_train, confidence_val, confidence_test\")\n",
    "\n",
    "print(f\"\\n   Targets (train/val/test):\")\n",
    "print(f\"   ‚Ä¢ scores_train, scores_val, scores_test\")\n",
    "\n",
    "print(f\"\\n   Side information:\")\n",
    "print(f\"   ‚Ä¢ player_ratings_tensor (indexed by player_ids_in_side_info)\")\n",
    "print(f\"   ‚Ä¢ opening_eco_letter_tensor (indexed by opening_ids_in_side_info)\")\n",
    "print(f\"   ‚Ä¢ opening_eco_number_tensor (indexed by opening_ids_in_side_info)\")\n",
    "\n",
    "print(f\"\\nüí° Ready for model training!\")\n",
    "print(f\"   These tensors can be directly fed into PyTorch DataLoaders and models.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
