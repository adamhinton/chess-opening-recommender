{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40e163a7",
   "metadata": {},
   "source": [
    "# Notebook 26 ‚Äî Opening Recommender Model: Training Pipeline\n",
    "\n",
    "### 0. Overview and Goals\n",
    "\n",
    "This notebook defines the full pipeline for training the chess opening recommender model.  \n",
    "The objective is to predict **player‚Äìopening performance scores** ((wins + (0.5 * draws) / num games)) for openings a player hasn‚Äôt yet played, based on their results in the openings they *have* played.  \n",
    "\n",
    "The model will use **matrix factorization** with **stochastic gradient descent (SGD)** to learn latent factors representing player and opening characteristics.  \n",
    "All computations will be implemented in **PyTorch**, with data loaded from my local **DuckDB** database.\n",
    "\n",
    "**High-level specs:**\n",
    "- Use only *White* openings initially (we‚Äôll extend to Black later).  \n",
    "- Data source: processed player‚Äìopening stats from local DuckDB.  \n",
    "- Predict: normalized ‚Äúscore‚Äù = win rate ((wins + 0.5 x draws) / total games).  \n",
    "- Filter: only include entries with ‚â• `MIN_GAMES_THRESHOLD` (default = 50).  \n",
    "- Ignore: rating differences, time controls, and other metadata.  \n",
    "- Model parameters (to be defined in appropriate places for easy editing):  \n",
    "  - `NUM_FACTORS`, `LEARNING_RATE`, `BATCH_SIZE`, `N_EPOCHS`, `NUM_PLAYERS_TO_PROCESS`  \n",
    "- Logging and checkpoints throughout for reproducibility.  \n",
    "- All random operations seeded for deterministic runs.  \n",
    "\n",
    "---\n",
    "\n",
    "### 1. Data Extraction\n",
    "- Connect to local DuckDB\n",
    "- Pull all processed player‚Äìopening statistics from\n",
    "- Verify schema consistency:  \n",
    "  - Required columns: `player_id`, `opening_id`, `eco`, `num_games`, `wins`, `draws`, `losses`.  \n",
    "- Include a row-count sanity check.\n",
    "- Only players with ratings above 1200\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Data Sanitization & Normalization\n",
    "- Optionally normalize scores if needed for MF convergence.  \n",
    "- Drop players with no qualifying openings and openings with no qualifying players.  \n",
    "  - I believe there shouldn't be any but we'll double check.\n",
    "- Resequence player_id and opening_id to be sequential integers - right now there are gaps because of entries we deleted from the DB \n",
    "- Check for sparsity consistency (no implicit zeros yet).  \n",
    "- Note that this data has already been split in to white and black games further up the pipeline\n",
    "\n",
    "### Data Quality\n",
    "- Drop entries with fewer than `MIN_GAMES_THRESHOLD` games\n",
    "- Handle any duplicate `(player_id, opening_id)` combinations\n",
    "- Remove players with no qualifying openings\n",
    "- Remove openings with no qualifying players\n",
    "- Verify no null values remain\n",
    "\n",
    "### ECO Codes\n",
    "- Keep ECO codes for later categorical encoding (Step 4)\n",
    "- ECO will be used as opening side information (similar to rating for players)\n",
    "\n",
    "### Confidence Weighting\n",
    "- Use `MIN_GAMES_THRESHOLD = 10` to keep more data\n",
    "- Add a **confidence weight** column: `confidence = num_games / (num_games + K)` where K ‚âà 50\n",
    "- This weight will be used in the loss function to down-weight uncertain predictions\n",
    "- High-game-count entries ‚Üí high confidence ‚Üí larger loss impact\n",
    "- Low-game-count entries ‚Üí low confidence ‚Üí smaller loss impact\n",
    "\n",
    "### Player Rating (Side Information)\n",
    "- **Player ratings are side information** - they describe player characteristics, not individual player-opening interactions\n",
    "- Ratings will be stored separately and joined to player embeddings during training\n",
    "- We'll **normalize ratings** (likely z-score normalization) to avoid scaling issues with the embedding layer\n",
    "- Rating normalization will be done once after extraction, not per-row\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Data Splits\n",
    "- Split into train/test/val sets.  \n",
    "- Ensure every player and every opening appears at least once in the training data.  \n",
    "- Strategy:  \n",
    "  - Sample unique players and openings to guarantee coverage in train.  \n",
    "  - Remaining data ‚Üí stratified random split into train/test.  \n",
    "  - Deduplicate and merge unique IDs back into train if needed.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Enumerate Categorical Variables\n",
    "- Enumerate `eco` (if included) as an integer categorical variable.  \n",
    "- Confirm all columns are numeric and compatible with PyTorch tensors.  \n",
    "- Verify no missing or out-of-range IDs.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Training Data Structure\n",
    "- Each row: one `(player_id, opening_id, score)` record.\n",
    "- Include other fields- eco, num games etc\n",
    "- Convert DataFrame to PyTorch tensors (`torch.long` for IDs, `torch.float` for scores).  \n",
    "- Log dataset shapes and sparsity metrics.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Training Setup\n",
    "Define constants:\n",
    "- `LEARNING_RATE`, `BATCH_SIZE`, `N_EPOCHS`, `NUM_FACTORS`  \n",
    "- Loss functions: MSE and RMSE  \n",
    "- Activation: sigmoid or none (depending on score normalization)  \n",
    "- Optimizer: SGD  \n",
    "- Figure out if there's anything else we need to design or specify\n",
    "\n",
    "Implement helper functions:\n",
    "- `train_one_epoch()`\n",
    "- `evaluate_model()`\n",
    "- `calculate_rmse()`\n",
    "- `save_checkpoint()`  \n",
    "\n",
    "Ensure detailed logging, ETA reporting, and reproducible random seeds.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Training Loop\n",
    "- Initialize player and opening embeddings.  \n",
    "- Iterate through epochs with mini-batch SGD (`BATCH_SIZE = 1024`).  \n",
    "- Compute and log MSE/RMSE per epoch.  \n",
    "- Save model checkpoints locally after each epoch.\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Evaluation\n",
    "- Evaluate on test set.  \n",
    "- Report MSE, RMSE, and visual diagnostics (predicted vs actual score).  \n",
    "- Inspect a few player and opening latent factors for sanity.\n",
    "\n",
    "---\n",
    "\n",
    "### 9. Cross-Validation & Hyperparameter Tuning\n",
    "- Define ranges for:  \n",
    "  - `NUM_FACTORS`, `LEARNING_RATE`, `BATCH_SIZE`, `N_EPOCHS`  \n",
    "- Perform small-scale grid or random search for best configuration.  \n",
    "- Compare validation RMSE across runs.\n",
    "\n",
    "---\n",
    "\n",
    "### 10. Next Steps\n",
    "- Extend model to include Black openings.  \n",
    "- Experiment with hybrid inputs (player rating, ECO grouping).  \n",
    "- Consider implicit feedback handling (unplayed openings as zeros).  \n",
    "- Integrate trained model into API for recommendation output.\n",
    "\n",
    "---\n",
    "\n",
    "**Notes:**  \n",
    "- Every random seed and parameter definition will be explicit.  \n",
    "- Every major step includes row-count, schema, and type validation.  \n",
    "- Model artifacts and logs will be saved locally for reproducibility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc6d823",
   "metadata": {},
   "source": [
    "## Step 1: Data Extraction\n",
    "\n",
    "Connect to DuckDB and extract all player-opening statistics.\n",
    "Verify schema and perform sanity checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fcea569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 1: DATA EXTRACTION\n",
      "============================================================\n",
      "\n",
      "üìÅ Database: /Users/a/Documents/personalprojects/chess-opening-recommender/data/processed/chess_games.db\n",
      "üìÅ Database exists: True\n",
      "üé® Color filter: White\n",
      "üîí Minimum holdout players: 1,000\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# Add utils to path\n",
    "sys.path.append(str(Path.cwd() / 'utils'))\n",
    "from database.db_utils import get_db_connection\n",
    "\n",
    "# Configuration\n",
    "DB_PATH = Path.cwd().parent / \"data\" / \"processed\" / \"chess_games.db\"\n",
    "COLOR_FILTER = 'w'  # 'w' for white, 'b' for black\n",
    "MIN_HOLDOUT_PLAYERS = 1000  # Minimum number of players to reserve for fold-in verification. These will not be used at all in this notebook for training, test/val or anything else.\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 1: DATA EXTRACTION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüìÅ Database: {DB_PATH}\")\n",
    "print(f\"üìÅ Database exists: {DB_PATH.exists()}\")\n",
    "print(f\"üé® Color filter: {'White' if COLOR_FILTER == 'w' else 'Black'}\")\n",
    "print(f\"üîí Minimum holdout players: {MIN_HOLDOUT_PLAYERS:,}\")\n",
    "\n",
    "if not DB_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Database not found at {DB_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9435033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1Ô∏è‚É£  Extracting player-opening statistics (color: 'w')...\n",
      "   ‚Ä¢ Minimum rating filter: 1200\n",
      "\n",
      "2Ô∏è‚É£  Selecting holdout players for fold-in verification...\n",
      "   ‚Ä¢ Holdout size: 1,000 players minimum\n",
      "   ‚Ä¢ Total eligible players: 49,551\n",
      "   ‚Ä¢ Holdout players selected: 1,000\n",
      "   ‚Ä¢ Training players available: 48,551\n",
      "   ‚Ä¢ Holdout percentage: 2.0%\n",
      "\n",
      "3Ô∏è‚É£  Extracting training data (excluding holdout players)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec37c0b1b30b4ccf90b50d7f73939efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Extracted 11,567,190 rows\n",
      "\n",
      "   üíæ Saved holdout_players_df with 1,000 player IDs\n",
      "   ‚Ä¢ These players are COMPLETELY UNSEEN by the training process\n",
      "   ‚Ä¢ Use them later for fold-in verification\n",
      "\n",
      "4Ô∏è‚É£  Verifying schema...\n",
      "   ‚úì All required columns present: ['player_id', 'opening_id', 'num_games', 'score', 'eco']\n",
      "\n",
      "5Ô∏è‚É£  Checking data types...\n",
      "   ‚Ä¢ player_id: int32\n",
      "   ‚Ä¢ opening_id: int32\n",
      "   ‚Ä¢ num_games: int32\n",
      "   ‚Ä¢ score: float64\n",
      "   ‚Ä¢ eco: object\n",
      "\n",
      "6Ô∏è‚É£  Data statistics...\n",
      "   ‚Ä¢ Total rows: 11,567,190\n",
      "   ‚Ä¢ Unique players: 48,551\n",
      "   ‚Ä¢ Unique openings: 2,991\n",
      "   ‚Ä¢ Total games (sum): 228,827,356\n",
      "\n",
      "   Player ID range:\n",
      "   ‚Ä¢ Min: 1\n",
      "   ‚Ä¢ Max: 50000\n",
      "\n",
      "   Opening ID range:\n",
      "   ‚Ä¢ Min: 2\n",
      "   ‚Ä¢ Max: 3589\n",
      "\n",
      "   Games per entry:\n",
      "   ‚Ä¢ Min: 1\n",
      "   ‚Ä¢ Max: 13462\n",
      "   ‚Ä¢ Mean: 19.8\n",
      "   ‚Ä¢ Median: 3\n",
      "\n",
      "   Score distribution:\n",
      "   ‚Ä¢ Min: 0.0000\n",
      "   ‚Ä¢ Max: 1.0000\n",
      "   ‚Ä¢ Mean: 0.5007\n",
      "   ‚Ä¢ Median: 0.5000\n",
      "\n",
      "7Ô∏è‚É£  Checking for null values...\n",
      "   ‚úì No null values found\n",
      "\n",
      "8Ô∏è‚É£  Sample of extracted data (first 10 rows):\n",
      "   player_id  opening_id  num_games     score  eco\n",
      "0          1          39          6  0.666667  A00\n",
      "1          1          49          2  0.500000  A00\n",
      "2          1          53          1  0.000000  A00\n",
      "3          1         182          1  0.000000  A04\n",
      "4          1         187          1  1.000000  A04\n",
      "5          1         671          3  1.000000  B00\n",
      "6          1         675          3  0.000000  B00\n",
      "7          1         677          6  0.333333  B00\n",
      "8          1         688         25  0.620000  B00\n",
      "9          1         717          1  1.000000  B00\n",
      "\n",
      "============================================================\n",
      "‚úÖ DATA EXTRACTION COMPLETE\n",
      "============================================================\n",
      "\n",
      "Data shape: (11567190, 5)\n",
      "Columns: ['player_id', 'opening_id', 'num_games', 'score', 'eco']\n",
      "\n",
      "‚ö†Ô∏è  IMPORTANT: 1,000 players held out for fold-in verification\n",
      "   ‚Ä¢ Access via: holdout_players_df\n",
      "   ‚Ä¢ These players will NOT appear in any training, validation, or test splits\n",
      "\n",
      "‚úì Database connection closed\n"
     ]
    }
   ],
   "source": [
    "# Connect to DuckDB and extract player-opening statistics\n",
    "con = get_db_connection(str(DB_PATH))\n",
    "MAX_PLAYERS = 50_000 # for testing, will increase later\n",
    "\n",
    "try:\n",
    "    print(f\"\\n1Ô∏è‚É£  Extracting player-opening statistics (color: '{COLOR_FILTER}')...\")\n",
    "    \n",
    "    # Extract stats with calculated score and num_games\n",
    "    # Filter by color, minimum rating, and calculate score in the database\n",
    "    MIN_RATING = 1200\n",
    "    print(f\"   ‚Ä¢ Minimum rating filter: {MIN_RATING}\")\n",
    "    \n",
    "    # First, get all eligible players and randomly select holdout set\n",
    "    print(f\"\\n2Ô∏è‚É£  Selecting holdout players for fold-in verification...\")\n",
    "    print(f\"   ‚Ä¢ Holdout size: {MIN_HOLDOUT_PLAYERS:,} players minimum\")\n",
    "    \n",
    "    # Get all players with sufficient data\n",
    "    player_query = f\"\"\"\n",
    "        SELECT DISTINCT p.id as player_id\n",
    "        FROM player p\n",
    "        JOIN player_opening_stats pos ON p.id = pos.player_id\n",
    "        WHERE p.rating >= {MIN_RATING}\n",
    "        AND pos.color = '{COLOR_FILTER}'\n",
    "        LIMIT {MAX_PLAYERS}\n",
    "    \"\"\"\n",
    "    \n",
    "    all_eligible_players = pd.DataFrame(con.execute(player_query).df())\n",
    "    total_eligible = len(all_eligible_players)\n",
    "    print(f\"   ‚Ä¢ Total eligible players: {total_eligible:,}\")\n",
    "    \n",
    "    if total_eligible < MIN_HOLDOUT_PLAYERS:\n",
    "        raise ValueError(f\"Not enough eligible players ({total_eligible:,}) to create holdout set of {MIN_HOLDOUT_PLAYERS:,}\")\n",
    "    \n",
    "    # Randomly sample holdout players (deterministic with seed)\n",
    "    import numpy as np\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    \n",
    "    holdout_player_ids = np.random.choice(\n",
    "        all_eligible_players['player_id'].values,\n",
    "        size=MIN_HOLDOUT_PLAYERS,\n",
    "        replace=False\n",
    "    )\n",
    "    \n",
    "    training_player_ids = set(all_eligible_players['player_id'].values) - set(holdout_player_ids)\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Holdout players selected: {len(holdout_player_ids):,}\")\n",
    "    print(f\"   ‚Ä¢ Training players available: {len(training_player_ids):,}\")\n",
    "    print(f\"   ‚Ä¢ Holdout percentage: {100 * len(holdout_player_ids) / total_eligible:.1f}%\")\n",
    "    \n",
    "    # Convert training player IDs to SQL-friendly string\n",
    "    training_player_ids_str = ','.join(map(str, training_player_ids))\n",
    "    \n",
    "    # Extract data ONLY for training players\n",
    "    print(f\"\\n3Ô∏è‚É£  Extracting training data (excluding holdout players)...\")\n",
    "    \n",
    "    query = f\"\"\"\n",
    "        SELECT \n",
    "            pos.player_id,\n",
    "            pos.opening_id,\n",
    "            pos.num_wins + pos.num_draws + pos.num_losses as num_games,\n",
    "            (pos.num_wins + (pos.num_draws * 0.5)) / \n",
    "                NULLIF(pos.num_wins + pos.num_draws + pos.num_losses, 0) as score,\n",
    "            o.eco\n",
    "        FROM player_opening_stats pos\n",
    "        JOIN opening o ON pos.opening_id = o.id\n",
    "        JOIN player p ON pos.player_id = p.id\n",
    "        WHERE pos.color = '{COLOR_FILTER}'\n",
    "        AND p.rating >= {MIN_RATING}\n",
    "        AND pos.player_id IN ({training_player_ids_str})\n",
    "        ORDER BY pos.player_id, pos.opening_id\n",
    "    \"\"\"\n",
    "    \n",
    "    raw_data = pd.DataFrame(con.execute(query).df())\n",
    "    \n",
    "    print(f\"   ‚úì Extracted {len(raw_data):,} rows\")\n",
    "    \n",
    "    # Also save holdout player IDs for later use\n",
    "    holdout_players_df = pd.DataFrame({'player_id': holdout_player_ids})\n",
    "    print(f\"\\n   üíæ Saved holdout_players_df with {len(holdout_players_df):,} player IDs\")\n",
    "    print(f\"   ‚Ä¢ These players are COMPLETELY UNSEEN by the training process\")\n",
    "    print(f\"   ‚Ä¢ Use them later for fold-in verification\")\n",
    "    \n",
    "    # Schema verification\n",
    "    print(\"\\n4Ô∏è‚É£  Verifying schema...\")\n",
    "    required_columns = ['player_id', 'opening_id', 'num_games', 'score', 'eco']\n",
    "    \n",
    "    for col in required_columns:\n",
    "        if col not in raw_data.columns:\n",
    "            raise ValueError(f\"Missing required column: {col}\")\n",
    "    \n",
    "    print(f\"   ‚úì All required columns present: {required_columns}\")\n",
    "    \n",
    "    # Data types verification\n",
    "    print(\"\\n5Ô∏è‚É£  Checking data types...\")\n",
    "    print(f\"   ‚Ä¢ player_id: {raw_data['player_id'].dtype}\")\n",
    "    print(f\"   ‚Ä¢ opening_id: {raw_data['opening_id'].dtype}\")\n",
    "    print(f\"   ‚Ä¢ num_games: {raw_data['num_games'].dtype}\")\n",
    "    print(f\"   ‚Ä¢ score: {raw_data['score'].dtype}\")\n",
    "    print(f\"   ‚Ä¢ eco: {raw_data['eco'].dtype}\")\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(\"\\n6Ô∏è‚É£  Data statistics...\")\n",
    "    print(f\"   ‚Ä¢ Total rows: {len(raw_data):,}\")\n",
    "    print(f\"   ‚Ä¢ Unique players: {raw_data['player_id'].nunique():,}\")\n",
    "    print(f\"   ‚Ä¢ Unique openings: {raw_data['opening_id'].nunique():,}\")\n",
    "    print(f\"   ‚Ä¢ Total games (sum): {raw_data['num_games'].sum():,}\")\n",
    "    \n",
    "    # Player ID range\n",
    "    print(f\"\\n   Player ID range:\")\n",
    "    print(f\"   ‚Ä¢ Min: {raw_data['player_id'].min()}\")\n",
    "    print(f\"   ‚Ä¢ Max: {raw_data['player_id'].max()}\")\n",
    "    \n",
    "    # Opening ID range\n",
    "    print(f\"\\n   Opening ID range:\")\n",
    "    print(f\"   ‚Ä¢ Min: {raw_data['opening_id'].min()}\")\n",
    "    print(f\"   ‚Ä¢ Max: {raw_data['opening_id'].max()}\")\n",
    "    \n",
    "    # Games per entry statistics\n",
    "    print(f\"\\n   Games per entry:\")\n",
    "    print(f\"   ‚Ä¢ Min: {raw_data['num_games'].min()}\")\n",
    "    print(f\"   ‚Ä¢ Max: {raw_data['num_games'].max()}\")\n",
    "    print(f\"   ‚Ä¢ Mean: {raw_data['num_games'].mean():.1f}\")\n",
    "    print(f\"   ‚Ä¢ Median: {raw_data['num_games'].median():.0f}\")\n",
    "    \n",
    "    # Score statistics\n",
    "    print(f\"\\n   Score distribution:\")\n",
    "    print(f\"   ‚Ä¢ Min: {raw_data['score'].min():.4f}\")\n",
    "    print(f\"   ‚Ä¢ Max: {raw_data['score'].max():.4f}\")\n",
    "    print(f\"   ‚Ä¢ Mean: {raw_data['score'].mean():.4f}\")\n",
    "    print(f\"   ‚Ä¢ Median: {raw_data['score'].median():.4f}\")\n",
    "    \n",
    "    # Check for null values\n",
    "    print(\"\\n7Ô∏è‚É£  Checking for null values...\")\n",
    "    null_counts = raw_data.isnull().sum()\n",
    "    if null_counts.sum() == 0:\n",
    "        print(\"   ‚úì No null values found\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  Found null values:\")\n",
    "        for col, count in null_counts[null_counts > 0].items():\n",
    "            print(f\"      ‚Ä¢ {col}: {count} nulls\")\n",
    "    \n",
    "    # Sample data\n",
    "    print(\"\\n8Ô∏è‚É£  Sample of extracted data (first 10 rows):\")\n",
    "    print(raw_data.head(10).to_string())\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úÖ DATA EXTRACTION COMPLETE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nData shape: {raw_data.shape}\")\n",
    "    print(f\"Columns: {list(raw_data.columns)}\")\n",
    "    print(f\"\\n‚ö†Ô∏è  IMPORTANT: {len(holdout_player_ids):,} players held out for fold-in verification\")\n",
    "    print(f\"   ‚Ä¢ Access via: holdout_players_df\")\n",
    "    print(f\"   ‚Ä¢ These players will NOT appear in any training, validation, or test splits\")\n",
    "    \n",
    "finally:\n",
    "    con.close()\n",
    "    print(\"\\n‚úì Database connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad110b85",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "519d8f2f",
   "metadata": {},
   "source": [
    "## Step 2: Data Sanitization & Normalization\n",
    "\n",
    "Filter low-quality data, handle duplicates, and prepare for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e74f0b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 2: DATA SANITIZATION & NORMALIZATION\n",
      "============================================================\n",
      "\n",
      "‚öôÔ∏è  Configuration:\n",
      "   ‚Ä¢ MIN_GAMES_THRESHOLD: 10\n",
      "\n",
      "üìä Starting data shape: (11567190, 5)\n",
      "   ‚Ä¢ Rows: 11,567,190\n",
      "   ‚Ä¢ Unique players: 48,551\n",
      "   ‚Ä¢ Unique openings: 2,991\n",
      "\n",
      "1Ô∏è‚É£  Filtering entries with < 10 games...\n",
      "   ‚Ä¢ Before: 11,567,190 rows\n",
      "   ‚Ä¢ After: 2,897,386 rows\n",
      "   ‚Ä¢ Filtered out: 8,669,804 rows (75.0%)\n",
      "\n",
      "2Ô∏è‚É£  Checking for duplicate (player_id, opening_id) combinations...\n",
      "   ‚úì No duplicates found\n",
      "\n",
      "3Ô∏è‚É£  Removing players with no qualifying openings...\n",
      "   ‚Ä¢ Players before: 48,468\n",
      "   ‚Ä¢ Players after: 48,468\n",
      "   ‚Ä¢ Removed: 0\n",
      "\n",
      "4Ô∏è‚É£  Removing openings with no qualifying players...\n",
      "   ‚Ä¢ Openings before: 2,714\n",
      "   ‚Ä¢ Openings after: 2,714\n",
      "   ‚Ä¢ Removed: 0\n",
      "\n",
      "5Ô∏è‚É£  Verifying no null values...\n",
      "   ‚úì No null values found\n",
      "\n",
      "6Ô∏è‚É£  Final data statistics:\n",
      "   ‚Ä¢ Total rows: 2,897,386\n",
      "   ‚Ä¢ Unique players: 48,468\n",
      "   ‚Ä¢ Unique openings: 2,714\n",
      "   ‚Ä¢ Total games: 206,228,841\n",
      "   ‚Ä¢ Avg games per entry: 71.2\n",
      "   ‚Ä¢ Avg openings per player: 59.8\n",
      "   ‚Ä¢ Avg players per opening: 1067.6\n",
      "\n",
      "   Score statistics:\n",
      "   ‚Ä¢ Min: 0.0000\n",
      "   ‚Ä¢ 25th percentile: 0.4500\n",
      "   ‚Ä¢ Median: 0.5125\n",
      "   ‚Ä¢ 75th percentile: 0.5750\n",
      "   ‚Ä¢ Max: 1.0000\n",
      "   ‚Ä¢ Mean: 0.5110\n",
      "   ‚Ä¢ Std: 0.1083\n",
      "\n",
      "7Ô∏è‚É£  Sample of cleaned data (10 random rows):\n",
      "         player_id  opening_id  num_games     score  eco\n",
      "2281163      38565        2613        131  0.488550  D30\n",
      "253352        4271         394         21  0.309524  A40\n",
      "2856783      48938         770         25  0.440000  B01\n",
      "1930023      32581         799         80  0.525000  B02\n",
      "503242        8457        2490         87  0.402299  D06\n",
      "1498709      25355         143         10  0.700000  A01\n",
      "1487038      25158         400         23  0.434783  A40\n",
      "372318        6291        2714         17  0.588235  D46\n",
      "208577        3496        2175         27  0.574074  C57\n",
      "392447        6630         800         10  0.400000  B02\n",
      "\n",
      "============================================================\n",
      "‚úÖ DATA SANITIZATION COMPLETE\n",
      "============================================================\n",
      "\n",
      "Cleaned data shape: (2897386, 5)\n",
      "Data reduction: 75.0%\n"
     ]
    }
   ],
   "source": [
    "# 2a. Filter low-quality data, handle duplicates, and prepare for training.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Configuration\n",
    "MIN_GAMES_THRESHOLD = 10\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 2: DATA SANITIZATION & NORMALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n‚öôÔ∏è  Configuration:\")\n",
    "print(f\"   ‚Ä¢ MIN_GAMES_THRESHOLD: {MIN_GAMES_THRESHOLD}\")\n",
    "\n",
    "# Start with raw_data from Step 1\n",
    "print(f\"\\nüìä Starting data shape: {raw_data.shape}\")\n",
    "print(f\"   ‚Ä¢ Rows: {len(raw_data):,}\")\n",
    "print(f\"   ‚Ä¢ Unique players: {raw_data['player_id'].nunique():,}\")\n",
    "print(f\"   ‚Ä¢ Unique openings: {raw_data['opening_id'].nunique():,}\")\n",
    "\n",
    "# 1. Filter by minimum games threshold\n",
    "print(f\"\\n1Ô∏è‚É£  Filtering entries with < {MIN_GAMES_THRESHOLD} games...\")\n",
    "before_filter = len(raw_data)\n",
    "clean_data = raw_data.query(f'num_games >= {MIN_GAMES_THRESHOLD}').copy()\n",
    "num_rows_after_filter = len(clean_data)\n",
    "num_rows_filtered_out = before_filter - num_rows_after_filter\n",
    "\n",
    "print(f\"   ‚Ä¢ Before: {before_filter:,} rows\")\n",
    "print(f\"   ‚Ä¢ After: {num_rows_after_filter:,} rows\")\n",
    "print(f\"   ‚Ä¢ Filtered out: {num_rows_filtered_out:,} rows ({100*num_rows_filtered_out/before_filter:.1f}%)\")\n",
    "\n",
    "# 2. Check for duplicates\n",
    "print(f\"\\n2Ô∏è‚É£  Checking for duplicate (player_id, opening_id) combinations...\")\n",
    "num_duplicates = clean_data.duplicated(subset=['player_id', 'opening_id']).sum()\n",
    "\n",
    "if num_duplicates > 0:\n",
    "    print(f\"   ‚ö†Ô∏è  Found {num_duplicates} duplicate entries\")\n",
    "    dup_mask = clean_data.duplicated(subset=['player_id', 'opening_id'], keep=False)\n",
    "    print(\"\\n   Sample of duplicates:\")\n",
    "    print(clean_data[dup_mask].head(10).to_string())\n",
    "    \n",
    "    # Keep only first occurrence of any duplicate player-opening pair\n",
    "    print(\"\\n   Removing duplicates (keeping first occurrence)...\")\n",
    "    clean_data = pd.DataFrame.drop_duplicates(clean_data, subset=['player_id', 'opening_id'], keep='first')\n",
    "    print(f\"   ‚úì After deduplication: {len(clean_data):,} rows\")\n",
    "else:\n",
    "    print(f\"   ‚úì No duplicates found\")\n",
    "\n",
    "# 3. Remove players with no qualifying openings\n",
    "print(f\"\\n3Ô∏è‚É£  Removing players with no qualifying openings...\") # Note that a few players only play stuff like the Van't Kruijs which we've excluded, so a small numer of players will be excluded here\n",
    "players_before = clean_data['player_id'].nunique()\n",
    "\n",
    "# Count openings per player\n",
    "num_openings_per_player = pd.DataFrame(clean_data.groupby('player_id').size(), columns=['count'])\n",
    "players_with_data = num_openings_per_player[num_openings_per_player['count'] > 0].index.tolist()\n",
    "\n",
    "# Filter\n",
    "clean_data = clean_data[clean_data['player_id'].isin(players_with_data)]\n",
    "players_after = clean_data['player_id'].nunique()\n",
    "\n",
    "print(f\"   ‚Ä¢ Players before: {players_before:,}\")\n",
    "print(f\"   ‚Ä¢ Players after: {players_after:,}\")\n",
    "print(f\"   ‚Ä¢ Removed: {players_before - players_after}\")\n",
    "\n",
    "# 4. Remove openings with no qualifying players\n",
    "print(f\"\\n4Ô∏è‚É£  Removing openings with no qualifying players...\")\n",
    "num_openings_before = clean_data['opening_id'].nunique()\n",
    "\n",
    "# Use pd.DataFrame.groupby() to count players per opening\n",
    "num_players_per_opening = pd.DataFrame(clean_data.groupby('opening_id').size(), columns=['count'])\n",
    "openings_with_data = num_players_per_opening[num_players_per_opening['count'] > 0].index.tolist()\n",
    "\n",
    "# Filter using pd.DataFrame.isin()\n",
    "clean_data = clean_data[clean_data['opening_id'].isin(openings_with_data)]\n",
    "openings_after = clean_data['opening_id'].nunique()\n",
    "\n",
    "print(f\"   ‚Ä¢ Openings before: {num_openings_before:,}\")\n",
    "print(f\"   ‚Ä¢ Openings after: {openings_after:,}\")\n",
    "print(f\"   ‚Ä¢ Removed: {num_openings_before - openings_after}\")\n",
    "\n",
    "# 5. Verify no null values using pd.isna()\n",
    "print(f\"\\n5Ô∏è‚É£  Verifying no null values...\")\n",
    "null_counts = pd.DataFrame.isna(clean_data).sum()\n",
    "if null_counts.sum() == 0:\n",
    "    print(\"   ‚úì No null values found\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  Found null values:\")\n",
    "    for col, count in null_counts[null_counts > 0].items():\n",
    "        print(f\"      ‚Ä¢ {col}: {count} nulls\")\n",
    "    # Drop rows with nulls using pd.DataFrame.dropna()\n",
    "    clean_data = pd.DataFrame.dropna(clean_data)\n",
    "    print(f\"   ‚úì Dropped null rows. New shape: {clean_data.shape}\")\n",
    "\n",
    "# TODO: Add confidence weighting column\n",
    "# TODO: Extract and normalize player ratings (side information)\n",
    "\n",
    "# Reset index using pd.DataFrame.reset_index()\n",
    "clean_data = pd.DataFrame.reset_index(clean_data, drop=True)\n",
    "\n",
    "# Final statistics using pd functions\n",
    "print(f\"\\n6Ô∏è‚É£  Final data statistics:\")\n",
    "print(f\"   ‚Ä¢ Total rows: {len(clean_data):,}\")\n",
    "print(f\"   ‚Ä¢ Unique players: {pd.Series.nunique(clean_data['player_id']):,}\")\n",
    "print(f\"   ‚Ä¢ Unique openings: {pd.Series.nunique(clean_data['opening_id']):,}\")\n",
    "print(f\"   ‚Ä¢ Total games: {pd.Series.sum(clean_data['num_games']):,}\")\n",
    "print(f\"   ‚Ä¢ Avg games per entry: {pd.Series.mean(clean_data['num_games']):.1f}\")\n",
    "print(f\"   ‚Ä¢ Avg openings per player: {len(clean_data) / pd.Series.nunique(clean_data['player_id']):.1f}\")\n",
    "print(f\"   ‚Ä¢ Avg players per opening: {len(clean_data) / pd.Series.nunique(clean_data['opening_id']):.1f}\")\n",
    "\n",
    "# Score distribution using pd functions\n",
    "print(f\"\\n   Score statistics:\")\n",
    "print(f\"   ‚Ä¢ Min: {pd.Series.min(clean_data['score']):.4f}\")\n",
    "print(f\"   ‚Ä¢ 25th percentile: {pd.Series.quantile(clean_data['score'], 0.25):.4f}\")\n",
    "print(f\"   ‚Ä¢ Median: {pd.Series.median(clean_data['score']):.4f}\")\n",
    "print(f\"   ‚Ä¢ 75th percentile: {pd.Series.quantile(clean_data['score'], 0.75):.4f}\")\n",
    "print(f\"   ‚Ä¢ Max: {pd.Series.max(clean_data['score']):.4f}\")\n",
    "print(f\"   ‚Ä¢ Mean: {pd.Series.mean(clean_data['score']):.4f}\")\n",
    "print(f\"   ‚Ä¢ Std: {pd.Series.std(clean_data['score']):.4f}\")\n",
    "\n",
    "# Sample of cleaned data using pd.DataFrame.sample()\n",
    "print(f\"\\n7Ô∏è‚É£  Sample of cleaned data (10 random rows):\")\n",
    "print(pd.DataFrame.sample(clean_data, min(10, len(clean_data)), random_state=42).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ DATA SANITIZATION COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nCleaned data shape: {clean_data.shape}\")\n",
    "print(f\"Data reduction: {100 * (1 - len(clean_data)/len(raw_data)):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e671b6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 2B: HIERARCHICAL BAYESIAN SCORE ADJUSTMENT\n",
      "============================================================\n",
      "\n",
      "‚öôÔ∏è  Configuration:\n",
      "   ‚Ä¢ K_PLAYER (shrinkage constant): 50\n",
      "   ‚Ä¢ Method: Two-level empirical Bayes shrinkage\n",
      "   ‚Ä¢ Level 1: Calculate opening-specific means\n",
      "   ‚Ä¢ Level 2: Shrink player scores toward opening means\n",
      "\n",
      "üìä Global statistics:\n",
      "   ‚Ä¢ Global mean score: 0.5110\n",
      "   ‚Ä¢ Total entries: 2,897,386\n",
      "   ‚Ä¢ Unique openings: 2,714\n",
      "\n",
      "1Ô∏è‚É£  LEVEL 1: Calculating opening-specific means...\n",
      "   ‚úì Calculated means for 2,714 openings\n",
      "\n",
      "   Opening mean score distribution:\n",
      "   ‚Ä¢ Min: 0.1667\n",
      "   ‚Ä¢ 25th percentile: 0.4963\n",
      "   ‚Ä¢ Median: 0.5162\n",
      "   ‚Ä¢ 75th percentile: 0.5368\n",
      "   ‚Ä¢ Max: 1.0000\n",
      "   ‚Ä¢ Std: 0.0509\n",
      "\n",
      "   Opening sample size distribution:\n",
      "   ‚Ä¢ Total games per opening (median): 4809\n",
      "   ‚Ä¢ Players per opening (median): 157\n",
      "   ‚Ä¢ Total games range: [10, 5489141]\n",
      "   ‚Ä¢ Players range: [1, 42893]\n",
      "\n",
      "2Ô∏è‚É£  LEVEL 2: Shrinking player scores toward opening means...\n",
      "   Formula: adjusted_score = (num_games √ó player_score + 50 √ó opening_mean) / (num_games + 50)\n",
      "   ‚úì Scores adjusted for 2,897,386 entries\n",
      "\n",
      "3Ô∏è‚É£  Calculating confidence weights...\n",
      "   ‚úì Confidence weights calculated\n",
      "   ‚Ä¢ Formula: confidence = num_games / (num_games + 50)\n",
      "   ‚Ä¢ Range: [0.1667, 0.9963]\n",
      "\n",
      "4Ô∏è‚É£  Adjustment statistics:\n",
      "   ‚Ä¢ Mean adjustment: 0.000961\n",
      "   ‚Ä¢ Std adjustment: 0.076767\n",
      "   ‚Ä¢ Max adjustment: 0.457567\n",
      "   ‚Ä¢ Min adjustment: -0.457589\n",
      "\n",
      "   Adjustment by num_games quartiles:\n",
      "   ‚Ä¢ 25th percentile (n=15 games): avg adjustment = 0.003643\n",
      "   ‚Ä¢ 50th percentile (n=27 games): avg adjustment = 0.001793\n",
      "   ‚Ä¢ 75th percentile (n=65 games): avg adjustment = -0.000400\n",
      "   ‚Ä¢ >75th percentile (n>65 games): avg adjustment = -0.001360\n",
      "\n",
      "5Ô∏è‚É£  Adjusted score statistics:\n",
      "   ‚Ä¢ Min: 0.1004\n",
      "   ‚Ä¢ 25th percentile: 0.4850\n",
      "   ‚Ä¢ Median: 0.5117\n",
      "   ‚Ä¢ 75th percentile: 0.5385\n",
      "   ‚Ä¢ Max: 1.0000\n",
      "   ‚Ä¢ Mean: 0.5120\n",
      "   ‚Ä¢ Std: 0.0411\n",
      "\n",
      "6Ô∏è‚É£  Sample comparisons (showing effect of hierarchical shrinkage):\n",
      "\n",
      "   ========================================================================================================================\n",
      "   Low-game entries (10-20 games) - HIGH shrinkage toward opening mean:\n",
      "   ========================================================================================================================\n",
      "   Player    46 | Opening  730 | Games:  16 | Opening mean: 0.5185 | Original: 0.4375 ‚Üí Adjusted: 0.4989 | Diff: +0.0614 | Confidence: 0.242\n",
      "   Player  3984 | Opening 3180 | Games:  10 | Opening mean: 0.4898 | Original: 0.4000 ‚Üí Adjusted: 0.4748 | Diff: +0.0748 | Confidence: 0.167\n",
      "   Player  5655 | Opening  495 | Games:  12 | Opening mean: 0.5027 | Original: 0.4583 ‚Üí Adjusted: 0.4941 | Diff: +0.0358 | Confidence: 0.194\n",
      "   Player 34996 | Opening 2523 | Games:  11 | Opening mean: 0.4878 | Original: 0.5000 ‚Üí Adjusted: 0.4900 | Diff: -0.0100 | Confidence: 0.180\n",
      "   Player 19466 | Opening 2245 | Games:  11 | Opening mean: 0.4806 | Original: 0.3636 ‚Üí Adjusted: 0.4595 | Diff: +0.0959 | Confidence: 0.180\n",
      "   Player 14750 | Opening  137 | Games:  11 | Opening mean: 0.4965 | Original: 0.5455 ‚Üí Adjusted: 0.5053 | Diff: -0.0402 | Confidence: 0.180\n",
      "   Player 42695 | Opening 3477 | Games:  10 | Opening mean: 0.5156 | Original: 0.5000 ‚Üí Adjusted: 0.5130 | Diff: +0.0130 | Confidence: 0.167\n",
      "   Player 49372 | Opening  744 | Games:  10 | Opening mean: 0.5133 | Original: 0.7000 ‚Üí Adjusted: 0.5444 | Diff: -0.1556 | Confidence: 0.167\n",
      "   Player 32380 | Opening  194 | Games:  10 | Opening mean: 0.5190 | Original: 0.4000 ‚Üí Adjusted: 0.4991 | Diff: +0.0991 | Confidence: 0.167\n",
      "   Player  5330 | Opening  977 | Games:  12 | Opening mean: 0.5279 | Original: 0.6667 ‚Üí Adjusted: 0.5548 | Diff: -0.1119 | Confidence: 0.194\n",
      "\n",
      "   ========================================================================================================================\n",
      "   Medium-game entries (50-100 games) - MODERATE shrinkage:\n",
      "   ========================================================================================================================\n",
      "   Player 27790 | Opening  235 | Games:  80 | Opening mean: 0.5249 | Original: 0.6438 ‚Üí Adjusted: 0.5981 | Diff: -0.0457 | Confidence: 0.615\n",
      "   Player 25653 | Opening 3471 | Games:  56 | Opening mean: 0.5104 | Original: 0.5982 ‚Üí Adjusted: 0.5568 | Diff: -0.0414 | Confidence: 0.528\n",
      "   Player 46349 | Opening 1356 | Games:  82 | Opening mean: 0.5053 | Original: 0.5061 ‚Üí Adjusted: 0.5058 | Diff: -0.0003 | Confidence: 0.621\n",
      "   Player 34703 | Opening  838 | Games:  94 | Opening mean: 0.5096 | Original: 0.5319 ‚Üí Adjusted: 0.5242 | Diff: -0.0078 | Confidence: 0.653\n",
      "   Player 15634 | Opening 1746 | Games:  65 | Opening mean: 0.4886 | Original: 0.5923 ‚Üí Adjusted: 0.5472 | Diff: -0.0451 | Confidence: 0.565\n",
      "   Player   977 | Opening 3204 | Games:  59 | Opening mean: 0.5174 | Original: 0.5000 ‚Üí Adjusted: 0.5080 | Diff: +0.0080 | Confidence: 0.541\n",
      "   Player 31697 | Opening  737 | Games:  90 | Opening mean: 0.5084 | Original: 0.4111 ‚Üí Adjusted: 0.4459 | Diff: +0.0347 | Confidence: 0.643\n",
      "   Player 10336 | Opening  838 | Games:  72 | Opening mean: 0.5096 | Original: 0.5486 ‚Üí Adjusted: 0.5326 | Diff: -0.0160 | Confidence: 0.590\n",
      "   Player 35875 | Opening 3190 | Games:  85 | Opening mean: 0.5130 | Original: 0.4588 ‚Üí Adjusted: 0.4789 | Diff: +0.0201 | Confidence: 0.630\n",
      "   Player  4501 | Opening 2467 | Games:  92 | Opening mean: 0.5223 | Original: 0.4946 ‚Üí Adjusted: 0.5043 | Diff: +0.0098 | Confidence: 0.648\n",
      "\n",
      "   ========================================================================================================================\n",
      "   High-game entries (200+ games) - LOW shrinkage:\n",
      "   ========================================================================================================================\n",
      "   Player 31677 | Opening 1854 | Games: 965 | Opening mean: 0.5256 | Original: 0.5378 ‚Üí Adjusted: 0.5372 | Diff: -0.0006 | Confidence: 0.951\n",
      "   Player 33890 | Opening 3214 | Games: 316 | Opening mean: 0.5145 | Original: 0.5016 ‚Üí Adjusted: 0.5033 | Diff: +0.0018 | Confidence: 0.863\n",
      "   Player 18860 | Opening  911 | Games: 229 | Opening mean: 0.5227 | Original: 0.5131 ‚Üí Adjusted: 0.5148 | Diff: +0.0017 | Confidence: 0.821\n",
      "   Player 26614 | Opening  921 | Games: 322 | Opening mean: 0.4678 | Original: 0.4394 ‚Üí Adjusted: 0.4433 | Diff: +0.0038 | Confidence: 0.866\n",
      "   Player 10865 | Opening  910 | Games: 310 | Opening mean: 0.5002 | Original: 0.4935 ‚Üí Adjusted: 0.4945 | Diff: +0.0009 | Confidence: 0.861\n",
      "   Player 33713 | Opening  737 | Games: 202 | Opening mean: 0.5084 | Original: 0.5297 ‚Üí Adjusted: 0.5255 | Diff: -0.0042 | Confidence: 0.802\n",
      "   Player  4443 | Opening 1585 | Games: 235 | Opening mean: 0.5175 | Original: 0.5255 ‚Üí Adjusted: 0.5241 | Diff: -0.0014 | Confidence: 0.825\n",
      "   Player  9719 | Opening 1968 | Games: 353 | Opening mean: 0.5535 | Original: 0.5850 ‚Üí Adjusted: 0.5811 | Diff: -0.0039 | Confidence: 0.876\n",
      "   Player 12552 | Opening 1733 | Games: 232 | Opening mean: 0.5294 | Original: 0.5194 ‚Üí Adjusted: 0.5212 | Diff: +0.0018 | Confidence: 0.823\n",
      "   Player  2778 | Opening 1614 | Games: 234 | Opening mean: 0.5383 | Original: 0.5171 ‚Üí Adjusted: 0.5208 | Diff: +0.0037 | Confidence: 0.824\n",
      "\n",
      "7Ô∏è‚É£  Extreme cases (showing why opening-specific shrinkage matters):\n",
      "\n",
      "   Openings with HIGHEST win rates (strong for White):\n",
      "   Opening 1811 (C39): mean = 1.0000 (+0.4890 vs global) | 1 player entries\n",
      "   Opening 3551 (C19): mean = 0.8000 (+0.2890 vs global) | 1 player entries\n",
      "   Opening 2881 (E10): mean = 0.8000 (+0.2890 vs global) | 1 player entries\n",
      "   Opening 2046 (C49): mean = 0.7857 (+0.2747 vs global) | 1 player entries\n",
      "   Opening 1659 (C30): mean = 0.7692 (+0.2582 vs global) | 1 player entries\n",
      "\n",
      "   Openings with LOWEST win rates (weak for White):\n",
      "   Opening 2593 (D26): mean = 0.1667 (-0.3444 vs global) | 1 player entries\n",
      "   Opening  636 (A83): mean = 0.2006 (-0.3104 vs global) | 2 player entries\n",
      "   Opening 3496 (A40): mean = 0.2273 (-0.2838 vs global) | 1 player entries\n",
      "   Opening 1763 (C37): mean = 0.2417 (-0.2694 vs global) | 2 player entries\n",
      "\n",
      "8Ô∏è‚É£  Examples showing hierarchical shrinkage benefit:\n",
      "\n",
      "   Strong opening + good player performance (shrunk toward HIGH opening mean):\n",
      "   Player 23562 | Opening 3292 (C54) | Games: 12 | Opening mean: 0.7306 | Original: 0.7500 ‚Üí 0.7344\n",
      "      If we'd shrunk to global mean: 0.5573 (would lose +0.1771 of deserved credit)\n",
      "   Player 14997 | Opening 3292 (C54) | Games: 13 | Opening mean: 0.7306 | Original: 0.9231 ‚Üí 0.7703\n",
      "      If we'd shrunk to global mean: 0.5961 (would lose +0.1743 of deserved credit)\n",
      "   Player  9893 | Opening 3292 (C54) | Games: 20 | Opening mean: 0.7306 | Original: 0.6500 ‚Üí 0.7076\n",
      "      If we'd shrunk to global mean: 0.5507 (would lose +0.1569 of deserved credit)\n",
      "\n",
      "   Weak opening + poor player performance (shrunk toward LOW opening mean):\n",
      "   Player 43311 | Opening 2057 (C50) | Games: 19 | Opening mean: 0.3329 | Original: 0.2368 ‚Üí 0.3065\n",
      "      If we'd shrunk to global mean: 0.4355 (would unfairly boost by +0.1291)\n",
      "   Player 33024 | Opening 2097 (C52) | Games: 13 | Opening mean: 0.3077 | Original: 0.3077 ‚Üí 0.3077\n",
      "      If we'd shrunk to global mean: 0.4691 (would unfairly boost by +0.1614)\n",
      "   Player 33325 | Opening  100 (A00) | Games: 14 | Opening mean: 0.2857 | Original: 0.2857 ‚Üí 0.2857\n",
      "      If we'd shrunk to global mean: 0.4618 (would unfairly boost by +0.1760)\n",
      "\n",
      "9Ô∏è‚É£  Cleaning up...\n",
      "   ‚úì Removed temporary columns\n",
      "\n",
      "============================================================\n",
      "‚úÖ HIERARCHICAL BAYESIAN ADJUSTMENT COMPLETE\n",
      "============================================================\n",
      "\n",
      "Final data shape: (2897386, 6)\n",
      "Columns: ['player_id', 'opening_id', 'num_games', 'score', 'eco', 'confidence']\n",
      "\n",
      "New columns added:\n",
      "   ‚Ä¢ 'confidence': weight for loss function (range [0,1])\n",
      "   ‚Ä¢ 'score': adjusted using hierarchical Bayesian shrinkage\n",
      "\n",
      "Key improvement over simple shrinkage:\n",
      "   ‚Ä¢ Player scores now shrink toward OPENING-SPECIFIC means, not global mean\n",
      "   ‚Ä¢ Preserves opening difficulty differences\n",
      "   ‚Ä¢ More accurate for both strong and weak openings\n"
     ]
    }
   ],
   "source": [
    "# 2b. Apply hierarchical Bayesian shrinkage to adjust scores based on sample size confidence\n",
    "\n",
    "# Check if confidence already exists - if so, skip this processing\n",
    "if 'confidence' in clean_data.columns:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"‚è≠Ô∏è  SKIPPING STEP 2B: HIERARCHICAL BAYESIAN SCORE ADJUSTMENT\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\n‚úì 'confidence' column already exists in data\")\n",
    "    print(\"   This indicates hierarchical Bayesian processing has already been applied.\")\n",
    "    print(f\"\\nCurrent data shape: {clean_data.shape}\")\n",
    "    print(f\"Confidence range: [{clean_data['confidence'].min():.4f}, {clean_data['confidence'].max():.4f}]\")\n",
    "else:\n",
    "    # Define the processing function\n",
    "    # This is a long function, I recommend you fold it down in your editor\n",
    "    def apply_hierarchical_bayesian_shrinkage(data, k_player=50):\n",
    "        \"\"\"\n",
    "        Apply two-level hierarchical Bayesian shrinkage to adjust scores.\n",
    "        \n",
    "        A lot of our player-opening entries have a small number of games played, because openings are so specific.\n",
    "        This introduces sample size issues.\n",
    "        \n",
    "        We use TWO-LEVEL shrinkage:\n",
    "        Level 1: Calculate opening-specific means (these are our \"ground truth\" for each opening)\n",
    "        Level 2: Shrink individual player-opening scores toward their opening's mean\n",
    "        This is better than shrinking toward global mean because different openings have different baseline win rates\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        data : pd.DataFrame\n",
    "            Clean data with columns: player_id, opening_id, score, num_games, eco\n",
    "        k_player : int\n",
    "            Shrinkage constant for player-opening scores (default: 50)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame\n",
    "            Data with adjusted scores and new 'confidence' column\n",
    "        \"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"STEP 2B: HIERARCHICAL BAYESIAN SCORE ADJUSTMENT\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        print(f\"\\n‚öôÔ∏è  Configuration:\")\n",
    "        print(f\"   ‚Ä¢ K_PLAYER (shrinkage constant): {k_player}\")\n",
    "        print(f\"   ‚Ä¢ Method: Two-level empirical Bayes shrinkage\")\n",
    "        print(f\"   ‚Ä¢ Level 1: Calculate opening-specific means\")\n",
    "        print(f\"   ‚Ä¢ Level 2: Shrink player scores toward opening means\")\n",
    "        \n",
    "        # Calculate global mean score for comparison\n",
    "        global_mean_score = data[\"score\"].mean()\n",
    "        print(f\"\\nüìä Global statistics:\")\n",
    "        print(f\"   ‚Ä¢ Global mean score: {global_mean_score:.4f}\")\n",
    "        print(f\"   ‚Ä¢ Total entries: {len(data):,}\")\n",
    "        print(f\"   ‚Ä¢ Unique openings: {data['opening_id'].nunique():,}\")\n",
    "        \n",
    "        # Store original scores for comparison\n",
    "        data = data.copy()  # Best practice: work on a copy\n",
    "        data[\"score_original\"] = data[\"score\"].copy()\n",
    "        \n",
    "        # LEVEL 1: Calculate opening-specific means and statistics\n",
    "        print(f\"\\n1Ô∏è‚É£  LEVEL 1: Calculating opening-specific means...\")\n",
    "        \n",
    "        opening_stats = (\n",
    "            data.groupby(\"opening_id\")\n",
    "            .agg(\n",
    "                {\n",
    "                    \"score\": \"mean\",\n",
    "                    \"num_games\": \"sum\",\n",
    "                    \"player_id\": \"count\",  # Number of players who played this opening\n",
    "                }\n",
    "            )\n",
    "            .rename(\n",
    "                columns={\n",
    "                    \"score\": \"opening_mean\",\n",
    "                    \"num_games\": \"opening_total_games\",\n",
    "                    \"player_id\": \"opening_num_players\",\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        print(f\"   ‚úì Calculated means for {len(opening_stats):,} openings\")\n",
    "        \n",
    "        # Opening mean statistics\n",
    "        print(f\"\\n   Opening mean score distribution:\")\n",
    "        print(f\"   ‚Ä¢ Min: {opening_stats['opening_mean'].min():.4f}\")\n",
    "        print(f\"   ‚Ä¢ 25th percentile: {opening_stats['opening_mean'].quantile(0.25):.4f}\")\n",
    "        print(f\"   ‚Ä¢ Median: {opening_stats['opening_mean'].median():.4f}\")\n",
    "        print(f\"   ‚Ä¢ 75th percentile: {opening_stats['opening_mean'].quantile(0.75):.4f}\")\n",
    "        print(f\"   ‚Ä¢ Max: {opening_stats['opening_mean'].max():.4f}\")\n",
    "        print(f\"   ‚Ä¢ Std: {opening_stats['opening_mean'].std():.4f}\")\n",
    "        \n",
    "        # Show distribution of opening sizes\n",
    "        print(f\"\\n   Opening sample size distribution:\")\n",
    "        print(\n",
    "            f\"   ‚Ä¢ Total games per opening (median): {opening_stats['opening_total_games'].median():.0f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"   ‚Ä¢ Players per opening (median): {opening_stats['opening_num_players'].median():.0f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"   ‚Ä¢ Total games range: [{opening_stats['opening_total_games'].min():.0f}, {opening_stats['opening_total_games'].max():.0f}]\"\n",
    "        )\n",
    "        print(\n",
    "            f\"   ‚Ä¢ Players range: [{opening_stats['opening_num_players'].min():.0f}, {opening_stats['opening_num_players'].max():.0f}]\"\n",
    "        )\n",
    "        \n",
    "        # Merge opening means back into main dataframe\n",
    "        data = data.merge(\n",
    "            opening_stats[[\"opening_mean\"]], left_on=\"opening_id\", right_index=True, how=\"left\"\n",
    "        )\n",
    "        \n",
    "        # LEVEL 2: Shrink player-opening scores toward opening-specific means\n",
    "        print(f\"\\n2Ô∏è‚É£  LEVEL 2: Shrinking player scores toward opening means...\")\n",
    "        print(\n",
    "            f\"   Formula: adjusted_score = (num_games √ó player_score + {k_player} √ó opening_mean) / (num_games + {k_player})\"\n",
    "        )\n",
    "        \n",
    "        numerator = (data[\"num_games\"] * data[\"score_original\"]) + (\n",
    "            k_player * data[\"opening_mean\"]\n",
    "        )\n",
    "        denominator = data[\"num_games\"] + k_player\n",
    "        data[\"score\"] = numerator / denominator\n",
    "        \n",
    "        print(f\"   ‚úì Scores adjusted for {len(data):,} entries\")\n",
    "        \n",
    "        # Calculate confidence weights (will be used in loss function later)\n",
    "        print(f\"\\n3Ô∏è‚É£  Calculating confidence weights...\")\n",
    "        data[\"confidence\"] = data[\"num_games\"] / (\n",
    "            data[\"num_games\"] + k_player\n",
    "        )\n",
    "        print(f\"   ‚úì Confidence weights calculated\")\n",
    "        print(f\"   ‚Ä¢ Formula: confidence = num_games / (num_games + {k_player})\")\n",
    "        print(\n",
    "            f\"   ‚Ä¢ Range: [{data['confidence'].min():.4f}, {data['confidence'].max():.4f}]\"\n",
    "        )\n",
    "        \n",
    "        # Statistics on the adjustment\n",
    "        score_diff = data[\"score\"] - data[\"score_original\"]\n",
    "        print(f\"\\n4Ô∏è‚É£  Adjustment statistics:\")\n",
    "        print(f\"   ‚Ä¢ Mean adjustment: {score_diff.mean():.6f}\")\n",
    "        print(f\"   ‚Ä¢ Std adjustment: {score_diff.std():.6f}\")\n",
    "        print(f\"   ‚Ä¢ Max adjustment: {score_diff.max():.6f}\")\n",
    "        print(f\"   ‚Ä¢ Min adjustment: {score_diff.min():.6f}\")\n",
    "        \n",
    "        # Show distribution of adjustments\n",
    "        print(f\"\\n   Adjustment by num_games quartiles:\")\n",
    "        quartiles = data[\"num_games\"].quantile([0.25, 0.5, 0.75])\n",
    "        print(\n",
    "            f\"   ‚Ä¢ 25th percentile (n={quartiles[0.25]:.0f} games): avg adjustment = {score_diff[data['num_games'] <= quartiles[0.25]].mean():.6f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"   ‚Ä¢ 50th percentile (n={quartiles[0.5]:.0f} games): avg adjustment = {score_diff[(data['num_games'] > quartiles[0.25]) & (data['num_games'] <= quartiles[0.5])].mean():.6f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"   ‚Ä¢ 75th percentile (n={quartiles[0.75]:.0f} games): avg adjustment = {score_diff[(data['num_games'] > quartiles[0.5]) & (data['num_games'] <= quartiles[0.75])].mean():.6f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"   ‚Ä¢ >75th percentile (n>{quartiles[0.75]:.0f} games): avg adjustment = {score_diff[data['num_games'] > quartiles[0.75]].mean():.6f}\"\n",
    "        )\n",
    "        \n",
    "        # New score distribution after adjustment\n",
    "        print(f\"\\n5Ô∏è‚É£  Adjusted score statistics:\")\n",
    "        print(f\"   ‚Ä¢ Min: {data['score'].min():.4f}\")\n",
    "        print(f\"   ‚Ä¢ 25th percentile: {data['score'].quantile(0.25):.4f}\")\n",
    "        print(f\"   ‚Ä¢ Median: {data['score'].median():.4f}\")\n",
    "        print(f\"   ‚Ä¢ 75th percentile: {data['score'].quantile(0.75):.4f}\")\n",
    "        print(f\"   ‚Ä¢ Max: {data['score'].max():.4f}\")\n",
    "        print(f\"   ‚Ä¢ Mean: {data['score'].mean():.4f}\")\n",
    "        print(f\"   ‚Ä¢ Std: {data['score'].std():.4f}\")\n",
    "        \n",
    "        # Detailed sample showing the effect across different game counts\n",
    "        print(f\"\\n6Ô∏è‚É£  Sample comparisons (showing effect of hierarchical shrinkage):\")\n",
    "        print(f\"\\n   {'='*120}\")\n",
    "        print(f\"   Low-game entries (10-20 games) - HIGH shrinkage toward opening mean:\")\n",
    "        print(f\"   {'='*120}\")\n",
    "        \n",
    "        low_game_sample = data[\n",
    "            (data[\"num_games\"] >= 10) & (data[\"num_games\"] <= 20)\n",
    "        ].sample(\n",
    "            min(\n",
    "                10,\n",
    "                len(\n",
    "                    data[\n",
    "                        (data[\"num_games\"] >= 10) & (data[\"num_games\"] <= 20)\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            random_state=42,\n",
    "        )\n",
    "        for idx, row in low_game_sample.iterrows():\n",
    "            adjustment = row[\"score\"] - row[\"score_original\"]\n",
    "            print(\n",
    "                f\"   Player {row['player_id']:>5} | Opening {row['opening_id']:>4} | Games: {row['num_games']:>3} | \"\n",
    "                f\"Opening mean: {row['opening_mean']:.4f} | Original: {row['score_original']:.4f} ‚Üí Adjusted: {row['score']:.4f} | \"\n",
    "                f\"Diff: {adjustment:>+.4f} | Confidence: {row['confidence']:.3f}\"\n",
    "            )\n",
    "        \n",
    "        print(f\"\\n   {'='*120}\")\n",
    "        print(f\"   Medium-game entries (50-100 games) - MODERATE shrinkage:\")\n",
    "        print(f\"   {'='*120}\")\n",
    "        \n",
    "        med_game_sample = data[\n",
    "            (data[\"num_games\"] >= 50) & (data[\"num_games\"] <= 100)\n",
    "        ].sample(\n",
    "            min(\n",
    "                10,\n",
    "                len(\n",
    "                    data[\n",
    "                        (data[\"num_games\"] >= 50) & (data[\"num_games\"] <= 100)\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            random_state=42,\n",
    "        )\n",
    "        for idx, row in med_game_sample.iterrows():\n",
    "            adjustment = row[\"score\"] - row[\"score_original\"]\n",
    "            print(\n",
    "                f\"   Player {row['player_id']:>5} | Opening {row['opening_id']:>4} | Games: {row['num_games']:>3} | \"\n",
    "                f\"Opening mean: {row['opening_mean']:.4f} | Original: {row['score_original']:.4f} ‚Üí Adjusted: {row['score']:.4f} | \"\n",
    "                f\"Diff: {adjustment:>+.4f} | Confidence: {row['confidence']:.3f}\"\n",
    "            )\n",
    "        \n",
    "        print(f\"\\n   {'='*120}\")\n",
    "        print(f\"   High-game entries (200+ games) - LOW shrinkage:\")\n",
    "        print(f\"   {'='*120}\")\n",
    "        \n",
    "        high_game_sample = data[data[\"num_games\"] >= 200].sample(\n",
    "            min(10, len(data[data[\"num_games\"] >= 200])), random_state=42\n",
    "        )\n",
    "        for idx, row in high_game_sample.iterrows():\n",
    "            adjustment = row[\"score\"] - row[\"score_original\"]\n",
    "            print(\n",
    "                f\"   Player {row['player_id']:>5} | Opening {row['opening_id']:>4} | Games: {row['num_games']:>3} | \"\n",
    "                f\"Opening mean: {row['opening_mean']:.4f} | Original: {row['score_original']:.4f} ‚Üí Adjusted: {row['score']:.4f} | \"\n",
    "                f\"Diff: {adjustment:>+.4f} | Confidence: {row['confidence']:.3f}\"\n",
    "            )\n",
    "        \n",
    "        # Show extreme cases - comparing to both opening mean AND global mean\n",
    "        print(f\"\\n7Ô∏è‚É£  Extreme cases (showing why opening-specific shrinkage matters):\")\n",
    "        \n",
    "        # Find entries where opening mean differs significantly from global mean\n",
    "        data[\"opening_deviation_from_global\"] = (\n",
    "            data[\"opening_mean\"] - global_mean_score\n",
    "        ).abs()\n",
    "        \n",
    "        print(f\"\\n   Openings with HIGHEST win rates (strong for White):\")\n",
    "        strong_openings = data.nlargest(5, \"opening_mean\")[\n",
    "            [\"opening_id\", \"opening_mean\", \"eco\"]\n",
    "        ].drop_duplicates(\"opening_id\")\n",
    "        for idx, row in strong_openings.iterrows():\n",
    "            num_entries = len(data[data[\"opening_id\"] == row[\"opening_id\"]])\n",
    "            deviation = row[\"opening_mean\"] - global_mean_score\n",
    "            print(\n",
    "                f\"   Opening {row['opening_id']:>4} ({row['eco']:>3}): mean = {row['opening_mean']:.4f} \"\n",
    "                f\"(+{deviation:.4f} vs global) | {num_entries} player entries\"\n",
    "            )\n",
    "        \n",
    "        print(f\"\\n   Openings with LOWEST win rates (weak for White):\")\n",
    "        weak_openings = data.nsmallest(5, \"opening_mean\")[\n",
    "            [\"opening_id\", \"opening_mean\", \"eco\"]\n",
    "        ].drop_duplicates(\"opening_id\")\n",
    "        for idx, row in weak_openings.iterrows():\n",
    "            num_entries = len(data[data[\"opening_id\"] == row[\"opening_id\"]])\n",
    "            deviation = row[\"opening_mean\"] - global_mean_score\n",
    "            print(\n",
    "                f\"   Opening {row['opening_id']:>4} ({row['eco']:>3}): mean = {row['opening_mean']:.4f} \"\n",
    "                f\"({deviation:.4f} vs global) | {num_entries} player entries\"\n",
    "            )\n",
    "        \n",
    "        # Show specific examples where hierarchical shrinkage made a difference\n",
    "        print(f\"\\n8Ô∏è‚É£  Examples showing hierarchical shrinkage benefit:\")\n",
    "        \n",
    "        # Find entries with strong openings where player did well\n",
    "        strong_opening_ids = data.nlargest(50, \"opening_mean\")[\"opening_id\"].unique()\n",
    "        strong_examples = data[\n",
    "            (data[\"opening_id\"].isin(strong_opening_ids))\n",
    "            & (data[\"num_games\"] <= 20)\n",
    "            & (data[\"score_original\"] > 0.6)\n",
    "        ].sample(\n",
    "            min(\n",
    "                3,\n",
    "                len(\n",
    "                    data[\n",
    "                        (data[\"opening_id\"].isin(strong_opening_ids))\n",
    "                        & (data[\"num_games\"] <= 20)\n",
    "                        & (data[\"score_original\"] > 0.6)\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            random_state=42,\n",
    "        )\n",
    "        \n",
    "        print(\n",
    "            f\"\\n   Strong opening + good player performance (shrunk toward HIGH opening mean):\"\n",
    "        )\n",
    "        for idx, row in strong_examples.iterrows():\n",
    "            adjustment = row[\"score\"] - row[\"score_original\"]\n",
    "            global_shrink_would_be = (\n",
    "                (row[\"num_games\"] * row[\"score_original\"]) + (k_player * global_mean_score)\n",
    "            ) / (row[\"num_games\"] + k_player)\n",
    "            difference = row[\"score\"] - global_shrink_would_be\n",
    "            print(\n",
    "                f\"   Player {row['player_id']:>5} | Opening {row['opening_id']:>4} ({row['eco']:>3}) | Games: {row['num_games']:>2} | \"\n",
    "                f\"Opening mean: {row['opening_mean']:.4f} | Original: {row['score_original']:.4f} ‚Üí {row['score']:.4f}\"\n",
    "            )\n",
    "            print(\n",
    "                f\"      If we'd shrunk to global mean: {global_shrink_would_be:.4f} (would lose {difference:+.4f} of deserved credit)\"\n",
    "            )\n",
    "        \n",
    "        # Find entries with weak openings where player did poorly\n",
    "        weak_opening_ids = data.nsmallest(50, \"opening_mean\")[\"opening_id\"].unique()\n",
    "        weak_examples = data[\n",
    "            (data[\"opening_id\"].isin(weak_opening_ids))\n",
    "            & (data[\"num_games\"] <= 20)\n",
    "            & (data[\"score_original\"] < 0.45)\n",
    "        ].sample(\n",
    "            min(\n",
    "                3,\n",
    "                len(\n",
    "                    data[\n",
    "                        (data[\"opening_id\"].isin(weak_opening_ids))\n",
    "                        & (data[\"num_games\"] <= 20)\n",
    "                        & (data[\"score_original\"] < 0.45)\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            random_state=42,\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n   Weak opening + poor player performance (shrunk toward LOW opening mean):\")\n",
    "        for idx, row in weak_examples.iterrows():\n",
    "            adjustment = row[\"score\"] - row[\"score_original\"]\n",
    "            global_shrink_would_be = (\n",
    "                (row[\"num_games\"] * row[\"score_original\"]) + (k_player * global_mean_score)\n",
    "            ) / (row[\"num_games\"] + k_player)\n",
    "            difference = row[\"score\"] - global_shrink_would_be\n",
    "            print(\n",
    "                f\"   Player {row['player_id']:>5} | Opening {row['opening_id']:>4} ({row['eco']:>3}) | Games: {row['num_games']:>2} | \"\n",
    "                f\"Opening mean: {row['opening_mean']:.4f} | Original: {row['score_original']:.4f} ‚Üí {row['score']:.4f}\"\n",
    "            )\n",
    "            print(\n",
    "                f\"      If we'd shrunk to global mean: {global_shrink_would_be:.4f} (would unfairly boost by {-difference:+.4f})\"\n",
    "            )\n",
    "        \n",
    "        # Drop temporary columns\n",
    "        print(f\"\\n9Ô∏è‚É£  Cleaning up...\")\n",
    "        data = data.drop(\n",
    "            columns=[\"score_original\", \"opening_mean\", \"opening_deviation_from_global\"]\n",
    "        )\n",
    "        print(f\"   ‚úì Removed temporary columns\")\n",
    "        \n",
    "        print(f\"\\n\" + \"=\" * 60)\n",
    "        print(\"‚úÖ HIERARCHICAL BAYESIAN ADJUSTMENT COMPLETE\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"\\nFinal data shape: {data.shape}\")\n",
    "        print(f\"Columns: {list(data.columns)}\")\n",
    "        print(f\"\\nNew columns added:\")\n",
    "        print(f\"   ‚Ä¢ 'confidence': weight for loss function (range [0,1])\")\n",
    "        print(f\"   ‚Ä¢ 'score': adjusted using hierarchical Bayesian shrinkage\")\n",
    "        print(f\"\\nKey improvement over simple shrinkage:\")\n",
    "        print(f\"   ‚Ä¢ Player scores now shrink toward OPENING-SPECIFIC means, not global mean\")\n",
    "        print(f\"   ‚Ä¢ Preserves opening difficulty differences\")\n",
    "        print(f\"   ‚Ä¢ More accurate for both strong and weak openings\")\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    # Configuration for Bayesian shrinkage\n",
    "    K_PLAYER = 50  # Shrinkage constant for player-opening scores\n",
    "    \n",
    "    # Call the function\n",
    "    clean_data = apply_hierarchical_bayesian_shrinkage(clean_data, k_player=K_PLAYER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73319d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         player_id  opening_id  num_games     score  eco  confidence\n",
      "1033881      17447        1394         31  0.428221  C02    0.382716\n"
     ]
    }
   ],
   "source": [
    "print(clean_data.sample().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85a80e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 2C: PLAYER RATING STATISTICS\n",
      "============================================================\n",
      "\n",
      "1Ô∏è‚É£  Extracting player ratings from database...\n",
      "   ‚úì Retrieved ratings for 48,468 players\n",
      "   ‚úì Database connection closed\n",
      "\n",
      "2Ô∏è‚É£  Merging ratings with clean_data...\n",
      "   ‚úì Merged successfully\n",
      "   ‚úì All entries have ratings\n",
      "\n",
      "3Ô∏è‚É£  Basic rating statistics:\n",
      "   ‚Ä¢ Count: 48,468\n",
      "   ‚Ä¢ Missing: 0\n",
      "   ‚Ä¢ Min: 1200\n",
      "   ‚Ä¢ Max: 2823\n",
      "   ‚Ä¢ Mean: 1765.12\n",
      "   ‚Ä¢ Median: 1762\n",
      "   ‚Ä¢ Std Dev: 249.34\n",
      "\n",
      "4Ô∏è‚É£  Quartile statistics:\n",
      "   ‚Ä¢ 25th percentile: 1584\n",
      "   ‚Ä¢ 50th percentile (median): 1762\n",
      "   ‚Ä¢ 75th percentile: 1936\n",
      "\n",
      "5Ô∏è‚É£  Detailed percentile distribution (5% increments):\n",
      "\n",
      "   Percentile   Rating     Visual\n",
      "   ------------ ---------- ----------------------------------------\n",
      "       0%          1200    \n",
      "       5%          1358    ‚ñà‚ñà‚ñà\n",
      "      10%          1435    ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      15%          1494    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      20%          1541    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      25%          1584    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      30%          1623    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      35%          1659    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      40%          1696    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      45%          1728    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      50%          1762    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      55%          1798    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      60%          1829    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      65%          1864    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      70%          1901    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      75%          1936    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      80%          1980    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      85%          2027    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      90%          2088    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      95%          2184    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     100%          2823    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "6Ô∏è‚É£  Rating distribution by range:\n",
      "\n",
      "   Range           Count      Percentage   Visual\n",
      "   --------------- ---------- ------------ ----------------------------------------\n",
      "      0-1000           0      0.00%      \n",
      "   1000-1200           0      0.00%      \n",
      "   1200-1400       3,592      7.41%      ‚ñà‚ñà\n",
      "   1400-1600       9,432     19.46%      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   1600-1800      13,744     28.36%      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   1800-2000      12,882     26.58%      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2000-2200       6,616     13.65%      ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2200-2400       1,850      3.82%      ‚ñà\n",
      "   2400-2600         328      0.68%      \n",
      "   2600-3000          24      0.05%      \n",
      "\n",
      "7Ô∏è‚É£  Spread statistics:\n",
      "   ‚Ä¢ Range: 1623\n",
      "   ‚Ä¢ Interquartile Range (IQR): 352\n",
      "   ‚Ä¢ 10th-90th percentile range: 653\n",
      "\n",
      "8Ô∏è‚É£  Distribution shape:\n",
      "   ‚Ä¢ Skewness: 0.1664 (right-skewed)\n",
      "   ‚Ä¢ Kurtosis: -0.3080 (light-tailed)\n",
      "\n",
      "9Ô∏è‚É£  Sample players at different rating levels:\n",
      "\n",
      "   ~10th percentile (rating ‚âà 1435):\n",
      "      Player 11878: Lathemill - Rating: 1435\n",
      "\n",
      "   ~25th percentile (rating ‚âà 1584):\n",
      "      Player 37028: olmarluzzi - Rating: 1584\n",
      "\n",
      "   ~50th percentile (rating ‚âà 1762):\n",
      "      Player 4322: Chihoto74 - Rating: 1762\n",
      "\n",
      "   ~75th percentile (rating ‚âà 1936):\n",
      "      Player 33361: kzbkv - Rating: 1936\n",
      "\n",
      "   ~90th percentile (rating ‚âà 2088):\n",
      "      Player 28263: engfi9 - Rating: 2088\n",
      "\n",
      "============================================================\n",
      "‚úÖ RATING STATISTICS COMPLETE\n",
      "============================================================\n",
      "\n",
      "Key takeaways:\n",
      "   ‚Ä¢ Total players: 48,468\n",
      "   ‚Ä¢ Rating range: [1200, 2823]\n",
      "   ‚Ä¢ Mean ¬± std: 1765 ¬± 249\n",
      "   ‚Ä¢ Median: 1762\n",
      "\n",
      "   Next steps: Normalize ratings for model input\n"
     ]
    }
   ],
   "source": [
    "# 2c. Gather player rating statistics (no mutation, just exploration)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 2C: PLAYER RATING STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Connect to database and extract player ratings\n",
    "con = get_db_connection(str(DB_PATH))\n",
    "\n",
    "try:\n",
    "    print(f\"\\n1Ô∏è‚É£  Extracting player ratings from database...\")\n",
    "    \n",
    "    # Get unique player IDs from our clean_data\n",
    "    unique_player_ids = clean_data['player_id'].unique()\n",
    "    player_ids_str = ','.join(map(str, unique_player_ids))\n",
    "    \n",
    "    # Query to get player ratings\n",
    "    rating_query = f\"\"\"\n",
    "        SELECT \n",
    "            id as player_id,\n",
    "            name,\n",
    "            title,\n",
    "            rating\n",
    "        FROM player\n",
    "        WHERE id IN ({player_ids_str})\n",
    "    \"\"\"\n",
    "    \n",
    "    player_ratings = pd.DataFrame(con.execute(rating_query).df())\n",
    "    print(f\"   ‚úì Retrieved ratings for {len(player_ratings):,} players\")\n",
    "    \n",
    "finally:\n",
    "    con.close()\n",
    "    print(\"   ‚úì Database connection closed\")\n",
    "\n",
    "# Merge ratings into clean_data for analysis\n",
    "print(f\"\\n2Ô∏è‚É£  Merging ratings with clean_data...\")\n",
    "clean_data_with_ratings = clean_data.merge(player_ratings[['player_id', 'rating']], on='player_id', how='left')\n",
    "print(f\"   ‚úì Merged successfully\")\n",
    "\n",
    "# Check for missing ratings\n",
    "num_missing_ratings = clean_data_with_ratings['rating'].isna().sum()\n",
    "if num_missing_ratings > 0:\n",
    "    print(f\"   ‚ö†Ô∏è  {num_missing_ratings:,} entries ({100*num_missing_ratings/len(clean_data_with_ratings):.2f}%) have missing ratings\")\n",
    "else:\n",
    "    print(f\"   ‚úì All entries have ratings\")\n",
    "\n",
    "# Basic rating statistics\n",
    "print(f\"\\n3Ô∏è‚É£  Basic rating statistics:\")\n",
    "print(f\"   ‚Ä¢ Count: {player_ratings['rating'].notna().sum():,}\")\n",
    "print(f\"   ‚Ä¢ Missing: {player_ratings['rating'].isna().sum():,}\")\n",
    "print(f\"   ‚Ä¢ Min: {player_ratings['rating'].min():.0f}\")\n",
    "print(f\"   ‚Ä¢ Max: {player_ratings['rating'].max():.0f}\")\n",
    "print(f\"   ‚Ä¢ Mean: {player_ratings['rating'].mean():.2f}\")\n",
    "print(f\"   ‚Ä¢ Median: {player_ratings['rating'].median():.0f}\")\n",
    "print(f\"   ‚Ä¢ Std Dev: {player_ratings['rating'].std():.2f}\")\n",
    "\n",
    "# Quartile statistics\n",
    "print(f\"\\n4Ô∏è‚É£  Quartile statistics:\")\n",
    "print(f\"   ‚Ä¢ 25th percentile: {player_ratings['rating'].quantile(0.25):.0f}\")\n",
    "print(f\"   ‚Ä¢ 50th percentile (median): {player_ratings['rating'].quantile(0.50):.0f}\")\n",
    "print(f\"   ‚Ä¢ 75th percentile: {player_ratings['rating'].quantile(0.75):.0f}\")\n",
    "\n",
    "# Granular percentile statistics (5% increments)\n",
    "print(f\"\\n5Ô∏è‚É£  Detailed percentile distribution (5% increments):\")\n",
    "percentiles = [0.00, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50,\n",
    "               0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 1.00]\n",
    "\n",
    "print(f\"\\n   {'Percentile':<12} {'Rating':<10} {'Visual'}\")\n",
    "print(f\"   {'-'*12} {'-'*10} {'-'*40}\")\n",
    "\n",
    "for p in percentiles:\n",
    "    rating_value = player_ratings['rating'].quantile(p)\n",
    "    # Create a simple bar visualization\n",
    "    bar_length = int((rating_value - player_ratings['rating'].min()) / \n",
    "                     (player_ratings['rating'].max() - player_ratings['rating'].min()) * 40)\n",
    "    bar = '‚ñà' * bar_length\n",
    "    print(f\"   {p*100:>5.0f}%       {rating_value:>7.0f}    {bar}\")\n",
    "\n",
    "# Rating ranges and counts\n",
    "print(f\"\\n6Ô∏è‚É£  Rating distribution by range:\")\n",
    "rating_ranges = [\n",
    "    (0, 1000), (1000, 1200), (1200, 1400), (1400, 1600), \n",
    "    (1600, 1800), (1800, 2000), (2000, 2200), (2200, 2400), \n",
    "    (2400, 2600), (2600, 3000)\n",
    "]\n",
    "\n",
    "print(f\"\\n   {'Range':<15} {'Count':<10} {'Percentage':<12} {'Visual'}\")\n",
    "print(f\"   {'-'*15} {'-'*10} {'-'*12} {'-'*40}\")\n",
    "\n",
    "for low, high in rating_ranges:\n",
    "    count = len(player_ratings[(player_ratings['rating'] >= low) & (player_ratings['rating'] < high)])\n",
    "    pct = 100 * count / len(player_ratings)\n",
    "    bar_length = int(pct * 0.4)  # Scale for visualization\n",
    "    bar = '‚ñà' * bar_length\n",
    "    print(f\"   {low:>4}-{high:<8} {count:>7,}    {pct:>6.2f}%      {bar}\")\n",
    "\n",
    "# Interquartile range\n",
    "iqr = player_ratings['rating'].quantile(0.75) - player_ratings['rating'].quantile(0.25)\n",
    "print(f\"\\n7Ô∏è‚É£  Spread statistics:\")\n",
    "print(f\"   ‚Ä¢ Range: {player_ratings['rating'].max() - player_ratings['rating'].min():.0f}\")\n",
    "print(f\"   ‚Ä¢ Interquartile Range (IQR): {iqr:.0f}\")\n",
    "print(f\"   ‚Ä¢ 10th-90th percentile range: {player_ratings['rating'].quantile(0.90) - player_ratings['rating'].quantile(0.10):.0f}\")\n",
    "\n",
    "# Skewness and kurtosis if available\n",
    "try:\n",
    "    from scipy.stats import skew, kurtosis\n",
    "    skewness = skew(player_ratings['rating'].dropna())\n",
    "    kurt = kurtosis(player_ratings['rating'].dropna())\n",
    "    print(f\"\\n8Ô∏è‚É£  Distribution shape:\")\n",
    "    print(f\"   ‚Ä¢ Skewness: {skewness:.4f} {'(right-skewed)' if skewness > 0 else '(left-skewed)' if skewness < 0 else '(symmetric)'}\")\n",
    "    print(f\"   ‚Ä¢ Kurtosis: {kurt:.4f} {'(heavy-tailed)' if kurt > 0 else '(light-tailed)' if kurt < 0 else '(normal)'}\")\n",
    "except ImportError:\n",
    "    print(f\"\\n8Ô∏è‚É£  Distribution shape:\")\n",
    "    print(f\"   ‚Ä¢ scipy not available for skewness/kurtosis calculation\")\n",
    "\n",
    "# Sample of players at different rating levels\n",
    "print(f\"\\n9Ô∏è‚É£  Sample players at different rating levels:\")\n",
    "sample_percentiles = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "for p in sample_percentiles:\n",
    "    rating_threshold = player_ratings['rating'].quantile(p)\n",
    "    # Get a player near this rating\n",
    "    sample_player = player_ratings.iloc[(player_ratings['rating'] - rating_threshold).abs().argsort()[:1]]\n",
    "    print(f\"\\n   ~{p*100:.0f}th percentile (rating ‚âà {rating_threshold:.0f}):\")\n",
    "    for idx, row in sample_player.iterrows():\n",
    "        # print(f\"      Player {row['player_id']}: {row['name']} - Rating: {row['rating']:.0f} {f'({row['title']})' if pd.notna(row['title']) else ''}\")\n",
    "        title_str = f\" ({row['title']})\" if pd.notna(row['title']) else \"\"\n",
    "        print(f\"      Player {row['player_id']}: {row['name']} - Rating: {row['rating']:.0f}{title_str}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ RATING STATISTICS COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nKey takeaways:\")\n",
    "print(f\"   ‚Ä¢ Total players: {len(player_ratings):,}\")\n",
    "print(f\"   ‚Ä¢ Rating range: [{player_ratings['rating'].min():.0f}, {player_ratings['rating'].max():.0f}]\")\n",
    "print(f\"   ‚Ä¢ Mean ¬± std: {player_ratings['rating'].mean():.0f} ¬± {player_ratings['rating'].std():.0f}\")\n",
    "print(f\"   ‚Ä¢ Median: {player_ratings['rating'].median():.0f}\")\n",
    "print(f\"\\n   Next steps: Normalize ratings for model input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8ab6b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 2D: NORMALIZE PLAYER RATINGS (SIDE INFORMATION)\n",
      "============================================================\n",
      "\n",
      "‚öôÔ∏è  Normalization strategy: Z-score\n",
      "   ‚Ä¢ Formula: (rating - mean) / std\n",
      "   ‚Ä¢ Purpose: Scale ratings for use as side information in MF model\n",
      "   ‚Ä¢ Storage: SEPARATE lookup table, NOT merged into clean_data\n",
      "   ‚Ä¢ Usage: Model will lookup player_id ‚Üí rating_z during training\n",
      "\n",
      "1Ô∏è‚É£  Normalization parameters (calculated from 48,468 players):\n",
      "   ‚Ä¢ Mean: 1765.12\n",
      "   ‚Ä¢ Std Dev: 249.34\n",
      "\n",
      "2Ô∏è‚É£  Normalized rating statistics:\n",
      "   ‚Ä¢ Min: -2.2665\n",
      "   ‚Ä¢ Max: 4.2428\n",
      "   ‚Ä¢ Mean: -0.000000 (should be ~0)\n",
      "   ‚Ä¢ Std: 1.000000 (should be ~1)\n",
      "   ‚Ä¢ Range: [-2.27, 4.24]\n",
      "\n",
      "3Ô∏è‚É£  Sample normalized ratings across skill levels:\n",
      "   ~10th percentile: Player 11489 | Rating: 1435 ‚Üí Z-score: -1.324\n",
      "   ~25th percentile: Player 35903 | Rating: 1584 ‚Üí Z-score: -0.726\n",
      "   ~50th percentile: Player 4177 | Rating: 1762 ‚Üí Z-score: -0.013\n",
      "   ~75th percentile: Player 32366 | Rating: 1936 ‚Üí Z-score:  0.685\n",
      "   ~90th percentile: Player 27401 | Rating: 2088 ‚Üí Z-score:  1.295\n",
      "\n",
      "4Ô∏è‚É£  Interpretation guide:\n",
      "   ‚Ä¢ rating_z ‚âà -2.3: 1200 player (minimum)\n",
      "   ‚Ä¢ rating_z ‚âà -0.7: 1584 player (25th percentile)\n",
      "   ‚Ä¢ rating_z ‚âà  0.0: 1765 player (mean)\n",
      "   ‚Ä¢ rating_z ‚âà 0.7: 1936 player (75th percentile)\n",
      "   ‚Ä¢ rating_z ‚âà 4.2: 2823 player (maximum)\n",
      "\n",
      "5Ô∏è‚É£  Side information table structure:\n",
      "   ‚Ä¢ Shape: (48468, 3)\n",
      "   ‚Ä¢ Columns: ['player_id', 'rating', 'rating_z']\n",
      "   ‚Ä¢ Indexing: Setting player_id as index for O(1) lookups\n",
      "\n",
      "6Ô∏è‚É£  Sample entries from side information table:\n",
      "   Player 14804 | Rating: 1698 ‚Üí Z-score: -0.269\n",
      "   Player 19143 | Rating: 1944 ‚Üí Z-score:  0.717\n",
      "   Player 45753 | Rating: 1780 ‚Üí Z-score:  0.060\n",
      "   Player  5249 | Rating: 2437 ‚Üí Z-score:  2.695\n",
      "   Player 32887 | Rating: 1311 ‚Üí Z-score: -1.821\n",
      "   Player 13320 | Rating: 1595 ‚Üí Z-score: -0.682\n",
      "   Player 18586 | Rating: 1562 ‚Üí Z-score: -0.815\n",
      "   Player 10834 | Rating: 1701 ‚Üí Z-score: -0.257\n",
      "   Player 48602 | Rating: 1518 ‚Üí Z-score: -0.991\n",
      "   Player 40114 | Rating: 2011 ‚Üí Z-score:  0.986\n",
      "\n",
      "7Ô∏è‚É£  Removing unnecessary columns...\n",
      "   ‚úì Dropped 'rating' column (only keeping 'rating_z')\n",
      "   ‚Ä¢ Final columns: ['rating_z']\n",
      "\n",
      "8Ô∏è‚É£  Verifying all clean_data players have ratings:\n",
      "   ‚úì All 48,468 players in clean_data have side information\n",
      "\n",
      "============================================================\n",
      "‚úÖ RATING NORMALIZATION COMPLETE\n",
      "============================================================\n",
      "\n",
      "Created: player_side_info\n",
      "   ‚Ä¢ Shape: (48468, 1)\n",
      "   ‚Ä¢ Index: player_id\n",
      "   ‚Ä¢ Columns: ['rating_z']\n",
      "\n",
      "üìä Data structure summary:\n",
      "   ‚Ä¢ clean_data: 2,897,386 rows (player-opening interactions)\n",
      "   ‚Ä¢ player_side_info: 48,468 rows (one per player)\n",
      "   ‚Ä¢ Rating storage: ONE value per player (not duplicated per interaction)\n",
      "\n",
      "‚ö†Ô∏è  CRITICAL: Save these parameters for inference!\n",
      "   RATING_MEAN = 1765.12\n",
      "   RATING_STD = 249.34\n",
      "\n",
      "   You'll need them to normalize ratings for new users at inference time.\n"
     ]
    }
   ],
   "source": [
    "# 2d. Normalize player ratings using z-score normalization (for use as side information in MF model)\n",
    "\n",
    "# Check if we've already created the player_side_info table\n",
    "if 'player_side_info' in globals() and 'rating_z' in player_side_info.columns:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"‚è≠Ô∏è  SKIPPING STEP 2D: RATING NORMALIZATION\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\n‚úì 'player_side_info' table already exists\")\n",
    "    print(\"   This indicates rating normalization has already been applied.\")\n",
    "    print(f\"\\nPlayer side info shape: {player_side_info.shape}\")\n",
    "    \n",
    "    # Show statistics\n",
    "    print(f\"\\nüìä Existing normalized rating statistics:\")\n",
    "    print(f\"   ‚Ä¢ Min: {player_side_info['rating_z'].min():.4f}\")\n",
    "    print(f\"   ‚Ä¢ Max: {player_side_info['rating_z'].max():.4f}\")\n",
    "    print(f\"   ‚Ä¢ Mean: {player_side_info['rating_z'].mean():.6f} (should be ~0)\")\n",
    "    print(f\"   ‚Ä¢ Std: {player_side_info['rating_z'].std():.6f} (should be ~1)\")\n",
    "    \n",
    "    print(f\"\\nüìã Sample of existing normalized ratings:\")\n",
    "    sample_data = player_side_info.sample(min(10, len(player_side_info)), random_state=42)\n",
    "    for idx, row in sample_data.iterrows():\n",
    "        print(f\"   Player {idx:>5} | {row['name']:<20} | \"\n",
    "              f\"Rating: {row['rating']:>4.0f} ‚Üí Z-score: {row['rating_z']:>6.3f}\")\n",
    "else:\n",
    "    def normalize_player_ratings(player_ratings_df):\n",
    "        \"\"\"\n",
    "        Apply z-score normalization to player ratings for use as side information.\n",
    "        \n",
    "        This creates a SEPARATE table of player-level features, NOT merged into clean_data.\n",
    "        Rating is side information - it describes the player, not the player-opening interaction.\n",
    "        \n",
    "        During training, the model will LOOK UP each player's rating_z from this table.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        player_ratings_df : pd.DataFrame\n",
    "            Player ratings with columns: player_id, name, title, rating\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        tuple: (player_side_info DataFrame, RATING_MEAN, RATING_STD)\n",
    "        \"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"STEP 2D: NORMALIZE PLAYER RATINGS (SIDE INFORMATION)\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        print(f\"\\n‚öôÔ∏è  Normalization strategy: Z-score\")\n",
    "        print(f\"   ‚Ä¢ Formula: (rating - mean) / std\")\n",
    "        print(f\"   ‚Ä¢ Purpose: Scale ratings for use as side information in MF model\")\n",
    "        print(f\"   ‚Ä¢ Storage: SEPARATE lookup table, NOT merged into clean_data\")\n",
    "        print(f\"   ‚Ä¢ Usage: Model will lookup player_id ‚Üí rating_z during training\")\n",
    "        \n",
    "        # Calculate normalization parameters\n",
    "        RATING_MEAN = player_ratings_df['rating'].mean()\n",
    "        RATING_STD = player_ratings_df['rating'].std()\n",
    "        \n",
    "        print(f\"\\n1Ô∏è‚É£  Normalization parameters (calculated from {len(player_ratings_df):,} players):\")\n",
    "        print(f\"   ‚Ä¢ Mean: {RATING_MEAN:.2f}\")\n",
    "        print(f\"   ‚Ä¢ Std Dev: {RATING_STD:.2f}\")\n",
    "        \n",
    "        # Create side information table - only keep player_id and rating for now\n",
    "        player_side_info = player_ratings_df[['player_id', 'rating']].copy()\n",
    "        player_side_info['rating_z'] = (player_side_info['rating'] - RATING_MEAN) / RATING_STD\n",
    "        \n",
    "        print(f\"\\n2Ô∏è‚É£  Normalized rating statistics:\")\n",
    "        print(f\"   ‚Ä¢ Min: {player_side_info['rating_z'].min():.4f}\")\n",
    "        print(f\"   ‚Ä¢ Max: {player_side_info['rating_z'].max():.4f}\")\n",
    "        print(f\"   ‚Ä¢ Mean: {player_side_info['rating_z'].mean():.6f} (should be ~0)\")\n",
    "        print(f\"   ‚Ä¢ Std: {player_side_info['rating_z'].std():.6f} (should be ~1)\")\n",
    "        print(f\"   ‚Ä¢ Range: [{player_side_info['rating_z'].min():.2f}, {player_side_info['rating_z'].max():.2f}]\")\n",
    "        \n",
    "        print(f\"\\n3Ô∏è‚É£  Sample normalized ratings across skill levels:\")\n",
    "        sample_percentiles = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "        for p in sample_percentiles:\n",
    "            rating_threshold = player_side_info['rating'].quantile(p)\n",
    "            sample_player = player_side_info.iloc[(player_side_info['rating'] - rating_threshold).abs().argsort()[:1]]\n",
    "            for idx, row in sample_player.iterrows():\n",
    "                print(f\"   ~{p*100:.0f}th percentile: Player {idx} | \"\n",
    "                      f\"Rating: {row['rating']:>4.0f} ‚Üí Z-score: {row['rating_z']:>6.3f}\")\n",
    "        \n",
    "        print(f\"\\n4Ô∏è‚É£  Interpretation guide:\")\n",
    "        print(f\"   ‚Ä¢ rating_z ‚âà {(1200 - RATING_MEAN)/RATING_STD:.1f}: 1200 player (minimum)\")\n",
    "        print(f\"   ‚Ä¢ rating_z ‚âà {(player_side_info['rating'].quantile(0.25) - RATING_MEAN)/RATING_STD:.1f}: {player_side_info['rating'].quantile(0.25):.0f} player (25th percentile)\")\n",
    "        print(f\"   ‚Ä¢ rating_z ‚âà  0.0: {RATING_MEAN:.0f} player (mean)\")\n",
    "        print(f\"   ‚Ä¢ rating_z ‚âà {(player_side_info['rating'].quantile(0.75) - RATING_MEAN)/RATING_STD:.1f}: {player_side_info['rating'].quantile(0.75):.0f} player (75th percentile)\")\n",
    "        print(f\"   ‚Ä¢ rating_z ‚âà {(player_side_info['rating'].max() - RATING_MEAN)/RATING_STD:.1f}: {player_side_info['rating'].max():.0f} player (maximum)\")\n",
    "        \n",
    "        print(f\"\\n5Ô∏è‚É£  Side information table structure:\")\n",
    "        print(f\"   ‚Ä¢ Shape: {player_side_info.shape}\")\n",
    "        print(f\"   ‚Ä¢ Columns: {list(player_side_info.columns)}\")\n",
    "        print(f\"   ‚Ä¢ Indexing: Setting player_id as index for O(1) lookups\")\n",
    "        \n",
    "        # Set player_id as index for fast lookups\n",
    "        player_side_info = player_side_info.set_index('player_id')\n",
    "        \n",
    "        print(f\"\\n6Ô∏è‚É£  Sample entries from side information table:\")\n",
    "        sample_data = player_side_info.sample(min(10, len(player_side_info)), random_state=42)\n",
    "        for idx, row in sample_data.iterrows():\n",
    "            print(f\"   Player {idx:>5} | Rating: {row['rating']:>4.0f} ‚Üí Z-score: {row['rating_z']:>6.3f}\")\n",
    "        \n",
    "        print(f\"\\n7Ô∏è‚É£  Removing unnecessary columns...\")\n",
    "        # Drop rating column - we only need rating_z for the model\n",
    "        player_side_info = player_side_info.drop(columns=['rating'])\n",
    "        print(f\"   ‚úì Dropped 'rating' column (only keeping 'rating_z')\")\n",
    "        print(f\"   ‚Ä¢ Final columns: {list(player_side_info.columns)}\")\n",
    "        \n",
    "        print(f\"\\n8Ô∏è‚É£  Verifying all clean_data players have ratings:\")\n",
    "        # This is important - make sure every player in clean_data has a rating\n",
    "        missing_players = set(clean_data['player_id'].unique()) - set(player_side_info.index)\n",
    "        if len(missing_players) > 0:\n",
    "            print(f\"   ‚ö†Ô∏è  WARNING: {len(missing_players)} players in clean_data are missing from side_info!\")\n",
    "            print(f\"   Missing player IDs: {sorted(list(missing_players))[:10]}...\")\n",
    "        else:\n",
    "            print(f\"   ‚úì All {len(player_side_info):,} players in clean_data have side information\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"‚úÖ RATING NORMALIZATION COMPLETE\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"\\nCreated: player_side_info\")\n",
    "        print(f\"   ‚Ä¢ Shape: {player_side_info.shape}\")\n",
    "        print(f\"   ‚Ä¢ Index: player_id\")\n",
    "        print(f\"   ‚Ä¢ Columns: {list(player_side_info.columns)}\")\n",
    "        \n",
    "        print(f\"\\nüìä Data structure summary:\")\n",
    "        print(f\"   ‚Ä¢ clean_data: {clean_data.shape[0]:,} rows (player-opening interactions)\")\n",
    "        print(f\"   ‚Ä¢ player_side_info: {len(player_side_info):,} rows (one per player)\")\n",
    "        print(f\"   ‚Ä¢ Rating storage: ONE value per player (not duplicated per interaction)\")\n",
    "        \n",
    "        print(f\"\\n‚ö†Ô∏è  CRITICAL: Save these parameters for inference!\")\n",
    "        print(f\"   RATING_MEAN = {RATING_MEAN:.2f}\")\n",
    "        print(f\"   RATING_STD = {RATING_STD:.2f}\")\n",
    "        print(f\"\\n   You'll need them to normalize ratings for new users at inference time.\")\n",
    "        \n",
    "        return player_side_info, RATING_MEAN, RATING_STD\n",
    "    \n",
    "    # Call the function\n",
    "    player_side_info, RATING_MEAN, RATING_STD = normalize_player_ratings(player_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14eba9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         player_id  opening_id  num_games     score  eco  confidence\n",
      "2069701      34950        2004         14  0.409109  C45    0.218750\n",
      "1262289      21411         730        171  0.542647  B00    0.773756\n",
      "1086302      18347         978         20  0.500723  B15    0.285714\n",
      "349268        5901         632         12  0.556795  A83    0.193548\n",
      "1182563      20017         758         14  0.529109  B01    0.218750\n",
      "962731       16206         509         85  0.509538  A48    0.629630\n",
      "823244       13846         305         16  0.455946  A18    0.242424\n",
      "1287297      21829         854         28  0.491564  B06    0.358974\n",
      "555788        9363        1878         14  0.590201  C41    0.218750\n",
      "1159938      19626        1974         13  0.505488  C44    0.206349\n",
      "1608640      27196        1829         12  0.509032  C40    0.193548\n",
      "1502388      25416         677         11  0.486199  B00    0.180328\n",
      "1378713      23366        1683         17  0.496894  C31    0.253731\n",
      "1794233      30289        1165         24  0.485119  B40    0.324324\n",
      "93289         1587        1167        471  0.575464  B40    0.904031\n",
      "2011557      33959         725         19  0.508850  B00    0.275362\n",
      "400720        6763        3485         37  0.539657  C43    0.425287\n",
      "130921        2206        2277         50  0.497505  C69    0.500000\n",
      "1671755      28223         857         13  0.527266  B06    0.206349\n",
      "1014486      17105        3103         59  0.540210  E90    0.541284\n"
     ]
    }
   ],
   "source": [
    "print(clean_data.sample(20).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac119ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           rating_z\n",
      "player_id          \n",
      "19104      1.150568\n",
      "9524       0.500840\n",
      "34689      0.781587\n",
      "40105      0.139880\n",
      "49582      0.641213\n",
      "21108     -0.846744\n",
      "11525      0.296296\n",
      "6069       0.629181\n",
      "35450     -0.706371\n",
      "46661     -0.878830\n"
     ]
    }
   ],
   "source": [
    "print(player_side_info.sample(10).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30280db",
   "metadata": {},
   "source": [
    "## Step 3: Train/Test/Val splits\n",
    "\n",
    "Here, I split my data and drop columns that are no longer needed. We're very close to being able to train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaf3849a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 3: TRAIN/VALIDATION/TEST SPLIT\n",
      "============================================================\n",
      "\n",
      "‚öôÔ∏è  Configuration:\n",
      "   ‚Ä¢ Train: 75%\n",
      "   ‚Ä¢ Validation: 15%\n",
      "   ‚Ä¢ Test: 10%\n",
      "   ‚Ä¢ Random seed: 42 (for reproducibility)\n",
      "\n",
      "1Ô∏è‚É£  Preparing data for split...\n",
      "   ‚Ä¢ Features (X): (2897386, 4)\n",
      "   ‚Ä¢ Target (y): (2897386,)\n",
      "   ‚Ä¢ Feature columns: ['player_id', 'opening_id', 'eco', 'confidence']\n",
      "\n",
      "2Ô∏è‚É£  Cleaning player side information...\n",
      "   ‚Ä¢ Original player_side_info shape: (48468, 1)\n",
      "   ‚Ä¢ Cleaned player_side_info shape: (48468, 1)\n",
      "   ‚Ä¢ Columns: ['rating_z']\n",
      "\n",
      "3Ô∏è‚É£  Splitting data (optimized approach)...\n",
      "   ‚Ä¢ Train: 2,173,039 samples (75.0%)\n",
      "   ‚Ä¢ Validation: 434,608 samples (15.0%)\n",
      "   ‚Ä¢ Test: 289,739 samples (10.0%)\n",
      "\n",
      "4Ô∏è‚É£  Verification:\n",
      "   ‚Ä¢ Total samples: 2,897,386 (should equal 2,897,386)\n",
      "   ‚Ä¢ Train %: 75.00% (target: 75%)\n",
      "   ‚Ä¢ Val %: 15.00% (target: 15%)\n",
      "   ‚Ä¢ Test %: 10.00% (target: 10%)\n",
      "\n",
      "5Ô∏è‚É£  Computing coverage statistics (cached)...\n",
      "\n",
      "   Players:\n",
      "   ‚Ä¢ Train: 48,410 unique players\n",
      "   ‚Ä¢ Val: 47,479 unique players\n",
      "   ‚Ä¢ Test: 46,493 unique players\n",
      "   ‚Ä¢ Total unique: 48,468 players\n",
      "\n",
      "   Openings:\n",
      "   ‚Ä¢ Train: 2,688 unique openings\n",
      "   ‚Ä¢ Val: 2,458 unique openings\n",
      "   ‚Ä¢ Test: 2,351 unique openings\n",
      "   ‚Ä¢ Total unique: 2,714 openings\n",
      "\n",
      "6Ô∏è‚É£  Cold start analysis (vectorized)...\n",
      "\n",
      "   Validation set:\n",
      "   ‚Ä¢ Players not in train: 39 (0.1%)\n",
      "   ‚Ä¢ Openings not in train: 20 (0.8%)\n",
      "\n",
      "   Test set:\n",
      "   ‚Ä¢ Players not in train: 27 (0.1%)\n",
      "   ‚Ä¢ Openings not in train: 9 (0.4%)\n",
      "\n",
      "7Ô∏è‚É£  Score distribution across splits:\n",
      "\n",
      "   Train:\n",
      "   ‚Ä¢ Mean: 0.5120\n",
      "   ‚Ä¢ Std: 0.0411\n",
      "   ‚Ä¢ Min: 0.1004\n",
      "   ‚Ä¢ Max: 1.0000\n",
      "\n",
      "   Validation:\n",
      "   ‚Ä¢ Mean: 0.5119\n",
      "   ‚Ä¢ Std: 0.0412\n",
      "   ‚Ä¢ Min: 0.1885\n",
      "   ‚Ä¢ Max: 0.8257\n",
      "\n",
      "   Test:\n",
      "   ‚Ä¢ Mean: 0.5121\n",
      "   ‚Ä¢ Std: 0.0411\n",
      "   ‚Ä¢ Min: 0.2244\n",
      "   ‚Ä¢ Max: 0.7754\n",
      "\n",
      "8Ô∏è‚É£  Confidence distribution across splits:\n",
      "\n",
      "   Train:\n",
      "   ‚Ä¢ Mean: 0.4147\n",
      "   ‚Ä¢ Median: 0.3506\n",
      "\n",
      "   Validation:\n",
      "   ‚Ä¢ Mean: 0.4148\n",
      "   ‚Ä¢ Median: 0.3506\n",
      "\n",
      "   Test:\n",
      "   ‚Ä¢ Mean: 0.4146\n",
      "   ‚Ä¢ Median: 0.3506\n",
      "\n",
      "============================================================\n",
      "‚úÖ DATA SPLIT COMPLETE\n",
      "============================================================\n",
      "\n",
      "üìä Summary:\n",
      "   ‚Ä¢ Training data: 2,173,039 samples (75%)\n",
      "   ‚Ä¢ Validation data: 434,608 samples (15%)\n",
      "   ‚Ä¢ Test data: 289,739 samples (10%)\n",
      "   ‚Ä¢ Player side info: 48,468 players\n",
      "   ‚Ä¢ Side info columns: ['rating_z']\n",
      "\n",
      "üì¶ Available datasets:\n",
      "   ‚Ä¢ X_train, y_train - Training features and targets\n",
      "   ‚Ä¢ X_val, y_val - Validation features and targets\n",
      "   ‚Ä¢ X_test, y_test - Test features and targets\n",
      "   ‚Ä¢ player_side_info_clean - Player ratings (indexed by player_id)\n",
      "\n",
      "üí° Next steps:\n",
      "   ‚Ä¢ Enumerate ECO codes as categorical features\n",
      "   ‚Ä¢ Convert to PyTorch tensors\n",
      "   ‚Ä¢ Build matrix factorization model with side information\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Train/Validation/Test Split (75/15/10) - OPTIMIZED\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 3: TRAIN/VALIDATION/TEST SPLIT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è  Configuration:\")\n",
    "print(f\"   ‚Ä¢ Train: 75%\")\n",
    "print(f\"   ‚Ä¢ Validation: 15%\")\n",
    "print(f\"   ‚Ä¢ Test: 10%\")\n",
    "print(f\"   ‚Ä¢ Random seed: 42 (for reproducibility)\")\n",
    "\n",
    "# Prepare the data\n",
    "print(f\"\\n1Ô∏è‚É£  Preparing data for split...\")\n",
    "\n",
    "# Drop num_games from clean_data - we don't need it for training\n",
    "# Keep: player_id, opening_id, score, eco, confidence\n",
    "X = clean_data[[\"player_id\", \"opening_id\", \"eco\", \"confidence\"]].copy()\n",
    "y = clean_data[\"score\"].copy()\n",
    "\n",
    "print(f\"   ‚Ä¢ Features (X): {X.shape}\")\n",
    "print(f\"   ‚Ä¢ Target (y): {y.shape}\")\n",
    "print(f\"   ‚Ä¢ Feature columns: {list(X.columns)}\")\n",
    "\n",
    "# Clean up player_side_info - only keep rating_z\n",
    "print(f\"\\n2Ô∏è‚É£  Cleaning player side information...\")\n",
    "player_side_info_clean = player_side_info[[\"rating_z\"]].copy()\n",
    "print(f\"   ‚Ä¢ Original player_side_info shape: {player_side_info.shape}\")\n",
    "print(f\"   ‚Ä¢ Cleaned player_side_info shape: {player_side_info_clean.shape}\")\n",
    "print(f\"   ‚Ä¢ Columns: {list(player_side_info_clean.columns)}\")\n",
    "\n",
    "# OPTIMIZED: Use index-based splitting to avoid DataFrame copies\n",
    "print(f\"\\n3Ô∏è‚É£  Splitting data (optimized approach)...\")\n",
    "idx = np.arange(len(X))\n",
    "\n",
    "# First split: separate out test set (10%)\n",
    "idx_temp, idx_test = train_test_split(idx, test_size=0.10, random_state=42, shuffle=True)\n",
    "\n",
    "# Second split: split remaining into train (75%) and val (15%)\n",
    "# 15% of original = 15/90 ‚âà 0.1667 of temp\n",
    "idx_train, idx_val = train_test_split(idx_temp, test_size=15/90, random_state=42, shuffle=True)\n",
    "\n",
    "# Create splits using iloc (view, not copy)\n",
    "X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n",
    "X_val, y_val = X.iloc[idx_val], y.iloc[idx_val]\n",
    "X_test, y_test = X.iloc[idx_test], y.iloc[idx_test]\n",
    "\n",
    "print(f\"   ‚Ä¢ Train: {len(X_train):,} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Validation: {len(X_val):,} samples ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Test: {len(X_test):,} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Verify the split\n",
    "print(f\"\\n4Ô∏è‚É£  Verification:\")\n",
    "total = len(X_train) + len(X_val) + len(X_test)\n",
    "print(f\"   ‚Ä¢ Total samples: {total:,} (should equal {len(X):,})\")\n",
    "print(f\"   ‚Ä¢ Train %: {len(X_train)/total*100:.2f}% (target: 75%)\")\n",
    "print(f\"   ‚Ä¢ Val %: {len(X_val)/total*100:.2f}% (target: 15%)\")\n",
    "print(f\"   ‚Ä¢ Test %: {len(X_test)/total*100:.2f}% (target: 10%)\")\n",
    "\n",
    "# OPTIMIZED: Pre-compute unique arrays once\n",
    "print(f\"\\n5Ô∏è‚É£  Computing coverage statistics (cached)...\")\n",
    "players_train = X_train[\"player_id\"].unique()\n",
    "players_val = X_val[\"player_id\"].unique()\n",
    "players_test = X_test[\"player_id\"].unique()\n",
    "\n",
    "openings_train = X_train[\"opening_id\"].unique()\n",
    "openings_val = X_val[\"opening_id\"].unique()\n",
    "openings_test = X_test[\"opening_id\"].unique()\n",
    "\n",
    "print(f\"\\n   Players:\")\n",
    "print(f\"   ‚Ä¢ Train: {len(players_train):,} unique players\")\n",
    "print(f\"   ‚Ä¢ Val: {len(players_val):,} unique players\")\n",
    "print(f\"   ‚Ä¢ Test: {len(players_test):,} unique players\")\n",
    "print(f\"   ‚Ä¢ Total unique: {X['player_id'].nunique():,} players\")\n",
    "\n",
    "print(f\"\\n   Openings:\")\n",
    "print(f\"   ‚Ä¢ Train: {len(openings_train):,} unique openings\")\n",
    "print(f\"   ‚Ä¢ Val: {len(openings_val):,} unique openings\")\n",
    "print(f\"   ‚Ä¢ Test: {len(openings_test):,} unique openings\")\n",
    "print(f\"   ‚Ä¢ Total unique: {X['opening_id'].nunique():,} openings\")\n",
    "\n",
    "# OPTIMIZED: Use NumPy setdiff1d for cold-start analysis (C-speed)\n",
    "print(f\"\\n6Ô∏è‚É£  Cold start analysis (vectorized)...\")\n",
    "\n",
    "val_cold_players = np.setdiff1d(players_val, players_train, assume_unique=True)\n",
    "val_cold_openings = np.setdiff1d(openings_val, openings_train, assume_unique=True)\n",
    "\n",
    "test_cold_players = np.setdiff1d(players_test, players_train, assume_unique=True)\n",
    "test_cold_openings = np.setdiff1d(openings_test, openings_train, assume_unique=True)\n",
    "\n",
    "print(f\"\\n   Validation set:\")\n",
    "print(f\"   ‚Ä¢ Players not in train: {len(val_cold_players):,} ({len(val_cold_players)/len(players_val)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Openings not in train: {len(val_cold_openings):,} ({len(val_cold_openings)/len(openings_val)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n   Test set:\")\n",
    "print(f\"   ‚Ä¢ Players not in train: {len(test_cold_players):,} ({len(test_cold_players)/len(players_test)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Openings not in train: {len(test_cold_openings):,} ({len(test_cold_openings)/len(openings_test)*100:.1f}%)\")\n",
    "\n",
    "# OPTIMIZED: Compute stats in one pass using describe()\n",
    "print(f\"\\n7Ô∏è‚É£  Score distribution across splits:\")\n",
    "\n",
    "y_train_stats = y_train.describe()\n",
    "y_val_stats = y_val.describe()\n",
    "y_test_stats = y_test.describe()\n",
    "\n",
    "print(f\"\\n   Train:\")\n",
    "print(f\"   ‚Ä¢ Mean: {y_train_stats['mean']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Std: {y_train_stats['std']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Min: {y_train_stats['min']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Max: {y_train_stats['max']:.4f}\")\n",
    "\n",
    "print(f\"\\n   Validation:\")\n",
    "print(f\"   ‚Ä¢ Mean: {y_val_stats['mean']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Std: {y_val_stats['std']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Min: {y_val_stats['min']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Max: {y_val_stats['max']:.4f}\")\n",
    "\n",
    "print(f\"\\n   Test:\")\n",
    "print(f\"   ‚Ä¢ Mean: {y_test_stats['mean']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Std: {y_test_stats['std']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Min: {y_test_stats['min']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Max: {y_test_stats['max']:.4f}\")\n",
    "\n",
    "# OPTIMIZED: Compute confidence stats in one pass\n",
    "print(f\"\\n8Ô∏è‚É£  Confidence distribution across splits:\")\n",
    "\n",
    "conf_train_stats = X_train['confidence'].describe()\n",
    "conf_val_stats = X_val['confidence'].describe()\n",
    "conf_test_stats = X_test['confidence'].describe()\n",
    "\n",
    "print(f\"\\n   Train:\")\n",
    "print(f\"   ‚Ä¢ Mean: {conf_train_stats['mean']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Median: {conf_train_stats['50%']:.4f}\")\n",
    "\n",
    "print(f\"\\n   Validation:\")\n",
    "print(f\"   ‚Ä¢ Mean: {conf_val_stats['mean']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Median: {conf_val_stats['50%']:.4f}\")\n",
    "\n",
    "print(f\"\\n   Test:\")\n",
    "print(f\"   ‚Ä¢ Mean: {conf_test_stats['mean']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Median: {conf_test_stats['50%']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ DATA SPLIT COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä Summary:\")\n",
    "print(f\"   ‚Ä¢ Training data: {len(X_train):,} samples (75%)\")\n",
    "print(f\"   ‚Ä¢ Validation data: {len(X_val):,} samples (15%)\")\n",
    "print(f\"   ‚Ä¢ Test data: {len(X_test):,} samples (10%)\")\n",
    "print(f\"   ‚Ä¢ Player side info: {len(player_side_info_clean):,} players\")\n",
    "print(f\"   ‚Ä¢ Side info columns: {list(player_side_info_clean.columns)}\")\n",
    "\n",
    "print(f\"\\nüì¶ Available datasets:\")\n",
    "print(f\"   ‚Ä¢ X_train, y_train - Training features and targets\")\n",
    "print(f\"   ‚Ä¢ X_val, y_val - Validation features and targets\")\n",
    "print(f\"   ‚Ä¢ X_test, y_test - Test features and targets\")\n",
    "print(f\"   ‚Ä¢ player_side_info_clean - Player ratings (indexed by player_id)\")\n",
    "\n",
    "print(f\"\\nüí° Next steps:\")\n",
    "print(f\"   ‚Ä¢ Enumerate ECO codes as categorical features\")\n",
    "print(f\"   ‚Ä¢ Convert to PyTorch tensors\")\n",
    "print(f\"   ‚Ä¢ Build matrix factorization model with side information\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4781a382",
   "metadata": {},
   "source": [
    "## Step 3b: Remap Player and Opening IDs to Sequential Integers\n",
    "\n",
    "**Why remap IDs?**\n",
    "- Database IDs may have gaps (e.g., [1, 5, 10, 15, ...]) from deleted entries\n",
    "- Embedding layers need 0-based contiguous indices for efficiency\n",
    "- Remapping saves memory (no unused embedding slots)\n",
    "\n",
    "**Process:**\n",
    "1. Check if IDs are already sequential (0 or 1-based with no gaps)\n",
    "2. If not, create mappings: old_id ‚Üí new_sequential_id\n",
    "3. Remap all DataFrames and side info tables\n",
    "4. Verify mappings with spot checks\n",
    "\n",
    "This ensures embeddings use minimal memory and indices align properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81b4c409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 3B: REMAP IDs TO SEQUENTIAL INTEGERS\n",
      "============================================================\n",
      "\n",
      "1Ô∏è‚É£  Processing player IDs...\n",
      "\n",
      "============================================================\n",
      "Checking player IDs...\n",
      "============================================================\n",
      "   ‚Ä¢ Total unique players: 48468\n",
      "   ‚Ä¢ ID range: [1, 50000]\n",
      "   ‚ö†Ô∏è  player IDs have gaps - will remap to 0-based sequential\n",
      "   ‚Ä¢ Number of gaps: 1532\n",
      "   ‚Ä¢ Wasted embedding slots without remapping: 1532\n",
      "\n",
      "   Creating mapping...\n",
      "   ‚Ä¢ Example mappings:\n",
      "      player_id 1 ‚Üí 0\n",
      "      player_id 2 ‚Üí 1\n",
      "      player_id 3 ‚Üí 2\n",
      "      player_id 4 ‚Üí 3\n",
      "      player_id 5 ‚Üí 4\n",
      "      player_id 49996 ‚Üí 48463\n",
      "      player_id 49997 ‚Üí 48464\n",
      "      player_id 49998 ‚Üí 48465\n",
      "      player_id 49999 ‚Üí 48466\n",
      "      player_id 50000 ‚Üí 48467\n",
      "\n",
      "   Remapping 5 DataFrames...\n",
      "   ‚úì Remapped DataFrame 1/5\n",
      "   ‚úì Remapped DataFrame 2/5\n",
      "   ‚úì Remapped DataFrame 3/5\n",
      "   ‚úì Remapped DataFrame 4/5\n",
      "   ‚úì Remapped DataFrame 5/5\n",
      "\n",
      "   ‚úÖ Player ID remapping complete!\n",
      "\n",
      "2Ô∏è‚É£  Processing opening IDs...\n",
      "\n",
      "============================================================\n",
      "Checking opening IDs...\n",
      "============================================================\n",
      "   ‚Ä¢ Total unique openings: 2714\n",
      "   ‚Ä¢ ID range: [2, 3589]\n",
      "   ‚ö†Ô∏è  opening IDs have gaps - will remap to 0-based sequential\n",
      "   ‚Ä¢ Number of gaps: 874\n",
      "   ‚Ä¢ Wasted embedding slots without remapping: 874\n",
      "\n",
      "   Creating mapping...\n",
      "   ‚Ä¢ Example mappings:\n",
      "      opening_id 2 ‚Üí 0\n",
      "      opening_id 3 ‚Üí 1\n",
      "      opening_id 4 ‚Üí 2\n",
      "      opening_id 5 ‚Üí 3\n",
      "      opening_id 6 ‚Üí 4\n",
      "      opening_id 3571 ‚Üí 2709\n",
      "      opening_id 3572 ‚Üí 2710\n",
      "      opening_id 3575 ‚Üí 2711\n",
      "      opening_id 3584 ‚Üí 2712\n",
      "      opening_id 3589 ‚Üí 2713\n",
      "\n",
      "   Remapping 4 DataFrames...\n",
      "   ‚úì Remapped DataFrame 1/4\n",
      "   ‚úì Remapped DataFrame 2/4\n",
      "   ‚úì Remapped DataFrame 3/4\n",
      "   ‚úì Remapped DataFrame 4/4\n",
      "\n",
      "   ‚úÖ Opening ID remapping complete!\n",
      "\n",
      "3Ô∏è‚É£  Running spot checks to verify ID remapping correctness...\n",
      "   Strategy: Sample entries BEFORE remapping, verify mappings AFTER\n",
      "\n",
      "   Sampling 10 entries from X_train (before remapping was applied)...\n",
      "   ‚Ä¢ Sample indices: [0, 241448, 482896, 724344, 965792, 1207240, 1448688, 1690136, 1931584, 2173038]\n",
      "   ‚Ä¢ These represent: first, evenly spaced middle rows, and last\n",
      "\n",
      "   Verification checks:\n",
      "   #    Row Idx    New Player   New Opening  Confidence   Status         \n",
      "   ---- ---------- ------------ ------------ ------------ ---------------\n",
      "   1    0          1586         533          0.2958       ‚úì PASS         \n",
      "   2    241448     43361        1707         0.1803       ‚úì PASS         \n",
      "   3    482896     2808         1356         0.2308       ‚úì PASS         \n",
      "   4    724344     44824        124          0.1803       ‚úì PASS         \n",
      "   5    965792     42709        863          0.2188       ‚úì PASS         \n",
      "   6    1207240    19327        1403         0.5238       ‚úì PASS         \n",
      "   7    1448688    39200        1498         0.2424       ‚úì PASS         \n",
      "   8    1690136    10360        1593         0.6503       ‚úì PASS         \n",
      "   9    1931584    8548         1596         0.6403       ‚úì PASS         \n",
      "   10   2173038    21032        565          0.5192       ‚úì PASS         \n",
      "\n",
      "   Reverse mapping verification (sample of 3 entries):\n",
      "   #    New‚ÜíOld Player                 New‚ÜíOld Opening               \n",
      "   ---- ------------------------------ ------------------------------\n",
      "   1    1586 ‚Üí 1637                    533 ‚Üí 690                     \n",
      "   6    19327 ‚Üí 19954                  1403 ‚Üí 1817                   \n",
      "   10   21032 ‚Üí 21709                  565 ‚Üí 730                     \n",
      "\n",
      "   ‚úÖ All spot checks passed! ID mappings are correct.\n",
      "\n",
      "4Ô∏è‚É£  Summary:\n",
      "\n",
      "   Player IDs:\n",
      "   ‚Ä¢ Original range: [1, 50000]\n",
      "   ‚Ä¢ New range: [0, 48467]\n",
      "   ‚Ä¢ Mapping saved as: player_id_to_idx, player_idx_to_id\n",
      "\n",
      "   Opening IDs:\n",
      "   ‚Ä¢ Original range: [2, 3589]\n",
      "   ‚Ä¢ New range: [0, 2713]\n",
      "   ‚Ä¢ Mapping saved as: opening_id_to_idx, opening_idx_to_id\n",
      "\n",
      "   Updated DataFrames:\n",
      "   ‚Ä¢ X_train: (2173039, 4)\n",
      "   ‚Ä¢ X_val: (434608, 4)\n",
      "   ‚Ä¢ X_test: (289739, 4)\n",
      "   ‚Ä¢ clean_data: (2897386, 6)\n",
      "   ‚Ä¢ player_side_info: (48468, 1)\n",
      "\n",
      "============================================================\n",
      "‚úÖ ID REMAPPING COMPLETE\n",
      "============================================================\n",
      "\n",
      "üí° Important:\n",
      "   ‚Ä¢ All player_id and opening_id values are now 0-based sequential\n",
      "   ‚Ä¢ Use these for embedding layers: nn.Embedding(num_players, dim)\n",
      "   ‚Ä¢ Save mappings for inference (to convert new user/opening IDs)\n",
      "   ‚Ä¢ player_side_info index is now 0-based sequential player IDs\n"
     ]
    }
   ],
   "source": [
    "# Step 3b: Remap player and opening IDs to 0-based sequential integers\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 3B: REMAP IDs TO SEQUENTIAL INTEGERS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def check_and_remap_ids(df_list, id_column, entity_name):\n",
    "    \"\"\"\n",
    "    Check if IDs are sequential starting from 0, and remap if not.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_list : list of DataFrames\n",
    "        List of DataFrames containing the ID column to check/remap\n",
    "    id_column : str\n",
    "        Name of the ID column ('player_id' or 'opening_id')\n",
    "    entity_name : str\n",
    "        Name for logging ('player' or 'opening')\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple: (df_list with remapped IDs, id_to_idx mapping dict, needs_remapping bool)\n",
    "    \"\"\"\n",
    "    # Get all unique IDs across all dataframes\n",
    "    all_ids = pd.concat([df[id_column] for df in df_list]).unique()\n",
    "    all_ids_sorted = sorted(all_ids)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Checking {entity_name} IDs...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"   ‚Ä¢ Total unique {entity_name}s: {len(all_ids_sorted)}\")\n",
    "    print(f\"   ‚Ä¢ ID range: [{all_ids_sorted[0]}, {all_ids_sorted[-1]}]\")\n",
    "    \n",
    "    # Check if IDs are already 0-based sequential (0, 1, 2, ...)\n",
    "    expected_sequential = list(range(len(all_ids_sorted)))\n",
    "    is_sequential = (all_ids_sorted == expected_sequential)\n",
    "    \n",
    "    if is_sequential:\n",
    "        print(f\"   ‚úì {entity_name} IDs are already 0-based sequential - no remapping needed!\")\n",
    "        return df_list, None, False\n",
    "    \n",
    "    # Check if IDs are 1-based sequential (1, 2, 3, ...)\n",
    "    expected_sequential_1based = list(range(1, len(all_ids_sorted) + 1))\n",
    "    is_sequential_1based = (all_ids_sorted == expected_sequential_1based)\n",
    "    \n",
    "    if is_sequential_1based:\n",
    "        print(f\"   ‚ö†Ô∏è  {entity_name} IDs are 1-based sequential - will remap to 0-based\")\n",
    "    else:\n",
    "        # Calculate gaps\n",
    "        num_gaps = (all_ids_sorted[-1] - all_ids_sorted[0] + 1) - len(all_ids_sorted)\n",
    "        print(f\"   ‚ö†Ô∏è  {entity_name} IDs have gaps - will remap to 0-based sequential\")\n",
    "        print(f\"   ‚Ä¢ Number of gaps: {num_gaps}\")\n",
    "        print(f\"   ‚Ä¢ Wasted embedding slots without remapping: {num_gaps}\")\n",
    "    \n",
    "    # Create mapping: old_id -> new_idx (0-based)\n",
    "    id_to_idx = {old_id: new_idx for new_idx, old_id in enumerate(all_ids_sorted)}\n",
    "    idx_to_id = {new_idx: old_id for old_id, new_idx in id_to_idx.items()}\n",
    "    \n",
    "    print(f\"\\n   Creating mapping...\")\n",
    "    print(f\"   ‚Ä¢ Example mappings:\")\n",
    "    sample_ids = all_ids_sorted[:5] + all_ids_sorted[-5:]\n",
    "    for old_id in sample_ids[:10]:  # Show first 5 and last 5\n",
    "        print(f\"      {entity_name}_id {old_id} ‚Üí {id_to_idx[old_id]}\")\n",
    "    \n",
    "    # Remap all DataFrames\n",
    "    print(f\"\\n   Remapping {len(df_list)} DataFrames...\")\n",
    "    remapped_dfs = []\n",
    "    for i, df in enumerate(df_list):\n",
    "        df_copy = df.copy()\n",
    "        df_copy[id_column] = df_copy[id_column].map(id_to_idx)\n",
    "        remapped_dfs.append(df_copy)\n",
    "        print(f\"   ‚úì Remapped DataFrame {i+1}/{len(df_list)}\")\n",
    "    \n",
    "    return remapped_dfs, (id_to_idx, idx_to_id), True\n",
    "\n",
    "# 1. Remap player IDs\n",
    "print(f\"\\n1Ô∏è‚É£  Processing player IDs...\")\n",
    "player_dfs = [X_train, X_val, X_test, clean_data, player_side_info.reset_index()]\n",
    "remapped_player_dfs, player_mappings, player_remapped = check_and_remap_ids(\n",
    "    player_dfs, 'player_id', 'player'\n",
    ")\n",
    "\n",
    "if player_remapped:\n",
    "    X_train, X_val, X_test, clean_data, player_side_info_remapped = remapped_player_dfs\n",
    "    player_id_to_idx, player_idx_to_id = player_mappings\n",
    "    player_side_info = player_side_info_remapped.set_index('player_id')\n",
    "    print(f\"\\n   ‚úÖ Player ID remapping complete!\")\n",
    "else:\n",
    "    player_id_to_idx, player_idx_to_id = None, None\n",
    "\n",
    "# 2. Remap opening IDs\n",
    "print(f\"\\n2Ô∏è‚É£  Processing opening IDs...\")\n",
    "opening_dfs = [X_train, X_val, X_test, clean_data]\n",
    "remapped_opening_dfs, opening_mappings, opening_remapped = check_and_remap_ids(\n",
    "    opening_dfs, 'opening_id', 'opening'\n",
    ")\n",
    "\n",
    "if opening_remapped:\n",
    "    X_train, X_val, X_test, clean_data = remapped_opening_dfs\n",
    "    opening_id_to_idx, opening_idx_to_id = opening_mappings\n",
    "    print(f\"\\n   ‚úÖ Opening ID remapping complete!\")\n",
    "else:\n",
    "    opening_id_to_idx, opening_idx_to_id = None, None\n",
    "\n",
    "# 3. Spot checks to verify mappings\n",
    "print(f\"\\n3Ô∏è‚É£  Running spot checks to verify ID remapping correctness...\")\n",
    "print(f\"   Strategy: Sample entries BEFORE remapping, verify mappings AFTER\")\n",
    "\n",
    "# Sample 10 entries: first, last, and 8 in between\n",
    "print(f\"\\n   Sampling 10 entries from X_train (before remapping was applied)...\")\n",
    "total_rows = len(X_train)\n",
    "# Get indices: first, last, and 8 evenly spaced in between\n",
    "sample_indices = [0]  # First row\n",
    "step = (total_rows - 1) // 9  # Divide remaining rows into 9 parts\n",
    "sample_indices.extend([min(i * step, total_rows - 1) for i in range(1, 9)])\n",
    "sample_indices.append(total_rows - 1)  # Last row\n",
    "\n",
    "print(f\"   ‚Ä¢ Sample indices: {sample_indices}\")\n",
    "print(f\"   ‚Ä¢ These represent: first, evenly spaced middle rows, and last\")\n",
    "\n",
    "# Store samples with their NEW (remapped) IDs\n",
    "samples = []\n",
    "for idx in sample_indices:\n",
    "    row = X_train.iloc[idx]\n",
    "    samples.append({\n",
    "        'index': idx,\n",
    "        'new_player_id': row['player_id'],\n",
    "        'new_opening_id': row['opening_id'],\n",
    "        'confidence': row['confidence']\n",
    "    })\n",
    "\n",
    "print(f\"\\n   Verification checks:\")\n",
    "print(f\"   {'#':<4} {'Row Idx':<10} {'New Player':<12} {'New Opening':<12} {'Confidence':<12} {'Status':<15}\")\n",
    "print(f\"   {'-'*4} {'-'*10} {'-'*12} {'-'*12} {'-'*12} {'-'*15}\")\n",
    "\n",
    "all_checks_passed = True\n",
    "for i, sample in enumerate(samples, 1):\n",
    "    new_player_id = sample['new_player_id']\n",
    "    new_opening_id = sample['new_opening_id']\n",
    "    confidence = sample['confidence']\n",
    "    idx = sample['index']\n",
    "    \n",
    "    checks = []\n",
    "    \n",
    "    # Check 1: New player ID is valid (0-based sequential)\n",
    "    if player_remapped:\n",
    "        player_valid = 0 <= new_player_id < len(player_id_to_idx)\n",
    "        checks.append((\"player_id\", player_valid))\n",
    "    else:\n",
    "        checks.append((\"player_id\", True))  # No remapping needed means original was valid\n",
    "    \n",
    "    # Check 2: New opening ID is valid (0-based sequential)\n",
    "    if opening_remapped:\n",
    "        opening_valid = 0 <= new_opening_id < len(opening_id_to_idx)\n",
    "        checks.append((\"opening_id\", opening_valid))\n",
    "    else:\n",
    "        checks.append((\"opening_id\", True))  # No remapping needed means original was valid\n",
    "    \n",
    "    # Check 3: Player exists in player_side_info\n",
    "    player_exists = new_player_id in player_side_info.index\n",
    "    checks.append((\"in_side_info\", player_exists))\n",
    "    \n",
    "    # Check 4: Opening exists in clean_data\n",
    "    opening_exists = new_opening_id in clean_data['opening_id'].values\n",
    "    checks.append((\"in_clean\", opening_exists))\n",
    "    \n",
    "    # All checks must pass\n",
    "    all_pass = all(check[1] for check in checks)\n",
    "    status = \"‚úì PASS\" if all_pass else f\"‚úó FAIL ({','.join([c[0] for c in checks if not c[1]])})\"\n",
    "    \n",
    "    if not all_pass:\n",
    "        all_checks_passed = False\n",
    "    \n",
    "    print(f\"   {i:<4} {idx:<10} {new_player_id:<12} {new_opening_id:<12} {confidence:<12.4f} {status:<15}\")\n",
    "\n",
    "# Additional verification: check if we can reverse map\n",
    "if player_remapped or opening_remapped:\n",
    "    print(f\"\\n   Reverse mapping verification (sample of 3 entries):\")\n",
    "    print(f\"   {'#':<4} {'New‚ÜíOld Player':<30} {'New‚ÜíOld Opening':<30}\")\n",
    "    print(f\"   {'-'*4} {'-'*30} {'-'*30}\")\n",
    "    \n",
    "    for i in [0, len(samples)//2, len(samples)-1]:  # First, middle, last\n",
    "        sample = samples[i]\n",
    "        \n",
    "        # Reverse map player\n",
    "        if player_remapped:\n",
    "            old_player = player_idx_to_id.get(sample['new_player_id'], 'NOT_FOUND')\n",
    "            player_str = f\"{sample['new_player_id']} ‚Üí {old_player}\"\n",
    "        else:\n",
    "            player_str = f\"{sample['new_player_id']} (unchanged)\"\n",
    "        \n",
    "        # Reverse map opening\n",
    "        if opening_remapped:\n",
    "            old_opening = opening_idx_to_id.get(sample['new_opening_id'], 'NOT_FOUND')\n",
    "            opening_str = f\"{sample['new_opening_id']} ‚Üí {old_opening}\"\n",
    "        else:\n",
    "            opening_str = f\"{sample['new_opening_id']} (unchanged)\"\n",
    "        \n",
    "        print(f\"   {i+1:<4} {player_str:<30} {opening_str:<30}\")\n",
    "\n",
    "if all_checks_passed:\n",
    "    print(f\"\\n   ‚úÖ All spot checks passed! ID mappings are correct.\")\n",
    "else:\n",
    "    print(f\"\\n   ‚ö†Ô∏è  Some spot checks failed - investigate immediately!\")\n",
    "    raise ValueError(\"ID remapping verification failed!\")\n",
    "\n",
    "# 4. Summary\n",
    "print(f\"\\n4Ô∏è‚É£  Summary:\")\n",
    "print(f\"\\n   Player IDs:\")\n",
    "if player_remapped:\n",
    "    print(f\"   ‚Ä¢ Original range: [{player_idx_to_id[0]}, {player_idx_to_id[len(player_idx_to_id)-1]}]\")\n",
    "    print(f\"   ‚Ä¢ New range: [0, {len(player_idx_to_id)-1}]\")\n",
    "    print(f\"   ‚Ä¢ Mapping saved as: player_id_to_idx, player_idx_to_id\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ No remapping needed - IDs already sequential\")\n",
    "    \n",
    "print(f\"\\n   Opening IDs:\")\n",
    "if opening_remapped:\n",
    "    print(f\"   ‚Ä¢ Original range: [{opening_idx_to_id[0]}, {opening_idx_to_id[len(opening_idx_to_id)-1]}]\")\n",
    "    print(f\"   ‚Ä¢ New range: [0, {len(opening_idx_to_id)-1}]\")\n",
    "    print(f\"   ‚Ä¢ Mapping saved as: opening_id_to_idx, opening_idx_to_id\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ No remapping needed - IDs already sequential\")\n",
    "\n",
    "print(f\"\\n   Updated DataFrames:\")\n",
    "print(f\"   ‚Ä¢ X_train: {X_train.shape}\")\n",
    "print(f\"   ‚Ä¢ X_val: {X_val.shape}\")\n",
    "print(f\"   ‚Ä¢ X_test: {X_test.shape}\")\n",
    "print(f\"   ‚Ä¢ clean_data: {clean_data.shape}\")\n",
    "print(f\"   ‚Ä¢ player_side_info: {player_side_info.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ ID REMAPPING COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüí° Important:\")\n",
    "print(f\"   ‚Ä¢ All player_id and opening_id values are now 0-based sequential\")\n",
    "print(f\"   ‚Ä¢ Use these for embedding layers: nn.Embedding(num_players, dim)\")\n",
    "print(f\"   ‚Ä¢ Save mappings for inference (to convert new user/opening IDs)\")\n",
    "print(f\"   ‚Ä¢ player_side_info index is now 0-based sequential player IDs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a580c0",
   "metadata": {},
   "source": [
    "## 4. Enumerate Categorical Variables\n",
    "\n",
    "I believe the only variable we need to enumerate here is `eco`. That's the broad categorization of a specific opening.\n",
    "\n",
    "Notes:\n",
    "\n",
    "- One ECO code will have many openings\n",
    "- They're sorted by letter, then further by number. For instance, C21 and C44 are in the `C` family.\n",
    "- Maybe we make this side information?\n",
    "\n",
    "First, let's get some data on ECO codes to help us better understand what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9504a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 4: ECO CODE STATISTICS\n",
      "============================================================\n",
      "\n",
      "1Ô∏è‚É£  Overall ECO statistics:\n",
      "   ‚Ä¢ Total unique ECO codes: 458\n",
      "   ‚Ä¢ Total entries: 2,897,386\n",
      "   ‚Ä¢ Missing ECO values: 0\n",
      "\n",
      "2Ô∏è‚É£  Distribution of entries per ECO code:\n",
      "   ‚Ä¢ Mean entries per ECO: 6326.2\n",
      "   ‚Ä¢ Median entries per ECO: 824.0\n",
      "   ‚Ä¢ Min entries: 1\n",
      "   ‚Ä¢ Max entries: 201306\n",
      "   ‚Ä¢ Std: 18381.2\n",
      "\n",
      "3Ô∏è‚É£  ECO families (by first letter):\n",
      "\n",
      "   Family   Count      Percentage   Visual\n",
      "   -------- ---------- ------------ ----------------------------------------\n",
      "   A        510,064     17.60%      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   B        1,048,210     36.18%      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   C        986,802     34.06%      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   D        279,282      9.64%      ‚ñà‚ñà‚ñà\n",
      "   E         73,028      2.52%      ‚ñà\n",
      "\n",
      "4Ô∏è‚É£  Top 20 most common ECO codes:\n",
      "\n",
      "   Rank   ECO    Count      Percentage   Visual\n",
      "   ------ ------ ---------- ------------ ------------------------------\n",
      "   1      B00    201,306      6.95%      ‚ñà‚ñà\n",
      "   2      B01    197,395      6.81%      ‚ñà‚ñà\n",
      "   3      A40    125,555      4.33%      ‚ñà\n",
      "   4      C50    101,140      3.49%      ‚ñà\n",
      "   5      C00     87,231      3.01%      \n",
      "   6      C40     81,504      2.81%      \n",
      "   7      B06     73,297      2.53%      \n",
      "   8      C42     65,651      2.27%      \n",
      "   9      C44     60,584      2.09%      \n",
      "   10     B10     56,868      1.96%      \n",
      "   11     C41     55,420      1.91%      \n",
      "   12     B40     52,371      1.81%      \n",
      "   13     B12     48,820      1.68%      \n",
      "   14     A00     48,448      1.67%      \n",
      "   15     C02     47,939      1.65%      \n",
      "   16     D00     41,248      1.42%      \n",
      "   17     B21     37,746      1.30%      \n",
      "   18     A43     35,770      1.23%      \n",
      "   19     B32     33,880      1.17%      \n",
      "   20     A04     32,859      1.13%      \n",
      "\n",
      "5Ô∏è‚É£  Bottom 20 least common ECO codes:\n",
      "\n",
      "   Rank   ECO    Count      Visual\n",
      "   ------ ------ ---------- ------------------------------\n",
      "   1      D62          9    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2      A97          9    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   3      D68          8    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   4      D98          8    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   5      D29          8    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   6      E78          8    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   7      E79          8    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   8      A63          7    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   9      A72          7    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   10     C76          6    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   11     D49          6    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   12     E55          5    ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   13     D84          5    ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   14     A99          4    ‚ñà‚ñà‚ñà‚ñà\n",
      "   15     B69          4    ‚ñà‚ñà‚ñà‚ñà\n",
      "   16     C94          4    ‚ñà‚ñà‚ñà‚ñà\n",
      "   17     E96          2    ‚ñà‚ñà\n",
      "   18     A93          2    ‚ñà‚ñà\n",
      "   19     E36          1    ‚ñà\n",
      "   20     A98          1    ‚ñà\n",
      "\n",
      "6Ô∏è‚É£  ECO code format analysis:\n",
      "   ‚Ä¢ ECO code lengths:\n",
      "      3 characters: 2,897,386 (100.00%)\n",
      "\n",
      "7Ô∏è‚É£  Sample of ECO codes:\n",
      "   A07, A20, B13, B22, B53, C03, C19, C43, C48, C66, D33, D36, D92, E10, E30, E48, E74, E78, E96, E97\n",
      "\n",
      "8Ô∏è‚É£  ECO distribution across splits:\n",
      "\n",
      "   Train split:\n",
      "   ‚Ä¢ Unique ECO codes: 456\n",
      "   ‚Ä¢ Total entries: 2,173,039\n",
      "\n",
      "   Validation split:\n",
      "   ‚Ä¢ Unique ECO codes: 450\n",
      "   ‚Ä¢ Total entries: 434,608\n",
      "   ‚Ä¢ ECO codes not in train: 2\n",
      "\n",
      "   Test split:\n",
      "   ‚Ä¢ Unique ECO codes: 445\n",
      "   ‚Ä¢ Total entries: 289,739\n",
      "   ‚Ä¢ ECO codes not in train: 1\n",
      "\n",
      "9Ô∏è‚É£  Average score by ECO code:\n",
      "\n",
      "   Top 10 ECO codes by average score:\n",
      "\n",
      "   ECO    Avg Score    Count     \n",
      "   ------ ------------ ----------\n",
      "   C94    0.6046             4\n",
      "   B77    0.5945           551\n",
      "   B85    0.5867            15\n",
      "   D57    0.5862            24\n",
      "   E96    0.5860             2\n",
      "   B71    0.5853           232\n",
      "   B55    0.5819            17\n",
      "   D29    0.5818             8\n",
      "   D49    0.5764             6\n",
      "   E99    0.5733            26\n",
      "\n",
      "   Bottom 10 ECO codes by average score:\n",
      "\n",
      "   ECO    Avg Score    Count     \n",
      "   ------ ------------ ----------\n",
      "   B70    0.4702         4,148\n",
      "   C74    0.4671            23\n",
      "   B58    0.4669            10\n",
      "   A58    0.4620           963\n",
      "   C76    0.4616             6\n",
      "   C38    0.4582         1,648\n",
      "   C99    0.4345            14\n",
      "   E55    0.3855             5\n",
      "   E36    0.3500             1\n",
      "   A98    0.2500             1\n",
      "\n",
      "üîü  ECO codes with highest score variance (may indicate difficulty):\n",
      "\n",
      "   ECO    Variance     Std Dev      Count     \n",
      "   ------ ------------ ------------ ----------\n",
      "   A93    0.0069       0.0829             2\n",
      "   E45    0.0068       0.0823            17\n",
      "   C57    0.0068       0.0822        11,851\n",
      "   A97    0.0061       0.0784             9\n",
      "   C37    0.0044       0.0662         5,901\n",
      "   C51    0.0038       0.0618         3,974\n",
      "   C39    0.0037       0.0605         1,456\n",
      "   C56    0.0036       0.0599         9,571\n",
      "   C31    0.0036       0.0597        10,962\n",
      "   C52    0.0035       0.0592         1,898\n",
      "\n",
      "1Ô∏è‚É£1Ô∏è‚É£  Openings per ECO code:\n",
      "   ‚Ä¢ Mean openings per ECO: 6.5\n",
      "   ‚Ä¢ Median openings per ECO: 3.0\n",
      "   ‚Ä¢ Max openings per ECO: 107\n",
      "   ‚Ä¢ Min openings per ECO: 1\n",
      "\n",
      "   Top 10 ECO codes by number of openings:\n",
      "\n",
      "   ECO    # Openings  \n",
      "   ------ ------------\n",
      "   A00           107\n",
      "   B00            87\n",
      "   D00            86\n",
      "   C42            59\n",
      "   A40            55\n",
      "   B01            45\n",
      "   C44            45\n",
      "   C00            42\n",
      "   B06            40\n",
      "   C33            38\n",
      "\n",
      "============================================================\n",
      "‚úÖ ECO CODE STATISTICS COMPLETE\n",
      "============================================================\n",
      "\n",
      "üìä Key takeaways:\n",
      "   ‚Ä¢ Total unique ECO codes: 458\n",
      "   ‚Ä¢ Most common family: B (1,048,210 entries)\n",
      "   ‚Ä¢ Most common ECO: B00 (201,306 entries)\n",
      "   ‚Ä¢ ECO codes appear in all splits (good for training)\n",
      "\n",
      "üí° Next steps:\n",
      "   ‚Ä¢ Enumerate ECO codes as integers for categorical encoding\n",
      "   ‚Ä¢ Consider ECO as opening-level side information (similar to player ratings)\n",
      "   ‚Ä¢ Verify all ECO codes in validation/test exist in training set\n"
     ]
    }
   ],
   "source": [
    "# Step 4: ECO Code Statistics (no mutations, just exploration)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 4: ECO CODE STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Basic ECO statistics across all data\n",
    "print(f\"\\n1Ô∏è‚É£  Overall ECO statistics:\")\n",
    "print(f\"   ‚Ä¢ Total unique ECO codes: {clean_data['eco'].nunique()}\")\n",
    "print(f\"   ‚Ä¢ Total entries: {len(clean_data):,}\")\n",
    "print(f\"   ‚Ä¢ Missing ECO values: {clean_data['eco'].isna().sum()}\")\n",
    "\n",
    "# ECO value counts\n",
    "eco_counts = clean_data['eco'].value_counts().sort_index()\n",
    "print(f\"\\n2Ô∏è‚É£  Distribution of entries per ECO code:\")\n",
    "print(f\"   ‚Ä¢ Mean entries per ECO: {eco_counts.mean():.1f}\")\n",
    "print(f\"   ‚Ä¢ Median entries per ECO: {eco_counts.median():.1f}\")\n",
    "print(f\"   ‚Ä¢ Min entries: {eco_counts.min()}\")\n",
    "print(f\"   ‚Ä¢ Max entries: {eco_counts.max()}\")\n",
    "print(f\"   ‚Ä¢ Std: {eco_counts.std():.1f}\")\n",
    "\n",
    "# ECO by first letter (family)\n",
    "print(f\"\\n3Ô∏è‚É£  ECO families (by first letter):\")\n",
    "eco_families = clean_data['eco'].str[0].value_counts().sort_index()\n",
    "print(f\"\\n   {'Family':<8} {'Count':<10} {'Percentage':<12} {'Visual'}\")\n",
    "print(f\"   {'-'*8} {'-'*10} {'-'*12} {'-'*40}\")\n",
    "for family, count in eco_families.items():\n",
    "    pct = 100 * count / len(clean_data)\n",
    "    bar_length = int(pct * 0.4)\n",
    "    bar = '‚ñà' * bar_length\n",
    "    print(f\"   {family:<8} {count:>7,}    {pct:>6.2f}%      {bar}\")\n",
    "\n",
    "# Top 20 most common ECO codes\n",
    "print(f\"\\n4Ô∏è‚É£  Top 20 most common ECO codes:\")\n",
    "top_eco = clean_data['eco'].value_counts().head(20)\n",
    "print(f\"\\n   {'Rank':<6} {'ECO':<6} {'Count':<10} {'Percentage':<12} {'Visual'}\")\n",
    "print(f\"   {'-'*6} {'-'*6} {'-'*10} {'-'*12} {'-'*30}\")\n",
    "for i, (eco, count) in enumerate(top_eco.items(), 1):\n",
    "    pct = 100 * count / len(clean_data)\n",
    "    bar_length = int(pct * 0.3)\n",
    "    bar = '‚ñà' * bar_length\n",
    "    print(f\"   {i:<6} {eco:<6} {count:>7,}    {pct:>6.2f}%      {bar}\")\n",
    "\n",
    "# Bottom 20 least common ECO codes\n",
    "print(f\"\\n5Ô∏è‚É£  Bottom 20 least common ECO codes:\")\n",
    "bottom_eco = clean_data['eco'].value_counts().tail(20)\n",
    "print(f\"\\n   {'Rank':<6} {'ECO':<6} {'Count':<10} {'Visual'}\")\n",
    "print(f\"   {'-'*6} {'-'*6} {'-'*10} {'-'*30}\")\n",
    "for i, (eco, count) in enumerate(bottom_eco.items(), 1):\n",
    "    bar_length = min(count, 30)\n",
    "    bar = '‚ñà' * bar_length\n",
    "    print(f\"   {i:<6} {eco:<6} {count:>7,}    {bar}\")\n",
    "\n",
    "# ECO code format analysis\n",
    "print(f\"\\n6Ô∏è‚É£  ECO code format analysis:\")\n",
    "eco_lengths = clean_data['eco'].str.len().value_counts().sort_index()\n",
    "print(f\"   ‚Ä¢ ECO code lengths:\")\n",
    "for length, count in eco_lengths.items():\n",
    "    pct = 100 * count / len(clean_data)\n",
    "    print(f\"      {length} characters: {count:,} ({pct:.2f}%)\")\n",
    "\n",
    "# Check for any unusual ECO codes\n",
    "print(f\"\\n7Ô∏è‚É£  Sample of ECO codes:\")\n",
    "sample_eco = clean_data['eco'].drop_duplicates().sample(min(20, clean_data['eco'].nunique()), random_state=42).sort_values()\n",
    "print(f\"   {', '.join(sample_eco.values)}\")\n",
    "\n",
    "# ECO statistics by split\n",
    "print(f\"\\n8Ô∏è‚É£  ECO distribution across splits:\")\n",
    "print(f\"\\n   Train split:\")\n",
    "print(f\"   ‚Ä¢ Unique ECO codes: {X_train['eco'].nunique()}\")\n",
    "print(f\"   ‚Ä¢ Total entries: {len(X_train):,}\")\n",
    "\n",
    "print(f\"\\n   Validation split:\")\n",
    "print(f\"   ‚Ä¢ Unique ECO codes: {X_val['eco'].nunique()}\")\n",
    "print(f\"   ‚Ä¢ Total entries: {len(X_val):,}\")\n",
    "val_new_eco = set(X_val['eco'].unique()) - set(X_train['eco'].unique())\n",
    "print(f\"   ‚Ä¢ ECO codes not in train: {len(val_new_eco)}\")\n",
    "\n",
    "print(f\"\\n   Test split:\")\n",
    "print(f\"   ‚Ä¢ Unique ECO codes: {X_test['eco'].nunique()}\")\n",
    "print(f\"   ‚Ä¢ Total entries: {len(X_test):,}\")\n",
    "test_new_eco = set(X_test['eco'].unique()) - set(X_train['eco'].unique())\n",
    "print(f\"   ‚Ä¢ ECO codes not in train: {len(test_new_eco)}\")\n",
    "\n",
    "# Average score by ECO code (top 10 and bottom 10)\n",
    "print(f\"\\n9Ô∏è‚É£  Average score by ECO code:\")\n",
    "eco_scores = clean_data.groupby('eco')['score'].agg(['mean', 'count']).sort_values('mean', ascending=False)\n",
    "\n",
    "print(f\"\\n   Top 10 ECO codes by average score:\")\n",
    "print(f\"\\n   {'ECO':<6} {'Avg Score':<12} {'Count':<10}\")\n",
    "print(f\"   {'-'*6} {'-'*12} {'-'*10}\")\n",
    "for eco, row in eco_scores.head(10).iterrows():\n",
    "    print(f\"   {eco:<6} {row['mean']:<12.4f} {int(row['count']):>7,}\")\n",
    "\n",
    "print(f\"\\n   Bottom 10 ECO codes by average score:\")\n",
    "print(f\"\\n   {'ECO':<6} {'Avg Score':<12} {'Count':<10}\")\n",
    "print(f\"   {'-'*6} {'-'*12} {'-'*10}\")\n",
    "for eco, row in eco_scores.tail(10).iterrows():\n",
    "    print(f\"   {eco:<6} {row['mean']:<12.4f} {int(row['count']):>7,}\")\n",
    "\n",
    "# ECO codes with high variance in scores\n",
    "print(f\"\\nüîü  ECO codes with highest score variance (may indicate difficulty):\")\n",
    "eco_variance = clean_data.groupby('eco')['score'].agg(['var', 'std', 'count']).sort_values('var', ascending=False).head(10)\n",
    "print(f\"\\n   {'ECO':<6} {'Variance':<12} {'Std Dev':<12} {'Count':<10}\")\n",
    "print(f\"   {'-'*6} {'-'*12} {'-'*12} {'-'*10}\")\n",
    "for eco, row in eco_variance.iterrows():\n",
    "    print(f\"   {eco:<6} {row['var']:<12.4f} {row['std']:<12.4f} {int(row['count']):>7,}\")\n",
    "\n",
    "# Number of openings per ECO code\n",
    "print(f\"\\n1Ô∏è‚É£1Ô∏è‚É£  Openings per ECO code:\")\n",
    "# Connect to database to get opening counts\n",
    "con = get_db_connection(str(DB_PATH))\n",
    "try:\n",
    "    eco_opening_query = \"\"\"\n",
    "        SELECT eco, COUNT(DISTINCT id) as num_openings\n",
    "        FROM opening\n",
    "        GROUP BY eco\n",
    "        ORDER BY num_openings DESC\n",
    "    \"\"\"\n",
    "    eco_opening_counts = pd.DataFrame(con.execute(eco_opening_query).df())\n",
    "    \n",
    "    # Filter to only ECO codes in our data\n",
    "    eco_opening_counts = eco_opening_counts[eco_opening_counts['eco'].isin(clean_data['eco'].unique())]\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Mean openings per ECO: {eco_opening_counts['num_openings'].mean():.1f}\")\n",
    "    print(f\"   ‚Ä¢ Median openings per ECO: {eco_opening_counts['num_openings'].median():.1f}\")\n",
    "    print(f\"   ‚Ä¢ Max openings per ECO: {eco_opening_counts['num_openings'].max()}\")\n",
    "    print(f\"   ‚Ä¢ Min openings per ECO: {eco_opening_counts['num_openings'].min()}\")\n",
    "    \n",
    "    print(f\"\\n   Top 10 ECO codes by number of openings:\")\n",
    "    print(f\"\\n   {'ECO':<6} {'# Openings':<12}\")\n",
    "    print(f\"   {'-'*6} {'-'*12}\")\n",
    "    for idx, row in eco_opening_counts.head(10).iterrows():\n",
    "        print(f\"   {row['eco']:<6} {int(row['num_openings']):>10}\")\n",
    "    \n",
    "finally:\n",
    "    con.close()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ ECO CODE STATISTICS COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä Key takeaways:\")\n",
    "print(f\"   ‚Ä¢ Total unique ECO codes: {clean_data['eco'].nunique()}\")\n",
    "print(f\"   ‚Ä¢ Most common family: {eco_families.idxmax()} ({eco_families.max():,} entries)\")\n",
    "print(f\"   ‚Ä¢ Most common ECO: {top_eco.index[0]} ({top_eco.iloc[0]:,} entries)\")\n",
    "print(f\"   ‚Ä¢ ECO codes appear in all splits (good for training)\")\n",
    "print(f\"\\nüí° Next steps:\")\n",
    "print(f\"   ‚Ä¢ Enumerate ECO codes as integers for categorical encoding\")\n",
    "print(f\"   ‚Ä¢ Consider ECO as opening-level side information (similar to player ratings)\")\n",
    "print(f\"   ‚Ä¢ Verify all ECO codes in validation/test exist in training set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bbad18",
   "metadata": {},
   "source": [
    "## 4b. Create ECO Side Information\n",
    "\n",
    "**Why ECO is Side Information:**\n",
    "- ECO codes describe **opening characteristics**, not individual player-opening interactions\n",
    "- Similar to how player ratings describe players, ECO describes openings\n",
    "- Each opening has ONE ECO code (not per player-opening pair)\n",
    "\n",
    "**Implementation Strategy:**\n",
    "- Split ECO codes into two categorical features:\n",
    "  - `eco_letter`: A, B, C, D, or E ‚Üí encoded as integers 0-4\n",
    "  - `eco_number`: The numeric part (e.g., \"21\" from \"C21\") ‚Üí encoded as sequential integers\n",
    "- Store in a separate `opening_side_info` lookup table (indexed by opening_id)\n",
    "- Remove `eco` from train/test/val DataFrames (it's not interaction data)\n",
    "- During training, model will lookup opening_id ‚Üí (eco_letter, eco_number)\n",
    "\n",
    "**Why Split ECO into Letter and Number:**\n",
    "- ECO families (A-E) represent fundamentally different opening types:\n",
    "  - **A**: Flank openings (English, R√©ti, Bird's, etc.)\n",
    "  - **B**: Semi-Open games (Sicilian, French, Caro-Kann, etc.)\n",
    "  - **C**: Open games (King's pawn openings, Spanish, Italian, etc.)\n",
    "  - **D**: Closed games (Queen's Gambit variations)\n",
    "  - **E**: Indian defenses (King's Indian, Nimzo-Indian, etc.)\n",
    "- Numbers within each family represent variations (C20-C29, C30-C39, etc.)\n",
    "- Model can learn separate embeddings for family vs variation\n",
    "\n",
    "**Categorical Encoding:**\n",
    "- Both features will be treated as categorical (not ordinal)\n",
    "- Higher numbers don't mean \"better\" openings\n",
    "- Model will learn embedding vectors for each category\n",
    "- This allows the model to capture non-linear relationships between ECO codes and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64124475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 4B: CREATE ECO SIDE INFORMATION\n",
      "============================================================\n",
      "\n",
      "‚öôÔ∏è  Strategy:\n",
      "   ‚Ä¢ Extract unique opening_id ‚Üí eco mappings from clean_data\n",
      "   ‚Ä¢ Split ECO codes: 'C21' ‚Üí letter='C', number='21'\n",
      "   ‚Ä¢ Encode as sequential integers (categorical, not ordinal)\n",
      "   ‚Ä¢ Store in opening_side_info lookup table\n",
      "   ‚Ä¢ Remove 'eco' column from X_train, X_val, X_test\n",
      "\n",
      "1Ô∏è‚É£  Extracting unique opening-ECO mappings...\n",
      "   ‚úì Extracted 2,714 unique openings\n",
      "   ‚úì Verified: Each opening has exactly one ECO code (good!)\n",
      "\n",
      "2Ô∏è‚É£  Splitting ECO codes into letter and number components...\n",
      "   ‚úì Extracted letter and number components\n",
      "   ‚Ä¢ Unique letters: ['B' 'C' 'A' 'D' 'E']\n",
      "   ‚Ä¢ Unique numbers: 100\n",
      "\n",
      "3Ô∏è‚É£  Encoding ECO letters as categorical integers...\n",
      "   ‚úì Letter encoding created:\n",
      "      'A' ‚Üí 0 (578 openings)\n",
      "      'B' ‚Üí 1 (590 openings)\n",
      "      'C' ‚Üí 2 (891 openings)\n",
      "      'D' ‚Üí 3 (419 openings)\n",
      "      'E' ‚Üí 4 (236 openings)\n",
      "\n",
      "4Ô∏è‚É£  Encoding ECO numbers as categorical integers...\n",
      "   ‚úì Number encoding created:\n",
      "      100 unique numbers mapped to [0, 99]\n",
      "      Range: '00' ‚Üí 0, ..., '99' ‚Üí 99\n",
      "\n",
      "   Distribution of ECO numbers (top 10):\n",
      "      '00' (‚Üí  0): 290 openings\n",
      "      '40' (‚Üí 40):  98 openings\n",
      "      '20' (‚Üí 20):  70 openings\n",
      "      '01' (‚Üí  1):  70 openings\n",
      "      '02' (‚Üí  2):  67 openings\n",
      "      '42' (‚Üí 42):  67 openings\n",
      "      '45' (‚Üí 45):  64 openings\n",
      "      '10' (‚Üí 10):  63 openings\n",
      "      '21' (‚Üí 21):  61 openings\n",
      "      '15' (‚Üí 15):  58 openings\n",
      "\n",
      "5Ô∏è‚É£  Creating opening_side_info lookup table...\n",
      "   ‚úì Created opening_side_info\n",
      "      ‚Ä¢ Shape: (2714, 2)\n",
      "      ‚Ä¢ Index: opening_id\n",
      "      ‚Ä¢ Columns: ['eco_letter_cat', 'eco_number_cat']\n",
      "      ‚Ä¢ eco_letter_cat: Categorical encoding of ECO letter (A-E ‚Üí 0-4)\n",
      "      ‚Ä¢ eco_number_cat: Categorical encoding of ECO number\n",
      "\n",
      "6Ô∏è‚É£  Verifying coverage of train/val/test openings...\n",
      "   ‚úì All 2,714 openings in train/val/test have ECO side information\n",
      "\n",
      "7Ô∏è‚É£  Removing 'eco' column from train/val/test DataFrames...\n",
      "   ‚Ä¢ X_train before: (2173039, 4), columns: ['player_id', 'opening_id', 'eco', 'confidence']\n",
      "   ‚Ä¢ X_val before: (434608, 4), columns: ['player_id', 'opening_id', 'eco', 'confidence']\n",
      "   ‚Ä¢ X_test before: (289739, 4), columns: ['player_id', 'opening_id', 'eco', 'confidence']\n",
      "\n",
      "   After removing 'eco':\n",
      "   ‚Ä¢ X_train: (2173039, 3), columns: ['player_id', 'opening_id', 'confidence']\n",
      "   ‚Ä¢ X_val: (434608, 3), columns: ['player_id', 'opening_id', 'confidence']\n",
      "   ‚Ä¢ X_test: (289739, 3), columns: ['player_id', 'opening_id', 'confidence']\n",
      "\n",
      "8Ô∏è‚É£  Sample of ECO encoding (10 random openings):\n",
      "\n",
      "   Opening ID   Letter (Cat)    Number (Cat)    Reconstructed ECO \n",
      "   ------------ --------------- --------------- ------------------\n",
      "   143          0               4               A04               \n",
      "   980          1               62              B62               \n",
      "   1863         3               1               D01               \n",
      "   780          1               19              B19               \n",
      "   399          0               50              A50               \n",
      "   928          1               40              B40               \n",
      "   2331         4               70              E70               \n",
      "   1171         2               17              C17               \n",
      "   2701         2               19              C19               \n",
      "   355          0               45              A45               \n",
      "\n",
      "9Ô∏è‚É£  ECO family distribution in opening_side_info:\n",
      "\n",
      "   Encoded  Letter   Count      Percentage   Visual\n",
      "   -------- -------- ---------- ------------ ----------------------------------------\n",
      "   0        A            578     21.30%      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   1        B            590     21.74%      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2        C            891     32.83%      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   3        D            419     15.44%      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   4        E            236      8.70%      ‚ñà‚ñà‚ñà\n",
      "\n",
      "============================================================\n",
      "‚úÖ ECO SIDE INFORMATION CREATION COMPLETE\n",
      "============================================================\n",
      "\n",
      "Created: opening_side_info\n",
      "   ‚Ä¢ Shape: (2714, 2)\n",
      "   ‚Ä¢ Index: opening_id (for O(1) lookups)\n",
      "   ‚Ä¢ Columns: ['eco_letter_cat', 'eco_number_cat']\n",
      "\n",
      "üìä Data structure summary:\n",
      "   ‚Ä¢ X_train: 2,173,039 rows, 3 features\n",
      "   ‚Ä¢ X_val: 434,608 rows, 3 features\n",
      "   ‚Ä¢ X_test: 289,739 rows, 3 features\n",
      "   ‚Ä¢ opening_side_info: 2,714 openings (one per opening)\n",
      "   ‚Ä¢ ECO storage: ONE entry per opening (not duplicated per interaction)\n",
      "\n",
      "‚ö†Ô∏è  CRITICAL: Save these mappings for inference!\n",
      "   ‚Ä¢ eco_letter_to_int: {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}\n",
      "   ‚Ä¢ eco_number_to_int: (dict with 100 entries)\n",
      "\n",
      "   You'll need them to encode ECO codes for new openings at inference time.\n",
      "\n",
      "üí° Model usage:\n",
      "   During training, for each (player_id, opening_id) pair:\n",
      "   1. Lookup opening_id ‚Üí opening_side_info[opening_id]\n",
      "   2. Get eco_letter_cat and eco_number_cat (already encoded as integers)\n",
      "   3. Feed into categorical embedding layers\n",
      "   4. Combine with opening latent factors\n",
      "\n",
      "üßπ Final cleanup:\n",
      "   ‚Ä¢ Kept only encoded categorical columns: eco_letter_cat, eco_number_cat\n",
      "   ‚Ä¢ Removed raw ECO strings (eco, eco_letter_str, eco_number_str)\n",
      "   ‚Ä¢ Column names clearly indicate categorical encoding (_cat suffix)\n",
      "\n",
      "‚úì Created reverse mappings for ECO decoding:\n",
      "   ‚Ä¢ eco_int_to_letter: 5 entries\n",
      "   ‚Ä¢ eco_int_to_number: 100 entries\n"
     ]
    }
   ],
   "source": [
    "# 4b. Create ECO side information and remove ECO from train/test/val DataFrames\n",
    "\n",
    "# Check if ECO processing has already been done\n",
    "if 'eco' not in X_train.columns and 'opening_side_info' in globals():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"‚è≠Ô∏è  SKIPPING STEP 4B: ECO SIDE INFORMATION CREATION\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\n‚úì ECO column already removed from train/test/val data\")\n",
    "    print(\"‚úì 'opening_side_info' table already exists\")\n",
    "    print(f\"\\nOpening side info shape: {opening_side_info.shape}\")\n",
    "    print(f\"Columns: {list(opening_side_info.columns)}\")\n",
    "    \n",
    "    # Show statistics\n",
    "    print(f\"\\nüìä Existing ECO encoding statistics:\")\n",
    "    print(f\"   ‚Ä¢ Unique eco_letter values: {opening_side_info['eco_letter'].nunique()}\")\n",
    "    print(f\"   ‚Ä¢ Unique eco_number values: {opening_side_info['eco_number'].nunique()}\")\n",
    "    print(f\"   ‚Ä¢ eco_letter range: [{opening_side_info['eco_letter'].min()}, {opening_side_info['eco_letter'].max()}]\")\n",
    "    print(f\"   ‚Ä¢ eco_number range: [{opening_side_info['eco_number'].min()}, {opening_side_info['eco_number'].max()}]\")\n",
    "    \n",
    "    print(f\"\\nüìã Sample of existing ECO encoding:\")\n",
    "    sample_data = opening_side_info.sample(min(10, len(opening_side_info)), random_state=42)\n",
    "    for idx, row in sample_data.iterrows():\n",
    "        print(f\"   Opening {idx:>4} | ECO: {row['eco']:>3} ‚Üí Letter: {row['eco_letter']} ({row['eco_letter_str']}), Number: {row['eco_number']:>2} ({row['eco_number_str']:>2})\")\n",
    "else:\n",
    "    def create_eco_side_information(clean_data_df, X_train_df, X_val_df, X_test_df):\n",
    "        \"\"\"\n",
    "        Create ECO side information table and remove ECO from train/test/val DataFrames.\n",
    "        \n",
    "        ECO codes are opening-level features, not player-opening interaction features.\n",
    "        We split each ECO code (e.g., \"C21\") into:\n",
    "        - eco_letter: The letter part (A, B, C, D, or E)\n",
    "        - eco_number: The numeric part (e.g., 21)\n",
    "        \n",
    "        Both are encoded as sequential integers for use as categorical features in embeddings.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        clean_data_df : pd.DataFrame\n",
    "            Full cleaned data with opening_id and eco columns\n",
    "        X_train_df, X_val_df, X_test_df : pd.DataFrame\n",
    "            Train/val/test feature DataFrames (will be modified to remove 'eco')\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        tuple: (opening_side_info, eco_letter_map, eco_number_map, X_train, X_val, X_test)\n",
    "        \"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"STEP 4B: CREATE ECO SIDE INFORMATION\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        print(f\"\\n‚öôÔ∏è  Strategy:\")\n",
    "        print(f\"   ‚Ä¢ Extract unique opening_id ‚Üí eco mappings from clean_data\")\n",
    "        print(f\"   ‚Ä¢ Split ECO codes: 'C21' ‚Üí letter='C', number='21'\")\n",
    "        print(f\"   ‚Ä¢ Encode as sequential integers (categorical, not ordinal)\")\n",
    "        print(f\"   ‚Ä¢ Store in opening_side_info lookup table\")\n",
    "        print(f\"   ‚Ä¢ Remove 'eco' column from X_train, X_val, X_test\")\n",
    "        \n",
    "        # Extract unique opening ‚Üí ECO mappings\n",
    "        print(f\"\\n1Ô∏è‚É£  Extracting unique opening-ECO mappings...\")\n",
    "        opening_eco_map = clean_data_df[['opening_id', 'eco']].drop_duplicates().set_index('opening_id')\n",
    "        print(f\"   ‚úì Extracted {len(opening_eco_map):,} unique openings\")\n",
    "        \n",
    "        # Verify one-to-one mapping\n",
    "        eco_per_opening = clean_data_df.groupby('opening_id')['eco'].nunique()\n",
    "        if (eco_per_opening > 1).any():\n",
    "            problematic = eco_per_opening[eco_per_opening > 1]\n",
    "            print(f\"   ‚ö†Ô∏è  WARNING: {len(problematic)} openings have multiple ECO codes!\")\n",
    "            print(f\"   Problematic opening IDs: {problematic.index.tolist()[:10]}...\")\n",
    "        else:\n",
    "            print(f\"   ‚úì Verified: Each opening has exactly one ECO code (good!)\")\n",
    "        \n",
    "        # Split ECO into letter and number components\n",
    "        print(f\"\\n2Ô∏è‚É£  Splitting ECO codes into letter and number components...\")\n",
    "        opening_eco_map['eco_letter_str'] = opening_eco_map['eco'].str[0]  # First character (A-E)\n",
    "        opening_eco_map['eco_number_str'] = opening_eco_map['eco'].str[1:]  # Remaining characters (numeric)\n",
    "        \n",
    "        print(f\"   ‚úì Extracted letter and number components\")\n",
    "        print(f\"   ‚Ä¢ Unique letters: {opening_eco_map['eco_letter_str'].unique()}\")\n",
    "        print(f\"   ‚Ä¢ Unique numbers: {opening_eco_map['eco_number_str'].nunique()}\")\n",
    "        \n",
    "        # Create encoding mappings for eco_letter (A-E ‚Üí 0-4)\n",
    "        print(f\"\\n3Ô∏è‚É£  Encoding ECO letters as categorical integers...\")\n",
    "        unique_letters = sorted(opening_eco_map['eco_letter_str'].unique())\n",
    "        eco_letter_to_int = {letter: idx for idx, letter in enumerate(unique_letters)}\n",
    "        eco_int_to_letter = {idx: letter for letter, idx in eco_letter_to_int.items()}\n",
    "        \n",
    "        opening_eco_map['eco_letter'] = opening_eco_map['eco_letter_str'].map(eco_letter_to_int)\n",
    "        \n",
    "        print(f\"   ‚úì Letter encoding created:\")\n",
    "        for letter, idx in sorted(eco_letter_to_int.items()):\n",
    "            count = (opening_eco_map['eco_letter_str'] == letter).sum()\n",
    "            print(f\"      '{letter}' ‚Üí {idx} ({count:,} openings)\")\n",
    "        \n",
    "        # Create encoding mappings for eco_number (00-99 ‚Üí sequential integers)\n",
    "        print(f\"\\n4Ô∏è‚É£  Encoding ECO numbers as categorical integers...\")\n",
    "        unique_numbers = sorted(opening_eco_map['eco_number_str'].unique())\n",
    "        eco_number_to_int = {num: idx for idx, num in enumerate(unique_numbers)}\n",
    "        eco_int_to_number = {idx: num for num, idx in eco_number_to_int.items()}\n",
    "        \n",
    "        opening_eco_map['eco_number'] = opening_eco_map['eco_number_str'].map(eco_number_to_int)\n",
    "        \n",
    "        print(f\"   ‚úì Number encoding created:\")\n",
    "        print(f\"      {len(unique_numbers)} unique numbers mapped to [0, {len(unique_numbers)-1}]\")\n",
    "        print(f\"      Range: '{unique_numbers[0]}' ‚Üí 0, ..., '{unique_numbers[-1]}' ‚Üí {len(unique_numbers)-1}\")\n",
    "        \n",
    "        # Show distribution of numbers\n",
    "        print(f\"\\n   Distribution of ECO numbers (top 10):\")\n",
    "        number_counts = opening_eco_map['eco_number_str'].value_counts().head(10)\n",
    "        for num, count in number_counts.items():\n",
    "            encoded = eco_number_to_int[num]\n",
    "            print(f\"      '{num}' (‚Üí {encoded:>2}): {count:>3} openings\")\n",
    "        \n",
    "        # Create final opening_side_info table\n",
    "        print(f\"\\n5Ô∏è‚É£  Creating opening_side_info lookup table...\")\n",
    "        # Only keep the encoded categorical columns and rename them for clarity\n",
    "        opening_side_info = opening_eco_map[['eco_letter', 'eco_number']].copy()\n",
    "        opening_side_info = opening_side_info.rename(columns={\n",
    "            'eco_letter': 'eco_letter_cat',  # _cat suffix indicates categorical encoding\n",
    "            'eco_number': 'eco_number_cat'\n",
    "        })\n",
    "        \n",
    "        print(f\"   ‚úì Created opening_side_info\")\n",
    "        print(f\"      ‚Ä¢ Shape: {opening_side_info.shape}\")\n",
    "        print(f\"      ‚Ä¢ Index: opening_id\")\n",
    "        print(f\"      ‚Ä¢ Columns: {list(opening_side_info.columns)}\")\n",
    "        print(f\"      ‚Ä¢ eco_letter_cat: Categorical encoding of ECO letter (A-E ‚Üí 0-4)\")\n",
    "        print(f\"      ‚Ä¢ eco_number_cat: Categorical encoding of ECO number\")\n",
    "        \n",
    "        # Verify all openings in train/val/test have ECO info\n",
    "        print(f\"\\n6Ô∏è‚É£  Verifying coverage of train/val/test openings...\")\n",
    "        all_openings = set(X_train_df['opening_id'].unique()) | \\\n",
    "                       set(X_val_df['opening_id'].unique()) | \\\n",
    "                       set(X_test_df['opening_id'].unique())\n",
    "        \n",
    "        missing_openings = all_openings - set(opening_side_info.index)\n",
    "        if len(missing_openings) > 0:\n",
    "            print(f\"   ‚ö†Ô∏è  WARNING: {len(missing_openings)} openings in splits are missing ECO info!\")\n",
    "            print(f\"   Missing opening IDs: {sorted(list(missing_openings))[:10]}...\")\n",
    "        else:\n",
    "            print(f\"   ‚úì All {len(all_openings):,} openings in train/val/test have ECO side information\")\n",
    "        \n",
    "        # Remove ECO from train/val/test DataFrames\n",
    "        print(f\"\\n7Ô∏è‚É£  Removing 'eco' column from train/val/test DataFrames...\")\n",
    "        print(f\"   ‚Ä¢ X_train before: {X_train_df.shape}, columns: {list(X_train_df.columns)}\")\n",
    "        print(f\"   ‚Ä¢ X_val before: {X_val_df.shape}, columns: {list(X_val_df.columns)}\")\n",
    "        print(f\"   ‚Ä¢ X_test before: {X_test_df.shape}, columns: {list(X_test_df.columns)}\")\n",
    "        \n",
    "        X_train_clean = X_train_df.drop(columns=['eco'])\n",
    "        X_val_clean = X_val_df.drop(columns=['eco'])\n",
    "        X_test_clean = X_test_df.drop(columns=['eco'])\n",
    "        \n",
    "        print(f\"\\n   After removing 'eco':\")\n",
    "        print(f\"   ‚Ä¢ X_train: {X_train_clean.shape}, columns: {list(X_train_clean.columns)}\")\n",
    "        print(f\"   ‚Ä¢ X_val: {X_val_clean.shape}, columns: {list(X_val_clean.columns)}\")\n",
    "        print(f\"   ‚Ä¢ X_test: {X_test_clean.shape}, columns: {list(X_test_clean.columns)}\")\n",
    "        \n",
    "        # Sample data showing the transformation\n",
    "        print(f\"\\n8Ô∏è‚É£  Sample of ECO encoding (10 random openings):\")\n",
    "        sample_openings = opening_side_info.sample(min(10, len(opening_side_info)), random_state=42)\n",
    "        \n",
    "        # For display purposes, reconstruct original values from the categorical encodings\n",
    "        print(f\"\\n   {'Opening ID':<12} {'Letter (Cat)':<15} {'Number (Cat)':<15} {'Reconstructed ECO':<18}\")\n",
    "        print(f\"   {'-'*12} {'-'*15} {'-'*15} {'-'*18}\")\n",
    "        for idx, row in sample_openings.iterrows():\n",
    "            letter_str = eco_int_to_letter[row['eco_letter_cat']]\n",
    "            number_str = eco_int_to_number[row['eco_number_cat']]\n",
    "            reconstructed = f\"{letter_str}{number_str}\"\n",
    "            print(f\"   {idx:<12} {row['eco_letter_cat']:<15} {row['eco_number_cat']:<15} {reconstructed:<18}\")\n",
    "        \n",
    "        # Show ECO family distribution\n",
    "        print(f\"\\n9Ô∏è‚É£  ECO family distribution in opening_side_info:\")\n",
    "        letter_dist = opening_side_info['eco_letter_cat'].value_counts().sort_index()\n",
    "        print(f\"\\n   {'Encoded':<8} {'Letter':<8} {'Count':<10} {'Percentage':<12} {'Visual'}\")\n",
    "        print(f\"   {'-'*8} {'-'*8} {'-'*10} {'-'*12} {'-'*40}\")\n",
    "        for encoded_val, count in letter_dist.items():\n",
    "            letter = eco_int_to_letter[encoded_val]\n",
    "            pct = 100 * count / len(opening_side_info)\n",
    "            bar_length = int(pct * 0.4)\n",
    "            bar = '‚ñà' * bar_length\n",
    "            print(f\"   {encoded_val:<8} {letter:<8} {count:>7,}    {pct:>6.2f}%      {bar}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"‚úÖ ECO SIDE INFORMATION CREATION COMPLETE\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        print(f\"\\nCreated: opening_side_info\")\n",
    "        print(f\"   ‚Ä¢ Shape: {opening_side_info.shape}\")\n",
    "        print(f\"   ‚Ä¢ Index: opening_id (for O(1) lookups)\")\n",
    "        print(f\"   ‚Ä¢ Columns: {list(opening_side_info.columns)}\")\n",
    "        \n",
    "        print(f\"\\nüìä Data structure summary:\")\n",
    "        print(f\"   ‚Ä¢ X_train: {X_train_clean.shape[0]:,} rows, {X_train_clean.shape[1]} features\")\n",
    "        print(f\"   ‚Ä¢ X_val: {X_val_clean.shape[0]:,} rows, {X_val_clean.shape[1]} features\")\n",
    "        print(f\"   ‚Ä¢ X_test: {X_test_clean.shape[0]:,} rows, {X_test_clean.shape[1]} features\")\n",
    "        print(f\"   ‚Ä¢ opening_side_info: {len(opening_side_info):,} openings (one per opening)\")\n",
    "        print(f\"   ‚Ä¢ ECO storage: ONE entry per opening (not duplicated per interaction)\")\n",
    "        \n",
    "        print(f\"\\n‚ö†Ô∏è  CRITICAL: Save these mappings for inference!\")\n",
    "        print(f\"   ‚Ä¢ eco_letter_to_int: {eco_letter_to_int}\")\n",
    "        print(f\"   ‚Ä¢ eco_number_to_int: (dict with {len(eco_number_to_int)} entries)\")\n",
    "        print(f\"\\n   You'll need them to encode ECO codes for new openings at inference time.\")\n",
    "        \n",
    "        print(f\"\\nüí° Model usage:\")\n",
    "        print(f\"   During training, for each (player_id, opening_id) pair:\")\n",
    "        print(f\"   1. Lookup opening_id ‚Üí opening_side_info[opening_id]\")\n",
    "        print(f\"   2. Get eco_letter_cat and eco_number_cat (already encoded as integers)\")\n",
    "        print(f\"   3. Feed into categorical embedding layers\")\n",
    "        print(f\"   4. Combine with opening latent factors\")\n",
    "        \n",
    "        print(f\"\\nüßπ Final cleanup:\")\n",
    "        print(f\"   ‚Ä¢ Kept only encoded categorical columns: eco_letter_cat, eco_number_cat\")\n",
    "        print(f\"   ‚Ä¢ Removed raw ECO strings (eco, eco_letter_str, eco_number_str)\")\n",
    "        print(f\"   ‚Ä¢ Column names clearly indicate categorical encoding (_cat suffix)\")\n",
    "        \n",
    "        return opening_side_info, eco_letter_to_int, eco_number_to_int, X_train_clean, X_val_clean, X_test_clean\n",
    "    \n",
    "    # Call the function\n",
    "    opening_side_info, eco_letter_map, eco_number_map, X_train, X_val, X_test = create_eco_side_information(\n",
    "        clean_data, X_train, X_val, X_test\n",
    "    )\n",
    "    \n",
    "    # Create reverse mappings for decoding (needed for verification and debugging)\n",
    "    eco_int_to_letter = {v: k for k, v in eco_letter_map.items()}\n",
    "    eco_int_to_number = {v: k for k, v in eco_number_map.items()}\n",
    "    print(f\"\\n‚úì Created reverse mappings for ECO decoding:\")\n",
    "    print(f\"   ‚Ä¢ eco_int_to_letter: {len(eco_int_to_letter)} entries\")\n",
    "    print(f\"   ‚Ä¢ eco_int_to_number: {len(eco_int_to_number)} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df4b4e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION: FINAL DATA STRUCTURE\n",
      "============================================================\n",
      "\n",
      "1Ô∏è‚É£  Train/Val/Test DataFrames (ECO removed):\n",
      "\n",
      "   X_train:\n",
      "   ‚Ä¢ Shape: (2173039, 3)\n",
      "   ‚Ä¢ Columns: ['player_id', 'opening_id', 'confidence']\n",
      "   ‚Ä¢ Sample:\n",
      "         player_id  opening_id  confidence\n",
      "96177         1586         533    0.295775\n",
      "1050675      17164         219    0.884259\n",
      "842384       13708        1281    0.193548\n",
      "\n",
      "   X_val:\n",
      "   ‚Ä¢ Shape: (434608, 3)\n",
      "   ‚Ä¢ Columns: ['player_id', 'opening_id', 'confidence']\n",
      "\n",
      "   X_test:\n",
      "   ‚Ä¢ Shape: (289739, 3)\n",
      "   ‚Ä¢ Columns: ['player_id', 'opening_id', 'confidence']\n",
      "\n",
      "2Ô∏è‚É£  Side Information Tables:\n",
      "\n",
      "   player_side_info (indexed by player_id):\n",
      "   ‚Ä¢ Shape: (48468, 1)\n",
      "   ‚Ä¢ Columns: ['rating_z']\n",
      "   ‚Ä¢ Sample:\n",
      "           rating_z\n",
      "player_id          \n",
      "0          0.609128\n",
      "1          1.058323\n",
      "2          0.561000\n",
      "\n",
      "   opening_side_info (indexed by opening_id):\n",
      "   ‚Ä¢ Shape: (2714, 2)\n",
      "   ‚Ä¢ Columns: ['eco_letter_cat', 'eco_number_cat']\n",
      "   ‚Ä¢ Sample:\n",
      "            eco_letter_cat  eco_number_cat\n",
      "opening_id                                \n",
      "531                      1               0\n",
      "565                      1               0\n",
      "572                      1               0\n",
      "\n",
      "3Ô∏è‚É£  Encoding Mappings (for inference):\n",
      "\n",
      "   eco_letter_map:\n",
      "      'A' ‚Üí 0\n",
      "      'B' ‚Üí 1\n",
      "      'C' ‚Üí 2\n",
      "      'D' ‚Üí 3\n",
      "      'E' ‚Üí 4\n",
      "\n",
      "   eco_number_map (first 10):\n",
      "      '00' ‚Üí 0\n",
      "      '01' ‚Üí 1\n",
      "      '02' ‚Üí 2\n",
      "      '03' ‚Üí 3\n",
      "      '04' ‚Üí 4\n",
      "      '05' ‚Üí 5\n",
      "      '06' ‚Üí 6\n",
      "      '07' ‚Üí 7\n",
      "      '08' ‚Üí 8\n",
      "      '09' ‚Üí 9\n",
      "      ... (100 total)\n",
      "\n",
      "4Ô∏è‚É£  Example: Lookup flow for a random train sample:\n",
      "\n",
      "   Sample interaction:\n",
      "   ‚Ä¢ player_id: 6238.0\n",
      "   ‚Ä¢ opening_id: 1639.0\n",
      "   ‚Ä¢ confidence: 0.4186\n",
      "\n",
      "   Player side info lookup:\n",
      "   ‚Ä¢ rating_z: -0.4256\n",
      "\n",
      "   Opening side info lookup:\n",
      "   ‚Ä¢ eco_letter_cat: 2 (letter: C)\n",
      "   ‚Ä¢ eco_number_cat: 54 (number: 54)\n",
      "\n",
      "============================================================\n",
      "‚úÖ VERIFICATION COMPLETE\n",
      "============================================================\n",
      "\n",
      "üì¶ Ready for PyTorch tensor conversion:\n",
      "   ‚Ä¢ Features: player_id, opening_id, confidence\n",
      "   ‚Ä¢ Target: score (in y_train, y_val, y_test)\n",
      "   ‚Ä¢ Player side info: rating_z\n",
      "   ‚Ä¢ Opening side info: eco_letter_cat, eco_number_cat\n",
      "\n",
      "   All ECO and rating data is now properly separated as side information!\n",
      "\n",
      "   Side info tables are clean - only contain necessary model inputs!\n"
     ]
    }
   ],
   "source": [
    "# Verify final data structure after ECO processing\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION: FINAL DATA STRUCTURE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n1Ô∏è‚É£  Train/Val/Test DataFrames (ECO removed):\")\n",
    "print(f\"\\n   X_train:\")\n",
    "print(f\"   ‚Ä¢ Shape: {X_train.shape}\")\n",
    "print(f\"   ‚Ä¢ Columns: {list(X_train.columns)}\")\n",
    "print(f\"   ‚Ä¢ Sample:\")\n",
    "print(X_train.head(3).to_string())\n",
    "\n",
    "print(f\"\\n   X_val:\")\n",
    "print(f\"   ‚Ä¢ Shape: {X_val.shape}\")\n",
    "print(f\"   ‚Ä¢ Columns: {list(X_val.columns)}\")\n",
    "\n",
    "print(f\"\\n   X_test:\")\n",
    "print(f\"   ‚Ä¢ Shape: {X_test.shape}\")\n",
    "print(f\"   ‚Ä¢ Columns: {list(X_test.columns)}\")\n",
    "\n",
    "print(f\"\\n2Ô∏è‚É£  Side Information Tables:\")\n",
    "\n",
    "print(f\"\\n   player_side_info (indexed by player_id):\")\n",
    "print(f\"   ‚Ä¢ Shape: {player_side_info.shape}\")\n",
    "print(f\"   ‚Ä¢ Columns: {list(player_side_info.columns)}\")\n",
    "print(f\"   ‚Ä¢ Sample:\")\n",
    "print(player_side_info.head(3).to_string())\n",
    "\n",
    "print(f\"\\n   opening_side_info (indexed by opening_id):\")\n",
    "print(f\"   ‚Ä¢ Shape: {opening_side_info.shape}\")\n",
    "print(f\"   ‚Ä¢ Columns: {list(opening_side_info.columns)}\")\n",
    "print(f\"   ‚Ä¢ Sample:\")\n",
    "print(opening_side_info.head(3).to_string())\n",
    "\n",
    "print(f\"\\n3Ô∏è‚É£  Encoding Mappings (for inference):\")\n",
    "print(f\"\\n   eco_letter_map:\")\n",
    "for k, v in sorted(eco_letter_map.items()):\n",
    "    print(f\"      '{k}' ‚Üí {v}\")\n",
    "\n",
    "print(f\"\\n   eco_number_map (first 10):\")\n",
    "for i, (k, v) in enumerate(sorted(eco_number_map.items())[:10]):\n",
    "    print(f\"      '{k}' ‚Üí {v}\")\n",
    "print(f\"      ... ({len(eco_number_map)} total)\")\n",
    "\n",
    "print(f\"\\n4Ô∏è‚É£  Example: Lookup flow for a random train sample:\")\n",
    "sample = X_train.sample(1, random_state=42).iloc[0]\n",
    "player_id = sample['player_id']\n",
    "opening_id = sample['opening_id']\n",
    "\n",
    "print(f\"\\n   Sample interaction:\")\n",
    "print(f\"   ‚Ä¢ player_id: {player_id}\")\n",
    "print(f\"   ‚Ä¢ opening_id: {opening_id}\")\n",
    "print(f\"   ‚Ä¢ confidence: {sample['confidence']:.4f}\")\n",
    "\n",
    "print(f\"\\n   Player side info lookup:\")\n",
    "player_info = player_side_info.loc[player_id]\n",
    "print(f\"   ‚Ä¢ rating_z: {player_info['rating_z']:.4f}\")\n",
    "\n",
    "print(f\"\\n   Opening side info lookup:\")\n",
    "opening_info = opening_side_info.loc[opening_id]\n",
    "print(f\"   ‚Ä¢ eco_letter_cat: {opening_info['eco_letter_cat']} (letter: {eco_int_to_letter[opening_info['eco_letter_cat']]})\")\n",
    "print(f\"   ‚Ä¢ eco_number_cat: {opening_info['eco_number_cat']} (number: {eco_int_to_number[opening_info['eco_number_cat']]})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ VERIFICATION COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüì¶ Ready for PyTorch tensor conversion:\")\n",
    "print(f\"   ‚Ä¢ Features: player_id, opening_id, confidence\")\n",
    "print(f\"   ‚Ä¢ Target: score (in y_train, y_val, y_test)\")\n",
    "print(f\"   ‚Ä¢ Player side info: rating_z\")\n",
    "print(f\"   ‚Ä¢ Opening side info: eco_letter_cat, eco_number_cat\")\n",
    "print(f\"\\n   All ECO and rating data is now properly separated as side information!\")\n",
    "print(f\"\\n   Side info tables are clean - only contain necessary model inputs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43752aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "============================================================\n",
      "STEP 4C: CORRELATION ANALYSIS OF PROCESSED DATA\n",
      "============================================================\n",
      "\n",
      "üìä Analyzing correlations of all features just before tensor conversion.\n",
      "   This includes all sanitization, normalization, and encoding.\n",
      "\n",
      "1Ô∏è‚É£  Assembling final feature set...\n",
      "   ‚úì Final DataFrame for correlation created.\n",
      "   ‚Ä¢ Shape: (2897386, 7)\n",
      "   ‚Ä¢ Columns: ['player_id', 'opening_id', 'score', 'confidence', 'rating_z', 'eco_letter_cat', 'eco_number_cat']\n",
      "\n",
      "2Ô∏è‚É£  Calculating correlation matrix...\n",
      "\n",
      "================================================================================\n",
      "CORRELATION MATRIX (PEARSON)\n",
      "================================================================================\n",
      "                player_id  opening_id     score  confidence  rating_z  eco_letter_cat  eco_number_cat\n",
      "player_id        1.000000    0.008685  0.002435   -0.006730 -0.034651        0.001698       -0.006604\n",
      "opening_id       0.008685    1.000000  0.125458   -0.052222 -0.004300        0.725503        0.348994\n",
      "score            0.002435    0.125458  1.000000    0.098085  0.042969        0.116776        0.055425\n",
      "confidence      -0.006730   -0.052222  0.098085    1.000000 -0.041747       -0.026254       -0.088681\n",
      "rating_z        -0.034651   -0.004300  0.042969   -0.041747  1.000000        0.002100        0.054682\n",
      "eco_letter_cat   0.001698    0.725503  0.116776   -0.026254  0.002100        1.000000        0.135723\n",
      "eco_number_cat  -0.006604    0.348994  0.055425   -0.088681  0.054682        0.135723        1.000000\n",
      "\n",
      "3Ô∏è‚É£  Generating heatmap visualization...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CORRELATIONS WITH TARGET VARIABLE (score)\n",
      "================================================================================\n",
      "opening_id        0.125458\n",
      "eco_letter_cat    0.116776\n",
      "confidence        0.098085\n",
      "eco_number_cat    0.055425\n",
      "rating_z          0.042969\n",
      "player_id         0.002435\n",
      "\n",
      "============================================================\n",
      "‚úÖ CORRELATION ANALYSIS COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 4c: Correlation Analysis of Processed Data\n",
    "\n",
    "%pip install seaborn --quiet\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 4C: CORRELATION ANALYSIS OF PROCESSED DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "# Start with the main interaction data (already has remapped IDs, adjusted score, confidence)\n",
    "corr_df = clean_data[[\"player_id\", \"opening_id\", \"score\", \"confidence\"]].copy()\n",
    "\n",
    "# Merge player side information (rating_z)\n",
    "# player_side_info is indexed by the remapped player_id\n",
    "corr_df = corr_df.merge(\n",
    "    player_side_info[[\"rating_z\"]], left_on=\"player_id\", right_index=True, how=\"left\"\n",
    ")\n",
    "\n",
    "# Merge opening side information (eco categories)\n",
    "# opening_side_info is indexed by the remapped opening_id\n",
    "corr_df = corr_df.merge(\n",
    "    opening_side_info[[\"eco_letter_cat\", \"eco_number_cat\"]],\n",
    "    left_on=\"opening_id\",\n",
    "    right_index=True,\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "print(f\"Final DataFrame for correlation created.\")\n",
    "print(f\"   ‚Ä¢ Columns: {corr_df.columns.tolist()}\")\n",
    "\n",
    "\n",
    "correlation_matrix = corr_df.corr()\n",
    "\n",
    "\n",
    "# 3. Visualize the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix of Model Features\", fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# 4. Analyze correlations with the target variable 'score'\n",
    "print(\"CORRELATIONS WITH TARGET VARIABLE (score)\")\n",
    "print(\"=\" * 80)\n",
    "score_correlations = (\n",
    "    correlation_matrix[\"score\"].drop(\"score\").sort_values(ascending=False)\n",
    ")\n",
    "print(score_correlations.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3831d7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "017515d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "VERIFICATION: ECO RECONSTRUCTION AND OPENING NAMES\n",
      "====================================================================================================\n",
      "\n",
      "Sampling 100 player-opening pairs for verification...\n",
      "\n",
      "   ‚Ä¢ Converting 86 NEW opening IDs to OLD database IDs for query\n",
      "   ‚Ä¢ Example: NEW ID 862 ‚Üí OLD ID 1104\n",
      "   ‚úì Retrieved 86 opening names from database\n",
      "\n",
      "#    Player   Opening   ECO (DB)   Reconstructed Match  Opening Name                                      \n",
      "====================================================================================================\n",
      "1    24448    862       B28        B28           ‚úì      Sicilian Defense: O'Kelly Variation, Normal S...  \n",
      "2    2363     1528      C44        C44           ‚úì      Scotch Game: Scotch Gambit, Dubois R√©ti Defense   \n",
      "3    38165    2153      D86        D86           ‚úì      Gr√ºnfeld Defense: Exchange Variation, Classic...  \n",
      "4    8697     1899      D07        D07           ‚úì      Queen's Gambit Declined: Chigorin Defense, Ex...  \n",
      "5    704      1743      C70        C70           ‚úì      Ruy Lopez: Morphy Defense, Caro Variation         \n",
      "6    45947    726       B12        B12           ‚úì      Caro-Kann Defense: Advance Variation              \n",
      "7    14548    336       A43        A43           ‚úì      Benoni Defense: Benoni Gambit Accepted            \n",
      "8    30859    1514      C44        C44           ‚úì      Scotch Game: Benima Defense                       \n",
      "9    12685    2425      C56        C56           ‚úì      Italian Game: Scotch Gambit, Janowski Defense     \n",
      "10   21641    421       A56        A56           ‚úì      Benoni Defense                                    \n",
      "11   43885    1502      C44        C44           ‚úì      Ponziani Opening: Jaenisch Counterattack          \n",
      "12   39081    398       A50        A50           ‚úì      Indian Defense: Normal Variation                  \n",
      "13   8636     37        A00        A00           ‚úì      Hungarian Opening: Sicilian Invitation            \n",
      "14   40048    1071      C00        C00           ‚úì      French Defense: Two Knights Variation             \n",
      "15   104      2628      A22        A22           ‚úì      English Opening: King's English Variation, Ad...  \n",
      "16   38714    2000      D31        D31           ‚úì      Queen's Gambit Declined: Charousek Variation      \n",
      "17   15809    47        A00        A00           ‚úì      Mieses Opening                                    \n",
      "18   12000    1519      C44        C44           ‚úì      Scotch Game: G√∂ring Gambit, Double Pawn Sacri...  \n",
      "19   3764     145       A04        A04           ‚úì      Zukertort Opening: Sicilian Invitation            \n",
      "20   30839    531       B00        B00           ‚úì      Nimzowitsch Defense                               \n",
      "21   15093    2024      D33        D33           ‚úì      Tarrasch Defense: Prague Variation                \n",
      "22   32288    408       A52        A52           ‚úì      Indian Defense: Budapest Defense, Adler Varia...  \n",
      "23   33077    2614      D01        D01           ‚úì      Rapport-Jobava System, with e6                    \n",
      "24   8887     343       A43        A43           ‚úì      Benoni Defense: Old Benoni                        \n",
      "25   7043     2641      A40        A40           ‚úì      Englund Gambit: Soller Gambit                     \n",
      "26   12852    1207      C21        C21           ‚úì      Danish Gambit Accepted                            \n",
      "27   29612    2450      B01        B01           ‚úì      Scandinavian Defense: Valencian Variation         \n",
      "28   28930    1670      C58        C58           ‚úì      Italian Game: Two Knights Defense, Polerio De...  \n",
      "29   23107    1411      C40        C40           ‚úì      King's Pawn Game: McConnell Defense               \n",
      "30   9922     1882      D05        D05           ‚úì      Queen's Pawn Game: Colle System, Traditional ...  \n",
      "31   7439     1358      C37        C37           ‚úì      King's Gambit Accepted: Blachly Gambit            \n",
      "32   38360    706       B10        B10           ‚úì      Caro-Kann Defense                                 \n",
      "33   26104    1471      C42        C42           ‚úì      Russian Game: Cozio Attack                        \n",
      "34   14954    598       B01        B01           ‚úì      Scandinavian Defense: Mieses-Kotroc Variation     \n",
      "35   19969    342       A43        A43           ‚úì      Benoni Defense: French Benoni                     \n",
      "36   12824    245       A21        A21           ‚úì      English Opening: King's English Variation, Kr...  \n",
      "37   699      1298      C31        C31           ‚úì      King's Gambit Declined: Falkbeer Countergambi...  \n",
      "38   38249    2610      C17        C17           ‚úì      French Defense: Winawer Variation, Bogoljubow...  \n",
      "39   3606     1411      C40        C40           ‚úì      King's Pawn Game: McConnell Defense               \n",
      "40   19870    1743      C70        C70           ‚úì      Ruy Lopez: Morphy Defense, Caro Variation         \n",
      "41   13952    798       B20        B20           ‚úì      Sicilian Defense: Wing Gambit, Marshall Varia...  \n",
      "42   14456    1428      C41        C41           ‚úì      Philidor Defense                                  \n",
      "43   2961     2420      B54        B54           ‚úì      Sicilian Defense: Dragon Variation, Accelerat...  \n",
      "44   35984    2322      E65        E65           ‚úì      King's Indian Defense: Fianchetto Variation, ...  \n",
      "45   25228    1314      C33        C33           ‚úì      King's Gambit Accepted: Bishop's Gambit           \n",
      "46   47831    1237      C25        C25           ‚úì      Vienna Game                                       \n",
      "47   7070     307       A40        A40           ‚úì      Englund Gambit Complex: Zilbermints Gambit        \n",
      "48   10813    598       B01        B01           ‚úì      Scandinavian Defense: Mieses-Kotroc Variation     \n",
      "49   201      1354      C35        C35           ‚úì      King's Gambit Accepted: Cunningham Defense, B...  \n",
      "50   11990    1648      C55        C55           ‚úì      Italian Game: Two Knights Defense, Modern Bis...  \n",
      "51   37421    166       A06        A06           ‚úì      Zukertort Opening: Tennison Gambit                \n",
      "52   38216    280       A34        A34           ‚úì      English Opening: Symmetrical Variation, Norma...  \n",
      "53   2553     1407      C40        C40           ‚úì      King's Pawn Game: Busch-Gass Gambit               \n",
      "54   29135    825       B22        B22           ‚úì      Sicilian Defense: Alapin Variation                \n",
      "55   20180    762       B15        B15           ‚úì      Caro-Kann Defense: Tartakower Variation           \n",
      "56   26073    1958      D20        D20           ‚úì      Queen's Gambit Accepted: Central Variation, M...  \n",
      "57   27645    1896      D06        D06           ‚úì      Queen's Gambit Declined: Marshall Defense         \n",
      "58   26899    2036      D35        D35           ‚úì      Queen's Gambit Declined: Exchange Variation, ...  \n",
      "59   14698    1530      C44        C44           ‚úì      Scotch Game: Scotch Gambit, Kingside Variation    \n",
      "60   40326    1556      C46        C46           ‚úì      Three Knights Opening                             \n",
      "61   1507     1596      C50        C50           ‚úì      Italian Game: Giuoco Pianissimo, Normal           \n",
      "62   12311    706       B10        B10           ‚úì      Caro-Kann Defense                                 \n",
      "63   16578    1413      C40        C40           ‚úì      Latvian Gambit Accepted                           \n",
      "64   6277     2413      B02        B02           ‚úì      Alekhine Defense: Two Pawns Attack                \n",
      "65   21653    543       B00        B00           ‚úì      Nimzowitsch Defense: Kennedy Variation, Links...  \n",
      "66   11536    302       A40        A40           ‚úì      Englund Gambit Complex: Hartlaub-Charlick Gambit  \n",
      "67   45341    2669      C42        C42           ‚úì      Petrov's Defense: Stafford Gambit                 \n",
      "68   26777    241       A20        A20           ‚úì      English Opening: King's English Variation         \n",
      "69   27052    1556      C46        C46           ‚úì      Three Knights Opening                             \n",
      "70   19519    168       A07        A07           ‚úì      King's Indian Attack                              \n",
      "71   21677    1578      C48        C48           ‚úì      Four Knights Game: Spanish Variation              \n",
      "72   8896     168       A07        A07           ‚úì      King's Indian Attack                              \n",
      "73   31065    589       B01        B01           ‚úì      Scandinavian Defense: Icelandic-Palme Gambit      \n",
      "74   9484     2476      C56        C56           ‚úì      Italian Game: Scotch Gambit, de Riviere Defense   \n",
      "75   25776    598       B01        B01           ‚úì      Scandinavian Defense: Mieses-Kotroc Variation     \n",
      "76   16869    825       B22        B22           ‚úì      Sicilian Defense: Alapin Variation                \n",
      "77   30079    1596      C50        C50           ‚úì      Italian Game: Giuoco Pianissimo, Normal           \n",
      "78   40773    831       B22        B22           ‚úì      Sicilian Defense: Alapin Variation, Smith-Mor...  \n",
      "79   16072    39        A00        A00           ‚úì      Hungarian Opening: Symmetrical Variation          \n",
      "80   7837     142       A04        A04           ‚úì      Zukertort Opening: Queen's Gambit Invitation      \n",
      "81   22863    2450      B01        B01           ‚úì      Scandinavian Defense: Valencian Variation         \n",
      "82   13837    575       B00        B00           ‚úì      St. George Defense                                \n",
      "83   5692     856       B28        B28           ‚úì      Sicilian Defense: O'Kelly Variation               \n",
      "84   40796    1234      C24        C24           ‚úì      Bishop's Opening: Ponziani Gambit                 \n",
      "85   22301    728       B12        B12           ‚úì      Caro-Kann Defense: Advance Variation, Botvinn...  \n",
      "86   28219    1679      C60        C60           ‚úì      Ruy Lopez: Cozio Defense                          \n",
      "87   4648     1654      C57        C57           ‚úì      Italian Game: Two Knights Defense, Fried Live...  \n",
      "88   32974    653       B06        B06           ‚úì      Modern Defense                                    \n",
      "89   42539    421       A56        A56           ‚úì      Benoni Defense                                    \n",
      "90   17237    706       B10        B10           ‚úì      Caro-Kann Defense                                 \n",
      "91   5723     205       A13        A13           ‚úì      English Opening: Agincourt Defense                \n",
      "92   14435    188       A10        A10           ‚úì      English Opening: Anglo-Scandinavian Defense       \n",
      "93   13861    1933      D15        D15           ‚úì      Slav Defense: Geller Gambit                       \n",
      "94   34393    2018      D32        D32           ‚úì      Tarrasch Defense                                  \n",
      "95   35697    575       B00        B00           ‚úì      St. George Defense                                \n",
      "96   5329     49        A00        A00           ‚úì      Mieses Opening: Reversed Rat                      \n",
      "97   193      1916      D10        D10           ‚úì      Slav Defense                                      \n",
      "98   11802    918       B40        B40           ‚úì      Sicilian Defense: Four Knights Variation          \n",
      "99   17954    1702      C64        C64           ‚úì      Ruy Lopez: Classical Variation                    \n",
      "100  33411    543       B00        B00           ‚úì      Nimzowitsch Defense: Kennedy Variation, Links...  \n",
      "====================================================================================================\n",
      "\n",
      "‚úÖ Verification Results:\n",
      "   ‚Ä¢ Total samples: 100\n",
      "   ‚Ä¢ Matches: 100/100 (100.0%)\n",
      "   ‚Ä¢ Mismatches: 0\n",
      "\n",
      "üéâ Perfect! All ECO codes reconstructed correctly!\n",
      "   ‚Ä¢ ID remapping preserved all ECO code mappings\n",
      "\n",
      "Sampling 100 player-opening pairs for verification...\n",
      "\n",
      "   ‚Ä¢ Converting 86 NEW opening IDs to OLD database IDs for query\n",
      "   ‚Ä¢ Example: NEW ID 862 ‚Üí OLD ID 1104\n",
      "   ‚úì Retrieved 86 opening names from database\n",
      "\n",
      "#    Player   Opening   ECO (DB)   Reconstructed Match  Opening Name                                      \n",
      "====================================================================================================\n",
      "1    24448    862       B28        B28           ‚úì      Sicilian Defense: O'Kelly Variation, Normal S...  \n",
      "2    2363     1528      C44        C44           ‚úì      Scotch Game: Scotch Gambit, Dubois R√©ti Defense   \n",
      "3    38165    2153      D86        D86           ‚úì      Gr√ºnfeld Defense: Exchange Variation, Classic...  \n",
      "4    8697     1899      D07        D07           ‚úì      Queen's Gambit Declined: Chigorin Defense, Ex...  \n",
      "5    704      1743      C70        C70           ‚úì      Ruy Lopez: Morphy Defense, Caro Variation         \n",
      "6    45947    726       B12        B12           ‚úì      Caro-Kann Defense: Advance Variation              \n",
      "7    14548    336       A43        A43           ‚úì      Benoni Defense: Benoni Gambit Accepted            \n",
      "8    30859    1514      C44        C44           ‚úì      Scotch Game: Benima Defense                       \n",
      "9    12685    2425      C56        C56           ‚úì      Italian Game: Scotch Gambit, Janowski Defense     \n",
      "10   21641    421       A56        A56           ‚úì      Benoni Defense                                    \n",
      "11   43885    1502      C44        C44           ‚úì      Ponziani Opening: Jaenisch Counterattack          \n",
      "12   39081    398       A50        A50           ‚úì      Indian Defense: Normal Variation                  \n",
      "13   8636     37        A00        A00           ‚úì      Hungarian Opening: Sicilian Invitation            \n",
      "14   40048    1071      C00        C00           ‚úì      French Defense: Two Knights Variation             \n",
      "15   104      2628      A22        A22           ‚úì      English Opening: King's English Variation, Ad...  \n",
      "16   38714    2000      D31        D31           ‚úì      Queen's Gambit Declined: Charousek Variation      \n",
      "17   15809    47        A00        A00           ‚úì      Mieses Opening                                    \n",
      "18   12000    1519      C44        C44           ‚úì      Scotch Game: G√∂ring Gambit, Double Pawn Sacri...  \n",
      "19   3764     145       A04        A04           ‚úì      Zukertort Opening: Sicilian Invitation            \n",
      "20   30839    531       B00        B00           ‚úì      Nimzowitsch Defense                               \n",
      "21   15093    2024      D33        D33           ‚úì      Tarrasch Defense: Prague Variation                \n",
      "22   32288    408       A52        A52           ‚úì      Indian Defense: Budapest Defense, Adler Varia...  \n",
      "23   33077    2614      D01        D01           ‚úì      Rapport-Jobava System, with e6                    \n",
      "24   8887     343       A43        A43           ‚úì      Benoni Defense: Old Benoni                        \n",
      "25   7043     2641      A40        A40           ‚úì      Englund Gambit: Soller Gambit                     \n",
      "26   12852    1207      C21        C21           ‚úì      Danish Gambit Accepted                            \n",
      "27   29612    2450      B01        B01           ‚úì      Scandinavian Defense: Valencian Variation         \n",
      "28   28930    1670      C58        C58           ‚úì      Italian Game: Two Knights Defense, Polerio De...  \n",
      "29   23107    1411      C40        C40           ‚úì      King's Pawn Game: McConnell Defense               \n",
      "30   9922     1882      D05        D05           ‚úì      Queen's Pawn Game: Colle System, Traditional ...  \n",
      "31   7439     1358      C37        C37           ‚úì      King's Gambit Accepted: Blachly Gambit            \n",
      "32   38360    706       B10        B10           ‚úì      Caro-Kann Defense                                 \n",
      "33   26104    1471      C42        C42           ‚úì      Russian Game: Cozio Attack                        \n",
      "34   14954    598       B01        B01           ‚úì      Scandinavian Defense: Mieses-Kotroc Variation     \n",
      "35   19969    342       A43        A43           ‚úì      Benoni Defense: French Benoni                     \n",
      "36   12824    245       A21        A21           ‚úì      English Opening: King's English Variation, Kr...  \n",
      "37   699      1298      C31        C31           ‚úì      King's Gambit Declined: Falkbeer Countergambi...  \n",
      "38   38249    2610      C17        C17           ‚úì      French Defense: Winawer Variation, Bogoljubow...  \n",
      "39   3606     1411      C40        C40           ‚úì      King's Pawn Game: McConnell Defense               \n",
      "40   19870    1743      C70        C70           ‚úì      Ruy Lopez: Morphy Defense, Caro Variation         \n",
      "41   13952    798       B20        B20           ‚úì      Sicilian Defense: Wing Gambit, Marshall Varia...  \n",
      "42   14456    1428      C41        C41           ‚úì      Philidor Defense                                  \n",
      "43   2961     2420      B54        B54           ‚úì      Sicilian Defense: Dragon Variation, Accelerat...  \n",
      "44   35984    2322      E65        E65           ‚úì      King's Indian Defense: Fianchetto Variation, ...  \n",
      "45   25228    1314      C33        C33           ‚úì      King's Gambit Accepted: Bishop's Gambit           \n",
      "46   47831    1237      C25        C25           ‚úì      Vienna Game                                       \n",
      "47   7070     307       A40        A40           ‚úì      Englund Gambit Complex: Zilbermints Gambit        \n",
      "48   10813    598       B01        B01           ‚úì      Scandinavian Defense: Mieses-Kotroc Variation     \n",
      "49   201      1354      C35        C35           ‚úì      King's Gambit Accepted: Cunningham Defense, B...  \n",
      "50   11990    1648      C55        C55           ‚úì      Italian Game: Two Knights Defense, Modern Bis...  \n",
      "51   37421    166       A06        A06           ‚úì      Zukertort Opening: Tennison Gambit                \n",
      "52   38216    280       A34        A34           ‚úì      English Opening: Symmetrical Variation, Norma...  \n",
      "53   2553     1407      C40        C40           ‚úì      King's Pawn Game: Busch-Gass Gambit               \n",
      "54   29135    825       B22        B22           ‚úì      Sicilian Defense: Alapin Variation                \n",
      "55   20180    762       B15        B15           ‚úì      Caro-Kann Defense: Tartakower Variation           \n",
      "56   26073    1958      D20        D20           ‚úì      Queen's Gambit Accepted: Central Variation, M...  \n",
      "57   27645    1896      D06        D06           ‚úì      Queen's Gambit Declined: Marshall Defense         \n",
      "58   26899    2036      D35        D35           ‚úì      Queen's Gambit Declined: Exchange Variation, ...  \n",
      "59   14698    1530      C44        C44           ‚úì      Scotch Game: Scotch Gambit, Kingside Variation    \n",
      "60   40326    1556      C46        C46           ‚úì      Three Knights Opening                             \n",
      "61   1507     1596      C50        C50           ‚úì      Italian Game: Giuoco Pianissimo, Normal           \n",
      "62   12311    706       B10        B10           ‚úì      Caro-Kann Defense                                 \n",
      "63   16578    1413      C40        C40           ‚úì      Latvian Gambit Accepted                           \n",
      "64   6277     2413      B02        B02           ‚úì      Alekhine Defense: Two Pawns Attack                \n",
      "65   21653    543       B00        B00           ‚úì      Nimzowitsch Defense: Kennedy Variation, Links...  \n",
      "66   11536    302       A40        A40           ‚úì      Englund Gambit Complex: Hartlaub-Charlick Gambit  \n",
      "67   45341    2669      C42        C42           ‚úì      Petrov's Defense: Stafford Gambit                 \n",
      "68   26777    241       A20        A20           ‚úì      English Opening: King's English Variation         \n",
      "69   27052    1556      C46        C46           ‚úì      Three Knights Opening                             \n",
      "70   19519    168       A07        A07           ‚úì      King's Indian Attack                              \n",
      "71   21677    1578      C48        C48           ‚úì      Four Knights Game: Spanish Variation              \n",
      "72   8896     168       A07        A07           ‚úì      King's Indian Attack                              \n",
      "73   31065    589       B01        B01           ‚úì      Scandinavian Defense: Icelandic-Palme Gambit      \n",
      "74   9484     2476      C56        C56           ‚úì      Italian Game: Scotch Gambit, de Riviere Defense   \n",
      "75   25776    598       B01        B01           ‚úì      Scandinavian Defense: Mieses-Kotroc Variation     \n",
      "76   16869    825       B22        B22           ‚úì      Sicilian Defense: Alapin Variation                \n",
      "77   30079    1596      C50        C50           ‚úì      Italian Game: Giuoco Pianissimo, Normal           \n",
      "78   40773    831       B22        B22           ‚úì      Sicilian Defense: Alapin Variation, Smith-Mor...  \n",
      "79   16072    39        A00        A00           ‚úì      Hungarian Opening: Symmetrical Variation          \n",
      "80   7837     142       A04        A04           ‚úì      Zukertort Opening: Queen's Gambit Invitation      \n",
      "81   22863    2450      B01        B01           ‚úì      Scandinavian Defense: Valencian Variation         \n",
      "82   13837    575       B00        B00           ‚úì      St. George Defense                                \n",
      "83   5692     856       B28        B28           ‚úì      Sicilian Defense: O'Kelly Variation               \n",
      "84   40796    1234      C24        C24           ‚úì      Bishop's Opening: Ponziani Gambit                 \n",
      "85   22301    728       B12        B12           ‚úì      Caro-Kann Defense: Advance Variation, Botvinn...  \n",
      "86   28219    1679      C60        C60           ‚úì      Ruy Lopez: Cozio Defense                          \n",
      "87   4648     1654      C57        C57           ‚úì      Italian Game: Two Knights Defense, Fried Live...  \n",
      "88   32974    653       B06        B06           ‚úì      Modern Defense                                    \n",
      "89   42539    421       A56        A56           ‚úì      Benoni Defense                                    \n",
      "90   17237    706       B10        B10           ‚úì      Caro-Kann Defense                                 \n",
      "91   5723     205       A13        A13           ‚úì      English Opening: Agincourt Defense                \n",
      "92   14435    188       A10        A10           ‚úì      English Opening: Anglo-Scandinavian Defense       \n",
      "93   13861    1933      D15        D15           ‚úì      Slav Defense: Geller Gambit                       \n",
      "94   34393    2018      D32        D32           ‚úì      Tarrasch Defense                                  \n",
      "95   35697    575       B00        B00           ‚úì      St. George Defense                                \n",
      "96   5329     49        A00        A00           ‚úì      Mieses Opening: Reversed Rat                      \n",
      "97   193      1916      D10        D10           ‚úì      Slav Defense                                      \n",
      "98   11802    918       B40        B40           ‚úì      Sicilian Defense: Four Knights Variation          \n",
      "99   17954    1702      C64        C64           ‚úì      Ruy Lopez: Classical Variation                    \n",
      "100  33411    543       B00        B00           ‚úì      Nimzowitsch Defense: Kennedy Variation, Links...  \n",
      "====================================================================================================\n",
      "\n",
      "‚úÖ Verification Results:\n",
      "   ‚Ä¢ Total samples: 100\n",
      "   ‚Ä¢ Matches: 100/100 (100.0%)\n",
      "   ‚Ä¢ Mismatches: 0\n",
      "\n",
      "üéâ Perfect! All ECO codes reconstructed correctly!\n",
      "   ‚Ä¢ ID remapping preserved all ECO code mappings\n"
     ]
    }
   ],
   "source": [
    "# Verification: Sample 100 player-opening pairs with reconstructed ECO codes and opening names\n",
    "# Doing this to make sure that our ECO encoding/decoding is correct\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"VERIFICATION: ECO RECONSTRUCTION AND OPENING NAMES\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Sample 100 random player-opening pairs from training data\n",
    "sample_size = 100\n",
    "sample_data = X_train.sample(min(sample_size, len(X_train)), random_state=42)\n",
    "\n",
    "print(f\"\\nSampling {len(sample_data)} player-opening pairs for verification...\\n\")\n",
    "\n",
    "# Get unique opening IDs from sample (these are NEW remapped IDs)\n",
    "new_opening_ids = sample_data['opening_id'].unique()\n",
    "\n",
    "# Convert NEW opening IDs back to OLD database IDs for query\n",
    "if opening_remapped:\n",
    "    old_opening_ids = [opening_idx_to_id[int(new_id)] for new_id in new_opening_ids]\n",
    "    print(f\"   ‚Ä¢ Converting {len(new_opening_ids)} NEW opening IDs to OLD database IDs for query\")\n",
    "    print(f\"   ‚Ä¢ Example: NEW ID {new_opening_ids[0]} ‚Üí OLD ID {old_opening_ids[0]}\")\n",
    "else:\n",
    "    old_opening_ids = new_opening_ids\n",
    "    print(f\"   ‚Ä¢ No remapping was done - using opening IDs directly\")\n",
    "\n",
    "opening_ids_str = ','.join(map(str, old_opening_ids))\n",
    "\n",
    "# Query database for opening names using OLD IDs\n",
    "con = get_db_connection(str(DB_PATH))\n",
    "try:\n",
    "    opening_query = f\"\"\"\n",
    "        SELECT id, name, eco\n",
    "        FROM opening\n",
    "        WHERE id IN ({opening_ids_str})\n",
    "    \"\"\"\n",
    "    opening_names = pd.DataFrame(con.execute(opening_query).df()).set_index('id')\n",
    "finally:\n",
    "    con.close()\n",
    "\n",
    "print(f\"   ‚úì Retrieved {len(opening_names)} opening names from database\\n\")\n",
    "\n",
    "# Create reverse mappings for ECO decoding\n",
    "eco_int_to_letter = {v: k for k, v in eco_letter_map.items()}\n",
    "eco_int_to_number = {v: k for k, v in eco_number_map.items()}\n",
    "\n",
    "# Build verification table\n",
    "print(f\"{'#':<4} {'Player':<8} {'Opening':<9} {'ECO (DB)':<10} {'Reconstructed':<13} {'Match':<6} {'Opening Name':<50}\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "matches = 0\n",
    "for i, (idx, row) in enumerate(sample_data.iterrows(), 1):\n",
    "    player_id = int(row['player_id'])\n",
    "    new_opening_id = int(row['opening_id'])\n",
    "    \n",
    "    # Convert NEW opening ID to OLD database ID for lookup\n",
    "    if opening_remapped:\n",
    "        old_opening_id = opening_idx_to_id[new_opening_id]\n",
    "    else:\n",
    "        old_opening_id = new_opening_id\n",
    "    \n",
    "    # Lookup opening side info using NEW ID\n",
    "    opening_info = opening_side_info.loc[new_opening_id]\n",
    "    \n",
    "    # Reconstruct ECO from encoded categorical values\n",
    "    eco_letter_encoded = opening_info['eco_letter_cat']\n",
    "    eco_number_encoded = opening_info['eco_number_cat']\n",
    "    \n",
    "    eco_letter_decoded = eco_int_to_letter[eco_letter_encoded]\n",
    "    eco_number_decoded = eco_int_to_number[eco_number_encoded]\n",
    "    \n",
    "    reconstructed_eco = f\"{eco_letter_decoded}{eco_number_decoded}\"\n",
    "    \n",
    "    # Get original ECO from database using OLD ID\n",
    "    db_eco = opening_names.loc[old_opening_id, 'eco']\n",
    "    opening_name = opening_names.loc[old_opening_id, 'name']\n",
    "    \n",
    "    # Check if they match\n",
    "    match = \"‚úì\" if reconstructed_eco == db_eco else \"‚úó\"\n",
    "    if reconstructed_eco == db_eco:\n",
    "        matches += 1\n",
    "    \n",
    "    # Truncate opening name if too long\n",
    "    if len(opening_name) > 48:\n",
    "        opening_name = opening_name[:45] + \"...\"\n",
    "    \n",
    "    # Display using NEW opening ID (what's in the data now)\n",
    "    print(f\"{i:<4} {player_id:<8} {new_opening_id:<9} {db_eco:<10} {reconstructed_eco:<13} {match:<6} {opening_name:<50}\")\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(f\"\\n‚úÖ Verification Results:\")\n",
    "print(f\"   ‚Ä¢ Total samples: {len(sample_data)}\")\n",
    "print(f\"   ‚Ä¢ Matches: {matches}/{len(sample_data)} ({100*matches/len(sample_data):.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Mismatches: {len(sample_data) - matches}\")\n",
    "\n",
    "if matches == len(sample_data):\n",
    "    print(f\"\\nüéâ Perfect! All ECO codes reconstructed correctly!\")\n",
    "    print(f\"   ‚Ä¢ ID remapping preserved all ECO code mappings\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Warning: Some ECO codes did not match. Investigate mismatches above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcf4878",
   "metadata": {},
   "source": [
    "## 5. Data Verification and Examination\n",
    "We're almost there. Let's examine our data structures to check for any obvious flaws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f76afbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train \n",
      "          player_id  opening_id  confidence\n",
      "130071        2125         653    0.456522\n",
      "2459660      40362         578    0.206349\n",
      "725099       11754         501    0.462366\n",
      "1426531      23420         653    0.484536\n",
      "899254       14629         198    0.342105\n",
      "============================================================\n",
      "X_val \n",
      "          player_id  opening_id  confidence\n",
      "1841273      30178         962    0.748744\n",
      "169628        2766         333    0.285714\n",
      "1916321      31399        2447    0.295775\n",
      "1620906      26570        1074    0.425287\n",
      "452506        7342        2460    0.333333\n",
      "============================================================\n",
      "X_test \n",
      "          player_id  opening_id  confidence\n",
      "241950        3931         825    0.242424\n",
      "322549        5259        1074    0.324324\n",
      "1447696      23755        1952    0.404762\n",
      "1445711      23721        1602    0.206349\n",
      "1624170      26626         561    0.295775\n",
      "============================================================\n",
      "y_train \n",
      " 130071     0.483502\n",
      "2459660    0.531574\n",
      "725099     0.503618\n",
      "1426531    0.443116\n",
      "899254     0.497497\n",
      "Name: score, dtype: float64\n",
      "============================================================\n",
      "y_val \n",
      " 1841273    0.481139\n",
      "169628     0.527952\n",
      "1916321    0.530243\n",
      "1620906    0.518127\n",
      "452506     0.489669\n",
      "Name: score, dtype: float64\n",
      "============================================================\n",
      "y_test \n",
      " 241950     0.478565\n",
      "322549     0.501042\n",
      "1447696    0.545123\n",
      "1445711    0.541089\n",
      "1624170    0.537578\n",
      "Name: score, dtype: float64\n",
      "player_side_info \n",
      "            rating_z\n",
      "player_id          \n",
      "0          0.609707\n",
      "1          1.059306\n",
      "2          0.561535\n",
      "3          0.617735\n",
      "4         -2.168176\n",
      "============================================================\n",
      "opening_side_info \n",
      "             eco_letter_cat  eco_number_cat\n",
      "opening_id                                \n",
      "531                      1               0\n",
      "565                      1               0\n",
      "572                      1               0\n",
      "579                      1               1\n",
      "589                      1               1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"X_train \\n\", X_train.head())\n",
    "print(\"=\"*60)\n",
    "print(\"X_val \\n\", X_val.head())\n",
    "print(\"=\" * 60)\n",
    "print(\"X_test \\n\", X_test.head())\n",
    "print(\"=\" * 60)\n",
    "print(\"y_train \\n\", y_train.head())\n",
    "print(\"=\" * 60)\n",
    "print(\"y_val \\n\", y_val.head())\n",
    "print(\"=\" * 60) \n",
    "print(\"y_test \\n\", y_test.head())\n",
    "\n",
    "# Now side information\n",
    "print(\"player_side_info \\n\", player_side_info.head())\n",
    "print(\"=\" * 60)\n",
    "print(\"opening_side_info \\n\", opening_side_info.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f00d8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52936cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CLEANED SIDE INFORMATION TABLES\n",
      "============================================================\n",
      "\n",
      "üìä player_side_info (cleaned):\n",
      "   ‚Ä¢ Shape: (48468, 1)\n",
      "   ‚Ä¢ Columns: ['rating_z']\n",
      "   ‚Ä¢ Index: player_id\n",
      "\n",
      "   Sample (5 rows):\n",
      "           rating_z\n",
      "player_id          \n",
      "0          0.609707\n",
      "1          1.059306\n",
      "2          0.561535\n",
      "3          0.617735\n",
      "4         -2.168176\n",
      "\n",
      "üìä opening_side_info (cleaned):\n",
      "   ‚Ä¢ Shape: (2715, 2)\n",
      "   ‚Ä¢ Columns: ['eco_letter_cat', 'eco_number_cat']\n",
      "   ‚Ä¢ Index: opening_id\n",
      "\n",
      "   Sample (5 rows):\n",
      "            eco_letter_cat  eco_number_cat\n",
      "opening_id                                \n",
      "531                      1               0\n",
      "565                      1               0\n",
      "572                      1               0\n",
      "579                      1               1\n",
      "589                      1               1\n",
      "\n",
      "‚úÖ Both side info tables contain ONLY the necessary model inputs:\n",
      "   ‚Ä¢ player_side_info: rating_z (normalized rating)\n",
      "   ‚Ä¢ opening_side_info: eco_letter_cat, eco_number_cat (categorical encodings)\n",
      "   ‚Ä¢ No unnecessary columns (names, titles, raw strings, etc.)\n"
     ]
    }
   ],
   "source": [
    "# Final verification: Display cleaned side info tables\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CLEANED SIDE INFORMATION TABLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä player_side_info (cleaned):\")\n",
    "print(f\"   ‚Ä¢ Shape: {player_side_info.shape}\")\n",
    "print(f\"   ‚Ä¢ Columns: {list(player_side_info.columns)}\")\n",
    "print(f\"   ‚Ä¢ Index: player_id\")\n",
    "print(f\"\\n   Sample (5 rows):\")\n",
    "print(player_side_info.head().to_string())\n",
    "\n",
    "print(f\"\\nüìä opening_side_info (cleaned):\")\n",
    "print(f\"   ‚Ä¢ Shape: {opening_side_info.shape}\")\n",
    "print(f\"   ‚Ä¢ Columns: {list(opening_side_info.columns)}\")\n",
    "print(f\"   ‚Ä¢ Index: opening_id\")\n",
    "print(f\"\\n   Sample (5 rows):\")\n",
    "print(opening_side_info.head().to_string())\n",
    "\n",
    "print(f\"\\n‚úÖ Both side info tables contain ONLY the necessary model inputs:\")\n",
    "print(f\"   ‚Ä¢ player_side_info: rating_z (normalized rating)\")\n",
    "print(f\"   ‚Ä¢ opening_side_info: eco_letter_cat, eco_number_cat (categorical encodings)\")\n",
    "print(f\"   ‚Ä¢ No unnecessary columns (names, titles, raw strings, etc.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19883cba",
   "metadata": {},
   "source": [
    "## Step 5: Convert to PyTorch Tensors\n",
    "\n",
    "**What are tensors?**\n",
    "Tensors are PyTorch's version of arrays - just multi-dimensional data structures optimized for deep learning. Think of them like fancy NumPy arrays that can run on GPUs.\n",
    "\n",
    "**What we need to convert:**\n",
    "\n",
    "1. **Main features** (X_train, X_val, X_test):\n",
    "   - `player_id` ‚Üí long tensor (integer IDs)\n",
    "   - `opening_id` ‚Üí long tensor (integer IDs)\n",
    "   - `confidence` ‚Üí float tensor (weights for loss function)\n",
    "\n",
    "2. **Targets** (y_train, y_val, y_test):\n",
    "   - `score` ‚Üí float tensor (what we're predicting)\n",
    "\n",
    "3. **Player side info** (player_side_info):\n",
    "   - `rating_z` ‚Üí float tensor (normalized ratings)\n",
    "   - Indexed by player_id for fast lookup\n",
    "\n",
    "4. **Opening side info** (opening_side_info):\n",
    "   - `eco_letter_cat` ‚Üí long tensor (categorical)\n",
    "   - `eco_number_cat` ‚Üí long tensor (categorical)\n",
    "   - Indexed by opening_id for fast lookup\n",
    "\n",
    "**Why these data types?**\n",
    "- `long` (int64): For IDs and categorical features that will be embedded\n",
    "- `float` (float32): For continuous values like scores, confidence, and normalized ratings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "350be514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/a/Documents/personalprojects/chess-opening-recommender/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/a/Documents/personalprojects/chess-opening-recommender/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/a/Documents/personalprojects/chess-opening-recommender/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/a/Documents/personalprojects/chess-opening-recommender/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/miniconda3/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/miniconda3/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/miniconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/a/Documents/personalprojects/chess-opening-recommender/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/a/Documents/personalprojects/chess-opening-recommender/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/a/Documents/personalprojects/chess-opening-recommender/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/a/Documents/personalprojects/chess-opening-recommender/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/a/Documents/personalprojects/chess-opening-recommender/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/a/Documents/personalprojects/chess-opening-recommender/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/a/Documents/personalprojects/chess-opening-recommender/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/a/Documents/personalprojects/chess-opening-recommender/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/a/Documents/personalprojects/chess-opening-recommender/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/a/Documents/personalprojects/chess-opening-recommender/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/a/Documents/personalprojects/chess-opening-recommender/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/a/Documents/personalprojects/chess-opening-recommender/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/a/Documents/personalprojects/chess-opening-recommender/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/4c/gt84bby56mqdnzwsg72zvd680000gn/T/ipykernel_15257/1901790236.py\", line 4, in <module>\n",
      "    import torch\n",
      "  File \"/Users/a/Documents/personalprojects/chess-opening-recommender/.venv/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/a/Documents/personalprojects/chess-opening-recommender/.venv/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/a/Documents/personalprojects/chess-opening-recommender/.venv/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/a/Documents/personalprojects/chess-opening-recommender/.venv/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/a/Documents/personalprojects/chess-opening-recommender/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/a/Documents/personalprojects/chess-opening-recommender/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "# Install PyTorch (if not already installed)\n",
    "import sys\n",
    "import subprocess\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eda01b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 5: CONVERT TO PYTORCH TENSORS\n",
      "============================================================\n",
      "\n",
      "‚öôÔ∏è  Configuration:\n",
      "   ‚Ä¢ PyTorch version: 2.2.2\n",
      "   ‚Ä¢ CUDA available: False\n",
      "   ‚Ä¢ Default dtype: float32 for continuous, int64 for IDs/categorical\n",
      "\n",
      "0Ô∏è‚É£  Index alignment sanity checks...\n",
      "   Checking player_side_info index alignment...\n",
      "   ‚úì player_side_info index is sorted\n",
      "   ‚Ä¢ Index range: [0, 48467]\n",
      "   ‚Ä¢ Index dtype: int64\n",
      "\n",
      "   Checking opening_side_info index alignment...\n",
      "   ‚ö†Ô∏è  opening_side_info index is not sorted - this is OK, we'll use index values directly\n",
      "   ‚Ä¢ Index range: [0, 2714]\n",
      "   ‚Ä¢ Index dtype: int64\n",
      "\n",
      "   Checking if indices are contiguous 0-based...\n",
      "   ‚Ä¢ player_side_info contiguous 0-based: True\n",
      "   ‚Ä¢ opening_side_info contiguous 0-based: False\n",
      "   ‚ÑπÔ∏è  Opening IDs are NOT 0-based contiguous - will need mapping for embedding lookup\n",
      "\n",
      "1Ô∏è‚É£  Converting main features (X_train, X_val, X_test)...\n",
      "   Train tensors:\n",
      "   ‚Ä¢ player_ids_train: torch.Size([2172843]), dtype=torch.int64\n",
      "   ‚Ä¢ opening_ids_train: torch.Size([2172843]), dtype=torch.int64\n",
      "   ‚Ä¢ confidence_train: torch.Size([2172843]), dtype=torch.float32\n",
      "\n",
      "   Validation tensors:\n",
      "   ‚Ä¢ player_ids_val: torch.Size([434569]), dtype=torch.int64\n",
      "   ‚Ä¢ opening_ids_val: torch.Size([434569]), dtype=torch.int64\n",
      "   ‚Ä¢ confidence_val: torch.Size([434569]), dtype=torch.float32\n",
      "   Train tensors:\n",
      "   ‚Ä¢ player_ids_train: torch.Size([2172843]), dtype=torch.int64\n",
      "   ‚Ä¢ opening_ids_train: torch.Size([2172843]), dtype=torch.int64\n",
      "   ‚Ä¢ confidence_train: torch.Size([2172843]), dtype=torch.float32\n",
      "\n",
      "   Validation tensors:\n",
      "   ‚Ä¢ player_ids_val: torch.Size([434569]), dtype=torch.int64\n",
      "   ‚Ä¢ opening_ids_val: torch.Size([434569]), dtype=torch.int64\n",
      "   ‚Ä¢ confidence_val: torch.Size([434569]), dtype=torch.float32\n",
      "\n",
      "   Test tensors:\n",
      "   ‚Ä¢ player_ids_test: torch.Size([289713]), dtype=torch.int64\n",
      "   ‚Ä¢ opening_ids_test: torch.Size([289713]), dtype=torch.int64\n",
      "   ‚Ä¢ confidence_test: torch.Size([289713]), dtype=torch.float32\n",
      "\n",
      "2Ô∏è‚É£  Converting target scores (y_train, y_val, y_test)...\n",
      "   ‚Ä¢ scores_train: torch.Size([2172843]), dtype=torch.float32\n",
      "   ‚Ä¢ scores_val: torch.Size([434569]), dtype=torch.float32\n",
      "   ‚Ä¢ scores_test: torch.Size([289713]), dtype=torch.float32\n",
      "\n",
      "   Score ranges (sanity check):\n",
      "   ‚Ä¢ Train: [0.1003, 0.8020]\n",
      "   ‚Ä¢ Val: [0.1351, 0.8250]\n",
      "   ‚Ä¢ Test: [0.1138, 1.0000]\n",
      "\n",
      "3Ô∏è‚É£  Converting player side information...\n",
      "   ‚Ä¢ player_ratings_tensor: torch.Size([48468]), dtype=torch.float32\n",
      "   ‚Ä¢ player_ids_in_side_info: torch.Size([48468]), dtype=torch.int64\n",
      "   ‚Ä¢ Rating range: [-2.2685, 4.2466]\n",
      "   ‚úì All 48468 unique players in splits have side information\n",
      "\n",
      "4Ô∏è‚É£  Converting opening side information...\n",
      "   ‚Ä¢ opening_eco_letter_tensor: torch.Size([2715]), dtype=torch.int64\n",
      "   ‚Ä¢ opening_eco_number_tensor: torch.Size([2715]), dtype=torch.int64\n",
      "   ‚Ä¢ opening_ids_in_side_info: torch.Size([2715]), dtype=torch.int64\n",
      "   ‚Ä¢ ECO letter range: [0, 4]\n",
      "   ‚Ä¢ ECO number range: [0, 99]\n",
      "\n",
      "   Test tensors:\n",
      "   ‚Ä¢ player_ids_test: torch.Size([289713]), dtype=torch.int64\n",
      "   ‚Ä¢ opening_ids_test: torch.Size([289713]), dtype=torch.int64\n",
      "   ‚Ä¢ confidence_test: torch.Size([289713]), dtype=torch.float32\n",
      "\n",
      "2Ô∏è‚É£  Converting target scores (y_train, y_val, y_test)...\n",
      "   ‚Ä¢ scores_train: torch.Size([2172843]), dtype=torch.float32\n",
      "   ‚Ä¢ scores_val: torch.Size([434569]), dtype=torch.float32\n",
      "   ‚Ä¢ scores_test: torch.Size([289713]), dtype=torch.float32\n",
      "\n",
      "   Score ranges (sanity check):\n",
      "   ‚Ä¢ Train: [0.1003, 0.8020]\n",
      "   ‚Ä¢ Val: [0.1351, 0.8250]\n",
      "   ‚Ä¢ Test: [0.1138, 1.0000]\n",
      "\n",
      "3Ô∏è‚É£  Converting player side information...\n",
      "   ‚Ä¢ player_ratings_tensor: torch.Size([48468]), dtype=torch.float32\n",
      "   ‚Ä¢ player_ids_in_side_info: torch.Size([48468]), dtype=torch.int64\n",
      "   ‚Ä¢ Rating range: [-2.2685, 4.2466]\n",
      "   ‚úì All 48468 unique players in splits have side information\n",
      "\n",
      "4Ô∏è‚É£  Converting opening side information...\n",
      "   ‚Ä¢ opening_eco_letter_tensor: torch.Size([2715]), dtype=torch.int64\n",
      "   ‚Ä¢ opening_eco_number_tensor: torch.Size([2715]), dtype=torch.int64\n",
      "   ‚Ä¢ opening_ids_in_side_info: torch.Size([2715]), dtype=torch.int64\n",
      "   ‚Ä¢ ECO letter range: [0, 4]\n",
      "   ‚Ä¢ ECO number range: [0, 99]\n",
      "   ‚úì All 2715 unique openings in splits have side information\n",
      "\n",
      "5Ô∏è‚É£  Summary statistics:\n",
      "\n",
      "   Dataset sizes:\n",
      "   ‚Ä¢ Train: 2,172,843 samples\n",
      "   ‚Ä¢ Val: 434,569 samples\n",
      "   ‚Ä¢ Test: 289,713 samples\n",
      "\n",
      "   Unique entities:\n",
      "   ‚Ä¢ Players: 48,468\n",
      "   ‚Ä¢ Openings: 2,715\n",
      "\n",
      "   Vocabulary sizes (for embedding layers):\n",
      "   ‚Ä¢ num_players: 48468 (max player_id + 1)\n",
      "   ‚Ä¢ num_openings: 2715 (max opening_id + 1)\n",
      "   ‚Ä¢ num_eco_letters: 5 (max eco_letter_cat + 1)\n",
      "   ‚Ä¢ num_eco_numbers: 100 (max eco_number_cat + 1)\n",
      "\n",
      "6Ô∏è‚É£  Approximate memory usage:\n",
      "   ‚Ä¢ Total tensor memory: 66.54 MB\n",
      "\n",
      "============================================================\n",
      "‚úÖ TENSOR CONVERSION COMPLETE\n",
      "============================================================\n",
      "\n",
      "üì¶ Available tensors for training:\n",
      "\n",
      "   Main features (train/val/test):\n",
      "   ‚Ä¢ player_ids_train, player_ids_val, player_ids_test\n",
      "   ‚Ä¢ opening_ids_train, opening_ids_val, opening_ids_test\n",
      "   ‚Ä¢ confidence_train, confidence_val, confidence_test\n",
      "\n",
      "   Targets (train/val/test):\n",
      "   ‚Ä¢ scores_train, scores_val, scores_test\n",
      "\n",
      "   Side information:\n",
      "   ‚Ä¢ player_ratings_tensor (indexed by player_ids_in_side_info)\n",
      "   ‚Ä¢ opening_eco_letter_tensor (indexed by opening_ids_in_side_info)\n",
      "   ‚Ä¢ opening_eco_number_tensor (indexed by opening_ids_in_side_info)\n",
      "\n",
      "üí° Ready for model training!\n",
      "   These tensors can be directly fed into PyTorch DataLoaders and models.\n",
      "   ‚úì All 2715 unique openings in splits have side information\n",
      "\n",
      "5Ô∏è‚É£  Summary statistics:\n",
      "\n",
      "   Dataset sizes:\n",
      "   ‚Ä¢ Train: 2,172,843 samples\n",
      "   ‚Ä¢ Val: 434,569 samples\n",
      "   ‚Ä¢ Test: 289,713 samples\n",
      "\n",
      "   Unique entities:\n",
      "   ‚Ä¢ Players: 48,468\n",
      "   ‚Ä¢ Openings: 2,715\n",
      "\n",
      "   Vocabulary sizes (for embedding layers):\n",
      "   ‚Ä¢ num_players: 48468 (max player_id + 1)\n",
      "   ‚Ä¢ num_openings: 2715 (max opening_id + 1)\n",
      "   ‚Ä¢ num_eco_letters: 5 (max eco_letter_cat + 1)\n",
      "   ‚Ä¢ num_eco_numbers: 100 (max eco_number_cat + 1)\n",
      "\n",
      "6Ô∏è‚É£  Approximate memory usage:\n",
      "   ‚Ä¢ Total tensor memory: 66.54 MB\n",
      "\n",
      "============================================================\n",
      "‚úÖ TENSOR CONVERSION COMPLETE\n",
      "============================================================\n",
      "\n",
      "üì¶ Available tensors for training:\n",
      "\n",
      "   Main features (train/val/test):\n",
      "   ‚Ä¢ player_ids_train, player_ids_val, player_ids_test\n",
      "   ‚Ä¢ opening_ids_train, opening_ids_val, opening_ids_test\n",
      "   ‚Ä¢ confidence_train, confidence_val, confidence_test\n",
      "\n",
      "   Targets (train/val/test):\n",
      "   ‚Ä¢ scores_train, scores_val, scores_test\n",
      "\n",
      "   Side information:\n",
      "   ‚Ä¢ player_ratings_tensor (indexed by player_ids_in_side_info)\n",
      "   ‚Ä¢ opening_eco_letter_tensor (indexed by opening_ids_in_side_info)\n",
      "   ‚Ä¢ opening_eco_number_tensor (indexed by opening_ids_in_side_info)\n",
      "\n",
      "üí° Ready for model training!\n",
      "   These tensors can be directly fed into PyTorch DataLoaders and models.\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Convert all data to PyTorch tensors\n",
    "\n",
    "import torch\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 5: CONVERT TO PYTORCH TENSORS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è  Configuration:\")\n",
    "print(f\"   ‚Ä¢ PyTorch version: {torch.__version__}\")\n",
    "print(f\"   ‚Ä¢ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   ‚Ä¢ CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"   ‚Ä¢ Default dtype: float32 for continuous, int64 for IDs/categorical\")\n",
    "\n",
    "# 0. Index alignment sanity checks\n",
    "print(f\"\\n0Ô∏è‚É£  Index alignment sanity checks...\")\n",
    "\n",
    "# Check player_side_info is properly indexed\n",
    "print(f\"   Checking player_side_info index alignment...\")\n",
    "player_ids_sorted = sorted(player_side_info.index.values)\n",
    "if player_ids_sorted != list(player_side_info.index.values):\n",
    "    print(f\"   ‚ö†Ô∏è  player_side_info index is not sorted - this is OK, we'll use index values directly\")\n",
    "else:\n",
    "    print(f\"   ‚úì player_side_info index is sorted\")\n",
    "print(f\"   ‚Ä¢ Index range: [{player_side_info.index.min()}, {player_side_info.index.max()}]\")\n",
    "print(f\"   ‚Ä¢ Index dtype: {player_side_info.index.dtype}\")\n",
    "\n",
    "# Check opening_side_info is properly indexed\n",
    "print(f\"\\n   Checking opening_side_info index alignment...\")\n",
    "opening_ids_sorted = sorted(opening_side_info.index.values)\n",
    "if opening_ids_sorted != list(opening_side_info.index.values):\n",
    "    print(f\"   ‚ö†Ô∏è  opening_side_info index is not sorted - this is OK, we'll use index values directly\")\n",
    "else:\n",
    "    print(f\"   ‚úì opening_side_info index is sorted\")\n",
    "print(f\"   ‚Ä¢ Index range: [{opening_side_info.index.min()}, {opening_side_info.index.max()}]\")\n",
    "print(f\"   ‚Ä¢ Index dtype: {opening_side_info.index.dtype}\")\n",
    "\n",
    "# CRITICAL: Check if indices are contiguous 0-based\n",
    "# If opening_side_info.index = [0, 1, 2, ..., N-1], then we can use opening_id as direct array index\n",
    "# If not (e.g., [10, 15, 23, ...]), we'll need a mapping dictionary\n",
    "print(f\"\\n   Checking if indices are contiguous 0-based...\")\n",
    "player_contiguous = (player_side_info.index == range(len(player_side_info))).all()\n",
    "opening_contiguous = (opening_side_info.index == range(len(opening_side_info))).all()\n",
    "\n",
    "print(f\"   ‚Ä¢ player_side_info contiguous 0-based: {player_contiguous}\")\n",
    "print(f\"   ‚Ä¢ opening_side_info contiguous 0-based: {opening_contiguous}\")\n",
    "\n",
    "if not player_contiguous:\n",
    "    print(f\"   ‚ÑπÔ∏è  Player IDs are NOT 0-based contiguous - will need mapping for embedding lookup\")\n",
    "if not opening_contiguous:\n",
    "    print(f\"   ‚ÑπÔ∏è  Opening IDs are NOT 0-based contiguous - will need mapping for embedding lookup\")\n",
    "\n",
    "# 1. Convert main features (train/val/test)\n",
    "print(f\"\\n1Ô∏è‚É£  Converting main features (X_train, X_val, X_test)...\")\n",
    "\n",
    "# Train set\n",
    "player_ids_train = torch.tensor(X_train['player_id'].values, dtype=torch.long)\n",
    "opening_ids_train = torch.tensor(X_train['opening_id'].values, dtype=torch.long)\n",
    "confidence_train = torch.tensor(X_train['confidence'].values, dtype=torch.float32)\n",
    "\n",
    "print(f\"   Train tensors:\")\n",
    "print(f\"   ‚Ä¢ player_ids_train: {player_ids_train.shape}, dtype={player_ids_train.dtype}\")\n",
    "print(f\"   ‚Ä¢ opening_ids_train: {opening_ids_train.shape}, dtype={opening_ids_train.dtype}\")\n",
    "print(f\"   ‚Ä¢ confidence_train: {confidence_train.shape}, dtype={confidence_train.dtype}\")\n",
    "\n",
    "# Validation set\n",
    "player_ids_val = torch.tensor(X_val['player_id'].values, dtype=torch.long)\n",
    "opening_ids_val = torch.tensor(X_val['opening_id'].values, dtype=torch.long)\n",
    "confidence_val = torch.tensor(X_val['confidence'].values, dtype=torch.float32)\n",
    "\n",
    "print(f\"\\n   Validation tensors:\")\n",
    "print(f\"   ‚Ä¢ player_ids_val: {player_ids_val.shape}, dtype={player_ids_val.dtype}\")\n",
    "print(f\"   ‚Ä¢ opening_ids_val: {opening_ids_val.shape}, dtype={opening_ids_val.dtype}\")\n",
    "print(f\"   ‚Ä¢ confidence_val: {confidence_val.shape}, dtype={confidence_val.dtype}\")\n",
    "\n",
    "# Test set\n",
    "player_ids_test = torch.tensor(X_test['player_id'].values, dtype=torch.long)\n",
    "opening_ids_test = torch.tensor(X_test['opening_id'].values, dtype=torch.long)\n",
    "confidence_test = torch.tensor(X_test['confidence'].values, dtype=torch.float32)\n",
    "\n",
    "print(f\"\\n   Test tensors:\")\n",
    "print(f\"   ‚Ä¢ player_ids_test: {player_ids_test.shape}, dtype={player_ids_test.dtype}\")\n",
    "print(f\"   ‚Ä¢ opening_ids_test: {opening_ids_test.shape}, dtype={opening_ids_test.dtype}\")\n",
    "print(f\"   ‚Ä¢ confidence_test: {confidence_test.shape}, dtype={confidence_test.dtype}\")\n",
    "\n",
    "# 2. Convert targets (scores)\n",
    "print(f\"\\n2Ô∏è‚É£  Converting target scores (y_train, y_val, y_test)...\")\n",
    "\n",
    "scores_train = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "scores_val = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "scores_test = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "print(f\"   ‚Ä¢ scores_train: {scores_train.shape}, dtype={scores_train.dtype}\")\n",
    "print(f\"   ‚Ä¢ scores_val: {scores_val.shape}, dtype={scores_val.dtype}\")\n",
    "print(f\"   ‚Ä¢ scores_test: {scores_test.shape}, dtype={scores_test.dtype}\")\n",
    "\n",
    "print(f\"\\n   Score ranges (sanity check):\")\n",
    "print(f\"   ‚Ä¢ Train: [{scores_train.min():.4f}, {scores_train.max():.4f}]\")\n",
    "print(f\"   ‚Ä¢ Val: [{scores_val.min():.4f}, {scores_val.max():.4f}]\")\n",
    "print(f\"   ‚Ä¢ Test: [{scores_test.min():.4f}, {scores_test.max():.4f}]\")\n",
    "\n",
    "# 3. Convert player side information\n",
    "print(f\"\\n3Ô∏è‚É£  Converting player side information...\")\n",
    "\n",
    "# Create tensor of all player ratings (indexed by player_id)\n",
    "# Since player_side_info is indexed by player_id, we need to ensure coverage\n",
    "player_ratings_tensor = torch.tensor(player_side_info['rating_z'].values, dtype=torch.float32)\n",
    "player_ids_in_side_info = torch.tensor(player_side_info.index.values, dtype=torch.long)\n",
    "\n",
    "print(f\"   ‚Ä¢ player_ratings_tensor: {player_ratings_tensor.shape}, dtype={player_ratings_tensor.dtype}\")\n",
    "print(f\"   ‚Ä¢ player_ids_in_side_info: {player_ids_in_side_info.shape}, dtype={player_ids_in_side_info.dtype}\")\n",
    "print(f\"   ‚Ä¢ Rating range: [{player_ratings_tensor.min():.4f}, {player_ratings_tensor.max():.4f}]\")\n",
    "\n",
    "# Verify all player IDs in train/val/test are covered\n",
    "all_player_ids = torch.cat([player_ids_train, player_ids_val, player_ids_test]).unique()\n",
    "missing_players = set(all_player_ids.tolist()) - set(player_ids_in_side_info.tolist())\n",
    "if len(missing_players) > 0:\n",
    "    print(f\"   ‚ö†Ô∏è  WARNING: {len(missing_players)} players in splits missing from side_info!\")\n",
    "else:\n",
    "    print(f\"   ‚úì All {len(all_player_ids)} unique players in splits have side information\")\n",
    "\n",
    "# 4. Convert opening side information\n",
    "print(f\"\\n4Ô∏è‚É£  Converting opening side information...\")\n",
    "\n",
    "# Verify column names exist (using eco_letter_cat and eco_number_cat consistently)\n",
    "if 'eco_letter_cat' not in opening_side_info.columns:\n",
    "    raise ValueError(f\"Column 'eco_letter_cat' not found. Available: {opening_side_info.columns.tolist()}\")\n",
    "if 'eco_number_cat' not in opening_side_info.columns:\n",
    "    raise ValueError(f\"Column 'eco_number_cat' not found. Available: {opening_side_info.columns.tolist()}\")\n",
    "\n",
    "# Create tensors for opening ECO features (indexed by opening_id)\n",
    "opening_eco_letter_tensor = torch.tensor(opening_side_info['eco_letter_cat'].values, dtype=torch.long)\n",
    "opening_eco_number_tensor = torch.tensor(opening_side_info['eco_number_cat'].values, dtype=torch.long)\n",
    "opening_ids_in_side_info = torch.tensor(opening_side_info.index.values, dtype=torch.long)\n",
    "\n",
    "print(f\"   ‚Ä¢ opening_eco_letter_tensor: {opening_eco_letter_tensor.shape}, dtype={opening_eco_letter_tensor.dtype}\")\n",
    "print(f\"   ‚Ä¢ opening_eco_number_tensor: {opening_eco_number_tensor.shape}, dtype={opening_eco_number_tensor.dtype}\")\n",
    "print(f\"   ‚Ä¢ opening_ids_in_side_info: {opening_ids_in_side_info.shape}, dtype={opening_ids_in_side_info.dtype}\")\n",
    "print(f\"   ‚Ä¢ ECO letter range: [{opening_eco_letter_tensor.min()}, {opening_eco_letter_tensor.max()}]\")\n",
    "print(f\"   ‚Ä¢ ECO number range: [{opening_eco_number_tensor.min()}, {opening_eco_number_tensor.max()}]\")\n",
    "\n",
    "# Verify all opening IDs in train/val/test are covered\n",
    "all_opening_ids = torch.cat([opening_ids_train, opening_ids_val, opening_ids_test]).unique()\n",
    "missing_openings = set(all_opening_ids.tolist()) - set(opening_ids_in_side_info.tolist())\n",
    "if len(missing_openings) > 0:\n",
    "    print(f\"   ‚ö†Ô∏è  WARNING: {len(missing_openings)} openings in splits missing from side_info!\")\n",
    "else:\n",
    "    print(f\"   ‚úì All {len(all_opening_ids)} unique openings in splits have side information\")\n",
    "\n",
    "# 5. Summary statistics\n",
    "print(f\"\\n5Ô∏è‚É£  Summary statistics:\")\n",
    "print(f\"\\n   Dataset sizes:\")\n",
    "print(f\"   ‚Ä¢ Train: {len(scores_train):,} samples\")\n",
    "print(f\"   ‚Ä¢ Val: {len(scores_val):,} samples\")\n",
    "print(f\"   ‚Ä¢ Test: {len(scores_test):,} samples\")\n",
    "\n",
    "print(f\"\\n   Unique entities:\")\n",
    "print(f\"   ‚Ä¢ Players: {len(player_ids_in_side_info):,}\")\n",
    "print(f\"   ‚Ä¢ Openings: {len(opening_ids_in_side_info):,}\")\n",
    "\n",
    "print(f\"\\n   Vocabulary sizes (for embedding layers):\")\n",
    "print(f\"   ‚Ä¢ num_players: {player_ids_in_side_info.max() + 1} (max player_id + 1)\")\n",
    "print(f\"   ‚Ä¢ num_openings: {opening_ids_in_side_info.max() + 1} (max opening_id + 1)\")\n",
    "print(f\"   ‚Ä¢ num_eco_letters: {opening_eco_letter_tensor.max() + 1} (max eco_letter_cat + 1)\")\n",
    "print(f\"   ‚Ä¢ num_eco_numbers: {opening_eco_number_tensor.max() + 1} (max eco_number_cat + 1)\")\n",
    "\n",
    "# 6. Memory usage (approximate - using simple calculation)\n",
    "print(f\"\\n6Ô∏è‚É£  Approximate memory usage:\")\n",
    "# More efficient calculation: element_size * nelement for each tensor\n",
    "# Using list comprehension with helper function for cleaner code\n",
    "def tensor_memory_mb(t):\n",
    "    \"\"\"Calculate tensor memory in MB\"\"\"\n",
    "    return (t.element_size() * t.nelement()) / (1024 * 1024)\n",
    "\n",
    "tensors = [\n",
    "    player_ids_train, opening_ids_train, confidence_train, scores_train,\n",
    "    player_ids_val, opening_ids_val, confidence_val, scores_val,\n",
    "    player_ids_test, opening_ids_test, confidence_test, scores_test,\n",
    "    player_ratings_tensor, opening_eco_letter_tensor, opening_eco_number_tensor\n",
    "]\n",
    "total_memory_mb = sum(tensor_memory_mb(t) for t in tensors)\n",
    "print(f\"   ‚Ä¢ Total tensor memory: {total_memory_mb:.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ TENSOR CONVERSION COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüì¶ Available tensors for training:\")\n",
    "print(f\"\\n   Main features (train/val/test):\")\n",
    "print(f\"   ‚Ä¢ player_ids_train, player_ids_val, player_ids_test\")\n",
    "print(f\"   ‚Ä¢ opening_ids_train, opening_ids_val, opening_ids_test\")\n",
    "print(f\"   ‚Ä¢ confidence_train, confidence_val, confidence_test\")\n",
    "\n",
    "print(f\"\\n   Targets (train/val/test):\")\n",
    "print(f\"   ‚Ä¢ scores_train, scores_val, scores_test\")\n",
    "\n",
    "print(f\"\\n   Side information:\")\n",
    "print(f\"   ‚Ä¢ player_ratings_tensor (indexed by player_ids_in_side_info)\")\n",
    "print(f\"   ‚Ä¢ opening_eco_letter_tensor (indexed by opening_ids_in_side_info)\")\n",
    "print(f\"   ‚Ä¢ opening_eco_number_tensor (indexed by opening_ids_in_side_info)\")\n",
    "\n",
    "print(f\"\\nüí° Ready for model training!\")\n",
    "print(f\"   These tensors can be directly fed into PyTorch DataLoaders and models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376fc308",
   "metadata": {},
   "source": [
    "## Step 6: Training Setup\n",
    "\n",
    "Define all constants, loss functions, optimizer, and helper functions for training.\n",
    "\n",
    "**What we need to set up:**\n",
    "\n",
    "1. **Constants and Hyperparameters:**\n",
    "   - `NUM_FACTORS`: Dimensionality of latent factor embeddings (e.g., 50)\n",
    "   - `LEARNING_RATE`: Step size for SGD optimizer (e.g., 0.01)\n",
    "   - `BATCH_SIZE`: Number of samples per training batch (e.g., 1024)\n",
    "   - `N_EPOCHS`: Number of full passes through training data (e.g., 10)\n",
    "   - Random seeds for reproducibility\n",
    "\n",
    "2. **Loss Functions:**\n",
    "   - MSE (Mean Squared Error): Main training loss\n",
    "   - RMSE (Root Mean Squared Error): Evaluation metric\n",
    "   - Confidence-weighted loss: Down-weight uncertain predictions\n",
    "\n",
    "3. **Optimizer:**\n",
    "   - SGD (Stochastic Gradient Descent) with momentum\n",
    "\n",
    "4. **Helper Functions:**\n",
    "   - `train_one_epoch()`: Train for one epoch\n",
    "   - `evaluate_model()`: Evaluate on validation/test set\n",
    "   - `calculate_rmse()`: Compute RMSE metric\n",
    "   - `save_checkpoint()`: Save model state\n",
    "\n",
    "5. **Logging:**\n",
    "   - Progress bars with ETA\n",
    "   - Loss tracking per epoch\n",
    "   - Model checkpointing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54d13c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 6A: DEFINE HYPERPARAMETERS AND CONSTANTS\n",
      "============================================================\n",
      "\n",
      "üìã Hyperparameters:\n",
      "   ‚Ä¢ NUM_FACTORS: 50\n",
      "   ‚Ä¢ LEARNING_RATE: 0.01\n",
      "   ‚Ä¢ MOMENTUM: 0.9\n",
      "   ‚Ä¢ BATCH_SIZE: 1024\n",
      "   ‚Ä¢ N_EPOCHS: 20\n",
      "   ‚Ä¢ WEIGHT_DECAY: 0.0\n",
      "\n",
      "üé≤ Random Seed:\n",
      "   ‚Ä¢ RANDOM_SEED: 42\n",
      "\n",
      "üíª Device Configuration:\n",
      "   ‚Ä¢ DEVICE: cpu\n",
      "\n",
      "üíæ Model Saving:\n",
      "   ‚Ä¢ Save directory: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models\n",
      "\n",
      "üîí Setting random seeds for reproducibility...\n",
      "   ‚úì Python random seed set to 42\n",
      "   ‚úì NumPy random seed set to 42\n",
      "   ‚úì PyTorch CPU random seed set to 42\n",
      "\n",
      "üìä Vocabulary Sizes (for embedding layers):\n",
      "   ‚Ä¢ NUM_PLAYERS: 48,468 (max player_id + 1)\n",
      "   ‚Ä¢ NUM_OPENINGS: 2,715 (max opening_id + 1)\n",
      "   ‚Ä¢ NUM_ECO_LETTERS: 5 (ECO letter categories)\n",
      "   ‚Ä¢ NUM_ECO_NUMBERS: 100 (ECO number categories)\n",
      "\n",
      "üìà Dataset Statistics:\n",
      "   ‚Ä¢ Train samples: 2,172,843\n",
      "   ‚Ä¢ Validation samples: 434,569\n",
      "   ‚Ä¢ Test samples: 289,713\n",
      "   ‚Ä¢ Total samples: 2,897,125\n",
      "\n",
      "   ‚Ä¢ Batches per epoch: 2,121\n",
      "   ‚Ä¢ Training iterations (total): 42,420\n",
      "\n",
      "============================================================\n",
      "‚úÖ HYPERPARAMETERS AND CONSTANTS DEFINED\n",
      "============================================================\n",
      "\n",
      "üí° To modify hyperparameters:\n",
      "   ‚Ä¢ Edit the values at the top of this cell\n",
      "   ‚Ä¢ Rerun this cell to apply changes\n",
      "   ‚Ä¢ All subsequent cells will use the updated values\n"
     ]
    }
   ],
   "source": [
    "# Step 6a: Define Hyperparameters and Constants\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 6A: DEFINE HYPERPARAMETERS AND CONSTANTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ========================================\n",
    "# HYPERPARAMETERS (Easy to modify here)\n",
    "# ========================================\n",
    "\n",
    "# Model architecture\n",
    "NUM_FACTORS = 50  # Dimensionality of latent factor embeddings\n",
    "\n",
    "# Training parameters\n",
    "LEARNING_RATE = 0.01  # SGD learning rate\n",
    "MOMENTUM = 0.9  # SGD momentum\n",
    "BATCH_SIZE = 1024  # Mini-batch size\n",
    "N_EPOCHS = 20  # Number of training epochs\n",
    "\n",
    "# Regularization (if needed)\n",
    "WEIGHT_DECAY = 0.0  # L2 regularization (0 = no regularization)\n",
    "\n",
    "# Random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model saving configuration\n",
    "MODEL_SAVE_DIR = Path.cwd().parent / \"data\" / \"models\"  # Saves to root/data/models\n",
    "MODEL_SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "print(f\"\\nüìã Hyperparameters:\")\n",
    "print(f\"   ‚Ä¢ NUM_FACTORS: {NUM_FACTORS}\")\n",
    "print(f\"   ‚Ä¢ LEARNING_RATE: {LEARNING_RATE}\")\n",
    "print(f\"   ‚Ä¢ MOMENTUM: {MOMENTUM}\")\n",
    "print(f\"   ‚Ä¢ BATCH_SIZE: {BATCH_SIZE}\")\n",
    "print(f\"   ‚Ä¢ N_EPOCHS: {N_EPOCHS}\")\n",
    "print(f\"   ‚Ä¢ WEIGHT_DECAY: {WEIGHT_DECAY}\")\n",
    "\n",
    "print(f\"\\nüé≤ Random Seed:\")\n",
    "print(f\"   ‚Ä¢ RANDOM_SEED: {RANDOM_SEED}\")\n",
    "\n",
    "print(f\"\\nüíª Device Configuration:\")\n",
    "print(f\"   ‚Ä¢ DEVICE: {DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   ‚Ä¢ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   ‚Ä¢ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "print(f\"\\nüíæ Model Saving:\")\n",
    "print(f\"   ‚Ä¢ Save directory: {MODEL_SAVE_DIR}\")\n",
    "\n",
    "# ========================================\n",
    "# SET RANDOM SEEDS FOR REPRODUCIBILITY\n",
    "# ========================================\n",
    "\n",
    "print(f\"\\nüîí Setting random seeds for reproducibility...\")\n",
    "\n",
    "# Python random\n",
    "random.seed(RANDOM_SEED)\n",
    "print(f\"   ‚úì Python random seed set to {RANDOM_SEED}\")\n",
    "\n",
    "# NumPy random\n",
    "np.random.seed(RANDOM_SEED)\n",
    "print(f\"   ‚úì NumPy random seed set to {RANDOM_SEED}\")\n",
    "\n",
    "# PyTorch random\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "print(f\"   ‚úì PyTorch CPU random seed set to {RANDOM_SEED}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)  # For multi-GPU\n",
    "    print(f\"   ‚úì PyTorch GPU random seed set to {RANDOM_SEED}\")\n",
    "    \n",
    "    # Additional CUDA reproducibility settings\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(f\"   ‚úì CUDA deterministic mode enabled\")\n",
    "\n",
    "# ========================================\n",
    "# CALCULATE VOCABULARY SIZES\n",
    "# ========================================\n",
    "\n",
    "print(f\"\\nüìä Vocabulary Sizes (for embedding layers):\")\n",
    "\n",
    "# Calculate from our tensors\n",
    "NUM_PLAYERS = int(player_ids_in_side_info.max()) + 1\n",
    "NUM_OPENINGS = int(opening_ids_in_side_info.max()) + 1\n",
    "NUM_ECO_LETTERS = int(opening_eco_letter_tensor.max()) + 1\n",
    "NUM_ECO_NUMBERS = int(opening_eco_number_tensor.max()) + 1\n",
    "\n",
    "print(f\"   ‚Ä¢ NUM_PLAYERS: {NUM_PLAYERS:,} (max player_id + 1)\")\n",
    "print(f\"   ‚Ä¢ NUM_OPENINGS: {NUM_OPENINGS:,} (max opening_id + 1)\")\n",
    "print(f\"   ‚Ä¢ NUM_ECO_LETTERS: {NUM_ECO_LETTERS} (ECO letter categories)\")\n",
    "print(f\"   ‚Ä¢ NUM_ECO_NUMBERS: {NUM_ECO_NUMBERS} (ECO number categories)\")\n",
    "\n",
    "# ========================================\n",
    "# DATASET STATISTICS\n",
    "# ========================================\n",
    "\n",
    "print(f\"\\nüìà Dataset Statistics:\")\n",
    "print(f\"   ‚Ä¢ Train samples: {len(scores_train):,}\")\n",
    "print(f\"   ‚Ä¢ Validation samples: {len(scores_val):,}\")\n",
    "print(f\"   ‚Ä¢ Test samples: {len(scores_test):,}\")\n",
    "print(f\"   ‚Ä¢ Total samples: {len(scores_train) + len(scores_val) + len(scores_test):,}\")\n",
    "\n",
    "print(f\"\\n   ‚Ä¢ Batches per epoch: {len(scores_train) // BATCH_SIZE:,}\")\n",
    "print(f\"   ‚Ä¢ Training iterations (total): {(len(scores_train) // BATCH_SIZE) * N_EPOCHS:,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ HYPERPARAMETERS AND CONSTANTS DEFINED\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüí° To modify hyperparameters:\")\n",
    "print(f\"   ‚Ä¢ Edit the values at the top of this cell\")\n",
    "print(f\"   ‚Ä¢ Rerun this cell to apply changes\")\n",
    "print(f\"   ‚Ä¢ All subsequent cells will use the updated values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59a93e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 6B: DEFINE LOSS FUNCTIONS\n",
      "============================================================\n",
      "\n",
      "‚úÖ Loss functions defined:\n",
      "   ‚Ä¢ mse_loss(): Mean Squared Error (with optional confidence weighting)\n",
      "   ‚Ä¢ rmse_loss(): Root Mean Squared Error\n",
      "   ‚Ä¢ calculate_rmse(): RMSE evaluation metric\n",
      "\n",
      "üß™ Testing loss functions with dummy data...\n",
      "\n",
      "   Dummy data:\n",
      "   ‚Ä¢ Predictions: [0.5, 0.6000000238418579, 0.699999988079071, 0.800000011920929]\n",
      "   ‚Ä¢ Targets: [0.550000011920929, 0.6200000047683716, 0.6800000071525574, 0.75]\n",
      "   ‚Ä¢ Confidence: [0.800000011920929, 0.8999999761581421, 0.699999988079071, 1.0]\n",
      "\n",
      "   MSE (unweighted): 0.001450\n",
      "   MSE (weighted): 0.001512\n",
      "\n",
      "   RMSE (unweighted): 0.038079\n",
      "   RMSE (weighted): 0.038881\n",
      "\n",
      "   calculate_rmse() result: 0.038881\n",
      "   ‚úì Returns Python float (not tensor): <class 'float'>\n",
      "\n",
      "============================================================\n",
      "‚úÖ LOSS FUNCTIONS COMPLETE\n",
      "============================================================\n",
      "\n",
      "üí° Training will use:\n",
      "   ‚Ä¢ Loss function: mse_loss() with confidence weighting\n",
      "   ‚Ä¢ Evaluation metric: calculate_rmse()\n",
      "   ‚Ä¢ Confidence weights: From 'confidence' column in data\n",
      "   ‚Ä¢ Weighting strategy: confidence = num_games / (num_games + K)\n",
      "   ‚Ä¢ Effect: High-game-count entries have larger loss impact\n"
     ]
    }
   ],
   "source": [
    "# Step 6b: Define Loss Functions\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 6B: DEFINE LOSS FUNCTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ========================================\n",
    "# LOSS FUNCTIONS\n",
    "# ========================================\n",
    "\n",
    "def mse_loss(predictions, targets, confidence_weights=None):\n",
    "    \"\"\"\n",
    "    Mean Squared Error loss with optional confidence weighting.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    predictions : torch.Tensor\n",
    "        Model predictions (shape: [batch_size])\n",
    "    targets : torch.Tensor\n",
    "        Ground truth scores (shape: [batch_size])\n",
    "    confidence_weights : torch.Tensor, optional\n",
    "        Confidence weights for each sample (shape: [batch_size])\n",
    "        Higher confidence = larger loss contribution\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    torch.Tensor\n",
    "        Scalar loss value\n",
    "    \"\"\"\n",
    "    # Compute squared error\n",
    "    squared_error = (predictions - targets) ** 2\n",
    "    \n",
    "    # Apply confidence weighting if provided\n",
    "    if confidence_weights is not None:\n",
    "        weighted_squared_error = squared_error * confidence_weights\n",
    "        # Average over all samples (sum of weighted errors / sum of weights)\n",
    "        loss = weighted_squared_error.sum() / confidence_weights.sum()\n",
    "    else:\n",
    "        # Standard MSE (average over all samples)\n",
    "        loss = squared_error.mean()\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def rmse_loss(predictions, targets, confidence_weights=None):\n",
    "    \"\"\"\n",
    "    Root Mean Squared Error loss.\n",
    "    \n",
    "    This is the square root of MSE and is our primary evaluation metric.\n",
    "    RMSE is in the same units as the target (score), making it interpretable.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    predictions : torch.Tensor\n",
    "        Model predictions (shape: [batch_size])\n",
    "    targets : torch.Tensor\n",
    "        Ground truth scores (shape: [batch_size])\n",
    "    confidence_weights : torch.Tensor, optional\n",
    "        Confidence weights for each sample (shape: [batch_size])\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    torch.Tensor\n",
    "        Scalar RMSE value\n",
    "    \"\"\"\n",
    "    mse = mse_loss(predictions, targets, confidence_weights)\n",
    "    return torch.sqrt(mse)\n",
    "\n",
    "\n",
    "def calculate_rmse(predictions, targets, confidence_weights=None):\n",
    "    \"\"\"\n",
    "    Calculate RMSE metric (convenience function for evaluation).\n",
    "    \n",
    "    This is the same as rmse_loss but with clearer naming for evaluation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    predictions : torch.Tensor\n",
    "        Model predictions (shape: [batch_size])\n",
    "    targets : torch.Tensor\n",
    "        Ground truth scores (shape: [batch_size])\n",
    "    confidence_weights : torch.Tensor, optional\n",
    "        Confidence weights for each sample (shape: [batch_size])\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        RMSE value (Python float, not tensor)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():  # Don't compute gradients for evaluation\n",
    "        rmse = rmse_loss(predictions, targets, confidence_weights)\n",
    "    return rmse.item()\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# TEST LOSS FUNCTIONS\n",
    "# ========================================\n",
    "\n",
    "print(f\"\\n‚úÖ Loss functions defined:\")\n",
    "print(f\"   ‚Ä¢ mse_loss(): Mean Squared Error (with optional confidence weighting)\")\n",
    "print(f\"   ‚Ä¢ rmse_loss(): Root Mean Squared Error\")\n",
    "print(f\"   ‚Ä¢ calculate_rmse(): RMSE evaluation metric\")\n",
    "\n",
    "print(f\"\\nüß™ Testing loss functions with dummy data...\")\n",
    "\n",
    "# Create dummy data for testing\n",
    "dummy_predictions = torch.tensor([0.5, 0.6, 0.7, 0.8], dtype=torch.float32)\n",
    "dummy_targets = torch.tensor([0.55, 0.62, 0.68, 0.75], dtype=torch.float32)\n",
    "dummy_confidence = torch.tensor([0.8, 0.9, 0.7, 1.0], dtype=torch.float32)\n",
    "\n",
    "print(f\"\\n   Dummy data:\")\n",
    "print(f\"   ‚Ä¢ Predictions: {dummy_predictions.tolist()}\")\n",
    "print(f\"   ‚Ä¢ Targets: {dummy_targets.tolist()}\")\n",
    "print(f\"   ‚Ä¢ Confidence: {dummy_confidence.tolist()}\")\n",
    "\n",
    "# Test MSE without confidence weighting\n",
    "mse_unweighted = mse_loss(dummy_predictions, dummy_targets)\n",
    "print(f\"\\n   MSE (unweighted): {mse_unweighted.item():.6f}\")\n",
    "\n",
    "# Test MSE with confidence weighting\n",
    "mse_weighted = mse_loss(dummy_predictions, dummy_targets, dummy_confidence)\n",
    "print(f\"   MSE (weighted): {mse_weighted.item():.6f}\")\n",
    "\n",
    "# Test RMSE\n",
    "rmse_unweighted = rmse_loss(dummy_predictions, dummy_targets)\n",
    "rmse_weighted = rmse_loss(dummy_predictions, dummy_targets, dummy_confidence)\n",
    "print(f\"\\n   RMSE (unweighted): {rmse_unweighted.item():.6f}\")\n",
    "print(f\"   RMSE (weighted): {rmse_weighted.item():.6f}\")\n",
    "\n",
    "# Test calculate_rmse\n",
    "rmse_eval = calculate_rmse(dummy_predictions, dummy_targets, dummy_confidence)\n",
    "print(f\"\\n   calculate_rmse() result: {rmse_eval:.6f}\")\n",
    "print(f\"   ‚úì Returns Python float (not tensor): {type(rmse_eval)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ LOSS FUNCTIONS COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüí° Training will use:\")\n",
    "print(f\"   ‚Ä¢ Loss function: mse_loss() with confidence weighting\")\n",
    "print(f\"   ‚Ä¢ Evaluation metric: calculate_rmse()\")\n",
    "print(f\"   ‚Ä¢ Confidence weights: From 'confidence' column in data\")\n",
    "print(f\"   ‚Ä¢ Weighting strategy: confidence = num_games / (num_games + K)\")\n",
    "print(f\"   ‚Ä¢ Effect: High-game-count entries have larger loss impact\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35e00b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 6C: CREATE PYTORCH DATASET AND DATALOADER\n",
      "============================================================\n",
      "\n",
      "1Ô∏è‚É£  Creating PyTorch Datasets...\n",
      "   ‚úì Train dataset: 2,172,843 samples\n",
      "   ‚úì Validation dataset: 434,569 samples\n",
      "   ‚úì Test dataset: 289,713 samples\n",
      "\n",
      "2Ô∏è‚É£  Testing dataset access...\n",
      "   Sample from train_dataset[0]:\n",
      "   ‚Ä¢ player_id: 2125\n",
      "   ‚Ä¢ opening_id: 653\n",
      "   ‚Ä¢ confidence: 0.4565\n",
      "   ‚Ä¢ score: 0.4835\n",
      "\n",
      "3Ô∏è‚É£  Creating PyTorch DataLoaders...\n",
      "   ‚úì Train loader: 2,122 batches of size 1024\n",
      "   ‚úì Validation loader: 425 batches of size 1024\n",
      "   ‚úì Test loader: 283 batches of size 1024\n",
      "\n",
      "4Ô∏è‚É£  Testing DataLoader batch access...\n",
      "   First batch from train_loader:\n",
      "   ‚Ä¢ player_id shape: torch.Size([1024])\n",
      "   ‚Ä¢ opening_id shape: torch.Size([1024])\n",
      "   ‚Ä¢ confidence shape: torch.Size([1024])\n",
      "   ‚Ä¢ score shape: torch.Size([1024])\n",
      "\n",
      "   Sample values from first batch (first 5):\n",
      "   [0] player=33836, opening=733, conf=0.2308, score=0.4848\n",
      "   [1] player=21504, opening=2287, conf=0.2308, score=0.5979\n",
      "   [2] player=22465, opening=1078, conf=0.7807, score=0.4376\n",
      "   [3] player=22684, opening=124, conf=0.2537, score=0.5198\n",
      "   [4] player=30851, opening=848, conf=0.4737, score=0.4894\n",
      "\n",
      "============================================================\n",
      "‚úÖ DATASET AND DATALOADER COMPLETE\n",
      "============================================================\n",
      "\n",
      "üì¶ Available objects:\n",
      "   ‚Ä¢ train_dataset, val_dataset, test_dataset\n",
      "   ‚Ä¢ train_loader, val_loader, test_loader\n",
      "\n",
      "üí° DataLoader features:\n",
      "   ‚Ä¢ Automatic batching: 1024 samples per batch\n",
      "   ‚Ä¢ Shuffling: Training data shuffled each epoch\n",
      "   ‚Ä¢ Pin memory: Disabled (speeds up GPU transfer)\n",
      "   ‚Ä¢ Ready for training loop!\n",
      "   First batch from train_loader:\n",
      "   ‚Ä¢ player_id shape: torch.Size([1024])\n",
      "   ‚Ä¢ opening_id shape: torch.Size([1024])\n",
      "   ‚Ä¢ confidence shape: torch.Size([1024])\n",
      "   ‚Ä¢ score shape: torch.Size([1024])\n",
      "\n",
      "   Sample values from first batch (first 5):\n",
      "   [0] player=33836, opening=733, conf=0.2308, score=0.4848\n",
      "   [1] player=21504, opening=2287, conf=0.2308, score=0.5979\n",
      "   [2] player=22465, opening=1078, conf=0.7807, score=0.4376\n",
      "   [3] player=22684, opening=124, conf=0.2537, score=0.5198\n",
      "   [4] player=30851, opening=848, conf=0.4737, score=0.4894\n",
      "\n",
      "============================================================\n",
      "‚úÖ DATASET AND DATALOADER COMPLETE\n",
      "============================================================\n",
      "\n",
      "üì¶ Available objects:\n",
      "   ‚Ä¢ train_dataset, val_dataset, test_dataset\n",
      "   ‚Ä¢ train_loader, val_loader, test_loader\n",
      "\n",
      "üí° DataLoader features:\n",
      "   ‚Ä¢ Automatic batching: 1024 samples per batch\n",
      "   ‚Ä¢ Shuffling: Training data shuffled each epoch\n",
      "   ‚Ä¢ Pin memory: Disabled (speeds up GPU transfer)\n",
      "   ‚Ä¢ Ready for training loop!\n"
     ]
    }
   ],
   "source": [
    "# Step 6c: Create PyTorch Dataset and DataLoader\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 6C: CREATE PYTORCH DATASET AND DATALOADER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ========================================\n",
    "# CUSTOM DATASET CLASS\n",
    "# ========================================\n",
    "\n",
    "class ChessOpeningDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for chess player-opening interactions.\n",
    "    \n",
    "    Each sample contains:\n",
    "    - player_id: Integer ID for embedding lookup\n",
    "    - opening_id: Integer ID for embedding lookup\n",
    "    - confidence: Confidence weight for loss function\n",
    "    - score: Target value (win rate)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, player_ids, opening_ids, confidence, scores):\n",
    "        \"\"\"\n",
    "        Initialize dataset.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        player_ids : torch.Tensor\n",
    "            Player IDs (long tensor)\n",
    "        opening_ids : torch.Tensor\n",
    "            Opening IDs (long tensor)\n",
    "        confidence : torch.Tensor\n",
    "            Confidence weights (float tensor)\n",
    "        scores : torch.Tensor\n",
    "            Target scores (float tensor)\n",
    "        \"\"\"\n",
    "        self.player_ids = player_ids\n",
    "        self.opening_ids = opening_ids\n",
    "        self.confidence = confidence\n",
    "        self.scores = scores\n",
    "        \n",
    "        # Validate shapes\n",
    "        assert len(player_ids) == len(opening_ids) == len(confidence) == len(scores), \\\n",
    "            \"All tensors must have the same length\"\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Return the number of samples.\"\"\"\n",
    "        return len(self.player_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get a single sample.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        idx : int\n",
    "            Index of the sample to retrieve\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            Dictionary with keys: 'player_id', 'opening_id', 'confidence', 'score'\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'player_id': self.player_ids[idx],\n",
    "            'opening_id': self.opening_ids[idx],\n",
    "            'confidence': self.confidence[idx],\n",
    "            'score': self.scores[idx]\n",
    "        }\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# CREATE DATASETS\n",
    "# ========================================\n",
    "\n",
    "print(f\"\\n1Ô∏è‚É£  Creating PyTorch Datasets...\")\n",
    "\n",
    "train_dataset = ChessOpeningDataset(\n",
    "    player_ids_train, opening_ids_train, confidence_train, scores_train\n",
    ")\n",
    "val_dataset = ChessOpeningDataset(\n",
    "    player_ids_val, opening_ids_val, confidence_val, scores_val\n",
    ")\n",
    "test_dataset = ChessOpeningDataset(\n",
    "    player_ids_test, opening_ids_test, confidence_test, scores_test\n",
    ")\n",
    "\n",
    "print(f\"   ‚úì Train dataset: {len(train_dataset):,} samples\")\n",
    "print(f\"   ‚úì Validation dataset: {len(val_dataset):,} samples\")\n",
    "print(f\"   ‚úì Test dataset: {len(test_dataset):,} samples\")\n",
    "\n",
    "# Test dataset access\n",
    "print(f\"\\n2Ô∏è‚É£  Testing dataset access...\")\n",
    "sample = train_dataset[0]\n",
    "print(f\"   Sample from train_dataset[0]:\")\n",
    "print(f\"   ‚Ä¢ player_id: {sample['player_id']}\")\n",
    "print(f\"   ‚Ä¢ opening_id: {sample['opening_id']}\")\n",
    "print(f\"   ‚Ä¢ confidence: {sample['confidence']:.4f}\")\n",
    "print(f\"   ‚Ä¢ score: {sample['score']:.4f}\")\n",
    "\n",
    "# ========================================\n",
    "# CREATE DATALOADERS\n",
    "# ========================================\n",
    "\n",
    "print(f\"\\n3Ô∏è‚É£  Creating PyTorch DataLoaders...\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,  # Shuffle training data each epoch\n",
    "    num_workers=0,  # Number of subprocesses for data loading (0 = main process)\n",
    "    pin_memory=True if torch.cuda.is_available() else False  # Speed up GPU transfer\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,  # Don't shuffle validation data\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,  # Don't shuffle test data\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print(f\"   ‚úì Train loader: {len(train_loader):,} batches of size {BATCH_SIZE}\")\n",
    "print(f\"   ‚úì Validation loader: {len(val_loader):,} batches of size {BATCH_SIZE}\")\n",
    "print(f\"   ‚úì Test loader: {len(test_loader):,} batches of size {BATCH_SIZE}\")\n",
    "\n",
    "# Test dataloader\n",
    "print(f\"\\n4Ô∏è‚É£  Testing DataLoader batch access...\")\n",
    "batch = next(iter(train_loader))\n",
    "print(f\"   First batch from train_loader:\")\n",
    "print(f\"   ‚Ä¢ player_id shape: {batch['player_id'].shape}\")\n",
    "print(f\"   ‚Ä¢ opening_id shape: {batch['opening_id'].shape}\")\n",
    "print(f\"   ‚Ä¢ confidence shape: {batch['confidence'].shape}\")\n",
    "print(f\"   ‚Ä¢ score shape: {batch['score'].shape}\")\n",
    "\n",
    "print(f\"\\n   Sample values from first batch (first 5):\")\n",
    "for i in range(min(5, batch['player_id'].shape[0])):\n",
    "    print(f\"   [{i}] player={batch['player_id'][i]}, opening={batch['opening_id'][i]}, \"\n",
    "          f\"conf={batch['confidence'][i]:.4f}, score={batch['score'][i]:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ DATASET AND DATALOADER COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüì¶ Available objects:\")\n",
    "print(f\"   ‚Ä¢ train_dataset, val_dataset, test_dataset\")\n",
    "print(f\"   ‚Ä¢ train_loader, val_loader, test_loader\")\n",
    "\n",
    "print(f\"\\nüí° DataLoader features:\")\n",
    "print(f\"   ‚Ä¢ Automatic batching: {BATCH_SIZE} samples per batch\")\n",
    "print(f\"   ‚Ä¢ Shuffling: Training data shuffled each epoch\")\n",
    "print(f\"   ‚Ä¢ Pin memory: {'Enabled' if torch.cuda.is_available() else 'Disabled'} (speeds up GPU transfer)\")\n",
    "print(f\"   ‚Ä¢ Ready for training loop!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e5fbb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 6D: DEFINE HELPER FUNCTIONS\n",
      "============================================================\n",
      "\n",
      "‚úÖ Helper functions defined:\n",
      "   ‚Ä¢ save_checkpoint(): Save model and optimizer state\n",
      "   ‚Ä¢ load_checkpoint(): Load model and optimizer state\n",
      "   ‚Ä¢ format_time(): Format seconds as readable time\n",
      "   ‚Ä¢ print_progress(): Print training progress with ETA\n",
      "\n",
      "üß™ Testing helper functions...\n",
      "\n",
      "   format_time() tests:\n",
      "   ‚Ä¢ 30 seconds ‚Üí 30.0s\n",
      "   ‚Ä¢ 90 seconds ‚Üí 1m 30s\n",
      "   ‚Ä¢ 300 seconds ‚Üí 5m 0s\n",
      "   ‚Ä¢ 3661 seconds ‚Üí 1h 1m 1s\n",
      "   ‚Ä¢ 7384 seconds ‚Üí 2h 3m 4s\n",
      "\n",
      "   print_progress() test (simulating batch progress):\n",
      "   Epoch 1 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 101.00% | Loss: 0.020000 | ETA: -0.5s\n",
      "\n",
      "============================================================\n",
      "‚úÖ HELPER FUNCTIONS COMPLETE\n",
      "============================================================\n",
      "\n",
      "üí° These functions will be used during training for:\n",
      "   ‚Ä¢ Progress tracking with ETA estimation\n",
      "   ‚Ä¢ Saving checkpoints after each epoch\n",
      "   ‚Ä¢ Loading checkpoints for resuming training\n",
      "   Epoch 1 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 101.00% | Loss: 0.020000 | ETA: -0.5s\n",
      "\n",
      "============================================================\n",
      "‚úÖ HELPER FUNCTIONS COMPLETE\n",
      "============================================================\n",
      "\n",
      "üí° These functions will be used during training for:\n",
      "   ‚Ä¢ Progress tracking with ETA estimation\n",
      "   ‚Ä¢ Saving checkpoints after each epoch\n",
      "   ‚Ä¢ Loading checkpoints for resuming training\n"
     ]
    }
   ],
   "source": [
    "# Step 6d: Define Helper Functions for Training\n",
    "\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 6D: DEFINE HELPER FUNCTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ========================================\n",
    "# HELPER FUNCTION: Save Checkpoint\n",
    "# ========================================\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, train_loss, val_loss, filepath):\n",
    "    \"\"\"\n",
    "    Save model checkpoint to disk.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : nn.Module\n",
    "        The model to save\n",
    "    optimizer : torch.optim.Optimizer\n",
    "        The optimizer state to save\n",
    "    epoch : int\n",
    "        Current epoch number\n",
    "    train_loss : float\n",
    "        Training loss for this epoch\n",
    "    val_loss : float\n",
    "        Validation loss for this epoch\n",
    "    filepath : Path or str\n",
    "        Where to save the checkpoint\n",
    "    \"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        \n",
    "        # Save hyperparameters for reproducibility\n",
    "        'hyperparameters': {\n",
    "            'num_factors': NUM_FACTORS,\n",
    "            'learning_rate': LEARNING_RATE,\n",
    "            'momentum': MOMENTUM,\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'num_players': NUM_PLAYERS,\n",
    "            'num_openings': NUM_OPENINGS,\n",
    "            'num_eco_letters': NUM_ECO_LETTERS,\n",
    "            'num_eco_numbers': NUM_ECO_NUMBERS,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    torch.save(checkpoint, filepath)\n",
    "    print(f\"   üíæ Checkpoint saved to: {filepath}\")\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# HELPER FUNCTION: Load Checkpoint\n",
    "# ========================================\n",
    "\n",
    "def load_checkpoint(model, optimizer, filepath):\n",
    "    \"\"\"\n",
    "    Load model checkpoint from disk.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : nn.Module\n",
    "        The model to load weights into\n",
    "    optimizer : torch.optim.Optimizer\n",
    "        The optimizer to load state into\n",
    "    filepath : Path or str\n",
    "        Where to load the checkpoint from\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    int\n",
    "        The epoch number from the checkpoint\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    \n",
    "    print(f\"   üìÇ Checkpoint loaded from: {filepath}\")\n",
    "    print(f\"   ‚Ä¢ Epoch: {epoch}\")\n",
    "    print(f\"   ‚Ä¢ Train loss: {checkpoint['train_loss']:.6f}\")\n",
    "    print(f\"   ‚Ä¢ Val loss: {checkpoint['val_loss']:.6f}\")\n",
    "    \n",
    "    return epoch\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# HELPER FUNCTION: Format Time\n",
    "# ========================================\n",
    "\n",
    "def format_time(seconds):\n",
    "    \"\"\"\n",
    "    Format seconds as human-readable time string.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    seconds : float\n",
    "        Number of seconds\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        Formatted time string (e.g., \"1h 23m 45s\")\n",
    "    \"\"\"\n",
    "    if seconds < 60:\n",
    "        return f\"{seconds:.1f}s\"\n",
    "    elif seconds < 3600:\n",
    "        minutes = int(seconds // 60)\n",
    "        secs = int(seconds % 60)\n",
    "        return f\"{minutes}m {secs}s\"\n",
    "    else:\n",
    "        hours = int(seconds // 3600)\n",
    "        minutes = int((seconds % 3600) // 60)\n",
    "        secs = int(seconds % 60)\n",
    "        return f\"{hours}h {minutes}m {secs}s\"\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# HELPER FUNCTION: Print Progress\n",
    "# ========================================\n",
    "\n",
    "def print_progress(epoch, batch_idx, total_batches, loss, elapsed_time):\n",
    "    \"\"\"\n",
    "    Print training progress with ETA.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    epoch : int\n",
    "        Current epoch number\n",
    "    batch_idx : int\n",
    "        Current batch index (0-based)\n",
    "    total_batches : int\n",
    "        Total number of batches per epoch\n",
    "    loss : float\n",
    "        Current loss value\n",
    "    elapsed_time : float\n",
    "        Elapsed time in seconds since epoch start\n",
    "    \"\"\"\n",
    "    # Calculate progress\n",
    "    progress_pct = 100.0 * (batch_idx + 1) / total_batches\n",
    "    \n",
    "    # Estimate time remaining\n",
    "    time_per_batch = elapsed_time / (batch_idx + 1)\n",
    "    remaining_batches = total_batches - (batch_idx + 1)\n",
    "    eta_seconds = time_per_batch * remaining_batches\n",
    "    \n",
    "    # Print progress bar\n",
    "    bar_length = 40\n",
    "    filled_length = int(bar_length * (batch_idx + 1) / total_batches)\n",
    "    bar = '‚ñà' * filled_length + '‚ñë' * (bar_length - filled_length)\n",
    "    \n",
    "    print(f\"   Epoch {epoch} [{bar}] {progress_pct:>6.2f}% | \"\n",
    "          f\"Loss: {loss:.6f} | \"\n",
    "          f\"ETA: {format_time(eta_seconds)}\", end='\\r')\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# TEST HELPER FUNCTIONS\n",
    "# ========================================\n",
    "\n",
    "print(f\"\\n‚úÖ Helper functions defined:\")\n",
    "print(f\"   ‚Ä¢ save_checkpoint(): Save model and optimizer state\")\n",
    "print(f\"   ‚Ä¢ load_checkpoint(): Load model and optimizer state\")\n",
    "print(f\"   ‚Ä¢ format_time(): Format seconds as readable time\")\n",
    "print(f\"   ‚Ä¢ print_progress(): Print training progress with ETA\")\n",
    "\n",
    "print(f\"\\nüß™ Testing helper functions...\")\n",
    "\n",
    "# Test format_time\n",
    "print(f\"\\n   format_time() tests:\")\n",
    "test_times = [30, 90, 300, 3661, 7384]\n",
    "for t in test_times:\n",
    "    print(f\"   ‚Ä¢ {t} seconds ‚Üí {format_time(t)}\")\n",
    "\n",
    "# Test print_progress (will overwrite line)\n",
    "print(f\"\\n   print_progress() test (simulating batch progress):\")\n",
    "for i in range(0, 101, 20):\n",
    "    total = 100\n",
    "    loss = 0.05 - i * 0.0003\n",
    "    elapsed = i * 0.5\n",
    "    print_progress(epoch=1, batch_idx=i, total_batches=total, loss=loss, elapsed_time=elapsed)\n",
    "    time.sleep(0.1)  # Brief pause to show animation\n",
    "print()  # New line after progress bar\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ HELPER FUNCTIONS COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüí° These functions will be used during training for:\")\n",
    "print(f\"   ‚Ä¢ Progress tracking with ETA estimation\")\n",
    "print(f\"   ‚Ä¢ Saving checkpoints after each epoch\")\n",
    "print(f\"   ‚Ä¢ Loading checkpoints for resuming training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cab0cbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 6E: DEFINE TRAINING AND EVALUATION FUNCTIONS\n",
      "============================================================\n",
      "\n",
      "‚úÖ Training and evaluation functions defined:\n",
      "   ‚Ä¢ train_one_epoch(): Train model for one epoch\n",
      "   ‚Ä¢ evaluate_model(): Evaluate model on a dataset\n",
      "\n",
      "üí° Function features:\n",
      "   ‚Ä¢ Automatic device handling (CPU/CUDA)\n",
      "   ‚Ä¢ Progress tracking with ETA\n",
      "   ‚Ä¢ Confidence-weighted loss\n",
      "   ‚Ä¢ Batch processing via DataLoader\n",
      "   ‚Ä¢ Train/eval mode switching\n",
      "\n",
      "============================================================\n",
      "‚úÖ TRAINING AND EVALUATION FUNCTIONS COMPLETE\n",
      "============================================================\n",
      "\n",
      "üìã Training workflow:\n",
      "   1. Initialize model and optimizer\n",
      "   2. For each epoch:\n",
      "      a. Call train_one_epoch()\n",
      "      b. Call evaluate_model() on validation set\n",
      "      c. Save checkpoint with save_checkpoint()\n",
      "      d. Log metrics\n",
      "   3. After training, evaluate on test set\n",
      "\n",
      "üöÄ Ready to define the model architecture (next cell)!\n"
     ]
    }
   ],
   "source": [
    "# Step 6e: Define Training and Evaluation Functions\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 6E: DEFINE TRAINING AND EVALUATION FUNCTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ========================================\n",
    "# TRAINING FUNCTION: Train One Epoch\n",
    "# ========================================\n",
    "\n",
    "def train_one_epoch(model, train_loader, optimizer, device, epoch_num):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : nn.Module\n",
    "        The model to train\n",
    "    train_loader : DataLoader\n",
    "        DataLoader for training data\n",
    "    optimizer : torch.optim.Optimizer\n",
    "        Optimizer for updating model parameters\n",
    "    device : torch.device\n",
    "        Device to train on (CPU or CUDA)\n",
    "    epoch_num : int\n",
    "        Current epoch number (for logging)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (average_loss, elapsed_time)\n",
    "    \"\"\"\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    num_batches = len(train_loader)\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        # Move batch to device\n",
    "        player_ids = batch['player_id'].to(device)\n",
    "        opening_ids = batch['opening_id'].to(device)\n",
    "        confidence = batch['confidence'].to(device)\n",
    "        targets = batch['score'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        predictions = model(player_ids, opening_ids)\n",
    "        \n",
    "        # Compute loss with confidence weighting\n",
    "        loss = mse_loss(predictions, targets, confidence)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "        loss.backward()  # Compute gradients\n",
    "        optimizer.step()  # Update parameters\n",
    "        \n",
    "        # Track loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Print progress every 10 batches or on last batch\n",
    "        if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == num_batches:\n",
    "            elapsed = time.time() - epoch_start_time\n",
    "            print_progress(epoch_num, batch_idx, num_batches, loss.item(), elapsed)\n",
    "    \n",
    "    # Calculate average loss\n",
    "    avg_loss = total_loss / num_batches\n",
    "    elapsed_time = time.time() - epoch_start_time\n",
    "    \n",
    "    # Clear progress line and print summary\n",
    "    print()  # New line after progress bar\n",
    "    \n",
    "    return avg_loss, elapsed_time\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# EVALUATION FUNCTION: Evaluate Model\n",
    "# ========================================\n",
    "\n",
    "def evaluate_model(model, data_loader, device, dataset_name=\"Validation\"):\n",
    "    \"\"\"\n",
    "    Evaluate the model on a dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : nn.Module\n",
    "        The model to evaluate\n",
    "    data_loader : DataLoader\n",
    "        DataLoader for evaluation data\n",
    "    device : torch.device\n",
    "        Device to evaluate on (CPU or CUDA)\n",
    "    dataset_name : str\n",
    "        Name of dataset for logging (e.g., \"Validation\", \"Test\")\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (mse, rmse)\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    total_mse = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "        for batch in data_loader:\n",
    "            # Move batch to device\n",
    "            player_ids = batch['player_id'].to(device)\n",
    "            opening_ids = batch['opening_id'].to(device)\n",
    "            confidence = batch['confidence'].to(device)\n",
    "            targets = batch['score'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            predictions = model(player_ids, opening_ids)\n",
    "            \n",
    "            # Compute MSE with confidence weighting\n",
    "            batch_mse = mse_loss(predictions, targets, confidence)\n",
    "            \n",
    "            # Track weighted sum of MSE\n",
    "            total_mse += batch_mse.item() * len(targets)\n",
    "            total_samples += len(targets)\n",
    "    \n",
    "    # Calculate average MSE and RMSE\n",
    "    avg_mse = total_mse / total_samples\n",
    "    avg_rmse = avg_mse ** 0.5\n",
    "    \n",
    "    return avg_mse, avg_rmse\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# TEST FUNCTIONS (with dummy model)\n",
    "# ========================================\n",
    "\n",
    "print(f\"\\n‚úÖ Training and evaluation functions defined:\")\n",
    "print(f\"   ‚Ä¢ train_one_epoch(): Train model for one epoch\")\n",
    "print(f\"   ‚Ä¢ evaluate_model(): Evaluate model on a dataset\")\n",
    "\n",
    "print(f\"\\nüí° Function features:\")\n",
    "print(f\"   ‚Ä¢ Automatic device handling (CPU/CUDA)\")\n",
    "print(f\"   ‚Ä¢ Progress tracking with ETA\")\n",
    "print(f\"   ‚Ä¢ Confidence-weighted loss\")\n",
    "print(f\"   ‚Ä¢ Batch processing via DataLoader\")\n",
    "print(f\"   ‚Ä¢ Train/eval mode switching\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ TRAINING AND EVALUATION FUNCTIONS COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìã Training workflow:\")\n",
    "print(f\"   1. Initialize model and optimizer\")\n",
    "print(f\"   2. For each epoch:\")\n",
    "print(f\"      a. Call train_one_epoch()\")\n",
    "print(f\"      b. Call evaluate_model() on validation set\")\n",
    "print(f\"      c. Save checkpoint with save_checkpoint()\")\n",
    "print(f\"      d. Log metrics\")\n",
    "print(f\"   3. After training, evaluate on test set\")\n",
    "\n",
    "print(f\"\\nüöÄ Ready to define the model architecture (next cell)!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50c5eb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 6F: DEFINE MODEL ARCHITECTURE\n",
      "============================================================\n",
      "\n",
      "‚úÖ ChessOpeningRecommender model class defined\n",
      "\n",
      "üìä Model Architecture:\n",
      "   Player Components:\n",
      "      ‚Ä¢ Latent factors: Embedding(48468, 50)\n",
      "      ‚Ä¢ Biases: Embedding(48468, 1)\n",
      "      ‚Ä¢ Ratings: Fixed side info (z-score normalized)\n",
      "      ‚Ä¢ Combiner: Linear(51, 50)\n",
      "\n",
      "   Opening Components:\n",
      "      ‚Ä¢ Latent factors: Embedding(2715, 50)\n",
      "      ‚Ä¢ Biases: Embedding(2715, 1)\n",
      "      ‚Ä¢ ECO letter embedding: Embedding(5, 4)\n",
      "      ‚Ä¢ ECO number embedding: Embedding(100, 4)\n",
      "      ‚Ä¢ Combiner: Linear(58, 50)\n",
      "\n",
      "   Prediction:\n",
      "      ‚Ä¢ Dot product of player and opening representations\n",
      "      ‚Ä¢ + player bias + opening bias + global bias\n",
      "      ‚Ä¢ ‚Üí Sigmoid activation (output ‚àà [0, 1])\n",
      "\n",
      "üí° Model Statistics:\n",
      "   ‚Ä¢ Total trainable parameters: 2,616,304\n",
      "   ‚Ä¢ Player parameters: 2,474,468\n",
      "   ‚Ä¢ Opening parameters: 141,835\n",
      "   ‚Ä¢ Global parameters: 1\n",
      "\n",
      "============================================================\n",
      "‚úÖ MODEL ARCHITECTURE COMPLETE\n",
      "============================================================\n",
      "\n",
      "üöÄ Ready for Step 7: Training Loop!\n"
     ]
    }
   ],
   "source": [
    "# Step 6f: Define Model Architecture\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 6F: DEFINE MODEL ARCHITECTURE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ========================================\n",
    "# Chess Opening Recommender Model\n",
    "# ========================================\n",
    "\n",
    "class ChessOpeningRecommender(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Matrix Factorization model for chess opening recommendations.\n",
    "    \n",
    "    The model learns latent factors for players and openings, incorporating\n",
    "    side information:\n",
    "    - Player ratings (normalized)\n",
    "    - Opening ECO codes (letter and number as categorical features)\n",
    "    \n",
    "    Architecture:\n",
    "    - Player embedding: learnable latent factors\n",
    "    - Opening embedding: learnable latent factors\n",
    "    - Player rating: fixed side information (no embedding)\n",
    "    - ECO letter/number: categorical embeddings\n",
    "    \n",
    "    Prediction: dot product of player and opening representations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_players, num_openings, num_factors,\n",
    "                 player_ratings, opening_eco_letters, opening_eco_numbers,\n",
    "                 num_eco_letters, num_eco_numbers, eco_embed_dim=4):\n",
    "        \"\"\"\n",
    "        Initialize the recommendation model.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        num_players : int\n",
    "            Total number of unique players\n",
    "        num_openings : int\n",
    "            Total number of unique openings\n",
    "        num_factors : int\n",
    "            Dimensionality of latent factor embeddings\n",
    "        player_ratings : torch.Tensor\n",
    "            Z-score normalized ratings for all players (shape: [num_players])\n",
    "        opening_eco_letters : torch.Tensor\n",
    "            ECO letter categories for all openings (shape: [num_openings])\n",
    "        opening_eco_numbers : torch.Tensor\n",
    "            ECO number categories for all openings (shape: [num_openings])\n",
    "        num_eco_letters : int\n",
    "            Number of unique ECO letter categories\n",
    "        num_eco_numbers : int\n",
    "            Number of unique ECO number categories\n",
    "        eco_embed_dim : int\n",
    "            Dimensionality of ECO categorical embeddings (default: 4)\n",
    "        \"\"\"\n",
    "        super(ChessOpeningRecommender, self).__init__()\n",
    "        \n",
    "        # Store configuration\n",
    "        self.num_players = num_players\n",
    "        self.num_openings = num_openings\n",
    "        self.num_factors = num_factors\n",
    "        self.eco_embed_dim = eco_embed_dim\n",
    "        \n",
    "        # ========================================\n",
    "        # Player Components\n",
    "        # ========================================\n",
    "        \n",
    "        # Player latent factors (learnable)\n",
    "        self.player_factors = torch.nn.Embedding(num_players, num_factors)\n",
    "        \n",
    "        # Player biases (learnable)\n",
    "        self.player_biases = torch.nn.Embedding(num_players, 1)\n",
    "        \n",
    "        # Player ratings (fixed side information - registered as buffer, not parameter)\n",
    "        self.register_buffer('player_ratings', player_ratings)\n",
    "        \n",
    "        # ========================================\n",
    "        # Opening Components\n",
    "        # ========================================\n",
    "        \n",
    "        # Opening latent factors (learnable)\n",
    "        self.opening_factors = torch.nn.Embedding(num_openings, num_factors)\n",
    "        \n",
    "        # Opening biases (learnable)\n",
    "        self.opening_biases = torch.nn.Embedding(num_openings, 1)\n",
    "        \n",
    "        # ECO letter and number (fixed side information - registered as buffers)\n",
    "        self.register_buffer('opening_eco_letters', opening_eco_letters)\n",
    "        self.register_buffer('opening_eco_numbers', opening_eco_numbers)\n",
    "        \n",
    "        # ECO embeddings (learnable)\n",
    "        self.eco_letter_embedding = torch.nn.Embedding(num_eco_letters, eco_embed_dim)\n",
    "        self.eco_number_embedding = torch.nn.Embedding(num_eco_numbers, eco_embed_dim)\n",
    "        \n",
    "        # ========================================\n",
    "        # Combination Layers\n",
    "        # ========================================\n",
    "        \n",
    "        # Combine player latent factors with rating\n",
    "        # Input: [num_factors + 1] ‚Üí Output: [num_factors]\n",
    "        self.player_combiner = torch.nn.Linear(num_factors + 1, num_factors)\n",
    "        \n",
    "        # Combine opening latent factors with ECO embeddings\n",
    "        # Input: [num_factors + 2*eco_embed_dim] ‚Üí Output: [num_factors]\n",
    "        self.opening_combiner = torch.nn.Linear(num_factors + 2 * eco_embed_dim, num_factors)\n",
    "        \n",
    "        # ========================================\n",
    "        # Global Bias\n",
    "        # ========================================\n",
    "        \n",
    "        # Global bias term (learnable scalar)\n",
    "        self.global_bias = torch.nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "        # ========================================\n",
    "        # Initialize Weights\n",
    "        # ========================================\n",
    "        \n",
    "        # Initialize embeddings with small random values\n",
    "        torch.nn.init.normal_(self.player_factors.weight, mean=0, std=0.01)\n",
    "        torch.nn.init.normal_(self.opening_factors.weight, mean=0, std=0.01)\n",
    "        torch.nn.init.normal_(self.eco_letter_embedding.weight, mean=0, std=0.01)\n",
    "        torch.nn.init.normal_(self.eco_number_embedding.weight, mean=0, std=0.01)\n",
    "        \n",
    "        # Initialize biases to zero\n",
    "        torch.nn.init.zeros_(self.player_biases.weight)\n",
    "        torch.nn.init.zeros_(self.opening_biases.weight)\n",
    "        \n",
    "        # Initialize linear layers with Xavier initialization\n",
    "        torch.nn.init.xavier_uniform_(self.player_combiner.weight)\n",
    "        torch.nn.init.zeros_(self.player_combiner.bias)\n",
    "        torch.nn.init.xavier_uniform_(self.opening_combiner.weight)\n",
    "        torch.nn.init.zeros_(self.opening_combiner.bias)\n",
    "    \n",
    "    def forward(self, player_ids, opening_ids):\n",
    "        \"\"\"\n",
    "        Forward pass: predict player-opening scores.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        player_ids : torch.Tensor\n",
    "            Player IDs (shape: [batch_size])\n",
    "        opening_ids : torch.Tensor\n",
    "            Opening IDs (shape: [batch_size])\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        torch.Tensor\n",
    "            Predicted scores (shape: [batch_size])\n",
    "        \"\"\"\n",
    "        # ========================================\n",
    "        # Get Player Representation\n",
    "        # ========================================\n",
    "        \n",
    "        # Get player latent factors [batch_size, num_factors]\n",
    "        player_embed = self.player_factors(player_ids)\n",
    "        \n",
    "        # Get player ratings [batch_size, 1]\n",
    "        player_rating = self.player_ratings[player_ids].unsqueeze(1)\n",
    "        \n",
    "        # Concatenate player factors with rating [batch_size, num_factors + 1]\n",
    "        player_concat = torch.cat([player_embed, player_rating], dim=1)\n",
    "        \n",
    "        # Combine into final player representation [batch_size, num_factors]\n",
    "        player_repr = self.player_combiner(player_concat)\n",
    "        \n",
    "        # Get player bias [batch_size]\n",
    "        player_bias = self.player_biases(player_ids).squeeze()\n",
    "        \n",
    "        # ========================================\n",
    "        # Get Opening Representation\n",
    "        # ========================================\n",
    "        \n",
    "        # Get opening latent factors [batch_size, num_factors]\n",
    "        opening_embed = self.opening_factors(opening_ids)\n",
    "        \n",
    "        # Get ECO embeddings\n",
    "        eco_letters = self.opening_eco_letters[opening_ids]  # [batch_size]\n",
    "        eco_numbers = self.opening_eco_numbers[opening_ids]  # [batch_size]\n",
    "        \n",
    "        eco_letter_embed = self.eco_letter_embedding(eco_letters)  # [batch_size, eco_embed_dim]\n",
    "        eco_number_embed = self.eco_number_embedding(eco_numbers)  # [batch_size, eco_embed_dim]\n",
    "        \n",
    "        # Concatenate opening factors with ECO embeddings\n",
    "        # [batch_size, num_factors + 2*eco_embed_dim]\n",
    "        opening_concat = torch.cat([opening_embed, eco_letter_embed, eco_number_embed], dim=1)\n",
    "        \n",
    "        # Combine into final opening representation [batch_size, num_factors]\n",
    "        opening_repr = self.opening_combiner(opening_concat)\n",
    "        \n",
    "        # Get opening bias [batch_size]\n",
    "        opening_bias = self.opening_biases(opening_ids).squeeze()\n",
    "        \n",
    "        # ========================================\n",
    "        # Compute Prediction\n",
    "        # ========================================\n",
    "        \n",
    "        # Dot product of player and opening representations [batch_size]\n",
    "        interaction = (player_repr * opening_repr).sum(dim=1)\n",
    "        \n",
    "        # Add biases and global bias\n",
    "        prediction = interaction + player_bias + opening_bias + self.global_bias\n",
    "        \n",
    "        # Apply sigmoid to constrain output to [0, 1] range (since scores are win rates)\n",
    "        prediction = torch.sigmoid(prediction)\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    def get_player_embedding(self, player_id):\n",
    "        \"\"\"\n",
    "        Get the full embedding for a specific player.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        player_id : int\n",
    "            Player ID\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        torch.Tensor\n",
    "            Player representation (shape: [num_factors])\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            player_ids = torch.tensor([player_id], device=self.player_factors.weight.device)\n",
    "            player_embed = self.player_factors(player_ids)\n",
    "            player_rating = self.player_ratings[player_ids].unsqueeze(1)\n",
    "            player_concat = torch.cat([player_embed, player_rating], dim=1)\n",
    "            player_repr = self.player_combiner(player_concat)\n",
    "            return player_repr.squeeze()\n",
    "    \n",
    "    def get_opening_embedding(self, opening_id):\n",
    "        \"\"\"\n",
    "        Get the full embedding for a specific opening.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        opening_id : int\n",
    "            Opening ID\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        torch.Tensor\n",
    "            Opening representation (shape: [num_factors])\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            opening_ids = torch.tensor([opening_id], device=self.opening_factors.weight.device)\n",
    "            opening_embed = self.opening_factors(opening_ids)\n",
    "            \n",
    "            eco_letters = self.opening_eco_letters[opening_ids]\n",
    "            eco_numbers = self.opening_eco_numbers[opening_ids]\n",
    "            \n",
    "            eco_letter_embed = self.eco_letter_embedding(eco_letters)\n",
    "            eco_number_embed = self.eco_number_embedding(eco_numbers)\n",
    "            \n",
    "            opening_concat = torch.cat([opening_embed, eco_letter_embed, eco_number_embed], dim=1)\n",
    "            opening_repr = self.opening_combiner(opening_concat)\n",
    "            return opening_repr.squeeze()\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# Model Summary\n",
    "# ========================================\n",
    "\n",
    "print(f\"\\n‚úÖ ChessOpeningRecommender model class defined\")\n",
    "\n",
    "print(f\"\\nüìä Model Architecture:\")\n",
    "print(f\"   Player Components:\")\n",
    "print(f\"      ‚Ä¢ Latent factors: Embedding({NUM_PLAYERS}, {NUM_FACTORS})\")\n",
    "print(f\"      ‚Ä¢ Biases: Embedding({NUM_PLAYERS}, 1)\")\n",
    "print(f\"      ‚Ä¢ Ratings: Fixed side info (z-score normalized)\")\n",
    "print(f\"      ‚Ä¢ Combiner: Linear({NUM_FACTORS + 1}, {NUM_FACTORS})\")\n",
    "\n",
    "print(f\"\\n   Opening Components:\")\n",
    "print(f\"      ‚Ä¢ Latent factors: Embedding({NUM_OPENINGS}, {NUM_FACTORS})\")\n",
    "print(f\"      ‚Ä¢ Biases: Embedding({NUM_OPENINGS}, 1)\")\n",
    "print(f\"      ‚Ä¢ ECO letter embedding: Embedding({NUM_ECO_LETTERS}, 4)\")\n",
    "print(f\"      ‚Ä¢ ECO number embedding: Embedding({NUM_ECO_NUMBERS}, 4)\")\n",
    "print(f\"      ‚Ä¢ Combiner: Linear({NUM_FACTORS + 8}, {NUM_FACTORS})\")\n",
    "\n",
    "print(f\"\\n   Prediction:\")\n",
    "print(f\"      ‚Ä¢ Dot product of player and opening representations\")\n",
    "print(f\"      ‚Ä¢ + player bias + opening bias + global bias\")\n",
    "print(f\"      ‚Ä¢ ‚Üí Sigmoid activation (output ‚àà [0, 1])\")\n",
    "\n",
    "# Calculate total parameters\n",
    "player_factor_params = NUM_PLAYERS * NUM_FACTORS\n",
    "player_bias_params = NUM_PLAYERS\n",
    "player_combiner_params = (NUM_FACTORS + 1) * NUM_FACTORS + NUM_FACTORS\n",
    "\n",
    "opening_factor_params = NUM_OPENINGS * NUM_FACTORS\n",
    "opening_bias_params = NUM_OPENINGS\n",
    "eco_letter_params = NUM_ECO_LETTERS * 4\n",
    "eco_number_params = NUM_ECO_NUMBERS * 4\n",
    "opening_combiner_params = (NUM_FACTORS + 8) * NUM_FACTORS + NUM_FACTORS\n",
    "\n",
    "global_bias_params = 1\n",
    "\n",
    "total_params = (player_factor_params + player_bias_params + player_combiner_params +\n",
    "                opening_factor_params + opening_bias_params + \n",
    "                eco_letter_params + eco_number_params + opening_combiner_params +\n",
    "                global_bias_params)\n",
    "\n",
    "print(f\"\\nüí° Model Statistics:\")\n",
    "print(f\"   ‚Ä¢ Total trainable parameters: {total_params:,}\")\n",
    "print(f\"   ‚Ä¢ Player parameters: {player_factor_params + player_bias_params + player_combiner_params:,}\")\n",
    "print(f\"   ‚Ä¢ Opening parameters: {opening_factor_params + opening_bias_params + eco_letter_params + eco_number_params + opening_combiner_params:,}\")\n",
    "print(f\"   ‚Ä¢ Global parameters: {global_bias_params}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ MODEL ARCHITECTURE COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüöÄ Ready for Step 7: Training Loop!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbc2c6d",
   "metadata": {},
   "source": [
    "## Step 7: Training Loop\n",
    "\n",
    "Now we'll implement the main training loop that:\n",
    "- Initializes the model with player and opening embeddings\n",
    "- Trains for multiple epochs using mini-batch SGD\n",
    "- Evaluates on validation set after each epoch\n",
    "- Saves checkpoints after each epoch\n",
    "- Logs MSE/RMSE metrics throughout training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da549756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 7: TRAINING LOOP\n",
      "============================================================\n",
      "\n",
      "üì¶ Initializing model...\n",
      "‚úÖ Model initialized on cpu\n",
      "   ‚Ä¢ Player embeddings: 48468 √ó 50\n",
      "   ‚Ä¢ Opening embeddings: 2715 √ó 50\n",
      "   ‚Ä¢ Player ratings: 48468 (z-score normalized)\n",
      "   ‚Ä¢ ECO letters: 5 categories\n",
      "   ‚Ä¢ ECO numbers: 100 categories\n",
      "\n",
      "üîß Initializing optimizer...\n",
      "‚úÖ SGD optimizer initialized:\n",
      "   ‚Ä¢ Learning rate: 0.01\n",
      "   ‚Ä¢ Momentum: 0.9\n",
      "   ‚Ä¢ Weight decay: 0.0\n",
      "\n",
      "============================================================\n",
      "üöÄ STARTING TRAINING\n",
      "============================================================\n",
      "\n",
      "Training configuration:\n",
      "   ‚Ä¢ Epochs: 20\n",
      "   ‚Ä¢ Batch size: 1024\n",
      "   ‚Ä¢ Training samples: 2,172,843\n",
      "   ‚Ä¢ Validation samples: 434,569\n",
      "   ‚Ä¢ Batches per epoch: 2,122\n",
      "\n",
      "============================================================\n",
      "TRAINING PROGRESS\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EPOCH 1/20\n",
      "============================================================\n",
      "‚úÖ SGD optimizer initialized:\n",
      "   ‚Ä¢ Learning rate: 0.01\n",
      "   ‚Ä¢ Momentum: 0.9\n",
      "   ‚Ä¢ Weight decay: 0.0\n",
      "\n",
      "============================================================\n",
      "üöÄ STARTING TRAINING\n",
      "============================================================\n",
      "\n",
      "Training configuration:\n",
      "   ‚Ä¢ Epochs: 20\n",
      "   ‚Ä¢ Batch size: 1024\n",
      "   ‚Ä¢ Training samples: 2,172,843\n",
      "   ‚Ä¢ Validation samples: 434,569\n",
      "   ‚Ä¢ Batches per epoch: 2,122\n",
      "\n",
      "============================================================\n",
      "TRAINING PROGRESS\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EPOCH 1/20\n",
      "============================================================\n",
      "   Epoch 1 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001678 | ETA: 0.0sss\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "   Epoch 1 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001678 | ETA: 0.0s\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "\n",
      "============================================================\n",
      "EPOCH 1 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001729\n",
      "   ‚Ä¢ Time: 62.87s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001699\n",
      "   ‚Ä¢ RMSE: 0.041219\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_001.pt\n",
      "   üåü New best model saved! (val_rmse: 0.041219)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 2/20\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EPOCH 1 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001729\n",
      "   ‚Ä¢ Time: 62.87s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001699\n",
      "   ‚Ä¢ RMSE: 0.041219\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_001.pt\n",
      "   üåü New best model saved! (val_rmse: 0.041219)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 2/20\n",
      "============================================================\n",
      "   Epoch 2 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001695 | ETA: 0.0sss\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "   Epoch 2 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001695 | ETA: 0.0s\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "\n",
      "============================================================\n",
      "EPOCH 2 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001679\n",
      "   ‚Ä¢ Time: 61.49s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001660\n",
      "   ‚Ä¢ RMSE: 0.040741\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_002.pt\n",
      "   üåü New best model saved! (val_rmse: 0.040741)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 3/20\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EPOCH 2 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001679\n",
      "   ‚Ä¢ Time: 61.49s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001660\n",
      "   ‚Ä¢ RMSE: 0.040741\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_002.pt\n",
      "   üåü New best model saved! (val_rmse: 0.040741)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 3/20\n",
      "============================================================\n",
      "   Epoch 3 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001595 | ETA: 0.0sss\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "   Epoch 3 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001595 | ETA: 0.0s\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "\n",
      "============================================================\n",
      "EPOCH 3 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001644\n",
      "   ‚Ä¢ Time: 59.50s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001629\n",
      "   ‚Ä¢ RMSE: 0.040357\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_003.pt\n",
      "   üåü New best model saved! (val_rmse: 0.040357)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 4/20\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EPOCH 3 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001644\n",
      "   ‚Ä¢ Time: 59.50s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001629\n",
      "   ‚Ä¢ RMSE: 0.040357\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_003.pt\n",
      "   üåü New best model saved! (val_rmse: 0.040357)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 4/20\n",
      "============================================================\n",
      "   Epoch 4 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001749 | ETA: 0.0sss\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "   Epoch 4 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001749 | ETA: 0.0s\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "\n",
      "============================================================\n",
      "EPOCH 4 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001615\n",
      "   ‚Ä¢ Time: 58.14s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001603\n",
      "   ‚Ä¢ RMSE: 0.040036\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_004.pt\n",
      "   üåü New best model saved! (val_rmse: 0.040036)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 5/20\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EPOCH 4 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001615\n",
      "   ‚Ä¢ Time: 58.14s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001603\n",
      "   ‚Ä¢ RMSE: 0.040036\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_004.pt\n",
      "   üåü New best model saved! (val_rmse: 0.040036)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 5/20\n",
      "============================================================\n",
      "   Epoch 5 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001535 | ETA: 0.0sss\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "   Epoch 5 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001535 | ETA: 0.0s\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "\n",
      "============================================================\n",
      "EPOCH 5 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001591\n",
      "   ‚Ä¢ Time: 59.40s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001581\n",
      "   ‚Ä¢ RMSE: 0.039762\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_005.pt\n",
      "   üåü New best model saved! (val_rmse: 0.039762)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 6/20\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EPOCH 5 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001591\n",
      "   ‚Ä¢ Time: 59.40s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001581\n",
      "   ‚Ä¢ RMSE: 0.039762\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_005.pt\n",
      "   üåü New best model saved! (val_rmse: 0.039762)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 6/20\n",
      "============================================================\n",
      "   Epoch 6 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001468 | ETA: 0.0sss\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "   Epoch 6 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001468 | ETA: 0.0s\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "\n",
      "============================================================\n",
      "EPOCH 6 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001571\n",
      "   ‚Ä¢ Time: 59.10s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001562\n",
      "   ‚Ä¢ RMSE: 0.039522\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_006.pt\n",
      "   üåü New best model saved! (val_rmse: 0.039522)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 7/20\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EPOCH 6 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001571\n",
      "   ‚Ä¢ Time: 59.10s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001562\n",
      "   ‚Ä¢ RMSE: 0.039522\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_006.pt\n",
      "   üåü New best model saved! (val_rmse: 0.039522)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 7/20\n",
      "============================================================\n",
      "   Epoch 7 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001531 | ETA: 0.0sss\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "   Epoch 7 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001531 | ETA: 0.0s\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "\n",
      "============================================================\n",
      "EPOCH 7 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001553\n",
      "   ‚Ä¢ Time: 59.68s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001545\n",
      "   ‚Ä¢ RMSE: 0.039312\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_007.pt\n",
      "   üåü New best model saved! (val_rmse: 0.039312)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 8/20\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EPOCH 7 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001553\n",
      "   ‚Ä¢ Time: 59.68s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001545\n",
      "   ‚Ä¢ RMSE: 0.039312\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_007.pt\n",
      "   üåü New best model saved! (val_rmse: 0.039312)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 8/20\n",
      "============================================================\n",
      "   Epoch 8 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001491 | ETA: 0.0sss\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "   Epoch 8 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001491 | ETA: 0.0s\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "\n",
      "============================================================\n",
      "EPOCH 8 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001537\n",
      "   ‚Ä¢ Time: 57.93s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001531\n",
      "   ‚Ä¢ RMSE: 0.039122\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_008.pt\n",
      "   üåü New best model saved! (val_rmse: 0.039122)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 9/20\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EPOCH 8 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001537\n",
      "   ‚Ä¢ Time: 57.93s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001531\n",
      "   ‚Ä¢ RMSE: 0.039122\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_008.pt\n",
      "   üåü New best model saved! (val_rmse: 0.039122)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 9/20\n",
      "============================================================\n",
      "   Epoch 9 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001677 | ETA: 0.0sss\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "   Epoch 9 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001677 | ETA: 0.0s\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "\n",
      "============================================================\n",
      "EPOCH 9 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001523\n",
      "   ‚Ä¢ Time: 59.16s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001517\n",
      "   ‚Ä¢ RMSE: 0.038953\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_009.pt\n",
      "   üåü New best model saved! (val_rmse: 0.038953)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 10/20\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EPOCH 9 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001523\n",
      "   ‚Ä¢ Time: 59.16s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001517\n",
      "   ‚Ä¢ RMSE: 0.038953\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_009.pt\n",
      "   üåü New best model saved! (val_rmse: 0.038953)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 10/20\n",
      "============================================================\n",
      "   Epoch 10 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001437 | ETA: 0.0sss\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "   Epoch 10 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001437 | ETA: 0.0s\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "\n",
      "============================================================\n",
      "EPOCH 10 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001511\n",
      "   ‚Ä¢ Time: 58.61s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001506\n",
      "   ‚Ä¢ RMSE: 0.038801\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_010.pt\n",
      "   üåü New best model saved! (val_rmse: 0.038801)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 11/20\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EPOCH 10 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001511\n",
      "   ‚Ä¢ Time: 58.61s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001506\n",
      "   ‚Ä¢ RMSE: 0.038801\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_010.pt\n",
      "   üåü New best model saved! (val_rmse: 0.038801)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 11/20\n",
      "============================================================\n",
      "   Epoch 11 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001486 | ETA: 0.0sss\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "   Epoch 11 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001486 | ETA: 0.0s\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "\n",
      "============================================================\n",
      "EPOCH 11 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001499\n",
      "   ‚Ä¢ Time: 59.88s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001495\n",
      "   ‚Ä¢ RMSE: 0.038663\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_011.pt\n",
      "   üåü New best model saved! (val_rmse: 0.038663)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 12/20\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EPOCH 11 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001499\n",
      "   ‚Ä¢ Time: 59.88s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001495\n",
      "   ‚Ä¢ RMSE: 0.038663\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_011.pt\n",
      "   üåü New best model saved! (val_rmse: 0.038663)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 12/20\n",
      "============================================================\n",
      "   Epoch 12 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001530 | ETA: 0.0sss\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "   Epoch 12 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001530 | ETA: 0.0s\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "\n",
      "============================================================\n",
      "EPOCH 12 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001489\n",
      "   ‚Ä¢ Time: 64.50s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001485\n",
      "   ‚Ä¢ RMSE: 0.038536\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_012.pt\n",
      "   üåü New best model saved! (val_rmse: 0.038536)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 13/20\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EPOCH 12 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001489\n",
      "   ‚Ä¢ Time: 64.50s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001485\n",
      "   ‚Ä¢ RMSE: 0.038536\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_012.pt\n",
      "   üåü New best model saved! (val_rmse: 0.038536)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 13/20\n",
      "============================================================\n",
      "   Epoch 13 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001389 | ETA: 0.0sss\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "   Epoch 13 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001389 | ETA: 0.0s\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "\n",
      "============================================================\n",
      "EPOCH 13 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001480\n",
      "   ‚Ä¢ Time: 61.18s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001476\n",
      "   ‚Ä¢ RMSE: 0.038421\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_013.pt\n",
      "   üåü New best model saved! (val_rmse: 0.038421)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 14/20\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EPOCH 13 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001480\n",
      "   ‚Ä¢ Time: 61.18s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001476\n",
      "   ‚Ä¢ RMSE: 0.038421\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_013.pt\n",
      "   üåü New best model saved! (val_rmse: 0.038421)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 14/20\n",
      "============================================================\n",
      "   Epoch 14 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001518 | ETA: 0.0sss\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "   Epoch 14 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001518 | ETA: 0.0s\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "\n",
      "============================================================\n",
      "EPOCH 14 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001471\n",
      "   ‚Ä¢ Time: 61.88s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001468\n",
      "   ‚Ä¢ RMSE: 0.038313\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_014.pt\n",
      "   üåü New best model saved! (val_rmse: 0.038313)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 15/20\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EPOCH 14 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001471\n",
      "   ‚Ä¢ Time: 61.88s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001468\n",
      "   ‚Ä¢ RMSE: 0.038313\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_014.pt\n",
      "   üåü New best model saved! (val_rmse: 0.038313)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 15/20\n",
      "============================================================\n",
      "   Epoch 15 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001477 | ETA: 0.0sss\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "   Epoch 15 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001477 | ETA: 0.0s\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "\n",
      "============================================================\n",
      "EPOCH 15 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001463\n",
      "   ‚Ä¢ Time: 59.74s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001460\n",
      "   ‚Ä¢ RMSE: 0.038214\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_015.pt\n",
      "   üåü New best model saved! (val_rmse: 0.038214)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 16/20\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EPOCH 15 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001463\n",
      "   ‚Ä¢ Time: 59.74s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001460\n",
      "   ‚Ä¢ RMSE: 0.038214\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_015.pt\n",
      "   üåü New best model saved! (val_rmse: 0.038214)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 16/20\n",
      "============================================================\n",
      "   Epoch 16 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001508 | ETA: 0.0sss\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "   Epoch 16 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001508 | ETA: 0.0s\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "\n",
      "============================================================\n",
      "EPOCH 16 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001456\n",
      "   ‚Ä¢ Time: 57.32s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001453\n",
      "   ‚Ä¢ RMSE: 0.038122\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_016.pt\n",
      "   üåü New best model saved! (val_rmse: 0.038122)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 17/20\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EPOCH 16 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001456\n",
      "   ‚Ä¢ Time: 57.32s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001453\n",
      "   ‚Ä¢ RMSE: 0.038122\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_016.pt\n",
      "   üåü New best model saved! (val_rmse: 0.038122)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 17/20\n",
      "============================================================\n",
      "   Epoch 17 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001459 | ETA: 0.0sss\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "   Epoch 17 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001459 | ETA: 0.0s\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "\n",
      "============================================================\n",
      "EPOCH 17 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001449\n",
      "   ‚Ä¢ Time: 58.30s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001447\n",
      "   ‚Ä¢ RMSE: 0.038036\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_017.pt\n",
      "   üåü New best model saved! (val_rmse: 0.038036)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 18/20\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EPOCH 17 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001449\n",
      "   ‚Ä¢ Time: 58.30s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001447\n",
      "   ‚Ä¢ RMSE: 0.038036\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_017.pt\n",
      "   üåü New best model saved! (val_rmse: 0.038036)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 18/20\n",
      "============================================================\n",
      "   Epoch 18 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001512 | ETA: 0.0sss\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "   Epoch 18 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001512 | ETA: 0.0s\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "\n",
      "============================================================\n",
      "EPOCH 18 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001442\n",
      "   ‚Ä¢ Time: 58.84s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001441\n",
      "   ‚Ä¢ RMSE: 0.037955\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_018.pt\n",
      "   üåü New best model saved! (val_rmse: 0.037955)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 19/20\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EPOCH 18 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001442\n",
      "   ‚Ä¢ Time: 58.84s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001441\n",
      "   ‚Ä¢ RMSE: 0.037955\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_018.pt\n",
      "   üåü New best model saved! (val_rmse: 0.037955)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 19/20\n",
      "============================================================\n",
      "   Epoch 19 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001582 | ETA: 0.0sss\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "   Epoch 19 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001582 | ETA: 0.0s\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "\n",
      "============================================================\n",
      "EPOCH 19 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001436\n",
      "   ‚Ä¢ Time: 57.36s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001435\n",
      "   ‚Ä¢ RMSE: 0.037880\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_019.pt\n",
      "   üåü New best model saved! (val_rmse: 0.037880)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 20/20\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EPOCH 19 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001436\n",
      "   ‚Ä¢ Time: 57.36s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001435\n",
      "   ‚Ä¢ RMSE: 0.037880\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_019.pt\n",
      "   üåü New best model saved! (val_rmse: 0.037880)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 20/20\n",
      "============================================================\n",
      "   Epoch 20 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001331 | ETA: 0.0sss\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "   Epoch 20 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.00% | Loss: 0.001331 | ETA: 0.0s\n",
      "\n",
      "üìä Evaluating on validation set...\n",
      "\n",
      "============================================================\n",
      "EPOCH 20 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001431\n",
      "   ‚Ä¢ Time: 57.33s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001429\n",
      "   ‚Ä¢ RMSE: 0.037809\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_020.pt\n",
      "   üåü New best model saved! (val_rmse: 0.037809)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "‚úÖ TRAINING COMPLETE\n",
      "============================================================\n",
      "\n",
      "üìä Training Summary:\n",
      "   ‚Ä¢ Total epochs: 20\n",
      "   ‚Ä¢ Best epoch: 20\n",
      "   ‚Ä¢ Best validation RMSE: 0.037809\n",
      "   ‚Ä¢ Final validation RMSE: 0.037809\n",
      "\n",
      "‚è±Ô∏è  Training Time:\n",
      "   ‚Ä¢ Total: 1192.22s (19.87m)\n",
      "   ‚Ä¢ Average per epoch: 59.61s\n",
      "\n",
      "üíæ Saved Models:\n",
      "   ‚Ä¢ Best model: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/best_model.pt\n",
      "   ‚Ä¢ Latest checkpoint: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_020.pt\n",
      "   ‚Ä¢ All checkpoints: 20 files in /Users/a/Documents/personalprojects/chess-opening-recommender/data/models\n",
      "\n",
      "üí° For production use, load 'best_model.pt' (epoch 20)\n",
      "\n",
      "============================================================\n",
      "EPOCH 20 SUMMARY\n",
      "============================================================\n",
      "Training:\n",
      "   ‚Ä¢ Average loss: 0.001431\n",
      "   ‚Ä¢ Time: 57.33s\n",
      "Validation:\n",
      "   ‚Ä¢ MSE: 0.001429\n",
      "   ‚Ä¢ RMSE: 0.037809\n",
      "   üíæ Checkpoint saved to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_020.pt\n",
      "   üåü New best model saved! (val_rmse: 0.037809)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "‚úÖ TRAINING COMPLETE\n",
      "============================================================\n",
      "\n",
      "üìä Training Summary:\n",
      "   ‚Ä¢ Total epochs: 20\n",
      "   ‚Ä¢ Best epoch: 20\n",
      "   ‚Ä¢ Best validation RMSE: 0.037809\n",
      "   ‚Ä¢ Final validation RMSE: 0.037809\n",
      "\n",
      "‚è±Ô∏è  Training Time:\n",
      "   ‚Ä¢ Total: 1192.22s (19.87m)\n",
      "   ‚Ä¢ Average per epoch: 59.61s\n",
      "\n",
      "üíæ Saved Models:\n",
      "   ‚Ä¢ Best model: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/best_model.pt\n",
      "   ‚Ä¢ Latest checkpoint: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/checkpoint_epoch_020.pt\n",
      "   ‚Ä¢ All checkpoints: 20 files in /Users/a/Documents/personalprojects/chess-opening-recommender/data/models\n",
      "\n",
      "üí° For production use, load 'best_model.pt' (epoch 20)\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Training Loop\n",
    "\n",
    "import shutil\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 7: TRAINING LOOP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ========================================\n",
    "# Initialize Model\n",
    "# ========================================\n",
    "\n",
    "print(\"\\nüì¶ Initializing model...\")\n",
    "model = ChessOpeningRecommender(\n",
    "    num_players=NUM_PLAYERS,\n",
    "    num_openings=NUM_OPENINGS,\n",
    "    num_factors=NUM_FACTORS,\n",
    "    player_ratings=player_ratings_tensor,\n",
    "    opening_eco_letters=opening_eco_letter_tensor,\n",
    "    opening_eco_numbers=opening_eco_number_tensor,\n",
    "    num_eco_letters=NUM_ECO_LETTERS,\n",
    "    num_eco_numbers=NUM_ECO_NUMBERS\n",
    ").to(DEVICE)\n",
    "\n",
    "print(f\"‚úÖ Model initialized on {DEVICE}\")\n",
    "print(f\"   ‚Ä¢ Player embeddings: {NUM_PLAYERS} √ó {NUM_FACTORS}\")\n",
    "print(f\"   ‚Ä¢ Opening embeddings: {NUM_OPENINGS} √ó {NUM_FACTORS}\")\n",
    "print(f\"   ‚Ä¢ Player ratings: {NUM_PLAYERS} (z-score normalized)\")\n",
    "print(f\"   ‚Ä¢ ECO letters: {NUM_ECO_LETTERS} categories\")\n",
    "print(f\"   ‚Ä¢ ECO numbers: {NUM_ECO_NUMBERS} categories\")\n",
    "\n",
    "# ========================================\n",
    "# Initialize Optimizer\n",
    "# ========================================\n",
    "\n",
    "print(\"\\nüîß Initializing optimizer...\")\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    momentum=MOMENTUM,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ SGD optimizer initialized:\")\n",
    "print(f\"   ‚Ä¢ Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"   ‚Ä¢ Momentum: {MOMENTUM}\")\n",
    "print(f\"   ‚Ä¢ Weight decay: {WEIGHT_DECAY}\")\n",
    "\n",
    "# ========================================\n",
    "# Training Loop\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üöÄ STARTING TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nTraining configuration:\")\n",
    "print(f\"   ‚Ä¢ Epochs: {N_EPOCHS}\")\n",
    "print(f\"   ‚Ä¢ Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   ‚Ä¢ Training samples: {len(train_dataset):,}\")\n",
    "print(f\"   ‚Ä¢ Validation samples: {len(val_dataset):,}\")\n",
    "print(f\"   ‚Ä¢ Batches per epoch: {len(train_loader):,}\")\n",
    "\n",
    "# Track best validation RMSE for saving best model\n",
    "best_val_rmse = float('inf')\n",
    "best_epoch = 0\n",
    "\n",
    "# Training history\n",
    "training_history = {\n",
    "    'epoch': [],\n",
    "    'train_loss': [],\n",
    "    'train_time': [],\n",
    "    'val_mse': [],\n",
    "    'val_rmse': [],\n",
    "    'learning_rate': []\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING PROGRESS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EPOCH {epoch}/{N_EPOCHS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Train for one epoch\n",
    "    train_loss, train_time = train_one_epoch(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        optimizer=optimizer,\n",
    "        device=DEVICE,\n",
    "        epoch_num=epoch\n",
    "    )\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    print(f\"\\nüìä Evaluating on validation set...\")\n",
    "    val_mse, val_rmse = evaluate_model(\n",
    "        model=model,\n",
    "        data_loader=val_loader,\n",
    "        device=DEVICE,\n",
    "        dataset_name=\"Validation\"\n",
    "    )\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EPOCH {epoch} SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Training:\")\n",
    "    print(f\"   ‚Ä¢ Average loss: {train_loss:.6f}\")\n",
    "    print(f\"   ‚Ä¢ Time: {train_time:.2f}s\")\n",
    "    print(f\"Validation:\")\n",
    "    print(f\"   ‚Ä¢ MSE: {val_mse:.6f}\")\n",
    "    print(f\"   ‚Ä¢ RMSE: {val_rmse:.6f}\")\n",
    "    \n",
    "    # Store history\n",
    "    training_history['epoch'].append(epoch)\n",
    "    training_history['train_loss'].append(train_loss)\n",
    "    training_history['train_time'].append(train_time)\n",
    "    training_history['val_mse'].append(val_mse)\n",
    "    training_history['val_rmse'].append(val_rmse)\n",
    "    training_history['learning_rate'].append(LEARNING_RATE)\n",
    "    \n",
    "    # Save checkpoint for this epoch\n",
    "    checkpoint_filename = f\"checkpoint_epoch_{epoch:03d}.pt\"\n",
    "    checkpoint_path = MODEL_SAVE_DIR / checkpoint_filename\n",
    "    save_checkpoint(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        epoch=epoch,\n",
    "        train_loss=train_loss,\n",
    "        val_loss=val_mse,\n",
    "        filepath=checkpoint_path\n",
    "    )\n",
    "    \n",
    "    # Track and save best model\n",
    "    if val_rmse < best_val_rmse:\n",
    "        best_val_rmse = val_rmse\n",
    "        best_epoch = epoch\n",
    "        best_model_path = MODEL_SAVE_DIR / \"best_model.pt\"\n",
    "        shutil.copy(checkpoint_path, best_model_path)\n",
    "        print(f\"   üåü New best model saved! (val_rmse: {val_rmse:.6f})\")\n",
    "    else:\n",
    "        print(f\"   ‚Ä¢ Current best: Epoch {best_epoch} (val_rmse: {best_val_rmse:.6f})\")\n",
    "    \n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "# ========================================\n",
    "# Training Complete\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ TRAINING COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä Training Summary:\")\n",
    "print(f\"   ‚Ä¢ Total epochs: {N_EPOCHS}\")\n",
    "print(f\"   ‚Ä¢ Best epoch: {best_epoch}\")\n",
    "print(f\"   ‚Ä¢ Best validation RMSE: {best_val_rmse:.6f}\")\n",
    "print(f\"   ‚Ä¢ Final validation RMSE: {training_history['val_rmse'][-1]:.6f}\")\n",
    "\n",
    "# Calculate total training time\n",
    "total_training_time = sum(training_history['train_time'])\n",
    "print(f\"\\n‚è±Ô∏è  Training Time:\")\n",
    "print(f\"   ‚Ä¢ Total: {total_training_time:.2f}s ({total_training_time/60:.2f}m)\")\n",
    "print(f\"   ‚Ä¢ Average per epoch: {total_training_time/N_EPOCHS:.2f}s\")\n",
    "\n",
    "print(f\"\\nüíæ Saved Models:\")\n",
    "print(f\"   ‚Ä¢ Best model: {MODEL_SAVE_DIR / 'best_model.pt'}\")\n",
    "print(f\"   ‚Ä¢ Latest checkpoint: {MODEL_SAVE_DIR / f'checkpoint_epoch_{N_EPOCHS:03d}.pt'}\")\n",
    "print(f\"   ‚Ä¢ All checkpoints: {N_EPOCHS} files in {MODEL_SAVE_DIR}\")\n",
    "\n",
    "print(f\"\\nüí° For production use, load 'best_model.pt' (epoch {best_epoch})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7becba99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0dc479f",
   "metadata": {},
   "source": [
    "## Step 8: Evaluation on Test Set\n",
    "\n",
    "Now that training is complete, we'll evaluate the final model on the held-out test set to get an unbiased estimate of model performance. We'll also:\n",
    "- Calculate MSE and RMSE metrics\n",
    "- Analyze prediction accuracy across different rating ranges\n",
    "- Examine predicted vs actual scores\n",
    "- Identify best and worst predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d8f0315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 8: EVALUATION ON TEST SET\n",
      "============================================================\n",
      "\n",
      "üìä Evaluating model on test set...\n",
      "\n",
      "============================================================\n",
      "TEST SET RESULTS\n",
      "============================================================\n",
      "   ‚Ä¢ MSE: 0.001434\n",
      "   ‚Ä¢ RMSE: 0.037869\n",
      "\n",
      "============================================================\n",
      "PERFORMANCE COMPARISON\n",
      "============================================================\n",
      "\n",
      "Final Training Loss:   0.001431\n",
      "Final Validation RMSE: 0.037809\n",
      "Test RMSE:             0.037869\n",
      "\n",
      "‚úÖ Test and validation RMSE are similar (within 10%)\n",
      "   Model generalizes appropriately.\n",
      "\n",
      "============================================================\n",
      "GENERATING PREDICTIONS FOR ANALYSIS\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "TEST SET RESULTS\n",
      "============================================================\n",
      "   ‚Ä¢ MSE: 0.001434\n",
      "   ‚Ä¢ RMSE: 0.037869\n",
      "\n",
      "============================================================\n",
      "PERFORMANCE COMPARISON\n",
      "============================================================\n",
      "\n",
      "Final Training Loss:   0.001431\n",
      "Final Validation RMSE: 0.037809\n",
      "Test RMSE:             0.037869\n",
      "\n",
      "‚úÖ Test and validation RMSE are similar (within 10%)\n",
      "   Model generalizes appropriately.\n",
      "\n",
      "============================================================\n",
      "GENERATING PREDICTIONS FOR ANALYSIS\n",
      "============================================================\n",
      "‚úÖ Generated 289,713 predictions\n",
      "\n",
      "============================================================\n",
      "PREDICTION STATISTICS\n",
      "============================================================\n",
      "\n",
      "Prediction Range:\n",
      "   ‚Ä¢ Min: 0.4497\n",
      "   ‚Ä¢ Max: 0.6257\n",
      "   ‚Ä¢ Mean: 0.5138\n",
      "   ‚Ä¢ Std: 0.0130\n",
      "\n",
      "Actual Score Range:\n",
      "   ‚Ä¢ Min: 0.1138\n",
      "   ‚Ä¢ Max: 1.0000\n",
      "   ‚Ä¢ Mean: 0.5120\n",
      "   ‚Ä¢ Std: 0.0412\n",
      "\n",
      "Prediction Errors:\n",
      "   ‚Ä¢ Mean Error: 0.001839\n",
      "   ‚Ä¢ Mean Absolute Error: 0.029214\n",
      "   ‚Ä¢ Median Absolute Error: 0.024270\n",
      "   ‚Ä¢ Max Error: 0.492487\n",
      "\n",
      "============================================================\n",
      "ERROR DISTRIBUTION\n",
      "============================================================\n",
      "\n",
      "Predictions within error threshold:\n",
      "   ‚Ä¢ ¬±0.01: 63,522 (21.9%)\n",
      "   ‚Ä¢ ¬±0.02: 122,623 (42.3%)\n",
      "   ‚Ä¢ ¬±0.05: 240,647 (83.1%)\n",
      "   ‚Ä¢ ¬±0.10: 286,775 (99.0%)\n",
      "   ‚Ä¢ ¬±0.15: 289,480 (99.9%)\n",
      "\n",
      "============================================================\n",
      "BEST AND WORST PREDICTIONS\n",
      "============================================================\n",
      "\n",
      "üéØ Top 10 Best Predictions (lowest error):\n",
      " Player ID   Opening ID   Actual  Predicted    Error\n",
      "------------------------------------------------------------\n",
      "     11040         1602   0.5209     0.5209   0.0000\n",
      "     29498          599   0.4901     0.4901   0.0000\n",
      "     38270          245   0.5164     0.5164  -0.0000\n",
      "     37589          726   0.5035     0.5035  -0.0000\n",
      "     34634         1896   0.5323     0.5323   0.0000\n",
      "     28360         1356   0.5063     0.5063   0.0000\n",
      "     39299         2429   0.5231     0.5231   0.0000\n",
      "     16511         1087   0.4923     0.4923   0.0000\n",
      "     47717          423   0.5171     0.5172   0.0000\n",
      "     31158         1702   0.5093     0.5093  -0.0000\n",
      "\n",
      "‚ùå Top 10 Worst Predictions (highest error):\n",
      " Player ID   Opening ID   Actual  Predicted    Error\n",
      "------------------------------------------------------------\n",
      "     20448         1399   1.0000     0.5075  -0.4925\n",
      "     34667          166   0.1138     0.4774   0.3637\n",
      "     17383          997   0.2500     0.5277   0.2777\n",
      "     23583          335   0.2727     0.5423   0.2696\n",
      "      7610         2532   0.7712     0.5203  -0.2509\n",
      "     30955         1245   0.7843     0.5368  -0.2474\n",
      "      5144         1641   0.7679     0.5205  -0.2474\n",
      "     27677         1245   0.7770     0.5340  -0.2430\n",
      "     27746          166   0.2417     0.4812   0.2396\n",
      "     23751           28   0.2774     0.5163   0.2390\n",
      "\n",
      "============================================================\n",
      "PERFORMANCE BY SCORE RANGE\n",
      "============================================================\n",
      "\n",
      "               Range    Count   Mean Error      MAE     RMSE\n",
      "--------------------------------------------------------------------\n",
      "       Low (0.0-0.3)        8     0.250896 0.250896 0.256016\n",
      " Below Avg (0.3-0.4)    1,086     0.115047 0.115047 0.117310\n",
      "   Average (0.4-0.5)  109,983     0.035639 0.036119 0.041738\n",
      " Above Avg (0.5-0.6)  173,145    -0.017432 0.022342 0.028942\n",
      "      High (0.6-1.0)    5,490    -0.090195 0.090218 0.094050\n",
      "\n",
      "============================================================\n",
      "‚úÖ EVALUATION COMPLETE\n",
      "============================================================\n",
      "\n",
      "üìä Final Test Set Metrics:\n",
      "   ‚Ä¢ Test MSE: 0.001434\n",
      "   ‚Ä¢ Test RMSE: 0.037869\n",
      "   ‚Ä¢ Mean Absolute Error: 0.029214\n",
      "   ‚Ä¢ Predictions within ¬±0.05: 83.1%\n",
      "\n",
      "üí° Interpretation:\n",
      "   ‚Ä¢ RMSE of 0.0379 means average prediction error is ~0.0379\n",
      "   ‚Ä¢ For a player with true win rate of 0.50, model typically predicts within ¬±0.0379\n",
      "   ‚Ä¢ This is equivalent to ¬±3.79 percentage points\n",
      "\n",
      "============================================================\n",
      "üéØ Next: Save model and create inference pipeline\n",
      "============================================================\n",
      "‚úÖ Generated 289,713 predictions\n",
      "\n",
      "============================================================\n",
      "PREDICTION STATISTICS\n",
      "============================================================\n",
      "\n",
      "Prediction Range:\n",
      "   ‚Ä¢ Min: 0.4497\n",
      "   ‚Ä¢ Max: 0.6257\n",
      "   ‚Ä¢ Mean: 0.5138\n",
      "   ‚Ä¢ Std: 0.0130\n",
      "\n",
      "Actual Score Range:\n",
      "   ‚Ä¢ Min: 0.1138\n",
      "   ‚Ä¢ Max: 1.0000\n",
      "   ‚Ä¢ Mean: 0.5120\n",
      "   ‚Ä¢ Std: 0.0412\n",
      "\n",
      "Prediction Errors:\n",
      "   ‚Ä¢ Mean Error: 0.001839\n",
      "   ‚Ä¢ Mean Absolute Error: 0.029214\n",
      "   ‚Ä¢ Median Absolute Error: 0.024270\n",
      "   ‚Ä¢ Max Error: 0.492487\n",
      "\n",
      "============================================================\n",
      "ERROR DISTRIBUTION\n",
      "============================================================\n",
      "\n",
      "Predictions within error threshold:\n",
      "   ‚Ä¢ ¬±0.01: 63,522 (21.9%)\n",
      "   ‚Ä¢ ¬±0.02: 122,623 (42.3%)\n",
      "   ‚Ä¢ ¬±0.05: 240,647 (83.1%)\n",
      "   ‚Ä¢ ¬±0.10: 286,775 (99.0%)\n",
      "   ‚Ä¢ ¬±0.15: 289,480 (99.9%)\n",
      "\n",
      "============================================================\n",
      "BEST AND WORST PREDICTIONS\n",
      "============================================================\n",
      "\n",
      "üéØ Top 10 Best Predictions (lowest error):\n",
      " Player ID   Opening ID   Actual  Predicted    Error\n",
      "------------------------------------------------------------\n",
      "     11040         1602   0.5209     0.5209   0.0000\n",
      "     29498          599   0.4901     0.4901   0.0000\n",
      "     38270          245   0.5164     0.5164  -0.0000\n",
      "     37589          726   0.5035     0.5035  -0.0000\n",
      "     34634         1896   0.5323     0.5323   0.0000\n",
      "     28360         1356   0.5063     0.5063   0.0000\n",
      "     39299         2429   0.5231     0.5231   0.0000\n",
      "     16511         1087   0.4923     0.4923   0.0000\n",
      "     47717          423   0.5171     0.5172   0.0000\n",
      "     31158         1702   0.5093     0.5093  -0.0000\n",
      "\n",
      "‚ùå Top 10 Worst Predictions (highest error):\n",
      " Player ID   Opening ID   Actual  Predicted    Error\n",
      "------------------------------------------------------------\n",
      "     20448         1399   1.0000     0.5075  -0.4925\n",
      "     34667          166   0.1138     0.4774   0.3637\n",
      "     17383          997   0.2500     0.5277   0.2777\n",
      "     23583          335   0.2727     0.5423   0.2696\n",
      "      7610         2532   0.7712     0.5203  -0.2509\n",
      "     30955         1245   0.7843     0.5368  -0.2474\n",
      "      5144         1641   0.7679     0.5205  -0.2474\n",
      "     27677         1245   0.7770     0.5340  -0.2430\n",
      "     27746          166   0.2417     0.4812   0.2396\n",
      "     23751           28   0.2774     0.5163   0.2390\n",
      "\n",
      "============================================================\n",
      "PERFORMANCE BY SCORE RANGE\n",
      "============================================================\n",
      "\n",
      "               Range    Count   Mean Error      MAE     RMSE\n",
      "--------------------------------------------------------------------\n",
      "       Low (0.0-0.3)        8     0.250896 0.250896 0.256016\n",
      " Below Avg (0.3-0.4)    1,086     0.115047 0.115047 0.117310\n",
      "   Average (0.4-0.5)  109,983     0.035639 0.036119 0.041738\n",
      " Above Avg (0.5-0.6)  173,145    -0.017432 0.022342 0.028942\n",
      "      High (0.6-1.0)    5,490    -0.090195 0.090218 0.094050\n",
      "\n",
      "============================================================\n",
      "‚úÖ EVALUATION COMPLETE\n",
      "============================================================\n",
      "\n",
      "üìä Final Test Set Metrics:\n",
      "   ‚Ä¢ Test MSE: 0.001434\n",
      "   ‚Ä¢ Test RMSE: 0.037869\n",
      "   ‚Ä¢ Mean Absolute Error: 0.029214\n",
      "   ‚Ä¢ Predictions within ¬±0.05: 83.1%\n",
      "\n",
      "üí° Interpretation:\n",
      "   ‚Ä¢ RMSE of 0.0379 means average prediction error is ~0.0379\n",
      "   ‚Ä¢ For a player with true win rate of 0.50, model typically predicts within ¬±0.0379\n",
      "   ‚Ä¢ This is equivalent to ¬±3.79 percentage points\n",
      "\n",
      "============================================================\n",
      "üéØ Next: Save model and create inference pipeline\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Evaluation on Test Set\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 8: EVALUATION ON TEST SET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ========================================\n",
    "# Evaluate on Test Set\n",
    "# ========================================\n",
    "\n",
    "print(\"\\nüìä Evaluating model on test set...\")\n",
    "test_mse, test_rmse = evaluate_model(\n",
    "    model=model,\n",
    "    data_loader=test_loader,\n",
    "    device=DEVICE,\n",
    "    dataset_name=\"Test\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"   ‚Ä¢ MSE: {test_mse:.6f}\")\n",
    "print(f\"   ‚Ä¢ RMSE: {test_rmse:.6f}\")\n",
    "\n",
    "# ========================================\n",
    "# Compare with Training and Validation\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PERFORMANCE COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "final_train_loss = training_history['train_loss'][-1]\n",
    "final_val_rmse = training_history['val_rmse'][-1]\n",
    "\n",
    "print(f\"\\nFinal Training Loss:   {final_train_loss:.6f}\")\n",
    "print(f\"Final Validation RMSE: {final_val_rmse:.6f}\")\n",
    "print(f\"Test RMSE:             {test_rmse:.6f}\")\n",
    "\n",
    "# Check for overfitting\n",
    "if test_rmse > final_val_rmse * 1.1:\n",
    "    print(f\"\\n‚ö†Ô∏è  Warning: Test RMSE is {(test_rmse/final_val_rmse - 1)*100:.1f}% higher than validation RMSE\")\n",
    "    print(f\"   This suggests possible overfitting.\")\n",
    "elif test_rmse < final_val_rmse * 0.9:\n",
    "    print(f\"\\n‚úÖ Test RMSE is {(1 - test_rmse/final_val_rmse)*100:.1f}% lower than validation RMSE\")\n",
    "    print(f\"   Model generalizes well!\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Test and validation RMSE are similar (within 10%)\")\n",
    "    print(f\"   Model generalizes appropriately.\")\n",
    "\n",
    "# ========================================\n",
    "# Get Predictions for Analysis\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"GENERATING PREDICTIONS FOR ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_actuals = []\n",
    "all_player_ids = []\n",
    "all_opening_ids = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        player_ids = batch['player_id'].to(DEVICE)\n",
    "        opening_ids = batch['opening_id'].to(DEVICE)\n",
    "        targets = batch['score'].to(DEVICE)\n",
    "        \n",
    "        predictions = model(player_ids, opening_ids)\n",
    "        \n",
    "        all_predictions.extend(predictions.detach().cpu().tolist())\n",
    "        all_actuals.extend(targets.detach().cpu().tolist())\n",
    "        all_player_ids.extend(player_ids.detach().cpu().tolist())\n",
    "        all_opening_ids.extend(opening_ids.detach().cpu().tolist())\n",
    "\n",
    "# Convert to numpy arrays\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_actuals = np.array(all_actuals)\n",
    "all_player_ids = np.array(all_player_ids)\n",
    "all_opening_ids = np.array(all_opening_ids)\n",
    "\n",
    "print(f\"‚úÖ Generated {len(all_predictions):,} predictions\")\n",
    "\n",
    "# ========================================\n",
    "# Prediction Statistics\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PREDICTION STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "errors = all_predictions - all_actuals\n",
    "abs_errors = np.abs(errors)\n",
    "\n",
    "print(f\"\\nPrediction Range:\")\n",
    "print(f\"   ‚Ä¢ Min: {all_predictions.min():.4f}\")\n",
    "print(f\"   ‚Ä¢ Max: {all_predictions.max():.4f}\")\n",
    "print(f\"   ‚Ä¢ Mean: {all_predictions.mean():.4f}\")\n",
    "print(f\"   ‚Ä¢ Std: {all_predictions.std():.4f}\")\n",
    "\n",
    "print(f\"\\nActual Score Range:\")\n",
    "print(f\"   ‚Ä¢ Min: {all_actuals.min():.4f}\")\n",
    "print(f\"   ‚Ä¢ Max: {all_actuals.max():.4f}\")\n",
    "print(f\"   ‚Ä¢ Mean: {all_actuals.mean():.4f}\")\n",
    "print(f\"   ‚Ä¢ Std: {all_actuals.std():.4f}\")\n",
    "\n",
    "print(f\"\\nPrediction Errors:\")\n",
    "print(f\"   ‚Ä¢ Mean Error: {errors.mean():.6f}\")\n",
    "print(f\"   ‚Ä¢ Mean Absolute Error: {abs_errors.mean():.6f}\")\n",
    "print(f\"   ‚Ä¢ Median Absolute Error: {np.median(abs_errors):.6f}\")\n",
    "print(f\"   ‚Ä¢ Max Error: {abs_errors.max():.6f}\")\n",
    "\n",
    "# ========================================\n",
    "# Error Distribution\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ERROR DISTRIBUTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Count predictions within various error thresholds\n",
    "thresholds = [0.01, 0.02, 0.05, 0.10, 0.15]\n",
    "print(f\"\\nPredictions within error threshold:\")\n",
    "for threshold in thresholds:\n",
    "    count = np.sum(abs_errors <= threshold)\n",
    "    pct = 100.0 * count / len(abs_errors)\n",
    "    print(f\"   ‚Ä¢ ¬±{threshold:.2f}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "# ========================================\n",
    "# Best and Worst Predictions\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BEST AND WORST PREDICTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Sort by absolute error\n",
    "sorted_indices = np.argsort(abs_errors)\n",
    "\n",
    "print(f\"\\nüéØ Top 10 Best Predictions (lowest error):\")\n",
    "print(f\"{'Player ID':>10} {'Opening ID':>12} {'Actual':>8} {'Predicted':>10} {'Error':>8}\")\n",
    "print(\"-\" * 60)\n",
    "for i in range(min(10, len(sorted_indices))):\n",
    "    idx = sorted_indices[i]\n",
    "    print(f\"{all_player_ids[idx]:>10.0f} {all_opening_ids[idx]:>12.0f} \"\n",
    "          f\"{all_actuals[idx]:>8.4f} {all_predictions[idx]:>10.4f} \"\n",
    "          f\"{errors[idx]:>8.4f}\")\n",
    "\n",
    "print(f\"\\n‚ùå Top 10 Worst Predictions (highest error):\")\n",
    "print(f\"{'Player ID':>10} {'Opening ID':>12} {'Actual':>8} {'Predicted':>10} {'Error':>8}\")\n",
    "print(\"-\" * 60)\n",
    "for i in range(min(10, len(sorted_indices))):\n",
    "    idx = sorted_indices[-(i+1)]\n",
    "    print(f\"{all_player_ids[idx]:>10.0f} {all_opening_ids[idx]:>12.0f} \"\n",
    "          f\"{all_actuals[idx]:>8.4f} {all_predictions[idx]:>10.4f} \"\n",
    "          f\"{errors[idx]:>8.4f}\")\n",
    "\n",
    "# ========================================\n",
    "# Analyze by Score Range\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PERFORMANCE BY SCORE RANGE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "score_ranges = [\n",
    "    (0.0, 0.3, \"Low (0.0-0.3)\"),\n",
    "    (0.3, 0.4, \"Below Avg (0.3-0.4)\"),\n",
    "    (0.4, 0.5, \"Average (0.4-0.5)\"),\n",
    "    (0.5, 0.6, \"Above Avg (0.5-0.6)\"),\n",
    "    (0.6, 1.0, \"High (0.6-1.0)\")\n",
    "]\n",
    "\n",
    "print(f\"\\n{'Range':>20} {'Count':>8} {'Mean Error':>12} {'MAE':>8} {'RMSE':>8}\")\n",
    "print(\"-\" * 68)\n",
    "\n",
    "for low, high, label in score_ranges:\n",
    "    mask = (all_actuals >= low) & (all_actuals < high)\n",
    "    if mask.sum() == 0:\n",
    "        continue\n",
    "    \n",
    "    range_errors = errors[mask]\n",
    "    range_abs_errors = abs_errors[mask]\n",
    "    range_rmse = np.sqrt(np.mean(range_errors ** 2))\n",
    "    \n",
    "    print(f\"{label:>20} {mask.sum():>8,} {range_errors.mean():>12.6f} \"\n",
    "          f\"{range_abs_errors.mean():>8.6f} {range_rmse:>8.6f}\")\n",
    "\n",
    "# ========================================\n",
    "# Summary\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ EVALUATION COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä Final Test Set Metrics:\")\n",
    "print(f\"   ‚Ä¢ Test MSE: {test_mse:.6f}\")\n",
    "print(f\"   ‚Ä¢ Test RMSE: {test_rmse:.6f}\")\n",
    "print(f\"   ‚Ä¢ Mean Absolute Error: {abs_errors.mean():.6f}\")\n",
    "print(f\"   ‚Ä¢ Predictions within ¬±0.05: {100.0 * np.sum(abs_errors <= 0.05) / len(abs_errors):.1f}%\")\n",
    "\n",
    "print(f\"\\nüí° Interpretation:\")\n",
    "print(f\"   ‚Ä¢ RMSE of {test_rmse:.4f} means average prediction error is ~{test_rmse:.4f}\")\n",
    "print(f\"   ‚Ä¢ For a player with true win rate of 0.50, model typically predicts within ¬±{test_rmse:.4f}\")\n",
    "print(f\"   ‚Ä¢ This is equivalent to ¬±{test_rmse*100:.2f} percentage points\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéØ Next: Save model and create inference pipeline\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68202800",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclean_data\u001b[49m.corr())\n",
      "\u001b[31mNameError\u001b[39m: name 'clean_data' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
