{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dab4527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database path: /Users/a/Documents/personalprojects/chess-opening-recommender/data/processed/chess_games.db\n",
      "Partitions: ['A', 'B', 'C', 'D', 'E', 'other']\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "from pathlib import Path\n",
    "from utils.database.db_utils import get_db_connection\n",
    " \n",
    "# Define the path to the DuckDB database file\n",
    "project_root = Path.cwd().parent if \"notebooks\" in str(Path.cwd()) else Path.cwd()\n",
    "db_path = project_root / \"data\" / \"processed\" / \"chess_games.db\"\n",
    " \n",
    "# Define partitions for player_opening_stats\n",
    "partitions = list(\"ABCDE\") + [\"other\"]\n",
    " \n",
    "# Print configuration details\n",
    "print(f\"Database path: {db_path}\")\n",
    "print(f\"Partitions: {partitions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8014e89b",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "To decrease the size of our opening stats DB, making queries faster and more efficient.\n",
    "\n",
    "# Methods:\n",
    "\n",
    "    1. Change INTs to SMALLINT\n",
    "        - player_id and opening_id\n",
    "        - num_draws\n",
    "            - Not doing this on num_wins and num_losses because those may exceed the limit of this data type (~32,000)\n",
    "        - Not doing this with player_opening_stats ID because that's a composite string, not an int \n",
    "        - Saves 2 bytes per entry\n",
    "    \n",
    "    2. Change `color` VARCHAR to w/b enum\n",
    "        - 1b\n",
    "        - Compared to the 12-16bytes the previous varchar took up\n",
    "\n",
    "# Considerations\n",
    "    - Saving a copy of the DB in case I bork this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1574311f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current database file size: 1385.51 MB\n"
     ]
    }
   ],
   "source": [
    "# Print current database size\n",
    "import os\n",
    "try:\n",
    "    db_size_bytes = os.path.getsize(db_path)\n",
    "    db_size_mb = db_size_bytes / (1024 * 1024)\n",
    "    print(f\"Current database file size: {db_size_mb:.2f} MB\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Database file not found.\")\n",
    "    db_size_mb = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9870cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CURRENT TABLE SCHEMAS ===\n",
      "\n",
      "PLAYER table schema:\n",
      "  id: INTEGER\n",
      "  name: VARCHAR\n",
      "  title: VARCHAR\n",
      "\n",
      "OPENING table schema:\n",
      "  id: INTEGER\n",
      "  eco: VARCHAR\n",
      "  name: VARCHAR\n",
      "\n",
      "PLAYER_OPENING_STATS_A table schema:\n",
      "  player_id: INTEGER\n",
      "  opening_id: INTEGER\n",
      "  color: ENUM('w', 'b')\n",
      "  num_wins: INTEGER\n",
      "  num_draws: SMALLINT\n",
      "  num_losses: INTEGER\n",
      "\n",
      "=== DATA RANGES ===\n",
      "Max player_id: 32,964,861\n",
      "Max opening_id: 5,222,927\n",
      "player_opening_stats_A: 3,137,793 rows\n",
      "player_opening_stats_B: 3,339,867 rows\n",
      "player_opening_stats_C: 4,175,489 rows\n",
      "player_opening_stats_D: 1,771,597 rows\n",
      "player_opening_stats_E: 442,866 rows\n",
      "player_opening_stats_other: 0 rows\n",
      "\n",
      "Total stats rows: 12,867,612\n",
      "\n",
      "Color distribution in stats_A: [('w', 1108563), ('b', 2029230)]\n",
      "\n",
      "num_draws in stats_A - Min: 0, Max: 480, Avg: 0.45\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic - check actual table schemas and data counts\n",
    "with get_db_connection(db_path) as con:\n",
    "    print(\"=== CURRENT TABLE SCHEMAS ===\")\n",
    "    \n",
    "    # Check player table\n",
    "    player_schema = con.execute(\"DESCRIBE player\").fetchall()\n",
    "    print(f\"\\nPLAYER table schema:\")\n",
    "    for col in player_schema:\n",
    "        print(f\"  {col[0]}: {col[1]}\")\n",
    "    \n",
    "    # Check opening table  \n",
    "    opening_schema = con.execute(\"DESCRIBE opening\").fetchall()\n",
    "    print(f\"\\nOPENING table schema:\")\n",
    "    for col in opening_schema:\n",
    "        print(f\"  {col[0]}: {col[1]}\")\n",
    "    \n",
    "    # Check one stats table\n",
    "    stats_schema = con.execute(\"DESCRIBE player_opening_stats_A\").fetchall()\n",
    "    print(f\"\\nPLAYER_OPENING_STATS_A table schema:\")\n",
    "    for col in stats_schema:\n",
    "        print(f\"  {col[0]}: {col[1]}\")\n",
    "    \n",
    "    print(\"\\n=== DATA RANGES ===\")\n",
    "    \n",
    "    # Check max values\n",
    "    max_player_id = con.execute(\"SELECT MAX(id) FROM player\").fetchone()[0]\n",
    "    max_opening_id = con.execute(\"SELECT MAX(id) FROM opening\").fetchone()[0]\n",
    "    print(f\"Max player_id: {max_player_id:,}\")\n",
    "    print(f\"Max opening_id: {max_opening_id:,}\")\n",
    "    \n",
    "    # Check total row counts\n",
    "    total_stats_rows = 0\n",
    "    for letter in ['A', 'B', 'C', 'D', 'E', 'other']:\n",
    "        count = con.execute(f\"SELECT COUNT(*) FROM player_opening_stats_{letter}\").fetchone()[0]\n",
    "        print(f\"player_opening_stats_{letter}: {count:,} rows\")\n",
    "        total_stats_rows += count\n",
    "    \n",
    "    print(f\"\\nTotal stats rows: {total_stats_rows:,}\")\n",
    "    \n",
    "    # Check color values distribution\n",
    "    color_dist = con.execute(\"SELECT color, COUNT(*) FROM player_opening_stats_A GROUP BY color\").fetchall()\n",
    "    print(f\"\\nColor distribution in stats_A: {color_dist}\")\n",
    "    \n",
    "    # Check num_draws distribution\n",
    "    draws_stats = con.execute(\"SELECT MIN(num_draws), MAX(num_draws), AVG(num_draws) FROM player_opening_stats_A\").fetchone()\n",
    "    print(f\"\\nnum_draws in stats_A - Min: {draws_stats[0]}, Max: {draws_stats[1]}, Avg: {draws_stats[2]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f7058f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max opening_id: 5222927\n",
      "WARNING: opening_id exceeds SMALLINT range. Using INTEGER.\n",
      "Creating new schema for partitioned tables...\n",
      "Creating new opening table with optimized ID type...\n",
      "Migrating data to new opening table...\n",
      "Creating new player_opening_stats tables with optimized data types...\n",
      "Migrating player_opening_stats data with optimized types...\n",
      "Migrating data from player_opening_stats_A to player_opening_stats_A_new...\n",
      "Migrating data from player_opening_stats_B to player_opening_stats_B_new...\n",
      "Migrating data from player_opening_stats_B to player_opening_stats_B_new...\n",
      "Migrating data from player_opening_stats_C to player_opening_stats_C_new...\n",
      "Migrating data from player_opening_stats_C to player_opening_stats_C_new...\n",
      "Migrating data from player_opening_stats_D to player_opening_stats_D_new...\n",
      "Migrating data from player_opening_stats_D to player_opening_stats_D_new...\n",
      "Migrating data from player_opening_stats_E to player_opening_stats_E_new...\n",
      "Migrating data from player_opening_stats_E to player_opening_stats_E_new...\n",
      "Migrating data from player_opening_stats_other to player_opening_stats_other_new...\n",
      "Swapping old tables with new tables...\n",
      "Migrating data from player_opening_stats_other to player_opening_stats_other_new...\n",
      "Swapping old tables with new tables...\n",
      "Migration complete. Data optimized with proper type casting.\n",
      "Migration complete. Data optimized with proper type casting.\n"
     ]
    }
   ],
   "source": [
    "# Execute PROPER database shrinking - compact the wasteful IDs\n",
    "if db_size_mb > 0:\n",
    "    with get_db_connection(db_path) as con:\n",
    "        print(\"=== ANALYZING THE WASTE ====\")\n",
    "        player_stats = con.execute('SELECT MIN(id), MAX(id), COUNT(*) FROM player').fetchone()\n",
    "        opening_stats = con.execute('SELECT MIN(id), MAX(id), COUNT(*) FROM opening').fetchone()\n",
    "        \n",
    "        print(f'Players: {player_stats[2]:,} records, IDs from {player_stats[0]:,} to {player_stats[1]:,}')\n",
    "        print(f'Openings: {opening_stats[2]:,} records, IDs from {opening_stats[0]:,} to {opening_stats[1]:,}')\n",
    "        print(f'Player ID waste: {((player_stats[1] - player_stats[2]) / player_stats[1] * 100):.1f}%')\n",
    "        print(f'Opening ID waste: {((opening_stats[1] - opening_stats[2]) / opening_stats[1] * 100):.1f}%')\n",
    "        \n",
    "        print(\"\\n=== COMPACTING DATABASE WITH SEQUENTIAL IDS ===\")\n",
    "        con.execute(\"CREATE TYPE IF NOT EXISTS color_enum AS ENUM ('w', 'b');\")\n",
    "\n",
    "        # Create new player table with compact sequential IDs\n",
    "        print(\"Creating compacted player table...\")\n",
    "        con.execute(\"\"\"\n",
    "            CREATE TABLE player_new AS\n",
    "            SELECT \n",
    "                ROW_NUMBER() OVER (ORDER BY name) as id,\n",
    "                name,\n",
    "                title\n",
    "            FROM player;\n",
    "        \"\"\")\n",
    "        \n",
    "        # Create new opening table with compact sequential IDs  \n",
    "        print(\"Creating compacted opening table...\")\n",
    "        con.execute(\"\"\"\n",
    "            CREATE TABLE opening_new AS\n",
    "            SELECT \n",
    "                ROW_NUMBER() OVER (ORDER BY eco, name) as id,\n",
    "                eco,\n",
    "                name\n",
    "            FROM opening;\n",
    "        \"\"\")\n",
    "        \n",
    "        # Create mapping tables to translate old IDs to new IDs\n",
    "        print(\"Creating ID mapping tables...\")\n",
    "        con.execute(\"\"\"\n",
    "            CREATE TEMP TABLE player_id_mapping AS\n",
    "            SELECT p_old.id as old_id, p_new.id as new_id, p_old.name\n",
    "            FROM player p_old\n",
    "            JOIN player_new p_new ON p_old.name = p_new.name;\n",
    "        \"\"\")\n",
    "        \n",
    "        con.execute(\"\"\"\n",
    "            CREATE TEMP TABLE opening_id_mapping AS\n",
    "            SELECT o_old.id as old_id, o_new.id as new_id, o_old.eco, o_old.name\n",
    "            FROM opening o_old\n",
    "            JOIN opening_new o_new ON o_old.eco = o_new.eco AND o_old.name = o_new.name;\n",
    "        \"\"\")\n",
    "        \n",
    "        # Verify the new ID ranges\n",
    "        new_player_stats = con.execute('SELECT MIN(id), MAX(id), COUNT(*) FROM player_new').fetchone()\n",
    "        new_opening_stats = con.execute('SELECT MIN(id), MAX(id), COUNT(*) FROM opening_new').fetchone()\n",
    "        \n",
    "        print(f'\\nNew player IDs: {new_player_stats[0]:,} to {new_player_stats[1]:,} ({new_player_stats[2]:,} records)')\n",
    "        print(f'New opening IDs: {new_opening_stats[0]:,} to {new_opening_stats[1]:,} ({new_opening_stats[2]:,} records)')\n",
    "        \n",
    "        # Check if we can use SMALLINT (max 32,767) - player_id needs INTEGER, opening_id can be SMALLINT\n",
    "        can_use_smallint_opening = new_opening_stats[1] <= 32767\n",
    "        can_use_smallint_player = new_player_stats[1] <= 32767\n",
    "        \n",
    "        player_id_type = \"SMALLINT\" if can_use_smallint_player else \"INTEGER\"\n",
    "        opening_id_type = \"SMALLINT\" if can_use_smallint_opening else \"INTEGER\"\n",
    "        \n",
    "        print(f'\\nPlayer IDs can use SMALLINT: {can_use_smallint_player} -> Using {player_id_type}')\n",
    "        print(f'Opening IDs can use SMALLINT: {can_use_smallint_opening} -> Using {opening_id_type}')\n",
    "\n",
    "        # Create optimized stats tables with compacted IDs\n",
    "        print(\"\\nCreating optimized stats tables with compacted IDs...\")\n",
    "        for letter in partitions:\n",
    "            new_table = f\"player_opening_stats_{letter}_new\"\n",
    "            print(f\"Creating {new_table}...\")\n",
    "            \n",
    "            con.execute(f\"\"\"\n",
    "                CREATE TABLE {new_table} (\n",
    "                    player_id   {player_id_type} NOT NULL,\n",
    "                    opening_id  {opening_id_type} NOT NULL,\n",
    "                    color       color_enum NOT NULL,\n",
    "                    num_wins    INTEGER DEFAULT 0,\n",
    "                    num_draws   SMALLINT DEFAULT 0,\n",
    "                    num_losses  INTEGER DEFAULT 0,\n",
    "                    PRIMARY KEY (player_id, opening_id, color)\n",
    "                );\n",
    "            \"\"\")\n",
    "            \n",
    "            # Migrate data with new compacted IDs and optimized types\n",
    "            old_table = f\"player_opening_stats_{letter}\"\n",
    "            print(f\"Migrating {old_table} with compacted IDs...\")\n",
    "            \n",
    "            con.execute(f\"\"\"\n",
    "                INSERT INTO {new_table} (player_id, opening_id, color, num_wins, num_draws, num_losses)\n",
    "                SELECT \n",
    "                    CAST(pm.new_id AS {player_id_type}) as player_id,\n",
    "                    CAST(om.new_id AS {opening_id_type}) as opening_id,\n",
    "                    CASE \n",
    "                        WHEN s.color = 'w' THEN 'w'::color_enum\n",
    "                        ELSE 'b'::color_enum\n",
    "                    END as color,\n",
    "                    s.num_wins,\n",
    "                    CAST(s.num_draws AS SMALLINT) as num_draws,\n",
    "                    s.num_losses\n",
    "                FROM {old_table} s\n",
    "                JOIN player_id_mapping pm ON s.player_id = pm.old_id\n",
    "                JOIN opening_id_mapping om ON s.opening_id = om.old_id\n",
    "                WHERE s.num_wins > 0 OR s.num_draws > 0 OR s.num_losses > 0;\n",
    "            \"\"\")\n",
    "\n",
    "        # Now swap the tables\n",
    "        print(\"\\nSwapping old tables with optimized new tables...\")\n",
    "        \n",
    "        # Drop old tables\n",
    "        for letter in partitions:\n",
    "            con.execute(f\"DROP TABLE player_opening_stats_{letter};\")\n",
    "        con.execute(\"DROP TABLE player;\")\n",
    "        con.execute(\"DROP TABLE opening;\")\n",
    "        \n",
    "        # Rename new tables\n",
    "        for letter in partitions:\n",
    "            con.execute(f\"ALTER TABLE player_opening_stats_{letter}_new RENAME TO player_opening_stats_{letter};\")\n",
    "        con.execute(\"ALTER TABLE player_new RENAME TO player;\")\n",
    "        con.execute(\"ALTER TABLE opening_new RENAME TO opening;\")\n",
    "        \n",
    "        # Reset sequences to reasonable values\n",
    "        print(\"\\nResetting sequences to proper values...\")\n",
    "        con.execute(f\"DROP SEQUENCE IF EXISTS player_id_seq;\")\n",
    "        con.execute(f\"DROP SEQUENCE IF EXISTS opening_id_seq;\")\n",
    "        con.execute(f\"CREATE SEQUENCE player_id_seq START {new_player_stats[1] + 1};\")\n",
    "        con.execute(f\"CREATE SEQUENCE opening_id_seq START {new_opening_stats[1] + 1};\")\n",
    "        \n",
    "        # Recreate the view\n",
    "        union_selects = \"\\nUNION ALL\\n\".join([\n",
    "            f\"SELECT * FROM player_opening_stats_{letter}\"\n",
    "            for letter in partitions\n",
    "        ])\n",
    "        con.execute(f\"\"\"\n",
    "            CREATE OR REPLACE VIEW player_opening_stats AS\n",
    "            {union_selects};\n",
    "        \"\"\")\n",
    "        \n",
    "        print(\"\\n=== COMPACTION COMPLETE ===\")\n",
    "        final_player_stats = con.execute('SELECT MIN(id), MAX(id), COUNT(*) FROM player').fetchone()\n",
    "        final_opening_stats = con.execute('SELECT MIN(id), MAX(id), COUNT(*) FROM opening').fetchone()\n",
    "        \n",
    "        print(f'Final player IDs: {final_player_stats[0]:,} to {final_player_stats[1]:,}')\n",
    "        print(f'Final opening IDs: {final_opening_stats[0]:,} to {final_opening_stats[1]:,}')\n",
    "        print(f'Space savings: Player IDs now use {player_id_type}, Opening IDs use {opening_id_type}')\n",
    "        print(f'Color values now use 1-byte ENUM instead of VARCHAR')\n",
    "        print(f'num_draws now uses SMALLINT instead of INTEGER')\n",
    "        print(\"Removed all zero-value records\")\n",
    "        \n",
    "        # Count final records\n",
    "        total_final_records = 0\n",
    "        for letter in partitions:\n",
    "            count = con.execute(f'SELECT COUNT(*) FROM player_opening_stats_{letter}').fetchone()[0]\n",
    "            total_final_records += count\n",
    "        print(f'\\nTotal optimized records: {total_final_records:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02881c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New database file size: 1722.51 MB\n",
      "Vacuuming database to optimize storage...\n",
      "Vacuum complete.\n",
      "Post-vacuum database file size: 1722.51 MB\n"
     ]
    }
   ],
   "source": [
    "# Print new database size and vacuum\n",
    "try:\n",
    "    db_size_bytes = os.path.getsize(db_path)\n",
    "    db_size_mb = db_size_bytes / (1024 * 1024)\n",
    "    print(f\"New database file size: {db_size_mb:.2f} MB\")\n",
    " \n",
    "    with get_db_connection(db_path) as con:\n",
    "        print(\"Vacuuming database to optimize storage...\")\n",
    "        con.execute(\"VACUUM;\")\n",
    "        print(\"Vacuum complete.\")\n",
    " \n",
    "        db_size_bytes = os.path.getsize(db_path)\n",
    "        db_size_mb = db_size_bytes / (1024 * 1024)\n",
    "        print(f\"Post-vacuum database file size: {db_size_mb:.2f} MB\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Database file not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ff22530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forcing database file rewrite to reclaim space...\n",
      "Checkpoint complete.\n",
      "Final database file size: 1722.51 MB\n"
     ]
    }
   ],
   "source": [
    "# Force DuckDB to rewrite the file to reclaim space\n",
    "with get_db_connection(db_path) as con:\n",
    "    print(\"Forcing database file rewrite to reclaim space...\")\n",
    "    con.execute(\"CHECKPOINT;\")\n",
    "    con.execute(\"PRAGMA force_checkpoint;\")\n",
    "    print(\"Checkpoint complete.\")\n",
    "\n",
    "# Final size check\n",
    "try:\n",
    "    db_size_bytes = os.path.getsize(db_path)\n",
    "    db_size_mb = db_size_bytes / (1024 * 1024)\n",
    "    print(f\"Final database file size: {db_size_mb:.2f} MB\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Database file not found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
