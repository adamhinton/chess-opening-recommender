{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8993ee05",
   "metadata": {},
   "source": [
    "# Notebook 30: Create Opening Stats JSON/CSV\n",
    "\n",
    "## Purpose\n",
    "Create opening-specific statistics files (JSON and CSV) for use in inference pipeline.\n",
    "These files contain the opening means needed for hierarchical Bayesian shrinkage.\n",
    "\n",
    "## What This Creates\n",
    "- `opening_stats_white.json`: Opening means for White openings (keyed by training_id)\n",
    "- `opening_stats_black.json`: Opening means for Black openings (keyed by training_id)\n",
    "- Also creates CSV versions for easy inspection\n",
    "\n",
    "## Data Source\n",
    "- Uses EXISTING openings in the database\n",
    "- Calculates mean scores from all player-opening interactions\n",
    "- Matches the calculation done in training notebook 28\n",
    "\n",
    "## Output Location\n",
    "`data/models/<model_dir>/opening_stats_<color>.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f3e8e4",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f00f3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n",
      "Project root: /Users/a/Documents/personalprojects/chess-opening-recommender\n",
      "DB path: /Users/a/Documents/personalprojects/chess-opening-recommender/data/processed/file_registry.json\n",
      "Models dir: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "DB_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"file_registry.json\"\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "MODELS_DIR = DATA_DIR / \"models\"\n",
    "\n",
    "print(\"Setup complete\")\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"DB path: {DB_PATH}\")\n",
    "print(f\"Models dir: {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09ca6dc",
   "metadata": {},
   "source": [
    "## Step 2: Load Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6650047b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection established\n",
      "Database: chess_games\n"
     ]
    }
   ],
   "source": [
    "def get_db_connection(db_dir: str) -> duckdb.DuckDBPyConnection:\n",
    "    \"\"\"Get a DuckDB connection to chess_games.db in the processed directory.\"\"\"\n",
    "    db_full_path = Path(db_dir).parent / \"chess_games.db\"\n",
    "    \n",
    "    if not db_full_path.exists():\n",
    "        raise FileNotFoundError(f\"Database not found: {db_full_path}\")\n",
    "    \n",
    "    return duckdb.connect(str(db_full_path), read_only=True)\n",
    "\n",
    "conn = get_db_connection(str(DB_PATH))\n",
    "print(\"Database connection established\")\n",
    "print(f\"Database: {conn.execute('SELECT current_database()').fetchone()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc106482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5145526",
   "metadata": {},
   "source": [
    "## Step 3: Define Processing Function\n",
    "\n",
    "This matches the calculation from training notebook 28's hierarchical Bayesian shrinkage section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edc53885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_opening_stats(color: str, min_games_threshold: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate opening-specific statistics from the database.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    color : str\n",
    "        'white' or 'black' (will be converted to 'w' or 'b' for database query)\n",
    "    min_games_threshold : int\n",
    "        Minimum games per player-opening to include (default: 10)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame with columns:\n",
    "        - opening_id (db id)\n",
    "        - opening_mean (mean score for this opening)\n",
    "        - opening_total_games (total games across all players)\n",
    "        - opening_num_players (number of players who played this opening)\n",
    "        - eco (ECO code for reference)\n",
    "        - name (opening name for reference)\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"CALCULATING OPENING STATS FOR {color.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    color_db = 'w' if color.lower() == 'white' else 'b'\n",
    "    \n",
    "    query = f\"\"\"\n",
    "        SELECT \n",
    "            pos.opening_id,\n",
    "            pos.player_id,\n",
    "            (pos.num_wins + pos.num_draws + pos.num_losses) as num_games,\n",
    "            pos.num_wins,\n",
    "            pos.num_draws,\n",
    "            pos.num_losses,\n",
    "            o.eco,\n",
    "            o.name\n",
    "        FROM player_opening_stats pos\n",
    "        JOIN opening o ON pos.opening_id = o.id\n",
    "        WHERE pos.color = '{color_db}'\n",
    "          AND (pos.num_wins + pos.num_draws + pos.num_losses) >= {min_games_threshold}\n",
    "          AND o.eco IS NOT NULL\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n1. Loading data from database...\")\n",
    "    data = pd.DataFrame(conn.execute(query).df())\n",
    "    print(f\"   Loaded {len(data):,} player-opening entries\")\n",
    "    print(f\"   Unique openings: {data['opening_id'].nunique():,}\")\n",
    "    print(f\"   Unique players: {data['player_id'].nunique():,}\")\n",
    "    \n",
    "    print(f\"\\n2. Calculating raw scores...\")\n",
    "    data['score'] = (data['num_wins'] + 0.5 * data['num_draws']) / data['num_games']\n",
    "    print(f\"   Score range: [{data['score'].min():.4f}, {data['score'].max():.4f}]\")\n",
    "    print(f\"   Global mean score: {data['score'].mean():.4f}\")\n",
    "    \n",
    "    print(f\"\\n3. Aggregating by opening...\")\n",
    "    opening_stats = (\n",
    "        data.groupby('opening_id')\n",
    "        .agg({\n",
    "            'score': 'mean',\n",
    "            'num_games': 'sum',\n",
    "            'player_id': 'count',\n",
    "            'eco': 'first',\n",
    "            'name': 'first'\n",
    "        })\n",
    "        .rename(columns={\n",
    "            'score': 'opening_mean',\n",
    "            'num_games': 'opening_total_games',\n",
    "            'player_id': 'opening_num_players'\n",
    "        })\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    print(f\"   Calculated stats for {len(opening_stats):,} openings\")\n",
    "    print(f\"\\n4. Opening mean distribution:\")\n",
    "    print(f\"   Min: {opening_stats['opening_mean'].min():.4f}\")\n",
    "    print(f\"   25th percentile: {opening_stats['opening_mean'].quantile(0.25):.4f}\")\n",
    "    print(f\"   Median: {opening_stats['opening_mean'].median():.4f}\")\n",
    "    print(f\"   75th percentile: {opening_stats['opening_mean'].quantile(0.75):.4f}\")\n",
    "    print(f\"   Max: {opening_stats['opening_mean'].max():.4f}\")\n",
    "    print(f\"   Std: {opening_stats['opening_mean'].std():.4f}\")\n",
    "    \n",
    "    print(f\"\\n5. Opening size distribution:\")\n",
    "    print(f\"   Total games (median): {opening_stats['opening_total_games'].median():.0f}\")\n",
    "    print(f\"   Players (median): {opening_stats['opening_num_players'].median():.0f}\")\n",
    "    print(f\"   Total games range: [{opening_stats['opening_total_games'].min():.0f}, {opening_stats['opening_total_games'].max():.0f}]\")\n",
    "    print(f\"   Players range: [{opening_stats['opening_num_players'].min():.0f}, {opening_stats['opening_num_players'].max():.0f}]\")\n",
    "    \n",
    "    return opening_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a07ae6",
   "metadata": {},
   "source": [
    "## Step 4: Calculate Opening Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80ffbeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CALCULATING OPENING STATS FOR BLACK\n",
      "============================================================\n",
      "\n",
      "1. Loading data from database...\n",
      "   Loaded 3,215,430 player-opening entries\n",
      "   Unique openings: 2,731\n",
      "   Unique players: 49,906\n",
      "\n",
      "2. Calculating raw scores...\n",
      "   Score range: [0.0000, 1.0000]\n",
      "   Global mean score: 0.4733\n",
      "\n",
      "3. Aggregating by opening...\n",
      "   Loaded 3,215,430 player-opening entries\n",
      "   Unique openings: 2,731\n",
      "   Unique players: 49,906\n",
      "\n",
      "2. Calculating raw scores...\n",
      "   Score range: [0.0000, 1.0000]\n",
      "   Global mean score: 0.4733\n",
      "\n",
      "3. Aggregating by opening...\n",
      "   Calculated stats for 2,731 openings\n",
      "\n",
      "4. Opening mean distribution:\n",
      "   Min: 0.0769\n",
      "   25th percentile: 0.4571\n",
      "   Median: 0.4769\n",
      "   75th percentile: 0.4989\n",
      "   Max: 0.7727\n",
      "   Std: 0.0516\n",
      "\n",
      "5. Opening size distribution:\n",
      "   Total games (median): 4208\n",
      "   Players (median): 146\n",
      "   Total games range: [10, 7107061]\n",
      "   Players range: [1, 39943]\n",
      "   Calculated stats for 2,731 openings\n",
      "\n",
      "4. Opening mean distribution:\n",
      "   Min: 0.0769\n",
      "   25th percentile: 0.4571\n",
      "   Median: 0.4769\n",
      "   75th percentile: 0.4989\n",
      "   Max: 0.7727\n",
      "   Std: 0.0516\n",
      "\n",
      "5. Opening size distribution:\n",
      "   Total games (median): 4208\n",
      "   Players (median): 146\n",
      "   Total games range: [10, 7107061]\n",
      "   Players range: [1, 39943]\n"
     ]
    }
   ],
   "source": [
    "# Set color here: 'white' or 'black'\n",
    "COLOR = 'black'\n",
    "\n",
    "opening_stats = calculate_opening_stats(COLOR, min_games_threshold=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce580c1d",
   "metadata": {},
   "source": [
    "## Step 5: Inspect Opening Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7c25e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "OPENING STATS SAMPLE FOR BLACK\n",
      "============================================================\n",
      "\n",
      "First 10 openings:\n",
      "   opening_id  opening_mean  opening_total_games  opening_num_players  eco  \\\n",
      "0           2      0.443428                  539                   39  A00   \n",
      "1           3      0.500000                   14                    1  A00   \n",
      "2           5      0.481769                25773                 1998  A00   \n",
      "3           8      0.446429                   26                    2  A00   \n",
      "4           9      0.500195                  338                   26  A00   \n",
      "5          10      0.489484                11839                  875  A00   \n",
      "6          12      0.461364                   21                    2  A00   \n",
      "7          13      0.555856                  220                   19  A00   \n",
      "8          17      0.498766                 1987                  159  A00   \n",
      "9          18      0.529715                  156                   14  A00   \n",
      "\n",
      "                                         name  \n",
      "0                                Amar Opening  \n",
      "1                  Amar Opening: Paris Gambit  \n",
      "2                         Anderssen's Opening  \n",
      "3               Barnes Opening: Gedult Gambit  \n",
      "4                Barnes Opening: Hammerschlag  \n",
      "5                             Clemenz Opening  \n",
      "6                                Crab Opening  \n",
      "7  Creepy Crawly Formation: Classical Defense  \n",
      "8                            Gedult's Opening  \n",
      "9                              Global Opening  \n",
      "\n",
      "\n",
      "Top 10 STRONGEST openings (highest win rate):\n",
      "   C49 | Four Knights Game: Spanish Variation, Janowski Variation | Mean: 0.7727 | Players:     1 | Games:      11\n",
      "   C51 | Italian Game: Evans Gambit Declined, Lange Variation | Mean: 0.7626 | Players:     3 | Games:      37\n",
      "   C71 | Ruy Lopez: Noah's Ark Trap                         | Mean: 0.7617 | Players:   163 | Games:    4479\n",
      "   E20 | Nimzo-Indian Defense: Romanishin Variation, English Hybrid | Mean: 0.7500 | Players:     1 | Games:      12\n",
      "   C37 | King's Gambit Accepted: Silberschmidt Gambit       | Mean: 0.7456 | Players:     7 | Games:     166\n",
      "   C51 | Italian Game: Evans Gambit Declined, Cordel Variation | Mean: 0.7286 | Players:     2 | Games:      24\n",
      "   C50 | Italian Game: Giuoco Pianissimo, Dubois Variation  | Mean: 0.7185 | Players:   213 | Games:    7738\n",
      "   C39 | King's Gambit Accepted: Allgaier, Horny Defense    | Mean: 0.7090 | Players:    18 | Games:     394\n",
      "   A16 | English Opening: Anglo-GrÃ¼nfeld Defense, Korchnoi Variation | Mean: 0.7083 | Players:     1 | Games:      12\n",
      "   C57 | Italian Game: Two Knights Defense, Fegatello Attack, Leonhardt Variation | Mean: 0.7059 | Players:     1 | Games:      17\n",
      "\n",
      "\n",
      "Top 10 WEAKEST openings (lowest win rate):\n",
      "   C37 | King's Gambit Accepted: McDonnell Gambit           | Mean: 0.0769 | Players:     1 | Games:      13\n",
      "   B02 | Alekhine Defense: Hunt Variation, Matsukevich Gambit | Mean: 0.0909 | Players:     1 | Games:      11\n",
      "   C39 | King's Gambit Accepted: Allgaier Gambit, Thorold Attack | Mean: 0.1818 | Players:     1 | Games:      11\n",
      "   B06 | Modern Defense: Anti-Modern                        | Mean: 0.2000 | Players:     1 | Games:      10\n",
      "   C33 | Van Geet Opening: Nowokunski Gambit                | Mean: 0.2000 | Players:     1 | Games:      10\n",
      "   C37 | King's Gambit Accepted: Muzio Gambit, Brentano Defense | Mean: 0.2000 | Players:     1 | Games:      10\n",
      "   C58 | Italian Game: Two Knights Defense, Polerio Defense, Yankovich Variation | Mean: 0.2000 | Players:     1 | Games:      10\n",
      "   D32 | Tarrasch Defense: Marshall Gambit                  | Mean: 0.2041 | Players:     4 | Games:      49\n",
      "   C39 | King's Gambit Accepted: Allgaier, Urusov Attack    | Mean: 0.2273 | Players:     1 | Games:      11\n",
      "   C29 | Vienna Game: Vienna Gambit, Wurzburger Trap        | Mean: 0.2405 | Players:     6 | Games:      64\n",
      "\n",
      "\n",
      "Data types:\n",
      "opening_id               int32\n",
      "opening_mean           float64\n",
      "opening_total_games      int32\n",
      "opening_num_players      int64\n",
      "eco                     object\n",
      "name                    object\n",
      "dtype: object\n",
      "\n",
      "Memory usage:\n",
      "Index                     132\n",
      "opening_id              10924\n",
      "opening_mean            21848\n",
      "opening_total_games     10924\n",
      "opening_num_players     21848\n",
      "eco                    142012\n",
      "name                   264054\n",
      "dtype: int64\n",
      "\n",
      "Total memory: 460.69 KB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"OPENING STATS SAMPLE FOR {COLOR.upper()}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nFirst 10 openings:\")\n",
    "print(opening_stats.head(10))\n",
    "\n",
    "print(\"\\n\\nTop 10 STRONGEST openings (highest win rate):\")\n",
    "strongest = opening_stats.nlargest(10, 'opening_mean')\n",
    "for idx, row in strongest.iterrows():\n",
    "    print(f\"   {row['eco']:>3} | {row['name']:<50} | Mean: {row['opening_mean']:.4f} | Players: {row['opening_num_players']:>5} | Games: {row['opening_total_games']:>7}\")\n",
    "\n",
    "print(\"\\n\\nTop 10 WEAKEST openings (lowest win rate):\")\n",
    "weakest = opening_stats.nsmallest(10, 'opening_mean')\n",
    "for idx, row in weakest.iterrows():\n",
    "    print(f\"   {row['eco']:>3} | {row['name']:<50} | Mean: {row['opening_mean']:.4f} | Players: {row['opening_num_players']:>5} | Games: {row['opening_total_games']:>7}\")\n",
    "\n",
    "print(\"\\n\\nData types:\")\n",
    "print(opening_stats.dtypes)\n",
    "\n",
    "print(\"\\nMemory usage:\")\n",
    "print(opening_stats.memory_usage(deep=True))\n",
    "print(f\"\\nTotal memory: {opening_stats.memory_usage(deep=True).sum() / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8e6243",
   "metadata": {},
   "source": [
    "## Step 6: Load Training Mappings\n",
    "\n",
    "We need to convert database IDs to training IDs before saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c053aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available model directories:\n",
      "   20251212_152017_black\n",
      "   20251111_155428_white\n",
      "\n",
      "Using model directory: 20251212_152017_black\n",
      "Full path: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/20251212_152017_black\n",
      "Model directory exists\n"
     ]
    }
   ],
   "source": [
    "print(\"Available model directories:\")\n",
    "for model_dir in MODELS_DIR.iterdir():\n",
    "    if model_dir.is_dir() and not model_dir.name.startswith('.'):\n",
    "        print(f\"   {model_dir.name}\")\n",
    "\n",
    "# UPDATE THIS TO YOUR MODEL DIRECTORY\n",
    "MODEL_DIR_NAME = \"20251212_152017_black\"\n",
    "MODEL_ARTIFACTS_DIR = MODELS_DIR / MODEL_DIR_NAME\n",
    "\n",
    "print(f\"\\nUsing model directory: {MODEL_DIR_NAME}\")\n",
    "print(f\"Full path: {MODEL_ARTIFACTS_DIR}\")\n",
    "\n",
    "if not MODEL_ARTIFACTS_DIR.exists():\n",
    "    print(f\"\\nWARNING: Model directory does not exist!\")\n",
    "    print(f\"Please create it or update MODEL_DIR_NAME\")\n",
    "else:\n",
    "    print(f\"Model directory exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcd05706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded opening mappings\n",
      "   Shape: (2728, 4)\n",
      "   Columns: ['db_id', 'eco', 'name', 'training_id']\n",
      "\n",
      "First few mappings:\n",
      "   db_id  eco                                        name  training_id\n",
      "0      2  A00                                Amar Opening            0\n",
      "1      3  A00                  Amar Opening: Paris Gambit            1\n",
      "2      5  A00                         Anderssen's Opening            2\n",
      "3      8  A00               Barnes Opening: Gedult Gambit            3\n",
      "4      9  A00                Barnes Opening: Hammerschlag            4\n",
      "5     10  A00                             Clemenz Opening            5\n",
      "6     12  A00                                Crab Opening            6\n",
      "7     13  A00  Creepy Crawly Formation: Classical Defense            7\n",
      "8     17  A00                            Gedult's Opening            8\n",
      "9     18  A00                              Global Opening            9\n"
     ]
    }
   ],
   "source": [
    "mappings_path = MODEL_ARTIFACTS_DIR / \"opening_mappings.csv\"\n",
    "\n",
    "if not mappings_path.exists():\n",
    "    print(f\"WARNING: opening_mappings.csv not found at {mappings_path}\")\n",
    "    print(f\"You need to run the training pipeline first to create this file.\")\n",
    "    opening_mappings = None\n",
    "else:\n",
    "    opening_mappings = pd.read_csv(mappings_path)\n",
    "    print(\"Loaded opening mappings\")\n",
    "    print(f\"   Shape: {opening_mappings.shape}\")\n",
    "    print(f\"   Columns: {list(opening_mappings.columns)}\")\n",
    "    print(f\"\\nFirst few mappings:\")\n",
    "    print(opening_mappings.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b20c258",
   "metadata": {},
   "source": [
    "## Step 7: Merge Stats with Training IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "613bc6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged opening stats with training IDs\n",
      "   Original openings: 2731\n",
      "   After merge: 2728\n",
      "   Dropped: 3 (not in training set)\n",
      "   No duplicate training_ids\n",
      "\n",
      "Sample of merged data:\n",
      "   opening_id  opening_mean  opening_total_games  opening_num_players  eco  \\\n",
      "0           2      0.443428                  539                   39  A00   \n",
      "1           3      0.500000                   14                    1  A00   \n",
      "2           5      0.481769                25773                 1998  A00   \n",
      "3           8      0.446429                   26                    2  A00   \n",
      "4           9      0.500195                  338                   26  A00   \n",
      "5          10      0.489484                11839                  875  A00   \n",
      "6          12      0.461364                   21                    2  A00   \n",
      "7          13      0.555856                  220                   19  A00   \n",
      "8          17      0.498766                 1987                  159  A00   \n",
      "9          18      0.529715                  156                   14  A00   \n",
      "\n",
      "                                         name  db_id  training_id  \n",
      "0                                Amar Opening      2            0  \n",
      "1                  Amar Opening: Paris Gambit      3            1  \n",
      "2                         Anderssen's Opening      5            2  \n",
      "3               Barnes Opening: Gedult Gambit      8            3  \n",
      "4                Barnes Opening: Hammerschlag      9            4  \n",
      "5                             Clemenz Opening     10            5  \n",
      "6                                Crab Opening     12            6  \n",
      "7  Creepy Crawly Formation: Classical Defense     13            7  \n",
      "8                            Gedult's Opening     17            8  \n",
      "9                              Global Opening     18            9  \n"
     ]
    }
   ],
   "source": [
    "if opening_mappings is not None:\n",
    "    stats_with_training_ids = opening_stats.merge(\n",
    "        opening_mappings[['db_id', 'training_id']], \n",
    "        left_on='opening_id', \n",
    "        right_on='db_id',\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    print(\"Merged opening stats with training IDs\")\n",
    "    print(f\"   Original openings: {len(opening_stats)}\")\n",
    "    print(f\"   After merge: {len(stats_with_training_ids)}\")\n",
    "    print(f\"   Dropped: {len(opening_stats) - len(stats_with_training_ids)} (not in training set)\")\n",
    "    \n",
    "    if stats_with_training_ids['training_id'].duplicated().any():\n",
    "        print(f\"\\nWARNING: Found duplicate training_ids!\")\n",
    "        dups = stats_with_training_ids[stats_with_training_ids['training_id'].duplicated(keep=False)]\n",
    "        print(dups)\n",
    "    else:\n",
    "        print(\"   No duplicate training_ids\")\n",
    "    \n",
    "    print(\"\\nSample of merged data:\")\n",
    "    print(stats_with_training_ids.head(10))\n",
    "else:\n",
    "    print(\"Skipping merge - no opening mappings available\")\n",
    "    stats_with_training_ids = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e918dfdd",
   "metadata": {},
   "source": [
    "## Step 8: Create Compact JSON Output (Keyed by Training ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ea986c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created COMPACT opening stats dictionary\n",
      "   Total openings: 2728\n",
      "   Training ID range: [0, 2727]\n",
      "   Format: training_id: [mean, total_games, db_id]\n",
      "\n",
      "Sample entries:\n",
      "   0: [0.44342817022621733, 539, 2]\n",
      "   1: [0.5, 14, 3]\n",
      "   2: [0.48176868177504945, 25773, 5]\n",
      "   3: [0.4464285714285714, 26, 8]\n",
      "   4: [0.5001945111597902, 338, 9]\n",
      "\n",
      "Compact JSON size: 112,905 bytes (110.26 KB)\n"
     ]
    }
   ],
   "source": [
    "if stats_with_training_ids is not None:\n",
    "    # COMPACT VERSION: [opening_mean, total_games, db_id]\n",
    "    opening_stats_dict = {}\n",
    "    \n",
    "    for idx, row in stats_with_training_ids.iterrows():\n",
    "        opening_stats_dict[int(row['training_id'])] = [\n",
    "            float(row['opening_mean']),          # Index 0: mean score for Bayesian shrinkage\n",
    "            int(row['opening_total_games']),     # Index 1: total games\n",
    "            int(row['db_id'])                    # Index 2: db_id for reference\n",
    "        ]\n",
    "    \n",
    "    print(\"Created COMPACT opening stats dictionary\")\n",
    "    print(f\"   Total openings: {len(opening_stats_dict)}\")\n",
    "    print(f\"   Training ID range: [{min(opening_stats_dict.keys())}, {max(opening_stats_dict.keys())}]\")\n",
    "    print(f\"   Format: training_id: [mean, total_games, db_id]\")\n",
    "    \n",
    "    print(\"\\nSample entries:\")\n",
    "    for training_id in sorted(opening_stats_dict.keys())[:5]:\n",
    "        stats = opening_stats_dict[training_id]\n",
    "        print(f\"   {training_id}: {stats}\")\n",
    "    \n",
    "    # Size check\n",
    "    json_str_compact = json.dumps(opening_stats_dict)\n",
    "    json_size_compact = len(json_str_compact.encode('utf-8'))\n",
    "    print(f\"\\nCompact JSON size: {json_size_compact:,} bytes ({json_size_compact / 1024:.2f} KB)\")\n",
    "else:\n",
    "    print(\"Skipping JSON creation - no merged data available\")\n",
    "    opening_stats_dict = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eebf7e6",
   "metadata": {},
   "source": [
    "## Step 9: Validate JSON Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6384da7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating compact JSON structure...\n",
      "\n",
      "All keys are integers: True\n",
      "All values are 3-element arrays: True\n",
      "\n",
      "Sample value structure: [0.44342817022621733, 539, 2]\n",
      "   [0] Opening mean: float\n",
      "   [1] Total games: int\n",
      "   [2] DB ID: int\n",
      "\n",
      "Opening mean range: [0.0769, 0.7727]\n",
      "All means in [0, 1]: True\n",
      "\n",
      "JSON structure validation complete\n"
     ]
    }
   ],
   "source": [
    "if opening_stats_dict is not None:\n",
    "    print(\"Validating compact JSON structure...\\n\")\n",
    "    \n",
    "    all_int_keys = all(isinstance(k, int) for k in opening_stats_dict.keys())\n",
    "    print(f\"All keys are integers: {all_int_keys}\")\n",
    "    \n",
    "    all_arrays = all(isinstance(v, list) and len(v) == 3 for v in opening_stats_dict.values())\n",
    "    print(f\"All values are 3-element arrays: {all_arrays}\")\n",
    "    \n",
    "    sample_value = list(opening_stats_dict.values())[0]\n",
    "    print(f\"\\nSample value structure: {sample_value}\")\n",
    "    print(f\"   [0] Opening mean: {type(sample_value[0]).__name__}\")\n",
    "    print(f\"   [1] Total games: {type(sample_value[1]).__name__}\")\n",
    "    print(f\"   [2] DB ID: {type(sample_value[2]).__name__}\")\n",
    "    \n",
    "    means = [v[0] for v in opening_stats_dict.values()]\n",
    "    print(f\"\\nOpening mean range: [{min(means):.4f}, {max(means):.4f}]\")\n",
    "    all_in_range = all(0 <= m <= 1 for m in means)\n",
    "    print(f\"All means in [0, 1]: {all_in_range}\")\n",
    "    \n",
    "    print(\"\\nJSON structure validation complete\")\n",
    "else:\n",
    "    print(\"Skipping validation - no data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeb59b0",
   "metadata": {},
   "source": [
    "## Step 10: Spot Check Data Integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c267f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SPOT CHECK: Verifying Opening Stats Integrity\n",
      "================================================================================\n",
      "\n",
      "Spot checking 200 random entries...\n",
      "   Checked 50/200 entries...\n",
      "   Checked 100/200 entries...\n",
      "   Checked 150/200 entries...\n",
      "   Checked 200/200 entries...\n",
      "\n",
      "Spot check complete!\n",
      "   Total entries checked: 200\n",
      "   Mismatches found: 0\n",
      "\n",
      "All 200 entries verified successfully!\n",
      "   JSON data matches source DataFrame exactly\n"
     ]
    }
   ],
   "source": [
    "if opening_stats_dict is not None and stats_with_training_ids is not None:\n",
    "    print(\"=\"*80)\n",
    "    print(\"SPOT CHECK: Verifying Opening Stats Integrity\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    import random\n",
    "    random.seed(42)\n",
    "    \n",
    "    all_training_ids = list(opening_stats_dict.keys())\n",
    "    sample_size = min(200, len(all_training_ids))\n",
    "    sample_training_ids = random.sample(all_training_ids, sample_size)\n",
    "    \n",
    "    print(f\"\\nSpot checking {sample_size} random entries...\")\n",
    "    \n",
    "    verification_df = stats_with_training_ids.set_index('training_id')\n",
    "    mismatches = []\n",
    "    \n",
    "    for i, training_id in enumerate(sample_training_ids, 1):\n",
    "        json_data = opening_stats_dict[training_id]\n",
    "        df_row = verification_df.loc[training_id]\n",
    "        \n",
    "        mean_match = abs(json_data[0] - float(df_row['opening_mean'])) < 1e-6\n",
    "        games_match = json_data[1] == int(df_row['opening_total_games'])\n",
    "        db_id_match = json_data[2] == int(df_row['db_id'])\n",
    "        \n",
    "        if not (mean_match and games_match and db_id_match):\n",
    "            mismatches.append({\n",
    "                'training_id': training_id,\n",
    "                'json_data': json_data,\n",
    "                'df_data': [float(df_row['opening_mean']), int(df_row['opening_total_games']), int(df_row['db_id'])],\n",
    "                'eco': df_row['eco'],\n",
    "                'name': df_row['name']\n",
    "            })\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print(f\"   Checked {i}/{sample_size} entries...\")\n",
    "    \n",
    "    print(f\"\\nSpot check complete!\")\n",
    "    print(f\"   Total entries checked: {sample_size}\")\n",
    "    print(f\"   Mismatches found: {len(mismatches)}\")\n",
    "    \n",
    "    if mismatches:\n",
    "        print(f\"\\nWARNING: Found {len(mismatches)} mismatches!\")\n",
    "        for mismatch in mismatches[:10]:\n",
    "            print(f\"\\n   Training ID {mismatch['training_id']}:\")\n",
    "            print(f\"      Opening: {mismatch['eco']} - {mismatch['name']}\")\n",
    "            print(f\"      JSON:  {mismatch['json_data']}\")\n",
    "            print(f\"      DF:    {mismatch['df_data']}\")\n",
    "    else:\n",
    "        print(f\"\\nAll {sample_size} entries verified successfully!\")\n",
    "        print(\"   JSON data matches source DataFrame exactly\")\n",
    "else:\n",
    "    print(\"Skipping spot check - no data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce6c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9590f25f",
   "metadata": {},
   "source": [
    "## Step 11: Save JSON and CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3efb80fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved compact JSON to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/20251212_152017_black/opening_stats_black.json\n",
      "   File size: 112,905 bytes (110.26 KB)\n",
      "\n",
      "Verified JSON can be loaded\n",
      "   Loaded 2728 openings\n",
      "   Matches original: True\n",
      "\n",
      "Saved CSV to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/20251212_152017_black/opening_stats_black.csv\n",
      "   File size: 257,957 bytes (251.91 KB)\n",
      "   Rows: 2728\n",
      "\n",
      "First 5 rows of CSV:\n",
      "   training_id  db_id  opening_id  eco                           name  \\\n",
      "0            0      2           2  A00                   Amar Opening   \n",
      "1            1      3           3  A00     Amar Opening: Paris Gambit   \n",
      "2            2      5           5  A00            Anderssen's Opening   \n",
      "3            3      8           8  A00  Barnes Opening: Gedult Gambit   \n",
      "4            4      9           9  A00   Barnes Opening: Hammerschlag   \n",
      "\n",
      "   opening_mean  opening_total_games  opening_num_players  \n",
      "0      0.443428                  539                   39  \n",
      "1      0.500000                   14                    1  \n",
      "2      0.481769                25773                 1998  \n",
      "3      0.446429                   26                    2  \n",
      "4      0.500195                  338                   26  \n"
     ]
    }
   ],
   "source": [
    "if opening_stats_dict is not None and stats_with_training_ids is not None:\n",
    "    # Save compact JSON\n",
    "    output_json_path = MODEL_ARTIFACTS_DIR / f\"opening_stats_{COLOR}.json\"\n",
    "    \n",
    "    with open(output_json_path, 'w') as f:\n",
    "        json.dump(opening_stats_dict, f)\n",
    "    \n",
    "    print(f\"Saved compact JSON to: {output_json_path}\")\n",
    "    print(f\"   File size: {output_json_path.stat().st_size:,} bytes ({output_json_path.stat().st_size / 1024:.2f} KB)\")\n",
    "    \n",
    "    # Verify JSON loads correctly\n",
    "    with open(output_json_path, 'r') as f:\n",
    "        loaded_dict = json.load(f)\n",
    "    \n",
    "    print(f\"\\nVerified JSON can be loaded\")\n",
    "    print(f\"   Loaded {len(loaded_dict)} openings\")\n",
    "    print(f\"   Matches original: {len(loaded_dict) == len(opening_stats_dict)}\")\n",
    "    \n",
    "    # Save CSV for human inspection\n",
    "    output_csv_path = MODEL_ARTIFACTS_DIR / f\"opening_stats_{COLOR}.csv\"\n",
    "    \n",
    "    csv_data = stats_with_training_ids[[\n",
    "        'training_id', 'db_id', 'opening_id', 'eco', 'name', \n",
    "        'opening_mean', 'opening_total_games', 'opening_num_players'\n",
    "    ]].sort_values('training_id')\n",
    "    \n",
    "    csv_data.to_csv(output_csv_path, index=False)\n",
    "    \n",
    "    print(f\"\\nSaved CSV to: {output_csv_path}\")\n",
    "    print(f\"   File size: {output_csv_path.stat().st_size:,} bytes ({output_csv_path.stat().st_size / 1024:.2f} KB)\")\n",
    "    print(f\"   Rows: {len(csv_data)}\")\n",
    "    \n",
    "    print(\"\\nFirst 5 rows of CSV:\")\n",
    "    print(csv_data.head(5))\n",
    "else:\n",
    "    print(\"Skipping save - no data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88717d4f",
   "metadata": {},
   "source": [
    "## Step 12: Test Bayesian Shrinkage Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39548d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing production usage: Bayesian shrinkage calculation\n",
      "\n",
      "Using k=50 for Bayesian shrinkage\n",
      "\n",
      "1. Training ID 0:\n",
      "   Opening mean from DB: 0.4434 (from 539 total games)\n",
      "   Player: 15 games, raw score: 0.6000\n",
      "   Adjusted score: 0.4796\n",
      "   Confidence: 0.2308\n",
      "   Adjustment: -0.1204\n",
      "\n",
      "2. Training ID 1:\n",
      "   Opening mean from DB: 0.5000 (from 14 total games)\n",
      "   Player: 15 games, raw score: 0.6000\n",
      "   Adjusted score: 0.5231\n",
      "   Confidence: 0.2308\n",
      "   Adjustment: -0.0769\n",
      "\n",
      "3. Training ID 2:\n",
      "   Opening mean from DB: 0.4818 (from 25,773 total games)\n",
      "   Player: 15 games, raw score: 0.6000\n",
      "   Adjusted score: 0.5091\n",
      "   Confidence: 0.2308\n",
      "   Adjustment: -0.0909\n",
      "\n",
      "4. Training ID 3:\n",
      "   Opening mean from DB: 0.4464 (from 26 total games)\n",
      "   Player: 15 games, raw score: 0.6000\n",
      "   Adjusted score: 0.4819\n",
      "   Confidence: 0.2308\n",
      "   Adjustment: -0.1181\n",
      "\n",
      "5. Training ID 4:\n",
      "   Opening mean from DB: 0.5002 (from 338 total games)\n",
      "   Player: 15 games, raw score: 0.6000\n",
      "   Adjusted score: 0.5232\n",
      "   Confidence: 0.2308\n",
      "   Adjustment: -0.0768\n",
      "\n",
      "Bayesian shrinkage test complete\n"
     ]
    }
   ],
   "source": [
    "if opening_stats_dict is not None:\n",
    "    print(\"Testing production usage: Bayesian shrinkage calculation\\n\")\n",
    "    \n",
    "    test_training_ids = list(opening_stats_dict.keys())[:5]\n",
    "    k = 50  # Shrinkage constant\n",
    "    \n",
    "    print(f\"Using k={k} for Bayesian shrinkage\\n\")\n",
    "    \n",
    "    for i, training_id in enumerate(test_training_ids, 1):\n",
    "        opening_mean = opening_stats_dict[training_id][0]  # Index 0: mean\n",
    "        total_games_db = opening_stats_dict[training_id][1]  # Index 1: total games\n",
    "        \n",
    "        # Simulate player with 15 games\n",
    "        player_games = 15\n",
    "        player_raw_score = 0.6\n",
    "        \n",
    "        adjusted_score = ((player_games * player_raw_score) + (k * opening_mean)) / (player_games + k)\n",
    "        confidence = player_games / (player_games + k)\n",
    "        \n",
    "        print(f\"{i}. Training ID {training_id}:\")\n",
    "        print(f\"   Opening mean from DB: {opening_mean:.4f} (from {total_games_db:,} total games)\")\n",
    "        print(f\"   Player: {player_games} games, raw score: {player_raw_score:.4f}\")\n",
    "        print(f\"   Adjusted score: {adjusted_score:.4f}\")\n",
    "        print(f\"   Confidence: {confidence:.4f}\")\n",
    "        print(f\"   Adjustment: {adjusted_score - player_raw_score:+.4f}\\n\")\n",
    "    \n",
    "    print(\"Bayesian shrinkage test complete\")\n",
    "else:\n",
    "    print(\"Skipping usage test - no data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbabb44c",
   "metadata": {},
   "source": [
    "## Step 13: Test Loading and Using the JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf591611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "\n",
      "Successfully created opening stats for BLACK\n",
      "\n",
      "JSON (compact format for production):\n",
      "   Location: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/20251212_152017_black/opening_stats_black.json\n",
      "   Total openings: 2728\n",
      "   File size: 110.26 KB\n",
      "   Format: {training_id: [mean, total_games, db_id]}\n",
      "\n",
      "CSV (human-readable for inspection):\n",
      "   Location: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/20251212_152017_black/opening_stats_black.csv\n",
      "   File size: 251.91 KB\n",
      "\n",
      "Next steps:\n",
      "   1. Load opening_stats_black.json in inference pipeline at startup\n",
      "   2. Use opening_mean (index 0) for Bayesian shrinkage during inference\n",
      "   3. To process other color: update COLOR variable and MODEL_DIR_NAME, then re-run\n",
      "\n",
      "============================================================\n",
      "NOTEBOOK COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if opening_stats_dict is not None:\n",
    "    json_path = MODEL_ARTIFACTS_DIR / f'opening_stats_{COLOR}.json'\n",
    "    csv_path = MODEL_ARTIFACTS_DIR / f'opening_stats_{COLOR}.csv'\n",
    "    \n",
    "    print(f\"\\nSuccessfully created opening stats for {COLOR.upper()}\")\n",
    "    print(f\"\\nJSON (compact format for production):\")\n",
    "    print(f\"   Location: {json_path}\")\n",
    "    print(f\"   Total openings: {len(opening_stats_dict)}\")\n",
    "    print(f\"   File size: {json_path.stat().st_size / 1024:.2f} KB\")\n",
    "    print(f\"   Format: {{training_id: [mean, total_games, db_id]}}\")\n",
    "    \n",
    "    print(f\"\\nCSV (human-readable for inspection):\")\n",
    "    print(f\"   Location: {csv_path}\")\n",
    "    print(f\"   File size: {csv_path.stat().st_size / 1024:.2f} KB\")\n",
    "    \n",
    "    print(f\"\\nNext steps:\")\n",
    "    print(f\"   1. Load opening_stats_{COLOR}.json in inference pipeline at startup\")\n",
    "    print(f\"   2. Use opening_mean (index 0) for Bayesian shrinkage during inference\")\n",
    "    print(f\"   3. To process other color: update COLOR variable and MODEL_DIR_NAME, then re-run\")\n",
    "else:\n",
    "    print(f\"\\nNo files created\")\n",
    "    print(f\"   Ensure opening_mappings.csv exists in model directory\")\n",
    "    print(f\"   Verify MODEL_DIR_NAME points to correct model\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NOTEBOOK COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c61bf275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection closed\n"
     ]
    }
   ],
   "source": [
    "conn.close()\n",
    "print(\"Database connection closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
