{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8993ee05",
   "metadata": {},
   "source": [
    "# Notebook 30: Create Opening Stats JSON/CSV\n",
    "\n",
    "## Purpose\n",
    "Create opening-specific statistics files (JSON and CSV) for use in inference pipeline.\n",
    "These files contain the opening means needed for hierarchical Bayesian shrinkage.\n",
    "\n",
    "## What This Creates\n",
    "- `opening_stats_white.json`: Opening means for White openings (keyed by training_id)\n",
    "- `opening_stats_black.json`: Opening means for Black openings (keyed by training_id)\n",
    "- Also creates CSV versions for easy inspection\n",
    "\n",
    "## Data Source\n",
    "- Uses EXISTING openings in the database\n",
    "- Calculates mean scores from all player-opening interactions\n",
    "- Matches the calculation done in training notebook 28\n",
    "\n",
    "## Output Location\n",
    "`data/models/<model_dir>/opening_stats_<color>.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f3e8e4",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f00f3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n",
      "Project root: /Users/a/Documents/personalprojects/chess-opening-recommender\n",
      "DB path: /Users/a/Documents/personalprojects/chess-opening-recommender/data/processed/file_registry.json\n",
      "Models dir: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "DB_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"file_registry.json\"\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "MODELS_DIR = DATA_DIR / \"models\"\n",
    "\n",
    "print(\"Setup complete\")\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"DB path: {DB_PATH}\")\n",
    "print(f\"Models dir: {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09ca6dc",
   "metadata": {},
   "source": [
    "## Step 2: Load Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6650047b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No current_db found in registry",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     12\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDatabase not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdb_full_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m duckdb.connect(\u001b[38;5;28mstr\u001b[39m(db_full_path), read_only=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m conn = \u001b[43mget_db_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDB_PATH\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDatabase connection established\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDatabase: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconn.execute(\u001b[33m'\u001b[39m\u001b[33mSELECT current_database()\u001b[39m\u001b[33m'\u001b[39m).fetchone()[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mget_db_connection\u001b[39m\u001b[34m(db_path_str)\u001b[39m\n\u001b[32m      6\u001b[39m db_file = registry.get(\u001b[33m'\u001b[39m\u001b[33mcurrent_db\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m db_file:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo current_db found in registry\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m db_full_path = Path(db_path_str).parent / db_file\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m db_full_path.exists():\n",
      "\u001b[31mValueError\u001b[39m: No current_db found in registry"
     ]
    }
   ],
   "source": [
    "def get_db_connection(db_dir: str) -> duckdb.DuckDBPyConnection:\n",
    "    \"\"\"Get a DuckDB connection to chess_games.db in the processed directory.\"\"\"\n",
    "    db_full_path = Path(db_dir).parent / \"chess_games.db\"\n",
    "    \n",
    "    if not db_full_path.exists():\n",
    "        raise FileNotFoundError(f\"Database not found: {db_full_path}\")\n",
    "    \n",
    "    return duckdb.connect(str(db_full_path), read_only=True)\n",
    "\n",
    "conn = get_db_connection(str(DB_PATH))\n",
    "print(\"Database connection established\")\n",
    "print(f\"Database: {conn.execute('SELECT current_database()').fetchone()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc106482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5145526",
   "metadata": {},
   "source": [
    "## Step 3: Define Processing Function\n",
    "\n",
    "This matches the calculation from training notebook 28's hierarchical Bayesian shrinkage section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc53885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_opening_stats(color: str, min_games_threshold: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate opening-specific statistics from the database.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    color : str\n",
    "        'white' or 'black'\n",
    "    min_games_threshold : int\n",
    "        Minimum games per player-opening to include (default: 10)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame with columns:\n",
    "        - opening_id (db id)\n",
    "        - opening_mean (mean score for this opening)\n",
    "        - opening_total_games (total games across all players)\n",
    "        - opening_num_players (number of players who played this opening)\n",
    "        - eco (ECO code for reference)\n",
    "        - name (opening name for reference)\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"CALCULATING OPENING STATS FOR {color.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    query = f\"\"\"\n",
    "        SELECT \n",
    "            pos.opening_id,\n",
    "            pos.player_id,\n",
    "            pos.num_games,\n",
    "            pos.num_wins,\n",
    "            pos.num_draws,\n",
    "            pos.num_losses,\n",
    "            o.eco,\n",
    "            o.name\n",
    "        FROM player_opening_stats pos\n",
    "        JOIN opening o ON pos.opening_id = o.id\n",
    "        WHERE pos.color = '{color}'\n",
    "          AND pos.num_games >= {min_games_threshold}\n",
    "          AND o.eco IS NOT NULL\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n1. Loading data from database...\")\n",
    "    data = pd.DataFrame(conn.execute(query).df())\n",
    "    print(f\"   Loaded {len(data):,} player-opening entries\")\n",
    "    print(f\"   Unique openings: {data['opening_id'].nunique():,}\")\n",
    "    print(f\"   Unique players: {data['player_id'].nunique():,}\")\n",
    "    \n",
    "    print(f\"\\n2. Calculating raw scores...\")\n",
    "    data['score'] = (data['num_wins'] + 0.5 * data['num_draws']) / data['num_games']\n",
    "    print(f\"   Score range: [{data['score'].min():.4f}, {data['score'].max():.4f}]\")\n",
    "    print(f\"   Global mean score: {data['score'].mean():.4f}\")\n",
    "    \n",
    "    print(f\"\\n3. Aggregating by opening...\")\n",
    "    opening_stats = (\n",
    "        data.groupby('opening_id')\n",
    "        .agg({\n",
    "            'score': 'mean',\n",
    "            'num_games': 'sum',\n",
    "            'player_id': 'count',\n",
    "            'eco': 'first',\n",
    "            'name': 'first'\n",
    "        })\n",
    "        .rename(columns={\n",
    "            'score': 'opening_mean',\n",
    "            'num_games': 'opening_total_games',\n",
    "            'player_id': 'opening_num_players'\n",
    "        })\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    print(f\"   Calculated stats for {len(opening_stats):,} openings\")\n",
    "    print(f\"\\n4. Opening mean distribution:\")\n",
    "    print(f\"   Min: {opening_stats['opening_mean'].min():.4f}\")\n",
    "    print(f\"   25th percentile: {opening_stats['opening_mean'].quantile(0.25):.4f}\")\n",
    "    print(f\"   Median: {opening_stats['opening_mean'].median():.4f}\")\n",
    "    print(f\"   75th percentile: {opening_stats['opening_mean'].quantile(0.75):.4f}\")\n",
    "    print(f\"   Max: {opening_stats['opening_mean'].max():.4f}\")\n",
    "    print(f\"   Std: {opening_stats['opening_mean'].std():.4f}\")\n",
    "    \n",
    "    print(f\"\\n5. Opening size distribution:\")\n",
    "    print(f\"   Total games (median): {opening_stats['opening_total_games'].median():.0f}\")\n",
    "    print(f\"   Players (median): {opening_stats['opening_num_players'].median():.0f}\")\n",
    "    print(f\"   Total games range: [{opening_stats['opening_total_games'].min():.0f}, {opening_stats['opening_total_games'].max():.0f}]\")\n",
    "    print(f\"   Players range: [{opening_stats['opening_num_players'].min():.0f}, {opening_stats['opening_num_players'].max():.0f}]\")\n",
    "    \n",
    "    return opening_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a07ae6",
   "metadata": {},
   "source": [
    "## Step 4: Calculate Stats for White Openings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ffbeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_stats = calculate_opening_stats('white', min_games_threshold=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce580c1d",
   "metadata": {},
   "source": [
    "## Step 5: Inspect White Opening Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c25e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"WHITE OPENING STATS SAMPLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nFirst 10 openings:\")\n",
    "print(white_stats.head(10))\n",
    "\n",
    "print(\"\\n\\nTop 10 STRONGEST openings for White (highest win rate):\")\n",
    "strongest = white_stats.nlargest(10, 'opening_mean')\n",
    "for idx, row in strongest.iterrows():\n",
    "    print(f\"   {row['eco']:>3} | {row['name']:<50} | Mean: {row['opening_mean']:.4f} | Players: {row['opening_num_players']:>5} | Games: {row['opening_total_games']:>7}\")\n",
    "\n",
    "print(\"\\n\\nTop 10 WEAKEST openings for White (lowest win rate):\")\n",
    "weakest = white_stats.nsmallest(10, 'opening_mean')\n",
    "for idx, row in weakest.iterrows():\n",
    "    print(f\"   {row['eco']:>3} | {row['name']:<50} | Mean: {row['opening_mean']:.4f} | Players: {row['opening_num_players']:>5} | Games: {row['opening_total_games']:>7}\")\n",
    "\n",
    "print(\"\\n\\nData types:\")\n",
    "print(white_stats.dtypes)\n",
    "\n",
    "print(\"\\nMemory usage:\")\n",
    "print(white_stats.memory_usage(deep=True))\n",
    "print(f\"\\nTotal memory: {white_stats.memory_usage(deep=True).sum() / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8e6243",
   "metadata": {},
   "source": [
    "## Step 6: Load Training Mappings\n",
    "\n",
    "We need to convert database IDs to training IDs before saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c053aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Available model directories:\")\n",
    "for model_dir in MODELS_DIR.iterdir():\n",
    "    if model_dir.is_dir() and not model_dir.name.startswith('.'):\n",
    "        print(f\"   {model_dir.name}\")\n",
    "\n",
    "# UPDATE THIS TO YOUR MODEL DIRECTORY\n",
    "MODEL_DIR_NAME = \"20251111_155428_white\"\n",
    "MODEL_ARTIFACTS_DIR = MODELS_DIR / MODEL_DIR_NAME\n",
    "\n",
    "print(f\"\\nUsing model directory: {MODEL_DIR_NAME}\")\n",
    "print(f\"Full path: {MODEL_ARTIFACTS_DIR}\")\n",
    "\n",
    "if not MODEL_ARTIFACTS_DIR.exists():\n",
    "    print(f\"\\nWARNING: Model directory does not exist!\")\n",
    "    print(f\"Please create it or update MODEL_DIR_NAME\")\n",
    "else:\n",
    "    print(f\"Model directory exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd05706",
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings_path = MODEL_ARTIFACTS_DIR / \"opening_mappings.csv\"\n",
    "\n",
    "if not mappings_path.exists():\n",
    "    print(f\"WARNING: opening_mappings.csv not found at {mappings_path}\")\n",
    "    print(f\"You need to run the training pipeline first to create this file.\")\n",
    "    opening_mappings = None\n",
    "else:\n",
    "    opening_mappings = pd.read_csv(mappings_path)\n",
    "    print(\"Loaded opening mappings\")\n",
    "    print(f\"   Shape: {opening_mappings.shape}\")\n",
    "    print(f\"   Columns: {list(opening_mappings.columns)}\")\n",
    "    print(f\"\\nFirst few mappings:\")\n",
    "    print(opening_mappings.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b20c258",
   "metadata": {},
   "source": [
    "## Step 7: Merge Stats with Training IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613bc6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opening_mappings is not None:\n",
    "    white_stats_with_training_ids = white_stats.merge(\n",
    "        opening_mappings[['db_id', 'training_id']], \n",
    "        left_on='opening_id', \n",
    "        right_on='db_id',\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    print(\"Merged opening stats with training IDs\")\n",
    "    print(f\"   Original openings: {len(white_stats)}\")\n",
    "    print(f\"   After merge: {len(white_stats_with_training_ids)}\")\n",
    "    print(f\"   Dropped: {len(white_stats) - len(white_stats_with_training_ids)} (not in training set)\")\n",
    "    \n",
    "    if white_stats_with_training_ids['training_id'].duplicated().any():\n",
    "        print(f\"\\nWARNING: Found duplicate training_ids!\")\n",
    "        dups = white_stats_with_training_ids[white_stats_with_training_ids['training_id'].duplicated(keep=False)]\n",
    "        print(dups)\n",
    "    else:\n",
    "        print(\"   No duplicate training_ids\")\n",
    "    \n",
    "    print(\"\\nSample of merged data:\")\n",
    "    print(white_stats_with_training_ids.head(10))\n",
    "else:\n",
    "    print(\"Skipping merge - no opening mappings available\")\n",
    "    white_stats_with_training_ids = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e918dfdd",
   "metadata": {},
   "source": [
    "## Step 8: Create JSON Output (Keyed by Training ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea986c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if white_stats_with_training_ids is not None:\n",
    "    opening_stats_dict = {}\n",
    "    \n",
    "    for idx, row in white_stats_with_training_ids.iterrows():\n",
    "        opening_stats_dict[int(row['training_id'])] = {\n",
    "            'opening_mean': float(row['opening_mean']),\n",
    "            'opening_total_games': int(row['opening_total_games']),\n",
    "            'opening_num_players': int(row['opening_num_players']),\n",
    "            'eco': str(row['eco']),\n",
    "            'name': str(row['name']),\n",
    "            'db_id': int(row['db_id'])\n",
    "        }\n",
    "    \n",
    "    print(\"Created opening stats dictionary\")\n",
    "    print(f\"   Total openings: {len(opening_stats_dict)}\")\n",
    "    print(f\"   Training ID range: [{min(opening_stats_dict.keys())}, {max(opening_stats_dict.keys())}]\")\n",
    "    \n",
    "    print(\"\\nSample entries:\")\n",
    "    for training_id in sorted(opening_stats_dict.keys())[:5]:\n",
    "        stats = opening_stats_dict[training_id]\n",
    "        print(f\"   Training ID {training_id}: {stats['eco']} | Mean: {stats['opening_mean']:.4f} | {stats['name']}\")\n",
    "else:\n",
    "    print(\"Skipping JSON creation - no merged data available\")\n",
    "    opening_stats_dict = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eebf7e6",
   "metadata": {},
   "source": [
    "## Step 9: Validate JSON Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6384da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opening_stats_dict is not None:\n",
    "    print(\"Validating JSON structure...\\n\")\n",
    "    \n",
    "    all_int_keys = all(isinstance(k, int) for k in opening_stats_dict.keys())\n",
    "    print(f\"All keys are integers: {all_int_keys}\")\n",
    "    \n",
    "    required_fields = ['opening_mean', 'opening_total_games', 'opening_num_players', 'eco', 'name', 'db_id']\n",
    "    all_have_fields = all(\n",
    "        all(field in v for field in required_fields) \n",
    "        for v in opening_stats_dict.values()\n",
    "    )\n",
    "    print(f\"All values have required fields: {all_have_fields}\")\n",
    "    \n",
    "    sample_value = list(opening_stats_dict.values())[0]\n",
    "    print(f\"\\nSample value structure:\")\n",
    "    for field, value in sample_value.items():\n",
    "        print(f\"   {field}: {type(value).__name__} = {value}\")\n",
    "    \n",
    "    has_none = any(\n",
    "        any(v is None or (isinstance(v, float) and pd.isna(v)) for v in vals.values())\n",
    "        for vals in opening_stats_dict.values()\n",
    "    )\n",
    "    print(f\"\\nNo None/NaN values: {not has_none}\")\n",
    "    \n",
    "    means = [v['opening_mean'] for v in opening_stats_dict.values()]\n",
    "    print(f\"\\nOpening mean range: [{min(means):.4f}, {max(means):.4f}]\")\n",
    "    all_in_range = all(0 <= m <= 1 for m in means)\n",
    "    print(f\"All means in [0, 1]: {all_in_range}\")\n",
    "    \n",
    "    print(\"\\nJSON structure validation complete\")\n",
    "else:\n",
    "    print(\"Skipping validation - no data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeb59b0",
   "metadata": {},
   "source": [
    "## Step 10: Check JSON Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c267f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opening_stats_dict is not None:\n",
    "    import sys\n",
    "    \n",
    "    memory_size = sys.getsizeof(opening_stats_dict)\n",
    "    print(f\"In-memory size: {memory_size:,} bytes ({memory_size / 1024:.2f} KB)\")\n",
    "    \n",
    "    json_str = json.dumps(opening_stats_dict, indent=2)\n",
    "    json_size = len(json_str.encode('utf-8'))\n",
    "    print(f\"JSON size (with indent=2): {json_size:,} bytes ({json_size / 1024:.2f} KB)\")\n",
    "    \n",
    "    json_str_compact = json.dumps(opening_stats_dict)\n",
    "    json_size_compact = len(json_str_compact.encode('utf-8'))\n",
    "    print(f\"JSON size (compact): {json_size_compact:,} bytes ({json_size_compact / 1024:.2f} KB)\")\n",
    "    \n",
    "    print(\"\\nFirst 500 characters of JSON:\")\n",
    "    print(json_str[:500])\n",
    "else:\n",
    "    print(\"Skipping size check - no data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9590f25f",
   "metadata": {},
   "source": [
    "## Step 11: Save JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efb80fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if opening_stats_dict is not None:\n",
    "#     output_json_path = MODEL_ARTIFACTS_DIR / \"opening_stats_white.json\"\n",
    "    \n",
    "#     with open(output_json_path, 'w') as f:\n",
    "#         json.dump(opening_stats_dict, f, indent=2)\n",
    "    \n",
    "#     print(f\"Saved JSON to: {output_json_path}\")\n",
    "#     print(f\"   File size: {output_json_path.stat().st_size:,} bytes ({output_json_path.stat().st_size / 1024:.2f} KB)\")\n",
    "    \n",
    "#     with open(output_json_path, 'r') as f:\n",
    "#         loaded_dict = json.load(f)\n",
    "    \n",
    "#     print(f\"\\nVerified file can be loaded\")\n",
    "#     print(f\"   Loaded {len(loaded_dict)} openings\")\n",
    "#     print(f\"   Matches original: {len(loaded_dict) == len(opening_stats_dict)}\")\n",
    "# else:\n",
    "#     print(\"Skipping save - no data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88717d4f",
   "metadata": {},
   "source": [
    "## Step 12: Save CSV File (for easy inspection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39548d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if white_stats_with_training_ids is not None:\n",
    "#     output_csv_path = MODEL_ARTIFACTS_DIR / \"opening_stats_white.csv\"\n",
    "    \n",
    "#     csv_data = white_stats_with_training_ids[[\n",
    "#         'training_id', 'db_id', 'opening_id', 'eco', 'name', \n",
    "#         'opening_mean', 'opening_total_games', 'opening_num_players'\n",
    "#     ]].sort_values('training_id')\n",
    "    \n",
    "#     csv_data.to_csv(output_csv_path, index=False)\n",
    "    \n",
    "#     print(f\"Saved CSV to: {output_csv_path}\")\n",
    "#     print(f\"   File size: {output_csv_path.stat().st_size:,} bytes ({output_csv_path.stat().st_size / 1024:.2f} KB)\")\n",
    "#     print(f\"   Rows: {len(csv_data)}\")\n",
    "    \n",
    "#     print(\"\\nFirst 10 rows of CSV:\")\n",
    "#     print(csv_data.head(10))\n",
    "# else:\n",
    "#     print(\"Skipping CSV save - no data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbabb44c",
   "metadata": {},
   "source": [
    "## Step 13: Test Loading and Using the JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea7d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if opening_stats_dict is not None:\n",
    "#     print(\"Testing practical usage of opening_stats.json...\\n\")\n",
    "    \n",
    "#     test_training_ids = list(opening_stats_dict.keys())[:5]\n",
    "    \n",
    "#     print(\"Simulating inference lookup:\")\n",
    "#     for training_id in test_training_ids:\n",
    "#         stats = opening_stats_dict[training_id]\n",
    "#         print(f\"\\n   Training ID {training_id}:\")\n",
    "#         print(f\"      ECO: {stats['eco']}\")\n",
    "#         print(f\"      Name: {stats['name']}\")\n",
    "#         print(f\"      Opening mean: {stats['opening_mean']:.4f}\")\n",
    "#         print(f\"      Total games: {stats['opening_total_games']}\")\n",
    "#         print(f\"      Num players: {stats['opening_num_players']}\")\n",
    "    \n",
    "#     print(\"\\n\\nSimulating Bayesian shrinkage calculation:\")\n",
    "#     k = 50\n",
    "    \n",
    "#     player_games = 15\n",
    "#     player_raw_score = 0.6\n",
    "#     training_id = test_training_ids[0]\n",
    "#     opening_mean = opening_stats_dict[training_id]['opening_mean']\n",
    "    \n",
    "#     adjusted_score = (\n",
    "#         (player_games * player_raw_score) + (k * opening_mean)\n",
    "#     ) / (player_games + k)\n",
    "    \n",
    "#     confidence = player_games / (player_games + k)\n",
    "    \n",
    "#     print(f\"   Player: {player_games} games, raw score = {player_raw_score:.4f}\")\n",
    "#     print(f\"   Opening: {opening_stats_dict[training_id]['eco']} (training_id={training_id})\")\n",
    "#     print(f\"   Opening mean: {opening_mean:.4f}\")\n",
    "#     print(f\"   Adjusted score: {adjusted_score:.4f}\")\n",
    "#     print(f\"   Confidence: {confidence:.4f}\")\n",
    "#     print(f\"   Adjustment: {adjusted_score - player_raw_score:+.4f}\")\n",
    "    \n",
    "#     print(\"\\nAll tests passed!\")\n",
    "# else:\n",
    "#     print(\"Skipping usage test - no data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f538094",
   "metadata": {},
   "source": [
    "## Step 14: Calculate Stats for Black Openings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd04d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_stats = calculate_opening_stats('black', min_games_threshold=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ea9e24",
   "metadata": {},
   "source": [
    "## Step 15: Process and Save Black Opening Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295a6572",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BLACK OPENING STATS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nTo process black openings:\")\n",
    "print(\"   1. Set MODEL_DIR_NAME to your black model directory\")\n",
    "print(\"   2. Load the black opening_mappings.csv\")\n",
    "print(\"   3. Repeat the merge, JSON creation, and save steps\")\n",
    "print(\"\\nBlack stats preview:\")\n",
    "print(black_stats.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39353de3",
   "metadata": {},
   "source": [
    "## Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf591611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"SUMMARY\")\n",
    "# print(\"=\"*60)\n",
    "\n",
    "# if opening_stats_dict is not None:\n",
    "#     print(f\"\\nSuccessfully created opening_stats_white.json\")\n",
    "#     print(f\"   Location: {MODEL_ARTIFACTS_DIR / 'opening_stats_white.json'}\")\n",
    "#     print(f\"   Total openings: {len(opening_stats_dict)}\")\n",
    "#     print(f\"   File size: {(MODEL_ARTIFACTS_DIR / 'opening_stats_white.json').stat().st_size / 1024:.2f} KB\")\n",
    "    \n",
    "#     print(f\"\\nAlso created opening_stats_white.csv for inspection\")\n",
    "#     print(f\"   Location: {MODEL_ARTIFACTS_DIR / 'opening_stats_white.csv'}\")\n",
    "    \n",
    "#     print(f\"\\nNext steps:\")\n",
    "#     print(f\"   1. Copy these files to your production model artifacts directory\")\n",
    "#     print(f\"   2. Update inference pipeline to load opening_stats.json at startup\")\n",
    "#     print(f\"   3. Use opening_mean values for Bayesian shrinkage during inference\")\n",
    "#     print(f\"   4. Repeat for black openings (update MODEL_DIR_NAME and re-run)\")\n",
    "# else:\n",
    "#     print(f\"\\nNo files created\")\n",
    "#     print(f\"   Make sure opening_mappings.csv exists in your model directory\")\n",
    "#     print(f\"   Update MODEL_DIR_NAME to point to the correct model\")\n",
    "#     print(f\"   Re-run the notebook\")\n",
    "\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"NOTEBOOK COMPLETE\")\n",
    "# print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61bf275",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n",
    "print(\"Database connection closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
