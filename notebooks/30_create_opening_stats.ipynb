{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8993ee05",
   "metadata": {},
   "source": [
    "# Notebook 30: Create Opening Stats JSON/CSV\n",
    "\n",
    "## Purpose\n",
    "Create opening-specific statistics files (JSON and CSV) for use in inference pipeline.\n",
    "These files contain the opening means needed for hierarchical Bayesian shrinkage.\n",
    "\n",
    "## What This Creates\n",
    "- `opening_stats_white.json`: Opening means for White openings (keyed by training_id)\n",
    "- `opening_stats_black.json`: Opening means for Black openings (keyed by training_id)\n",
    "- Also creates CSV versions for easy inspection\n",
    "\n",
    "## Data Source\n",
    "- Uses EXISTING openings in the database\n",
    "- Calculates mean scores from all player-opening interactions\n",
    "- Matches the calculation done in training notebook 28\n",
    "\n",
    "## Output Location\n",
    "`data/models/<model_dir>/opening_stats_<color>.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f3e8e4",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f00f3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n",
      "Project root: /Users/a/Documents/personalprojects/chess-opening-recommender\n",
      "DB path: /Users/a/Documents/personalprojects/chess-opening-recommender/data/processed/file_registry.json\n",
      "Models dir: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "DB_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"file_registry.json\"\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "MODELS_DIR = DATA_DIR / \"models\"\n",
    "\n",
    "print(\"Setup complete\")\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"DB path: {DB_PATH}\")\n",
    "print(f\"Models dir: {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09ca6dc",
   "metadata": {},
   "source": [
    "## Step 2: Load Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6650047b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection established\n",
      "Database: chess_games\n"
     ]
    }
   ],
   "source": [
    "def get_db_connection(db_dir: str) -> duckdb.DuckDBPyConnection:\n",
    "    \"\"\"Get a DuckDB connection to chess_games.db in the processed directory.\"\"\"\n",
    "    db_full_path = Path(db_dir).parent / \"chess_games.db\"\n",
    "    \n",
    "    if not db_full_path.exists():\n",
    "        raise FileNotFoundError(f\"Database not found: {db_full_path}\")\n",
    "    \n",
    "    return duckdb.connect(str(db_full_path), read_only=True)\n",
    "\n",
    "conn = get_db_connection(str(DB_PATH))\n",
    "print(\"Database connection established\")\n",
    "print(f\"Database: {conn.execute('SELECT current_database()').fetchone()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc106482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5145526",
   "metadata": {},
   "source": [
    "## Step 3: Define Processing Function\n",
    "\n",
    "This matches the calculation from training notebook 28's hierarchical Bayesian shrinkage section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edc53885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_opening_stats(color: str, min_games_threshold: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate opening-specific statistics from the database.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    color : str\n",
    "        'white' or 'black' (will be converted to 'w' or 'b' for database query)\n",
    "    min_games_threshold : int\n",
    "        Minimum games per player-opening to include (default: 10)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame with columns:\n",
    "        - opening_id (db id)\n",
    "        - opening_mean (mean score for this opening)\n",
    "        - opening_total_games (total games across all players)\n",
    "        - opening_num_players (number of players who played this opening)\n",
    "        - eco (ECO code for reference)\n",
    "        - name (opening name for reference)\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"CALCULATING OPENING STATS FOR {color.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    color_db = 'w' if color.lower() == 'white' else 'b'\n",
    "    \n",
    "    query = f\"\"\"\n",
    "        SELECT \n",
    "            pos.opening_id,\n",
    "            pos.player_id,\n",
    "            (pos.num_wins + pos.num_draws + pos.num_losses) as num_games,\n",
    "            pos.num_wins,\n",
    "            pos.num_draws,\n",
    "            pos.num_losses,\n",
    "            o.eco,\n",
    "            o.name\n",
    "        FROM player_opening_stats pos\n",
    "        JOIN opening o ON pos.opening_id = o.id\n",
    "        WHERE pos.color = '{color_db}'\n",
    "          AND (pos.num_wins + pos.num_draws + pos.num_losses) >= {min_games_threshold}\n",
    "          AND o.eco IS NOT NULL\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n1. Loading data from database...\")\n",
    "    data = pd.DataFrame(conn.execute(query).df())\n",
    "    print(f\"   Loaded {len(data):,} player-opening entries\")\n",
    "    print(f\"   Unique openings: {data['opening_id'].nunique():,}\")\n",
    "    print(f\"   Unique players: {data['player_id'].nunique():,}\")\n",
    "    \n",
    "    print(f\"\\n2. Calculating raw scores...\")\n",
    "    data['score'] = (data['num_wins'] + 0.5 * data['num_draws']) / data['num_games']\n",
    "    print(f\"   Score range: [{data['score'].min():.4f}, {data['score'].max():.4f}]\")\n",
    "    print(f\"   Global mean score: {data['score'].mean():.4f}\")\n",
    "    \n",
    "    print(f\"\\n3. Aggregating by opening...\")\n",
    "    opening_stats = (\n",
    "        data.groupby('opening_id')\n",
    "        .agg({\n",
    "            'score': 'mean',\n",
    "            'num_games': 'sum',\n",
    "            'player_id': 'count',\n",
    "            'eco': 'first',\n",
    "            'name': 'first'\n",
    "        })\n",
    "        .rename(columns={\n",
    "            'score': 'opening_mean',\n",
    "            'num_games': 'opening_total_games',\n",
    "            'player_id': 'opening_num_players'\n",
    "        })\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    print(f\"   Calculated stats for {len(opening_stats):,} openings\")\n",
    "    print(f\"\\n4. Opening mean distribution:\")\n",
    "    print(f\"   Min: {opening_stats['opening_mean'].min():.4f}\")\n",
    "    print(f\"   25th percentile: {opening_stats['opening_mean'].quantile(0.25):.4f}\")\n",
    "    print(f\"   Median: {opening_stats['opening_mean'].median():.4f}\")\n",
    "    print(f\"   75th percentile: {opening_stats['opening_mean'].quantile(0.75):.4f}\")\n",
    "    print(f\"   Max: {opening_stats['opening_mean'].max():.4f}\")\n",
    "    print(f\"   Std: {opening_stats['opening_mean'].std():.4f}\")\n",
    "    \n",
    "    print(f\"\\n5. Opening size distribution:\")\n",
    "    print(f\"   Total games (median): {opening_stats['opening_total_games'].median():.0f}\")\n",
    "    print(f\"   Players (median): {opening_stats['opening_num_players'].median():.0f}\")\n",
    "    print(f\"   Total games range: [{opening_stats['opening_total_games'].min():.0f}, {opening_stats['opening_total_games'].max():.0f}]\")\n",
    "    print(f\"   Players range: [{opening_stats['opening_num_players'].min():.0f}, {opening_stats['opening_num_players'].max():.0f}]\")\n",
    "    \n",
    "    return opening_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a07ae6",
   "metadata": {},
   "source": [
    "## Step 4: Calculate Stats for White Openings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80ffbeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CALCULATING OPENING STATS FOR WHITE\n",
      "============================================================\n",
      "\n",
      "1. Loading data from database...\n",
      "   Loaded 2,975,888 player-opening entries\n",
      "   Unique openings: 2,718\n",
      "   Unique players: 49,822\n",
      "\n",
      "2. Calculating raw scores...\n",
      "   Score range: [0.0000, 1.0000]\n",
      "   Global mean score: 0.5110\n",
      "\n",
      "3. Aggregating by opening...\n",
      "   Loaded 2,975,888 player-opening entries\n",
      "   Unique openings: 2,718\n",
      "   Unique players: 49,822\n",
      "\n",
      "2. Calculating raw scores...\n",
      "   Score range: [0.0000, 1.0000]\n",
      "   Global mean score: 0.5110\n",
      "\n",
      "3. Aggregating by opening...\n",
      "   Calculated stats for 2,718 openings\n",
      "\n",
      "4. Opening mean distribution:\n",
      "   Min: 0.1667\n",
      "   25th percentile: 0.4961\n",
      "   Median: 0.5163\n",
      "   75th percentile: 0.5366\n",
      "   Max: 1.0000\n",
      "   Std: 0.0504\n",
      "\n",
      "5. Opening size distribution:\n",
      "   Total games (median): 4913\n",
      "   Players (median): 160\n",
      "   Total games range: [10, 5648567]\n",
      "   Players range: [1, 44105]\n",
      "   Calculated stats for 2,718 openings\n",
      "\n",
      "4. Opening mean distribution:\n",
      "   Min: 0.1667\n",
      "   25th percentile: 0.4961\n",
      "   Median: 0.5163\n",
      "   75th percentile: 0.5366\n",
      "   Max: 1.0000\n",
      "   Std: 0.0504\n",
      "\n",
      "5. Opening size distribution:\n",
      "   Total games (median): 4913\n",
      "   Players (median): 160\n",
      "   Total games range: [10, 5648567]\n",
      "   Players range: [1, 44105]\n"
     ]
    }
   ],
   "source": [
    "white_stats = calculate_opening_stats('white', min_games_threshold=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce580c1d",
   "metadata": {},
   "source": [
    "## Step 5: Inspect White Opening Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7c25e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "WHITE OPENING STATS SAMPLE\n",
      "============================================================\n",
      "\n",
      "First 10 openings:\n",
      "   opening_id  opening_mean  opening_total_games  opening_num_players  eco  \\\n",
      "0           2      0.463462                25504                  175  A00   \n",
      "1           3      0.394048                   47                    2  A00   \n",
      "2           4      0.515821                  188                    7  A00   \n",
      "3           5      0.490290               176356                  697  A00   \n",
      "4           6      0.419735                  278                   11  A00   \n",
      "5           8      0.582516                   43                    3  A00   \n",
      "6           9      0.468210                 9266                   90  A00   \n",
      "7          10      0.476564               146431                  763  A00   \n",
      "8          11      0.633955                   92                    3  A00   \n",
      "9          12      0.471681                 6691                   51  A00   \n",
      "\n",
      "                                 name  \n",
      "0                        Amar Opening  \n",
      "1          Amar Opening: Paris Gambit  \n",
      "2                    Amsterdam Attack  \n",
      "3                 Anderssen's Opening  \n",
      "4  Anderssen's Opening: Polish Gambit  \n",
      "5       Barnes Opening: Gedult Gambit  \n",
      "6        Barnes Opening: Hammerschlag  \n",
      "7                     Clemenz Opening  \n",
      "8   Clemenz Opening: Spike Lee Gambit  \n",
      "9                        Crab Opening  \n",
      "\n",
      "\n",
      "Top 10 STRONGEST openings for White (highest win rate):\n",
      "   C39 | King's Gambit Accepted: Kieseritzky, Long Whip Defense, Jaenisch Variation | Mean: 1.0000 | Players:     1 | Games:      10\n",
      "   E10 | Indian Defense: Döry Indian                        | Mean: 0.8000 | Players:     1 | Games:      10\n",
      "   C19 | French Defense: Winawer Variation, Eingorn Variation | Mean: 0.8000 | Players:     1 | Games:      10\n",
      "   C49 | Four Knights Game: Symmetrical, Metger Unpin       | Mean: 0.7857 | Players:     1 | Games:      14\n",
      "   C30 | King's Gambit Declined: Panteldakis Countergambit, Greco Variation | Mean: 0.7692 | Players:     1 | Games:      13\n",
      "   C54 | Italian Game: Giuoco Piano, Rosentreter Variation  | Mean: 0.7297 | Players:    93 | Games:    2110\n",
      "   A02 | Bird Opening: From's Gambit, Lipke Variation       | Mean: 0.7273 | Players:     1 | Games:      11\n",
      "   C54 | Italian Game: Giuoco Piano, Aitken Variation       | Mean: 0.7147 | Players:   127 | Games:    3605\n",
      "   B28 | Sicilian Defense: O'Kelly Variation, Venice System, Barcza Line | Mean: 0.7063 | Players:     4 | Games:      53\n",
      "   C29 | Vienna Game: Vienna Gambit, Wurzburger Trap        | Mean: 0.7060 | Players:    32 | Games:    1268\n",
      "\n",
      "\n",
      "Top 10 WEAKEST openings for White (lowest win rate):\n",
      "   D26 | Queen's Gambit Accepted: Classical Defense, Normal Line | Mean: 0.1667 | Players:     1 | Games:      12\n",
      "   A83 | Dutch Defense: Staunton Gambit, Nimzowitsch Variation | Mean: 0.2006 | Players:     2 | Games:      31\n",
      "   A40 | Englund Gambit Declined: Diemer Counterattack      | Mean: 0.2273 | Players:     1 | Games:      11\n",
      "   C37 | King's Gambit Accepted: Muzio Gambit Accepted, From's Defense | Mean: 0.2417 | Players:     2 | Games:      22\n",
      "   A98 | Dutch Defense: Classical Variation, Ilyin-Zhenevsky Variation, Alatortsev-Lisitsyn Line | Mean: 0.2500 | Players:     1 | Games:      12\n",
      "   B74 | Sicilian Defense: Dragon Variation, Classical Variation, Tartakower Line | Mean: 0.2500 | Players:     1 | Games:      16\n",
      "   C71 | Ruy Lopez: Noah's Ark Trap                         | Mean: 0.2665 | Players:    13 | Games:     166\n",
      "   A42 | Pterodactyl Defense                                | Mean: 0.2727 | Players:     1 | Games:      11\n",
      "   A00 | Van Geet Opening: Düsseldorf Gambit                | Mean: 0.2857 | Players:     1 | Games:      14\n",
      "   A00 | Grob Opening: Keene Defense, Main Line             | Mean: 0.3000 | Players:     1 | Games:      10\n",
      "\n",
      "\n",
      "Data types:\n",
      "opening_id               int32\n",
      "opening_mean           float64\n",
      "opening_total_games      int32\n",
      "opening_num_players      int64\n",
      "eco                     object\n",
      "name                    object\n",
      "dtype: object\n",
      "\n",
      "Memory usage:\n",
      "Index                     132\n",
      "opening_id              10872\n",
      "opening_mean            21744\n",
      "opening_total_games     10872\n",
      "opening_num_players     21744\n",
      "eco                    141336\n",
      "name                   262666\n",
      "dtype: int64\n",
      "\n",
      "Total memory: 458.37 KB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"WHITE OPENING STATS SAMPLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nFirst 10 openings:\")\n",
    "print(white_stats.head(10))\n",
    "\n",
    "print(\"\\n\\nTop 10 STRONGEST openings for White (highest win rate):\")\n",
    "strongest = white_stats.nlargest(10, 'opening_mean')\n",
    "for idx, row in strongest.iterrows():\n",
    "    print(f\"   {row['eco']:>3} | {row['name']:<50} | Mean: {row['opening_mean']:.4f} | Players: {row['opening_num_players']:>5} | Games: {row['opening_total_games']:>7}\")\n",
    "\n",
    "print(\"\\n\\nTop 10 WEAKEST openings for White (lowest win rate):\")\n",
    "weakest = white_stats.nsmallest(10, 'opening_mean')\n",
    "for idx, row in weakest.iterrows():\n",
    "    print(f\"   {row['eco']:>3} | {row['name']:<50} | Mean: {row['opening_mean']:.4f} | Players: {row['opening_num_players']:>5} | Games: {row['opening_total_games']:>7}\")\n",
    "\n",
    "print(\"\\n\\nData types:\")\n",
    "print(white_stats.dtypes)\n",
    "\n",
    "print(\"\\nMemory usage:\")\n",
    "print(white_stats.memory_usage(deep=True))\n",
    "print(f\"\\nTotal memory: {white_stats.memory_usage(deep=True).sum() / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8e6243",
   "metadata": {},
   "source": [
    "## Step 6: Load Training Mappings\n",
    "\n",
    "We need to convert database IDs to training IDs before saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c053aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available model directories:\n",
      "   20251212_152017_black\n",
      "   20251111_155428_white\n",
      "\n",
      "Using model directory: 20251111_155428_white\n",
      "Full path: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/20251111_155428_white\n",
      "Model directory exists\n"
     ]
    }
   ],
   "source": [
    "print(\"Available model directories:\")\n",
    "for model_dir in MODELS_DIR.iterdir():\n",
    "    if model_dir.is_dir() and not model_dir.name.startswith('.'):\n",
    "        print(f\"   {model_dir.name}\")\n",
    "\n",
    "# UPDATE THIS TO YOUR MODEL DIRECTORY\n",
    "MODEL_DIR_NAME = \"20251111_155428_white\"\n",
    "MODEL_ARTIFACTS_DIR = MODELS_DIR / MODEL_DIR_NAME\n",
    "\n",
    "print(f\"\\nUsing model directory: {MODEL_DIR_NAME}\")\n",
    "print(f\"Full path: {MODEL_ARTIFACTS_DIR}\")\n",
    "\n",
    "if not MODEL_ARTIFACTS_DIR.exists():\n",
    "    print(f\"\\nWARNING: Model directory does not exist!\")\n",
    "    print(f\"Please create it or update MODEL_DIR_NAME\")\n",
    "else:\n",
    "    print(f\"Model directory exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcd05706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded opening mappings\n",
      "   Shape: (2714, 4)\n",
      "   Columns: ['db_id', 'eco', 'name', 'training_id']\n",
      "\n",
      "First few mappings:\n",
      "   db_id  eco                                name  training_id\n",
      "0      2  A00                        Amar Opening            0\n",
      "1      3  A00          Amar Opening: Paris Gambit            1\n",
      "2      4  A00                    Amsterdam Attack            2\n",
      "3      5  A00                 Anderssen's Opening            3\n",
      "4      6  A00  Anderssen's Opening: Polish Gambit            4\n",
      "5      8  A00       Barnes Opening: Gedult Gambit            5\n",
      "6      9  A00        Barnes Opening: Hammerschlag            6\n",
      "7     10  A00                     Clemenz Opening            7\n",
      "8     11  A00   Clemenz Opening: Spike Lee Gambit            8\n",
      "9     12  A00                        Crab Opening            9\n"
     ]
    }
   ],
   "source": [
    "mappings_path = MODEL_ARTIFACTS_DIR / \"opening_mappings.csv\"\n",
    "\n",
    "if not mappings_path.exists():\n",
    "    print(f\"WARNING: opening_mappings.csv not found at {mappings_path}\")\n",
    "    print(f\"You need to run the training pipeline first to create this file.\")\n",
    "    opening_mappings = None\n",
    "else:\n",
    "    opening_mappings = pd.read_csv(mappings_path)\n",
    "    print(\"Loaded opening mappings\")\n",
    "    print(f\"   Shape: {opening_mappings.shape}\")\n",
    "    print(f\"   Columns: {list(opening_mappings.columns)}\")\n",
    "    print(f\"\\nFirst few mappings:\")\n",
    "    print(opening_mappings.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b20c258",
   "metadata": {},
   "source": [
    "## Step 7: Merge Stats with Training IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "613bc6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged opening stats with training IDs\n",
      "   Original openings: 2718\n",
      "   After merge: 2714\n",
      "   Dropped: 4 (not in training set)\n",
      "   No duplicate training_ids\n",
      "\n",
      "Sample of merged data:\n",
      "   opening_id  opening_mean  opening_total_games  opening_num_players  eco  \\\n",
      "0           2      0.463462                25504                  175  A00   \n",
      "1           3      0.394048                   47                    2  A00   \n",
      "2           4      0.515821                  188                    7  A00   \n",
      "3           5      0.490290               176356                  697  A00   \n",
      "4           6      0.419735                  278                   11  A00   \n",
      "5           8      0.582516                   43                    3  A00   \n",
      "6           9      0.468210                 9266                   90  A00   \n",
      "7          10      0.476564               146431                  763  A00   \n",
      "8          11      0.633955                   92                    3  A00   \n",
      "9          12      0.471681                 6691                   51  A00   \n",
      "\n",
      "                                 name  db_id  training_id  \n",
      "0                        Amar Opening      2            0  \n",
      "1          Amar Opening: Paris Gambit      3            1  \n",
      "2                    Amsterdam Attack      4            2  \n",
      "3                 Anderssen's Opening      5            3  \n",
      "4  Anderssen's Opening: Polish Gambit      6            4  \n",
      "5       Barnes Opening: Gedult Gambit      8            5  \n",
      "6        Barnes Opening: Hammerschlag      9            6  \n",
      "7                     Clemenz Opening     10            7  \n",
      "8   Clemenz Opening: Spike Lee Gambit     11            8  \n",
      "9                        Crab Opening     12            9  \n"
     ]
    }
   ],
   "source": [
    "if opening_mappings is not None:\n",
    "    white_stats_with_training_ids = white_stats.merge(\n",
    "        opening_mappings[['db_id', 'training_id']], \n",
    "        left_on='opening_id', \n",
    "        right_on='db_id',\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    print(\"Merged opening stats with training IDs\")\n",
    "    print(f\"   Original openings: {len(white_stats)}\")\n",
    "    print(f\"   After merge: {len(white_stats_with_training_ids)}\")\n",
    "    print(f\"   Dropped: {len(white_stats) - len(white_stats_with_training_ids)} (not in training set)\")\n",
    "    \n",
    "    if white_stats_with_training_ids['training_id'].duplicated().any():\n",
    "        print(f\"\\nWARNING: Found duplicate training_ids!\")\n",
    "        dups = white_stats_with_training_ids[white_stats_with_training_ids['training_id'].duplicated(keep=False)]\n",
    "        print(dups)\n",
    "    else:\n",
    "        print(\"   No duplicate training_ids\")\n",
    "    \n",
    "    print(\"\\nSample of merged data:\")\n",
    "    print(white_stats_with_training_ids.head(10))\n",
    "else:\n",
    "    print(\"Skipping merge - no opening mappings available\")\n",
    "    white_stats_with_training_ids = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e918dfdd",
   "metadata": {},
   "source": [
    "## Step 8: Create JSON Output (Keyed by Training ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ea986c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created opening stats dictionary\n",
      "   Total openings: 2714\n",
      "   Training ID range: [0, 2713]\n",
      "\n",
      "Sample entries:\n",
      "   Training ID 0: A00 | Mean: 0.4635 | Amar Opening\n",
      "   Training ID 1: A00 | Mean: 0.3940 | Amar Opening: Paris Gambit\n",
      "   Training ID 2: A00 | Mean: 0.5158 | Amsterdam Attack\n",
      "   Training ID 3: A00 | Mean: 0.4903 | Anderssen's Opening\n",
      "   Training ID 4: A00 | Mean: 0.4197 | Anderssen's Opening: Polish Gambit\n",
      "\n",
      "   Total openings: 2714\n",
      "   Training ID range: [0, 2713]\n",
      "\n",
      "Sample entries:\n",
      "   Training ID 0: A00 | Mean: 0.4635 | Amar Opening\n",
      "   Training ID 1: A00 | Mean: 0.3940 | Amar Opening: Paris Gambit\n",
      "   Training ID 2: A00 | Mean: 0.5158 | Amsterdam Attack\n",
      "   Training ID 3: A00 | Mean: 0.4903 | Anderssen's Opening\n",
      "   Training ID 4: A00 | Mean: 0.4197 | Anderssen's Opening: Polish Gambit\n"
     ]
    }
   ],
   "source": [
    "if white_stats_with_training_ids is not None:\n",
    "    opening_stats_dict = {}\n",
    "    \n",
    "    for idx, row in white_stats_with_training_ids.iterrows():\n",
    "        opening_stats_dict[int(row['training_id'])] = {\n",
    "            'opening_mean': float(row['opening_mean']),\n",
    "            'opening_total_games': int(row['opening_total_games']),\n",
    "            'opening_num_players': int(row['opening_num_players']),\n",
    "            'eco': str(row['eco']),\n",
    "            'name': str(row['name']),\n",
    "            'db_id': int(row['db_id'])\n",
    "        }\n",
    "    \n",
    "    print(\"Created opening stats dictionary\")\n",
    "    print(f\"   Total openings: {len(opening_stats_dict)}\")\n",
    "    print(f\"   Training ID range: [{min(opening_stats_dict.keys())}, {max(opening_stats_dict.keys())}]\")\n",
    "    \n",
    "    print(\"\\nSample entries:\")\n",
    "    for training_id in sorted(opening_stats_dict.keys())[:5]:\n",
    "        stats = opening_stats_dict[training_id]\n",
    "        print(f\"   Training ID {training_id}: {stats['eco']} | Mean: {stats['opening_mean']:.4f} | {stats['name']}\")\n",
    "else:\n",
    "    print(\"Skipping JSON creation - no merged data available\")\n",
    "    opening_stats_dict = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eebf7e6",
   "metadata": {},
   "source": [
    "## Step 9: Validate JSON Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6384da7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating JSON structure...\n",
      "\n",
      "All keys are integers: True\n",
      "All values have required fields: True\n",
      "\n",
      "Sample value structure:\n",
      "   opening_mean: float = 0.4634619800953727\n",
      "   opening_total_games: int = 25504\n",
      "   opening_num_players: int = 175\n",
      "   eco: str = A00\n",
      "   name: str = Amar Opening\n",
      "   db_id: int = 2\n",
      "\n",
      "No None/NaN values: True\n",
      "\n",
      "Opening mean range: [0.1667, 1.0000]\n",
      "All means in [0, 1]: True\n",
      "\n",
      "JSON structure validation complete\n"
     ]
    }
   ],
   "source": [
    "if opening_stats_dict is not None:\n",
    "    print(\"Validating JSON structure...\\n\")\n",
    "    \n",
    "    all_int_keys = all(isinstance(k, int) for k in opening_stats_dict.keys())\n",
    "    print(f\"All keys are integers: {all_int_keys}\")\n",
    "    \n",
    "    required_fields = ['opening_mean', 'opening_total_games', 'opening_num_players', 'eco', 'name', 'db_id']\n",
    "    all_have_fields = all(\n",
    "        all(field in v for field in required_fields) \n",
    "        for v in opening_stats_dict.values()\n",
    "    )\n",
    "    print(f\"All values have required fields: {all_have_fields}\")\n",
    "    \n",
    "    sample_value = list(opening_stats_dict.values())[0]\n",
    "    print(f\"\\nSample value structure:\")\n",
    "    for field, value in sample_value.items():\n",
    "        print(f\"   {field}: {type(value).__name__} = {value}\")\n",
    "    \n",
    "    has_none = any(\n",
    "        any(v is None or (isinstance(v, float) and pd.isna(v)) for v in vals.values())\n",
    "        for vals in opening_stats_dict.values()\n",
    "    )\n",
    "    print(f\"\\nNo None/NaN values: {not has_none}\")\n",
    "    \n",
    "    means = [v['opening_mean'] for v in opening_stats_dict.values()]\n",
    "    print(f\"\\nOpening mean range: [{min(means):.4f}, {max(means):.4f}]\")\n",
    "    all_in_range = all(0 <= m <= 1 for m in means)\n",
    "    print(f\"All means in [0, 1]: {all_in_range}\")\n",
    "    \n",
    "    print(\"\\nJSON structure validation complete\")\n",
    "else:\n",
    "    print(\"Skipping validation - no data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeb59b0",
   "metadata": {},
   "source": [
    "## Step 10: Check JSON Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c267f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-memory size: 73,808 bytes (72.08 KB)\n",
      "JSON size (with indent=2): 596,258 bytes (582.28 KB)\n",
      "JSON size (compact): 514,836 bytes (502.77 KB)\n",
      "\n",
      "First 500 characters of JSON:\n",
      "{\n",
      "  \"0\": {\n",
      "    \"opening_mean\": 0.4634619800953727,\n",
      "    \"opening_total_games\": 25504,\n",
      "    \"opening_num_players\": 175,\n",
      "    \"eco\": \"A00\",\n",
      "    \"name\": \"Amar Opening\",\n",
      "    \"db_id\": 2\n",
      "  },\n",
      "  \"1\": {\n",
      "    \"opening_mean\": 0.3940476190476191,\n",
      "    \"opening_total_games\": 47,\n",
      "    \"opening_num_players\": 2,\n",
      "    \"eco\": \"A00\",\n",
      "    \"name\": \"Amar Opening: Paris Gambit\",\n",
      "    \"db_id\": 3\n",
      "  },\n",
      "  \"2\": {\n",
      "    \"opening_mean\": 0.5158208458208459,\n",
      "    \"opening_total_games\": 188,\n",
      "    \"opening_num_players\": 7,\n",
      "    \"eco\": \"A00\"\n"
     ]
    }
   ],
   "source": [
    "if opening_stats_dict is not None:\n",
    "    import sys\n",
    "    \n",
    "    memory_size = sys.getsizeof(opening_stats_dict)\n",
    "    print(f\"In-memory size: {memory_size:,} bytes ({memory_size / 1024:.2f} KB)\")\n",
    "    \n",
    "    json_str = json.dumps(opening_stats_dict, indent=2)\n",
    "    json_size = len(json_str.encode('utf-8'))\n",
    "    print(f\"JSON size (with indent=2): {json_size:,} bytes ({json_size / 1024:.2f} KB)\")\n",
    "    \n",
    "    json_str_compact = json.dumps(opening_stats_dict)\n",
    "    json_size_compact = len(json_str_compact.encode('utf-8'))\n",
    "    print(f\"JSON size (compact): {json_size_compact:,} bytes ({json_size_compact / 1024:.2f} KB)\")\n",
    "    \n",
    "    print(\"\\nFirst 500 characters of JSON:\")\n",
    "    print(json_str[:500])\n",
    "else:\n",
    "    print(\"Skipping size check - no data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce6c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created COMPACT opening stats dictionary\n",
      "   Total openings: 2714\n",
      "   Training ID range: [0, 2713]\n",
      "\n",
      "Sample entries (format: training_id: [mean, total_games, db_id]):\n",
      "   0: [0.4634619800953727, 25504, 2]\n",
      "   1: [0.3940476190476191, 47, 3]\n",
      "   2: [0.5158208458208459, 188, 4]\n",
      "   3: [0.4902903075070408, 176356, 5]\n",
      "   4: [0.41973459917978634, 278, 6]\n",
      "\n",
      "Compact JSON size: 111,646 bytes (109.03 KB)\n",
      "\n",
      "First 500 characters:\n",
      "{\"0\": [0.4634619800953727, 25504, 2], \"1\": [0.3940476190476191, 47, 3], \"2\": [0.5158208458208459, 188, 4], \"3\": [0.4902903075070408, 176356, 5], \"4\": [0.41973459917978634, 278, 6], \"5\": [0.5825163398692811, 43, 8], \"6\": [0.46820955187875546, 9266, 9], \"7\": [0.4765635718961671, 146431, 10], \"8\": [0.633954678362573, 92, 11], \"9\": [0.4716806547539441, 6691, 12], \"10\": [0.4832428523506279, 26504, 13], \"11\": [0.46769160716878666, 56599, 17], \"12\": [0.49383976805361535, 11125, 18], \"13\": [0.4762156747\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if white_stats_with_training_ids is not None:\n",
    "    # COMPACT VERSION - just the essentials for Bayesian shrinkage\n",
    "    opening_stats_dict = {}\n",
    "\n",
    "    for idx, row in white_stats_with_training_ids.iterrows():\n",
    "        opening_stats_dict[int(row[\"training_id\"])] = [\n",
    "            float(row[\"opening_mean\"]),  # Index 0: mean score\n",
    "            int(row[\"opening_total_games\"]),  # Index 1: total games\n",
    "            int(row[\"db_id\"]),  # Index 2: db_id for reference\n",
    "        ]\n",
    "\n",
    "    print(\"Created COMPACT opening stats dictionary\")\n",
    "    print(f\"   Total openings: {len(opening_stats_dict)}\")\n",
    "    print(\n",
    "        f\"   Training ID range: [{min(opening_stats_dict.keys())}, {max(opening_stats_dict.keys())}]\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nSample entries (format: training_id: [mean, total_games, db_id]):\")\n",
    "    for training_id in sorted(opening_stats_dict.keys())[:5]:\n",
    "        stats = opening_stats_dict[training_id]\n",
    "        print(f\"   {training_id}: {stats}\")\n",
    "\n",
    "    # Size comparison\n",
    "    json_str_compact = json.dumps(opening_stats_dict)\n",
    "    json_size_compact = len(json_str_compact.encode(\"utf-8\"))\n",
    "    print(\n",
    "        f\"\\nCompact JSON size: {json_size_compact:,} bytes ({json_size_compact / 1024:.2f} KB)\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nFirst 500 characters:\")\n",
    "    print(json_str_compact[:500])\n",
    "else:\n",
    "    print(\"Skipping JSON creation - no merged data available\")\n",
    "    opening_stats_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19427e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9590f25f",
   "metadata": {},
   "source": [
    "## Step 11: Save JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3efb80fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved JSON to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/20251111_155428_white/opening_stats_white.json\n",
      "   File size: 160,500 bytes (156.74 KB)\n",
      "\n",
      "Verified file can be loaded\n",
      "   Loaded 2714 openings\n",
      "   Matches original: True\n"
     ]
    }
   ],
   "source": [
    "if opening_stats_dict is not None:\n",
    "    output_json_path = MODEL_ARTIFACTS_DIR / \"opening_stats_white.json\"\n",
    "    \n",
    "    with open(output_json_path, 'w') as f:\n",
    "        json.dump(opening_stats_dict, f, indent=2)\n",
    "    \n",
    "    print(f\"Saved JSON to: {output_json_path}\")\n",
    "    print(f\"   File size: {output_json_path.stat().st_size:,} bytes ({output_json_path.stat().st_size / 1024:.2f} KB)\")\n",
    "    \n",
    "    with open(output_json_path, 'r') as f:\n",
    "        loaded_dict = json.load(f)\n",
    "    \n",
    "    print(f\"\\nVerified file can be loaded\")\n",
    "    print(f\"   Loaded {len(loaded_dict)} openings\")\n",
    "    print(f\"   Matches original: {len(loaded_dict) == len(opening_stats_dict)}\")\n",
    "else:\n",
    "    print(\"Skipping save - no data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88717d4f",
   "metadata": {},
   "source": [
    "## Step 12: Save CSV File (for easy inspection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39548d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CSV to: /Users/a/Documents/personalprojects/chess-opening-recommender/data/models/20251111_155428_white/opening_stats_white.csv\n",
      "   File size: 255,700 bytes (249.71 KB)\n",
      "   Rows: 2714\n",
      "\n",
      "First 10 rows of CSV:\n",
      "   training_id  db_id  opening_id  eco                                name  \\\n",
      "0            0      2           2  A00                        Amar Opening   \n",
      "1            1      3           3  A00          Amar Opening: Paris Gambit   \n",
      "2            2      4           4  A00                    Amsterdam Attack   \n",
      "3            3      5           5  A00                 Anderssen's Opening   \n",
      "4            4      6           6  A00  Anderssen's Opening: Polish Gambit   \n",
      "5            5      8           8  A00       Barnes Opening: Gedult Gambit   \n",
      "6            6      9           9  A00        Barnes Opening: Hammerschlag   \n",
      "7            7     10          10  A00                     Clemenz Opening   \n",
      "8            8     11          11  A00   Clemenz Opening: Spike Lee Gambit   \n",
      "9            9     12          12  A00                        Crab Opening   \n",
      "\n",
      "   opening_mean  opening_total_games  opening_num_players  \n",
      "0      0.463462                25504                  175  \n",
      "1      0.394048                   47                    2  \n",
      "2      0.515821                  188                    7  \n",
      "3      0.490290               176356                  697  \n",
      "4      0.419735                  278                   11  \n",
      "5      0.582516                   43                    3  \n",
      "6      0.468210                 9266                   90  \n",
      "7      0.476564               146431                  763  \n",
      "8      0.633955                   92                    3  \n",
      "9      0.471681                 6691                   51  \n"
     ]
    }
   ],
   "source": [
    "if white_stats_with_training_ids is not None:\n",
    "    output_csv_path = MODEL_ARTIFACTS_DIR / \"opening_stats_white.csv\"\n",
    "    \n",
    "    csv_data = white_stats_with_training_ids[[\n",
    "        'training_id', 'db_id', 'opening_id', 'eco', 'name', \n",
    "        'opening_mean', 'opening_total_games', 'opening_num_players'\n",
    "    ]].sort_values('training_id')\n",
    "    \n",
    "    csv_data.to_csv(output_csv_path, index=False)\n",
    "    \n",
    "    print(f\"Saved CSV to: {output_csv_path}\")\n",
    "    print(f\"   File size: {output_csv_path.stat().st_size:,} bytes ({output_csv_path.stat().st_size / 1024:.2f} KB)\")\n",
    "    print(f\"   Rows: {len(csv_data)}\")\n",
    "    \n",
    "    print(\"\\nFirst 10 rows of CSV:\")\n",
    "    print(csv_data.head(10))\n",
    "else:\n",
    "    print(\"Skipping CSV save - no data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbabb44c",
   "metadata": {},
   "source": [
    "## Step 13: Test Loading and Using the JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ea7d299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing practical usage of opening_stats.json...\n",
      "\n",
      "Simulating inference lookup:\n",
      "\n",
      "   Training ID 0:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m stats = opening_stats_dict[training_id]\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m   Training ID \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m      ECO: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mstats\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43meco\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m      Name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstats[\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m      Opening mean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstats[\u001b[33m'\u001b[39m\u001b[33mopening_mean\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "if opening_stats_dict is not None:\n",
    "    print(\"Testing practical usage of opening_stats.json...\\n\")\n",
    "    \n",
    "    test_training_ids = list(opening_stats_dict.keys())[:5]\n",
    "    \n",
    "    print(\"Simulating inference lookup:\")\n",
    "    for training_id in test_training_ids:\n",
    "        stats = opening_stats_dict[training_id]\n",
    "        print(f\"\\n   Training ID {training_id}:\")\n",
    "        print(f\"      ECO: {stats['eco']}\")\n",
    "        print(f\"      Name: {stats['name']}\")\n",
    "        print(f\"      Opening mean: {stats['opening_mean']:.4f}\")\n",
    "        print(f\"      Total games: {stats['opening_total_games']}\")\n",
    "        print(f\"      Num players: {stats['opening_num_players']}\")\n",
    "    \n",
    "    print(\"\\n\\nSimulating Bayesian shrinkage calculation:\")\n",
    "    k = 50\n",
    "    \n",
    "    player_games = 15\n",
    "    player_raw_score = 0.6\n",
    "    training_id = test_training_ids[0]\n",
    "    opening_mean = opening_stats_dict[training_id]['opening_mean']\n",
    "    \n",
    "    adjusted_score = (\n",
    "        (player_games * player_raw_score) + (k * opening_mean)\n",
    "    ) / (player_games + k)\n",
    "    \n",
    "    confidence = player_games / (player_games + k)\n",
    "    \n",
    "    print(f\"   Player: {player_games} games, raw score = {player_raw_score:.4f}\")\n",
    "    print(f\"   Opening: {opening_stats_dict[training_id]['eco']} (training_id={training_id})\")\n",
    "    print(f\"   Opening mean: {opening_mean:.4f}\")\n",
    "    print(f\"   Adjusted score: {adjusted_score:.4f}\")\n",
    "    print(f\"   Confidence: {confidence:.4f}\")\n",
    "    print(f\"   Adjustment: {adjusted_score - player_raw_score:+.4f}\")\n",
    "    \n",
    "    print(\"\\nAll tests passed!\")\n",
    "else:\n",
    "    print(\"Skipping usage test - no data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea96eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opening_stats_dict is not None and white_stats_with_training_ids is not None:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SPOT CHECK: Verifying Opening Stats Integrity\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Select 200 random entries to verify\n",
    "    import random\n",
    "\n",
    "    random.seed(42)  # For reproducibility\n",
    "\n",
    "    all_training_ids = list(opening_stats_dict.keys())\n",
    "    sample_size = min(200, len(all_training_ids))\n",
    "    sample_training_ids = random.sample(all_training_ids, sample_size)\n",
    "\n",
    "    print(f\"\\nSpot checking {sample_size} random entries...\")\n",
    "\n",
    "    # Create lookup from white_stats_with_training_ids for verification\n",
    "    verification_df = white_stats_with_training_ids.set_index(\"training_id\")\n",
    "\n",
    "    mismatches = []\n",
    "\n",
    "    for i, training_id in enumerate(sample_training_ids, 1):\n",
    "        # Get data from compact JSON\n",
    "        json_data = opening_stats_dict[training_id]\n",
    "        json_mean = json_data[0]\n",
    "        json_total_games = json_data[1]\n",
    "        json_db_id = json_data[2]\n",
    "\n",
    "        # Get data from original DataFrame\n",
    "        df_row = verification_df.loc[training_id]\n",
    "        df_mean = float(df_row[\"opening_mean\"])\n",
    "        df_total_games = int(df_row[\"opening_total_games\"])\n",
    "        df_db_id = int(df_row[\"db_id\"])\n",
    "        df_eco = df_row[\"eco\"]\n",
    "        df_name = df_row[\"name\"]\n",
    "\n",
    "        # Check for mismatches\n",
    "        mean_match = abs(json_mean - df_mean) < 1e-6  # Float comparison with tolerance\n",
    "        games_match = json_total_games == df_total_games\n",
    "        db_id_match = json_db_id == df_db_id\n",
    "\n",
    "        if not (mean_match and games_match and db_id_match):\n",
    "            mismatches.append(\n",
    "                {\n",
    "                    \"training_id\": training_id,\n",
    "                    \"issue\": \"DATA_MISMATCH\",\n",
    "                    \"json_data\": json_data,\n",
    "                    \"df_data\": [df_mean, df_total_games, df_db_id],\n",
    "                    \"eco\": df_eco,\n",
    "                    \"name\": df_name,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Print progress every 50 entries\n",
    "        if i % 50 == 0:\n",
    "            print(f\"   Checked {i}/{sample_size} entries...\")\n",
    "\n",
    "    print(f\"\\n✓ Spot check complete!\")\n",
    "    print(f\"   Total entries checked: {sample_size}\")\n",
    "    print(f\"   Mismatches found: {len(mismatches)}\")\n",
    "\n",
    "    if mismatches:\n",
    "        print(f\"\\n❌ WARNING: Found {len(mismatches)} mismatches!\")\n",
    "        print(\"\\nFirst 10 mismatches:\")\n",
    "        for mismatch in mismatches[:10]:\n",
    "            print(f\"\\n   Training ID {mismatch['training_id']}:\")\n",
    "            print(f\"      Opening: {mismatch['eco']} - {mismatch['name']}\")\n",
    "            print(f\"      JSON data:  {mismatch['json_data']}\")\n",
    "            print(f\"      DataFrame:  {mismatch['df_data']}\")\n",
    "            print(f\"      Issue: {mismatch['issue']}\")\n",
    "    else:\n",
    "        print(f\"\\n✓ All {sample_size} entries verified successfully!\")\n",
    "        print(\"   JSON data matches source DataFrame exactly\")\n",
    "\n",
    "    # Additional verification: Check a few specific entries in detail\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DETAILED VERIFICATION: Sample Entries\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    detail_sample = sample_training_ids[:5]\n",
    "\n",
    "    for training_id in detail_sample:\n",
    "        json_data = opening_stats_dict[training_id]\n",
    "        df_row = verification_df.loc[training_id]\n",
    "\n",
    "        print(f\"\\n Training ID: {training_id}\")\n",
    "        print(f\"   ECO: {df_row['eco']}\")\n",
    "        print(f\"   Name: {df_row['name']}\")\n",
    "        print(f\"   DB ID: {df_row['db_id']}\")\n",
    "        print(f\"\\n   Compact JSON array: {json_data}\")\n",
    "        print(f\"   Decoded:\")\n",
    "        print(f\"      [0] Opening mean: {json_data[0]:.6f}\")\n",
    "        print(f\"      [1] Total games: {json_data[1]:,}\")\n",
    "        print(f\"      [2] DB ID: {json_data[2]}\")\n",
    "        print(f\"\\n   DataFrame values:\")\n",
    "        print(f\"      Opening mean: {df_row['opening_mean']:.6f}\")\n",
    "        print(f\"      Total games: {df_row['opening_total_games']:,}\")\n",
    "        print(f\"      DB ID: {df_row['db_id']}\")\n",
    "        print(f\"      Num players: {df_row['opening_num_players']}\")\n",
    "\n",
    "        # Verify match\n",
    "        mean_match = abs(json_data[0] - df_row[\"opening_mean\"]) < 1e-6\n",
    "        games_match = json_data[1] == df_row[\"opening_total_games\"]\n",
    "        db_match = json_data[2] == df_row[\"db_id\"]\n",
    "\n",
    "        if mean_match and games_match and db_match:\n",
    "            print(f\"   ✓ All fields match\")\n",
    "        else:\n",
    "            print(f\"   ❌ MISMATCH DETECTED\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Spot check complete - JSON is ready for production\")\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    print(\"Skipping spot check - no data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f538094",
   "metadata": {},
   "source": [
    "## Step 14: Calculate Stats for Black Openings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd04d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_stats = calculate_opening_stats('black', min_games_threshold=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ea9e24",
   "metadata": {},
   "source": [
    "## Step 15: Process and Save Black Opening Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295a6572",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BLACK OPENING STATS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nTo process black openings:\")\n",
    "print(\"   1. Set MODEL_DIR_NAME to your black model directory\")\n",
    "print(\"   2. Load the black opening_mappings.csv\")\n",
    "print(\"   3. Repeat the merge, JSON creation, and save steps\")\n",
    "print(\"\\nBlack stats preview:\")\n",
    "print(black_stats.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39353de3",
   "metadata": {},
   "source": [
    "## Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf591611",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if opening_stats_dict is not None:\n",
    "    print(f\"\\nSuccessfully created opening_stats_white.json\")\n",
    "    print(f\"   Location: {MODEL_ARTIFACTS_DIR / 'opening_stats_white.json'}\")\n",
    "    print(f\"   Total openings: {len(opening_stats_dict)}\")\n",
    "    print(f\"   File size: {(MODEL_ARTIFACTS_DIR / 'opening_stats_white.json').stat().st_size / 1024:.2f} KB\")\n",
    "    \n",
    "    print(f\"\\nAlso created opening_stats_white.csv for inspection\")\n",
    "    print(f\"   Location: {MODEL_ARTIFACTS_DIR / 'opening_stats_white.csv'}\")\n",
    "    \n",
    "    print(f\"\\nNext steps:\")\n",
    "    print(f\"   1. Copy these files to your production model artifacts directory\")\n",
    "    print(f\"   2. Update inference pipeline to load opening_stats.json at startup\")\n",
    "    print(f\"   3. Use opening_mean values for Bayesian shrinkage during inference\")\n",
    "    print(f\"   4. Repeat for black openings (update MODEL_DIR_NAME and re-run)\")\n",
    "else:\n",
    "    print(f\"\\nNo files created\")\n",
    "    print(f\"   Make sure opening_mappings.csv exists in your model directory\")\n",
    "    print(f\"   Update MODEL_DIR_NAME to point to the correct model\")\n",
    "    print(f\"   Re-run the notebook\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NOTEBOOK COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61bf275",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n",
    "print(\"Database connection closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
