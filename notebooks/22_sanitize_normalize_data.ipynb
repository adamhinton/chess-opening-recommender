{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68168372",
   "metadata": {},
   "source": [
    "# Data Sanitization and Normalization\n",
    "\n",
    "## Purpose\n",
    "This notebook is designed to sanitize and normalize the chess database by removing inefficiencies, redundancies, and outliers that could negatively impact the quality of opening recommendations. The goal is to clean up the data while preserving the most valuable information for the chess opening recommender system.\n",
    "\n",
    "## Key Areas of Focus\n",
    "- **Redundant Opening Names**: Consolidate openings that share the same name but have different ECO codes\n",
    "- **Data Inefficiencies**: Remove or consolidate records that provide minimal analytical value\n",
    "- **Outliers**: Identify and handle extreme cases that might skew recommendations\n",
    "- **Database Optimization**: Reduce storage footprint while maintaining data integrity\n",
    "\n",
    "## Process Overview\n",
    "1. **Baseline Analysis**: Establish current database statistics and size metrics\n",
    "2. **Identify Redundancies**: Find opening names with multiple ECO codes\n",
    "3. **Data Consolidation**: Merge redundant records while preserving statistical accuracy\n",
    "4. **Quality Validation**: Verify that changes maintain data integrity\n",
    "5. **Performance Optimization**: Measure improvements in database size and query performance\n",
    "\n",
    "This systematic approach ensures that the database becomes more efficient and reliable for generating chess opening recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48d5e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration and setup\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from utils.database.db_utils import get_db_connection\n",
    "\n",
    "# Define the path to the DuckDB database file\n",
    "project_root = Path.cwd().parent if \"notebooks\" in str(Path.cwd()) else Path.cwd()\n",
    "db_path = project_root / \"data\" / \"processed\" / \"chess_games.db\"\n",
    "\n",
    "# Set pandas display options for better readability\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(f\"Database path: {db_path}\")\n",
    "print(f\"Database exists: {db_path.exists()}\")\n",
    "\n",
    "def log_database_statistics():\n",
    "    \"\"\"\n",
    "    Log comprehensive database statistics including table sizes, record counts,\n",
    "    file size, and key metrics. This function can be called repeatedly to track\n",
    "    changes as we sanitize and normalize the data.\n",
    "    \"\"\"\n",
    "    if not db_path.exists():\n",
    "        print(f\"Database file not found at {db_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get database file size\n",
    "    db_size_bytes = os.path.getsize(db_path)\n",
    "    db_size_mb = db_size_bytes / (1024 * 1024)\n",
    "    db_size_gb = db_size_mb / 1024\n",
    "    \n",
    "    with get_db_connection(db_path) as con:\n",
    "        print(\"=\" * 60)\n",
    "        print(\"DATABASE STATISTICS SNAPSHOT\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # File size information\n",
    "        print(f\"\\n--- Database File Size ---\")\n",
    "        print(f\"Size: {db_size_mb:,.1f} MB ({db_size_gb:.2f} GB)\")\n",
    "        print(f\"Raw bytes: {db_size_bytes:,}\")\n",
    "        \n",
    "        # Core table counts\n",
    "        print(f\"\\n--- Core Tables ---\")\n",
    "        player_count = con.execute('SELECT COUNT(*) FROM player').fetchone()[0]\n",
    "        opening_count = con.execute('SELECT COUNT(*) FROM opening').fetchone()[0]\n",
    "        total_stats_records = con.execute('SELECT COUNT(*) FROM player_opening_stats').fetchone()[0]\n",
    "        \n",
    "        print(f\"Players: {player_count:,}\")\n",
    "        print(f\"Openings: {opening_count:,}\")\n",
    "        print(f\"Player-Opening-Stats Records: {total_stats_records:,}\")\n",
    "        \n",
    "        # Partition distribution\n",
    "        print(f\"\\n--- Partition Distribution ---\")\n",
    "        partitions = ['A', 'B', 'C', 'D', 'E', 'other']\n",
    "        total_partition_records = 0\n",
    "        \n",
    "        for partition in partitions:\n",
    "            count = con.execute(f'SELECT COUNT(*) FROM player_opening_stats_{partition}').fetchone()[0]\n",
    "            total_partition_records += count\n",
    "            percentage = (count / total_stats_records * 100) if total_stats_records > 0 else 0\n",
    "            print(f\"  Partition {partition}: {count:,} ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Game statistics\n",
    "        print(f\"\\n--- Game Statistics ---\")\n",
    "        total_games = con.execute(\"\"\"\n",
    "            SELECT SUM(num_wins + num_draws + num_losses) as total_games\n",
    "            FROM player_opening_stats\n",
    "        \"\"\").fetchone()[0]\n",
    "        \n",
    "        total_wins = con.execute('SELECT SUM(num_wins) FROM player_opening_stats').fetchone()[0]\n",
    "        total_draws = con.execute('SELECT SUM(num_draws) FROM player_opening_stats').fetchone()[0]\n",
    "        total_losses = con.execute('SELECT SUM(num_losses) FROM player_opening_stats').fetchone()[0]\n",
    "        \n",
    "        print(f\"Total Games: {total_games:,}\")\n",
    "        print(f\"  Wins: {total_wins:,} ({total_wins/total_games*100:.1f}%)\")\n",
    "        print(f\"  Draws: {total_draws:,} ({total_draws/total_games*100:.1f}%)\")\n",
    "        print(f\"  Losses: {total_losses:,} ({total_losses/total_games*100:.1f}%)\")\n",
    "        print(f\"Average Games per Record: {total_games/total_stats_records:.1f}\")\n",
    "        \n",
    "        # Color distribution\n",
    "        print(f\"\\n--- Color Distribution ---\")\n",
    "        white_records = con.execute(\"SELECT COUNT(*) FROM player_opening_stats WHERE color = 'w'\").fetchone()[0]\n",
    "        black_records = con.execute(\"SELECT COUNT(*) FROM player_opening_stats WHERE color = 'b'\").fetchone()[0]\n",
    "        \n",
    "        print(f\"White Records: {white_records:,} ({white_records/total_stats_records*100:.1f}%)\")\n",
    "        print(f\"Black Records: {black_records:,} ({black_records/total_stats_records*100:.1f}%)\")\n",
    "        \n",
    "        # Opening name duplication check\n",
    "        print(f\"\\n--- Opening Name Analysis ---\")\n",
    "        unique_names = con.execute('SELECT COUNT(DISTINCT name) FROM opening').fetchone()[0]\n",
    "        duplicate_names_count = con.execute(\"\"\"\n",
    "            SELECT COUNT(*) FROM (\n",
    "                SELECT name, COUNT(DISTINCT eco) as eco_count\n",
    "                FROM opening\n",
    "                GROUP BY name\n",
    "                HAVING COUNT(DISTINCT eco) > 1\n",
    "            ) duplicate_check\n",
    "        \"\"\").fetchone()[0]\n",
    "        \n",
    "        print(f\"Unique Opening Names: {unique_names:,}\")\n",
    "        print(f\"Names with Multiple ECO Codes: {duplicate_names_count:,}\")\n",
    "        print(f\"Name Duplication Rate: {duplicate_names_count/unique_names*100:.1f}%\")\n",
    "        \n",
    "        # Storage efficiency metrics\n",
    "        print(f\"\\n--- Storage Efficiency ---\")\n",
    "        bytes_per_record = db_size_bytes / total_stats_records if total_stats_records > 0 else 0\n",
    "        bytes_per_game = db_size_bytes / total_games if total_games > 0 else 0\n",
    "        \n",
    "        print(f\"Bytes per Stats Record: {bytes_per_record:.1f}\")\n",
    "        print(f\"Bytes per Game: {bytes_per_game:.2f}\")\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(\"END STATISTICS SNAPSHOT\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "# Log initial database state\n",
    "log_database_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb6eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all opening names with multiple ECO codes (duplicated names)\n",
    "# This replicates the analysis from notebook 21 to identify consolidation opportunities\n",
    "\n",
    "if db_path.exists():\n",
    "    with get_db_connection(db_path) as con:\n",
    "        print(\"=== IDENTIFYING OPENING NAMES WITH MULTIPLE ECO CODES ===\")\n",
    "        print(\"This analysis will help us understand which openings can be consolidated.\\n\")\n",
    "        \n",
    "        # Find opening names that appear with multiple ECO codes\n",
    "        duplicate_names_query = \"\"\"\n",
    "            SELECT \n",
    "                name,\n",
    "                COUNT(DISTINCT eco) as eco_count,\n",
    "                STRING_AGG(DISTINCT eco, ', ' ORDER BY eco) as eco_codes,\n",
    "                COUNT(*) as total_opening_records,\n",
    "                SUM(total_games) as combined_games,\n",
    "                SUM(unique_players) as combined_players,\n",
    "                SUM(stats_records) as total_stats_records\n",
    "            FROM (\n",
    "                SELECT \n",
    "                    o.name,\n",
    "                    o.eco,\n",
    "                    o.id as opening_id,\n",
    "                    SUM(pos.num_wins + pos.num_draws + pos.num_losses) as total_games,\n",
    "                    COUNT(DISTINCT pos.player_id) as unique_players,\n",
    "                    COUNT(*) as stats_records\n",
    "                FROM opening o\n",
    "                JOIN player_opening_stats pos ON o.id = pos.opening_id\n",
    "                GROUP BY o.id, o.name, o.eco\n",
    "            ) stats\n",
    "            GROUP BY name\n",
    "            HAVING COUNT(DISTINCT eco) > 1\n",
    "            ORDER BY eco_count DESC, combined_games DESC\n",
    "        \"\"\"\n",
    "        \n",
    "        duplicate_names_df = con.execute(duplicate_names_query).fetchdf()\n",
    "        \n",
    "        if len(duplicate_names_df) > 0:\n",
    "            print(f\"Found {len(duplicate_names_df)} opening names with multiple ECO codes:\\n\")\n",
    "            \n",
    "            # Format the summary display\n",
    "            summary_display = duplicate_names_df.copy()\n",
    "            summary_display['total_opening_records'] = summary_display['total_opening_records'].apply('{:,}'.format)\n",
    "            summary_display['combined_games'] = summary_display['combined_games'].apply('{:,}'.format)\n",
    "            summary_display['combined_players'] = summary_display['combined_players'].apply('{:,}'.format)\n",
    "            summary_display['total_stats_records'] = summary_display['total_stats_records'].apply('{:,}'.format)\n",
    "            \n",
    "            # Rename columns for better display\n",
    "            summary_display.columns = [\n",
    "                'Opening Name', 'ECO Count', 'ECO Codes', 'Opening Records', \n",
    "                'Total Games', 'Total Players', 'Stats Records'\n",
    "            ]\n",
    "            \n",
    "            print(\"--- SUMMARY OF ALL DUPLICATED OPENING NAMES ---\")\n",
    "            print(summary_display.to_string(index=False))\n",
    "            \n",
    "            # Store the raw data for use in subsequent cells\n",
    "            duplicate_openings_raw = duplicate_names_df.copy()\n",
    "            \n",
    "            # Show detailed breakdown for top 10 most complex cases\n",
    "            print(f\"\\n=== DETAILED BREAKDOWN FOR TOP 10 MOST COMPLEX CASES ===\")\n",
    "            print(\"This shows exactly which ECO codes belong to each duplicated name.\\n\")\n",
    "            \n",
    "            top_complex_names = duplicate_names_df.head(10)['name'].tolist()\n",
    "            \n",
    "            detailed_breakdowns = {}\n",
    "            \n",
    "            for i, name in enumerate(top_complex_names, 1):\n",
    "                print(f\"{i}. '{name}'\")\n",
    "                print(\"-\" * (len(name) + 10))\n",
    "                \n",
    "                detailed_query = \"\"\"\n",
    "                    SELECT \n",
    "                        o.eco,\n",
    "                        o.id as opening_id,\n",
    "                        SUM(pos.num_wins + pos.num_draws + pos.num_losses) as total_games,\n",
    "                        COUNT(DISTINCT pos.player_id) as unique_players,\n",
    "                        COUNT(*) as stats_records,\n",
    "                        -- White performance\n",
    "                        SUM(CASE WHEN pos.color = 'w' THEN pos.num_wins + pos.num_draws + pos.num_losses ELSE 0 END) as white_games,\n",
    "                        ROUND(SUM(CASE WHEN pos.color = 'w' THEN pos.num_wins ELSE 0 END) * 100.0 / \n",
    "                              NULLIF(SUM(CASE WHEN pos.color = 'w' THEN pos.num_wins + pos.num_draws + pos.num_losses ELSE 0 END), 0), 1) as white_win_pct,\n",
    "                        -- Black performance  \n",
    "                        SUM(CASE WHEN pos.color = 'b' THEN pos.num_wins + pos.num_draws + pos.num_losses ELSE 0 END) as black_games,\n",
    "                        ROUND(SUM(CASE WHEN pos.color = 'b' THEN pos.num_wins ELSE 0 END) * 100.0 / \n",
    "                              NULLIF(SUM(CASE WHEN pos.color = 'b' THEN pos.num_wins + pos.num_draws + pos.num_losses ELSE 0 END), 0), 1) as black_win_pct\n",
    "                    FROM opening o\n",
    "                    JOIN player_opening_stats pos ON o.id = pos.opening_id\n",
    "                    WHERE o.name = ?\n",
    "                    GROUP BY o.id, o.eco\n",
    "                    ORDER BY total_games DESC\n",
    "                \"\"\"\n",
    "                \n",
    "                breakdown_df = con.execute(detailed_query, [name]).fetchdf()\n",
    "                detailed_breakdowns[name] = breakdown_df.copy()\n",
    "                \n",
    "                # Format for display\n",
    "                breakdown_display = breakdown_df.copy()\n",
    "                breakdown_display['total_games'] = breakdown_display['total_games'].apply('{:,}'.format)\n",
    "                breakdown_display['unique_players'] = breakdown_display['unique_players'].apply('{:,}'.format)\n",
    "                breakdown_display['stats_records'] = breakdown_display['stats_records'].apply('{:,}'.format)\n",
    "                breakdown_display['white_games'] = breakdown_display['white_games'].apply('{:,}'.format)\n",
    "                breakdown_display['black_games'] = breakdown_display['black_games'].apply('{:,}'.format)\n",
    "                \n",
    "                # Remove opening_id from display (keep for internal use)\n",
    "                display_cols = ['eco', 'total_games', 'unique_players', 'stats_records', \n",
    "                               'white_games', 'white_win_pct', 'black_games', 'black_win_pct']\n",
    "                breakdown_display = breakdown_display[display_cols]\n",
    "                breakdown_display.columns = ['ECO', 'Total Games', 'Players', 'Stats Records',\n",
    "                                           'White Games', 'White Win%', 'Black Games', 'Black Win%']\n",
    "                \n",
    "                print(breakdown_display.to_string(index=False))\n",
    "                print()  # Empty line for readability\n",
    "            \n",
    "            # Calculate and display potential consolidation impact\n",
    "            print(\"=== CONSOLIDATION IMPACT SUMMARY ===\")\n",
    "            \n",
    "            total_duplicated_names = len(duplicate_names_df)\n",
    "            total_affected_games = duplicate_names_df['combined_games'].sum()\n",
    "            total_affected_players = duplicate_names_df['combined_players'].sum()\n",
    "            total_opening_records = duplicate_names_df['total_opening_records'].sum()\n",
    "            total_stats_records_affected = duplicate_names_df['total_stats_records'].sum()\n",
    "            \n",
    "            # Get overall database stats for percentages\n",
    "            total_openings = con.execute('SELECT COUNT(*) FROM opening').fetchone()[0]\n",
    "            total_all_stats_records = con.execute('SELECT COUNT(*) FROM player_opening_stats').fetchone()[0]\n",
    "            \n",
    "            opening_reduction = total_opening_records - total_duplicated_names\n",
    "            opening_reduction_pct = (opening_reduction / total_openings * 100) if total_openings > 0 else 0\n",
    "            \n",
    "            print(f\"Names with multiple ECO codes: {total_duplicated_names:,}\")\n",
    "            print(f\"Total affected games: {total_affected_games:,}\")\n",
    "            print(f\"Total affected players: {total_affected_players:,}\")\n",
    "            print(f\"Opening table records affected: {total_opening_records:,}\")\n",
    "            print(f\"Stats records affected: {total_stats_records_affected:,} ({total_stats_records_affected/total_all_stats_records*100:.1f}% of total)\")\n",
    "            print(f\"\\nPotential opening table reduction: {opening_reduction:,} records ({opening_reduction_pct:.1f}%)\")\n",
    "            print(f\"Remaining openings after consolidation: {total_openings - opening_reduction:,}\")\n",
    "            \n",
    "            # Store data for next cells\n",
    "            print(f\"\\n✓ Data prepared for consolidation analysis in next cells\")\n",
    "            print(f\"✓ Found {total_duplicated_names} opening names ready for potential consolidation\")\n",
    "            print(f\"✓ Detailed breakdowns available for top {len(top_complex_names)} most complex cases\")\n",
    "            \n",
    "        else:\n",
    "            print(\"No opening names found with multiple ECO codes.\")\n",
    "            print(\"All opening names have unique ECO code assignments.\")\n",
    "            duplicate_openings_raw = pd.DataFrame()\n",
    "            detailed_breakdowns = {}\n",
    "    \n",
    "else:\n",
    "    print(f\"Database file not found at {db_path}\")\n",
    "    duplicate_openings_raw = pd.DataFrame()\n",
    "    detailed_breakdowns = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b966fa",
   "metadata": {},
   "source": [
    "## Opening Popularity Analysis\n",
    "\n",
    "Now that we've cleaned up the database, let's analyze which openings are most and least popular. This analysis helps us understand:\n",
    "- Which openings have the most statistical significance\n",
    "- Which openings might need more data\n",
    "- Distribution patterns across the opening repertoire\n",
    "\n",
    "We'll look at both the most-played and least-played openings to get a complete picture of the database coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965ce254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for opening popularity analysis\n",
    "# Adjust these variables to control how many results to display\n",
    "\n",
    "# Number of most-played openings to show\n",
    "TOP_N_MOST_PLAYED = 200\n",
    "\n",
    "# Number of least-played openings to show\n",
    "TOP_N_LEAST_PLAYED = 500\n",
    "\n",
    "# Minimum games threshold for percentile analysis\n",
    "MIN_GAMES_FOR_PERCENTILE = 50\n",
    "\n",
    "print(\"=== OPENING POPULARITY ANALYSIS CONFIGURATION ===\")\n",
    "print(f\"Most-played openings to display: {TOP_N_MOST_PLAYED}\")\n",
    "print(f\"Least-played openings to display: {TOP_N_LEAST_PLAYED}\")\n",
    "print(f\"Minimum games for percentile analysis: {MIN_GAMES_FOR_PERCENTILE}\")\n",
    "print(f\"\\nYou can modify these variables at the top of this cell to change the analysis scope.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc83827",
   "metadata": {},
   "source": [
    "## Most-Played Openings\n",
    "\n",
    "These are the openings with the highest number of total games across all players. These openings have the most statistical significance and are the most common in our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcae318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most-played openings by total number of games\n",
    "if db_path.exists():\n",
    "    with get_db_connection(db_path) as con:\n",
    "        print(f\"=== TOP {TOP_N_MOST_PLAYED} MOST-PLAYED OPENINGS BY TOTAL GAMES ===\\n\")\n",
    "        \n",
    "        most_played = con.execute(f\"\"\"\n",
    "            SELECT \n",
    "                o.eco,\n",
    "                o.name,\n",
    "                SUM(pos.num_wins + pos.num_draws + pos.num_losses) as total_games,\n",
    "                COUNT(DISTINCT pos.player_id) as unique_players,\n",
    "                -- Overall results\n",
    "                SUM(pos.num_wins) as total_wins,\n",
    "                SUM(pos.num_draws) as total_draws,\n",
    "                SUM(pos.num_losses) as total_losses,\n",
    "                -- White's performance\n",
    "                COUNT(DISTINCT CASE WHEN pos.color = 'w' THEN pos.player_id END) as white_players,\n",
    "                SUM(CASE WHEN pos.color = 'w' THEN pos.num_wins ELSE 0 END) as white_wins,\n",
    "                SUM(CASE WHEN pos.color = 'w' THEN pos.num_draws ELSE 0 END) as white_draws,\n",
    "                SUM(CASE WHEN pos.color = 'w' THEN pos.num_losses ELSE 0 END) as white_losses,\n",
    "                SUM(CASE WHEN pos.color = 'w' THEN pos.num_wins + pos.num_draws + pos.num_losses ELSE 0 END) as white_games,\n",
    "                -- Black's performance\n",
    "                COUNT(DISTINCT CASE WHEN pos.color = 'b' THEN pos.player_id END) as black_players,\n",
    "                SUM(CASE WHEN pos.color = 'b' THEN pos.num_wins ELSE 0 END) as black_wins,\n",
    "                SUM(CASE WHEN pos.color = 'b' THEN pos.num_draws ELSE 0 END) as black_draws,\n",
    "                SUM(CASE WHEN pos.color = 'b' THEN pos.num_losses ELSE 0 END) as black_losses,\n",
    "                SUM(CASE WHEN pos.color = 'b' THEN pos.num_wins + pos.num_draws + pos.num_losses ELSE 0 END) as black_games,\n",
    "                -- Win percentages by color\n",
    "                ROUND(SUM(CASE WHEN pos.color = 'w' THEN pos.num_wins ELSE 0 END) * 100.0 / \n",
    "                      NULLIF(SUM(CASE WHEN pos.color = 'w' THEN pos.num_wins + pos.num_draws + pos.num_losses ELSE 0 END), 0), 2) as white_win_pct,\n",
    "                ROUND(SUM(CASE WHEN pos.color = 'b' THEN pos.num_wins ELSE 0 END) * 100.0 / \n",
    "                      NULLIF(SUM(CASE WHEN pos.color = 'b' THEN pos.num_wins + pos.num_draws + pos.num_losses ELSE 0 END), 0), 2) as black_win_pct,\n",
    "                -- Overall win percentage (from both colors)\n",
    "                ROUND(SUM(pos.num_wins) * 100.0 / \n",
    "                      NULLIF(SUM(pos.num_wins + pos.num_draws + pos.num_losses), 0), 2) as overall_win_pct,\n",
    "                ROUND(SUM(pos.num_draws) * 100.0 / \n",
    "                      NULLIF(SUM(pos.num_wins + pos.num_draws + pos.num_losses), 0), 2) as overall_draw_pct,\n",
    "                ROUND(SUM(pos.num_losses) * 100.0 / \n",
    "                      NULLIF(SUM(pos.num_wins + pos.num_draws + pos.num_losses), 0), 2) as overall_loss_pct\n",
    "            FROM opening o\n",
    "            JOIN player_opening_stats pos ON o.id = pos.opening_id\n",
    "            GROUP BY o.id, o.eco, o.name\n",
    "            ORDER BY total_games DESC\n",
    "            LIMIT {TOP_N_MOST_PLAYED}\n",
    "        \"\"\").fetchdf()\n",
    "        \n",
    "        # Format the display\n",
    "        display_df = most_played.copy()\n",
    "        \n",
    "        # Format number columns with thousands separators\n",
    "        for col in ['total_games', 'unique_players', 'total_wins', 'total_draws', 'total_losses',\n",
    "                   'white_players', 'white_wins', 'white_draws', 'white_losses', 'white_games',\n",
    "                   'black_players', 'black_wins', 'black_draws', 'black_losses', 'black_games']:\n",
    "            display_df[col] = display_df[col].apply('{:,}'.format)\n",
    "        \n",
    "        # Rename columns for better display\n",
    "        display_df.columns = [\n",
    "            'ECO', 'Opening Name', 'Total Games', 'Unique Players',\n",
    "            'Total Wins', 'Total Draws', 'Total Losses',\n",
    "            'White Players', 'White Wins', 'White Draws', 'White Losses', 'White Games',\n",
    "            'Black Players', 'Black Wins', 'Black Draws', 'Black Losses', 'Black Games',\n",
    "            'White Win %', 'Black Win %', 'Overall Win %', 'Overall Draw %', 'Overall Loss %'\n",
    "        ]\n",
    "        \n",
    "        print(display_df.to_string(index=False))\n",
    "        \n",
    "        # Summary statistics\n",
    "        total_games_in_results = most_played['total_games'].sum()\n",
    "        avg_games_per_opening = most_played['total_games'].mean()\n",
    "        median_games_per_opening = most_played['total_games'].median()\n",
    "        avg_players_per_opening = most_played['unique_players'].mean()\n",
    "        median_players_per_opening = most_played['unique_players'].median()\n",
    "        \n",
    "        print(f\"\\n--- Summary Statistics for Top {TOP_N_MOST_PLAYED} Most-Played Openings ---\")\n",
    "        print(f\"Total games in these openings: {total_games_in_results:,}\")\n",
    "        print(f\"Average games per opening: {avg_games_per_opening:,.1f}\")\n",
    "        print(f\"Median games per opening: {median_games_per_opening:,.1f}\")\n",
    "        print(f\"Min games: {most_played['total_games'].min():,}\")\n",
    "        print(f\"Max games: {most_played['total_games'].max():,}\")\n",
    "        print(f\"\\nAverage unique players per opening: {avg_players_per_opening:,.1f}\")\n",
    "        print(f\"Median unique players per opening: {median_players_per_opening:,.1f}\")\n",
    "        print(f\"Min players: {most_played['unique_players'].min():,}\")\n",
    "        print(f\"Max players: {most_played['unique_players'].max():,}\")\n",
    "        \n",
    "        # Overall database perspective\n",
    "        total_games_db = con.execute('SELECT SUM(num_wins + num_draws + num_losses) FROM player_opening_stats').fetchone()[0]\n",
    "        percentage_of_total = (total_games_in_results / total_games_db * 100) if total_games_db > 0 else 0\n",
    "        \n",
    "        print(f\"\\nThese {TOP_N_MOST_PLAYED} openings represent {percentage_of_total:.1f}% of all games in the database\")\n",
    "else:\n",
    "    print(f\"Database file not found at {db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb1a482",
   "metadata": {},
   "source": [
    "## Delete Overly Generic Openings\n",
    "\n",
    "This cell deletes specific openings that are too generic or broad to provide meaningful recommendations. These openings (like \"Sicilian Defense\" without a specific variation) are parent categories that don't give players actionable insights.\n",
    "\n",
    "The deletion process uses **separate transactions** for each opening to avoid foreign key violations:\n",
    "1. **Transaction 1**: Delete all `player_opening_stats` entries from all partitioned tables for this opening\n",
    "2. **Verification**: Confirm no stats remain for this opening\n",
    "3. **Transaction 2**: Delete the opening from the `opening` table\n",
    "\n",
    "This two-phase approach ensures clean deletion without foreign key constraint violations.\n",
    "\n",
    "Each opening is logged individually with pre- and post-deletion statistics. Any openings not found in the database will be reported (may indicate typos in ECO code or name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675bbf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete specified generic openings using two-phase transaction approach\n",
    "# Testing with first 3 openings to validate the approach\n",
    "\n",
    "if db_path.exists():\n",
    "    # Define openings to delete (starting with first 3)\n",
    "    openings_to_delete = [\n",
    "        (\"D00\", \"Queen's Pawn Game\"),\n",
    "        (\"A40\", \"Horwitz Defense\"),\n",
    "        (\"A00\", \"Van't Kruijs Opening\"),\n",
    "        (\"A45\", \"Indian Defense\"),\n",
    "        (\"B30\", \"Sicilian Defense: Old Sicilian\"),\n",
    "        (\"C23\", \"Bishop's Opening\"),\n",
    "        (\"D02\", \"Queen's Pawn Game: Zukertort Variation\"),\n",
    "        (\"D02\", \"Queen's Pawn Game: Chigorin Variation\"),\n",
    "        (\"C20\", \"King's Pawn Game: Leonardis Variation\"),\n",
    "        (\"B20\", \"Sicilian Defense\"),\n",
    "        (\"C01\", \"French Defense: Exchange Variation\"),\n",
    "        (\"C00\", \"French Defense: Normal Variation\"),\n",
    "        (\"B13\", \"Caro-Kann Defense: Exchange Variation\"),\n",
    "        (\"D30\", \"Queen's Gambit Declined\"),\n",
    "        (\"B50\", \"Sicilian Defense: Modern Variations\"),\n",
    "        (\"C00\", \"French Defense\"),\n",
    "        (\"B23\", \"Sicilian Defense: Closed, Traditional\"),\n",
    "        (\"C50\", \"Italian Game\"),\n",
    "        (\"A41\", \"Old Indian Defense\"),\n",
    "        (\"A10\", \"English Opening\"),\n",
    "        (\"C20\", \"Center Game\"),\n",
    "        (\"A05\", \"Zukertort Opening\"),\n",
    "        (\"D02\", \"Queen's Pawn Game: Symmetrical Variation\"),\n",
    "        (\"A30\", \"English Opening: Symmetrical Variation\"),\n",
    "        (\"C20\", \"King's Pawn Game\"),\n",
    "    ]\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"DELETING OVERLY GENERIC OPENINGS - TWO-PHASE TRANSACTION APPROACH\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nProcessing {len(openings_to_delete)} openings...\")\n",
    "    print(\"Each opening will be deleted in two separate transactions:\")\n",
    "    print(\"  1. Delete all player_opening_stats entries\")\n",
    "    print(\"  2. Delete the opening from the opening table\")\n",
    "    print()\n",
    "    \n",
    "    # Log database state before deletion\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DATABASE STATE BEFORE DELETION\")\n",
    "    print(\"=\" * 80)\n",
    "    log_database_statistics()\n",
    "    \n",
    "    # Track results\n",
    "    openings_successfully_deleted = []\n",
    "    openings_not_found = []\n",
    "    openings_with_errors = []\n",
    "    \n",
    "    # Define partition letters\n",
    "    partition_letters = ['A', 'B', 'C', 'D', 'E', 'other']\n",
    "    \n",
    "    # Process each opening with separate transactions\n",
    "    for eco, name in openings_to_delete:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"PROCESSING: {eco} - {name}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        try:\n",
    "            # PHASE 1: Find and delete player_opening_stats\n",
    "            # Open a fresh connection for this phase\n",
    "            con = get_db_connection(db_path)\n",
    "            \n",
    "            # First, find the opening_id\n",
    "            opening_result = con.execute(\"\"\"\n",
    "                SELECT id, eco, name \n",
    "                FROM opening \n",
    "                WHERE eco = ? AND name = ?\n",
    "            \"\"\", [eco, name]).fetchone()\n",
    "            \n",
    "            if opening_result is None:\n",
    "                print(f\"⚠️  Opening not found in database: {eco} - {name}\")\n",
    "                print(f\"    This may be a typo in the ECO code or name.\")\n",
    "                openings_not_found.append((eco, name))\n",
    "                con.close()\n",
    "                continue\n",
    "            \n",
    "            opening_id = opening_result[0]\n",
    "            found_eco = opening_result[1]\n",
    "            found_name = opening_result[2]\n",
    "            \n",
    "            print(f\"✓ Found opening in database:\")\n",
    "            print(f\"  - Opening ID: {opening_id}\")\n",
    "            print(f\"  - ECO: {found_eco}\")\n",
    "            print(f\"  - Name: {found_name}\")\n",
    "            \n",
    "            # Count stats before deletion\n",
    "            total_stats_before = 0\n",
    "            partition_stats_before = {}\n",
    "            \n",
    "            for letter in partition_letters:\n",
    "                partition_table = f\"player_opening_stats_{letter}\"\n",
    "                count = con.execute(f\"\"\"\n",
    "                    SELECT COUNT(*) \n",
    "                    FROM {partition_table} \n",
    "                    WHERE opening_id = ?\n",
    "                \"\"\", [opening_id]).fetchone()[0]\n",
    "                partition_stats_before[letter] = count\n",
    "                total_stats_before += count\n",
    "            \n",
    "            print(f\"\\n📊 Player stats before deletion: {total_stats_before:,} total records\")\n",
    "            if total_stats_before > 0:\n",
    "                print(f\"    Distribution across partitions:\")\n",
    "                for letter in partition_letters:\n",
    "                    if partition_stats_before[letter] > 0:\n",
    "                        print(f\"      - Partition {letter}: {partition_stats_before[letter]:,}\")\n",
    "            \n",
    "            # TRANSACTION 1: Delete all player_opening_stats for this opening\n",
    "            print(f\"\\n🗑️  TRANSACTION 1: Deleting player_opening_stats entries...\")\n",
    "            \n",
    "            con.execute(\"BEGIN TRANSACTION\")\n",
    "            \n",
    "            total_deleted = 0\n",
    "            for letter in partition_letters:\n",
    "                if partition_stats_before[letter] > 0:\n",
    "                    partition_table = f\"player_opening_stats_{letter}\"\n",
    "                    con.execute(f\"\"\"\n",
    "                        DELETE FROM {partition_table}\n",
    "                        WHERE opening_id = ?\n",
    "                    \"\"\", [opening_id])\n",
    "                    print(f\"  ✓ Deleted {partition_stats_before[letter]:,} records from partition {letter}\")\n",
    "                    total_deleted += partition_stats_before[letter]\n",
    "            \n",
    "            con.execute(\"COMMIT\")\n",
    "            print(f\"  ✅ Transaction 1 complete: {total_deleted:,} stats records deleted and committed\")\n",
    "            \n",
    "            # VERIFICATION: Ensure all stats are deleted\n",
    "            print(f\"\\n🔍 VERIFICATION: Checking for remaining stats...\")\n",
    "            remaining_stats = 0\n",
    "            for letter in partition_letters:\n",
    "                partition_table = f\"player_opening_stats_{letter}\"\n",
    "                count = con.execute(f\"\"\"\n",
    "                    SELECT COUNT(*) \n",
    "                    FROM {partition_table} \n",
    "                    WHERE opening_id = ?\n",
    "                \"\"\", [opening_id]).fetchone()[0]\n",
    "                if count > 0:\n",
    "                    print(f\"  ⚠️  WARNING: Found {count} remaining records in partition {letter}\")\n",
    "                    remaining_stats += count\n",
    "            \n",
    "            if remaining_stats > 0:\n",
    "                print(f\"  ❌ VERIFICATION FAILED: {remaining_stats} stats records still exist!\")\n",
    "                print(f\"     Skipping opening deletion for safety.\")\n",
    "                openings_with_errors.append((eco, name, f\"Stats verification failed: {remaining_stats} records remain\"))\n",
    "                con.close()\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"  ✅ VERIFICATION PASSED: No stats records remain for opening_id {opening_id}\")\n",
    "            \n",
    "            # Close the connection to end this transaction phase\n",
    "            con.close()\n",
    "            \n",
    "            # PHASE 2: Delete the opening from the opening table\n",
    "            # Open a completely new connection for this phase\n",
    "            con2 = get_db_connection(db_path)\n",
    "            \n",
    "            print(f\"\\n🗑️  TRANSACTION 2: Deleting opening from opening table...\")\n",
    "            \n",
    "            # Verify opening still exists before deletion\n",
    "            verify_opening = con2.execute(\"\"\"\n",
    "                SELECT COUNT(*) \n",
    "                FROM opening \n",
    "                WHERE id = ?\n",
    "            \"\"\", [opening_id]).fetchone()[0]\n",
    "            \n",
    "            if verify_opening == 0:\n",
    "                print(f\"  ⚠️  Opening {opening_id} not found in opening table\")\n",
    "                openings_with_errors.append((eco, name, \"Opening not found before deletion\"))\n",
    "                con2.close()\n",
    "                continue\n",
    "            \n",
    "            con2.execute(\"BEGIN TRANSACTION\")\n",
    "            \n",
    "            con2.execute(\"\"\"\n",
    "                DELETE FROM opening\n",
    "                WHERE id = ?\n",
    "            \"\"\", [opening_id])\n",
    "            \n",
    "            con2.execute(\"COMMIT\")\n",
    "            print(f\"  ✅ Transaction 2 complete: Opening deleted from opening table\")\n",
    "            \n",
    "            # Final verification\n",
    "            final_check = con2.execute(\"\"\"\n",
    "                SELECT COUNT(*) \n",
    "                FROM opening \n",
    "                WHERE id = ?\n",
    "            \"\"\", [opening_id]).fetchone()[0]\n",
    "            \n",
    "            if final_check == 0:\n",
    "                print(f\"\\n✅ SUCCESS: Opening {eco} - {name} completely removed from database\")\n",
    "                openings_successfully_deleted.append((eco, name, total_deleted))\n",
    "            else:\n",
    "                print(f\"\\n❌ ERROR: Opening still exists after deletion!\")\n",
    "                openings_with_errors.append((eco, name, \"Opening still exists after deletion\"))\n",
    "            \n",
    "            con2.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ ERROR processing {eco} - {name}: {str(e)}\")\n",
    "            openings_with_errors.append((eco, name, str(e)))\n",
    "            try:\n",
    "                con.close()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                con2.close()\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Summary of deletion operation\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DELETION OPERATION SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\n✅ Successfully deleted: {len(openings_successfully_deleted)} openings\")\n",
    "    if openings_successfully_deleted:\n",
    "        total_stats_deleted = sum([stats for _, _, stats in openings_successfully_deleted])\n",
    "        print(f\"   Total stats records deleted: {total_stats_deleted:,}\")\n",
    "        for eco, name, stats in openings_successfully_deleted:\n",
    "            print(f\"   - {eco}: {name} ({stats:,} stats records)\")\n",
    "    \n",
    "    print(f\"\\n⚠️  Not found: {len(openings_not_found)} openings\")\n",
    "    if openings_not_found:\n",
    "        print(\"   These may be typos in ECO code or name:\")\n",
    "        for eco, name in openings_not_found:\n",
    "            print(f\"   - {eco}: {name}\")\n",
    "    \n",
    "    print(f\"\\n❌ Errors: {len(openings_with_errors)} openings\")\n",
    "    if openings_with_errors:\n",
    "        for eco, name, error in openings_with_errors:\n",
    "            print(f\"   - {eco}: {name}\")\n",
    "            print(f\"     Error: {error}\")\n",
    "    \n",
    "    # Log database state after deletion\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DATABASE STATE AFTER DELETION\")\n",
    "    print(\"=\" * 80)\n",
    "    log_database_statistics()\n",
    "    \n",
    "else:\n",
    "    print(f\"Database file not found at {db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2194cc8f",
   "metadata": {},
   "source": [
    "## Least-Played Openings\n",
    "\n",
    "These are the openings with the fewest number of total games. These might have insufficient data for reliable recommendations and could be candidates for filtering or consolidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6058399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least-played openings by total number of games\n",
    "if db_path.exists():\n",
    "    with get_db_connection(db_path) as con:\n",
    "        print(f\"=== TOP {TOP_N_LEAST_PLAYED} LEAST-PLAYED OPENINGS BY TOTAL GAMES ===\\n\")\n",
    "        \n",
    "        least_played = con.execute(f\"\"\"\n",
    "            SELECT \n",
    "                o.eco,\n",
    "                o.name,\n",
    "                SUM(pos.num_wins + pos.num_draws + pos.num_losses) as total_games,\n",
    "                COUNT(DISTINCT pos.player_id) as unique_players,\n",
    "                -- Overall results\n",
    "                SUM(pos.num_wins) as total_wins,\n",
    "                SUM(pos.num_draws) as total_draws,\n",
    "                SUM(pos.num_losses) as total_losses,\n",
    "                -- White's performance\n",
    "                COUNT(DISTINCT CASE WHEN pos.color = 'w' THEN pos.player_id END) as white_players,\n",
    "                SUM(CASE WHEN pos.color = 'w' THEN pos.num_wins ELSE 0 END) as white_wins,\n",
    "                SUM(CASE WHEN pos.color = 'w' THEN pos.num_draws ELSE 0 END) as white_draws,\n",
    "                SUM(CASE WHEN pos.color = 'w' THEN pos.num_losses ELSE 0 END) as white_losses,\n",
    "                SUM(CASE WHEN pos.color = 'w' THEN pos.num_wins + pos.num_draws + pos.num_losses ELSE 0 END) as white_games,\n",
    "                -- Black's performance\n",
    "                COUNT(DISTINCT CASE WHEN pos.color = 'b' THEN pos.player_id END) as black_players,\n",
    "                SUM(CASE WHEN pos.color = 'b' THEN pos.num_wins ELSE 0 END) as black_wins,\n",
    "                SUM(CASE WHEN pos.color = 'b' THEN pos.num_draws ELSE 0 END) as black_draws,\n",
    "                SUM(CASE WHEN pos.color = 'b' THEN pos.num_losses ELSE 0 END) as black_losses,\n",
    "                SUM(CASE WHEN pos.color = 'b' THEN pos.num_wins + pos.num_draws + pos.num_losses ELSE 0 END) as black_games,\n",
    "                -- Win percentages by color\n",
    "                ROUND(SUM(CASE WHEN pos.color = 'w' THEN pos.num_wins ELSE 0 END) * 100.0 / \n",
    "                      NULLIF(SUM(CASE WHEN pos.color = 'w' THEN pos.num_wins + pos.num_draws + pos.num_losses ELSE 0 END), 0), 2) as white_win_pct,\n",
    "                ROUND(SUM(CASE WHEN pos.color = 'b' THEN pos.num_wins ELSE 0 END) * 100.0 / \n",
    "                      NULLIF(SUM(CASE WHEN pos.color = 'b' THEN pos.num_wins + pos.num_draws + pos.num_losses ELSE 0 END), 0), 2) as black_win_pct,\n",
    "                -- Overall win percentage (from both colors)\n",
    "                ROUND(SUM(pos.num_wins) * 100.0 / \n",
    "                      NULLIF(SUM(pos.num_wins + pos.num_draws + pos.num_losses), 0), 2) as overall_win_pct,\n",
    "                ROUND(SUM(pos.num_draws) * 100.0 / \n",
    "                      NULLIF(SUM(pos.num_wins + pos.num_draws + pos.num_losses), 0), 2) as overall_draw_pct,\n",
    "                ROUND(SUM(pos.num_losses) * 100.0 / \n",
    "                      NULLIF(SUM(pos.num_wins + pos.num_draws + pos.num_losses), 0), 2) as overall_loss_pct\n",
    "            FROM opening o\n",
    "            JOIN player_opening_stats pos ON o.id = pos.opening_id\n",
    "            GROUP BY o.id, o.eco, o.name\n",
    "            ORDER BY total_games ASC\n",
    "            LIMIT {TOP_N_LEAST_PLAYED}\n",
    "        \"\"\").fetchdf()\n",
    "        \n",
    "        # Format the display\n",
    "        display_df = least_played.copy()\n",
    "        \n",
    "        # Format number columns with thousands separators\n",
    "        for col in ['total_games', 'unique_players', 'total_wins', 'total_draws', 'total_losses',\n",
    "                   'white_players', 'white_wins', 'white_draws', 'white_losses', 'white_games',\n",
    "                   'black_players', 'black_wins', 'black_draws', 'black_losses', 'black_games']:\n",
    "            display_df[col] = display_df[col].apply('{:,}'.format)\n",
    "        \n",
    "        # Rename columns for better display\n",
    "        display_df.columns = [\n",
    "            'ECO', 'Opening Name', 'Total Games', 'Unique Players',\n",
    "            'Total Wins', 'Total Draws', 'Total Losses',\n",
    "            'White Players', 'White Wins', 'White Draws', 'White Losses', 'White Games',\n",
    "            'Black Players', 'Black Wins', 'Black Draws', 'Black Losses', 'Black Games',\n",
    "            'White Win %', 'Black Win %', 'Overall Win %', 'Overall Draw %', 'Overall Loss %'\n",
    "        ]\n",
    "        \n",
    "        print(display_df.to_string(index=False))\n",
    "        \n",
    "        # Summary statistics\n",
    "        total_games_in_results = least_played['total_games'].sum()\n",
    "        avg_games_per_opening = least_played['total_games'].mean()\n",
    "        median_games_per_opening = least_played['total_games'].median()\n",
    "        avg_players_per_opening = least_played['unique_players'].mean()\n",
    "        median_players_per_opening = least_played['unique_players'].median()\n",
    "        \n",
    "        print(f\"\\n--- Summary Statistics for Top {TOP_N_LEAST_PLAYED} Least-Played Openings ---\")\n",
    "        print(f\"Total games in these openings: {total_games_in_results:,}\")\n",
    "        print(f\"Average games per opening: {avg_games_per_opening:,.1f}\")\n",
    "        print(f\"Median games per opening: {median_games_per_opening:,.1f}\")\n",
    "        print(f\"Min games: {least_played['total_games'].min():,}\")\n",
    "        print(f\"Max games: {least_played['total_games'].max():,}\")\n",
    "        print(f\"\\nAverage unique players per opening: {avg_players_per_opening:,.1f}\")\n",
    "        print(f\"Median unique players per opening: {median_players_per_opening:,.1f}\")\n",
    "        print(f\"Min players: {least_played['unique_players'].min():,}\")\n",
    "        print(f\"Max players: {least_played['unique_players'].max():,}\")\n",
    "        \n",
    "        # Overall database perspective\n",
    "        total_games_db = con.execute('SELECT SUM(num_wins + num_draws + num_losses) FROM player_opening_stats').fetchone()[0]\n",
    "        percentage_of_total = (total_games_in_results / total_games_db * 100) if total_games_db > 0 else 0\n",
    "        \n",
    "        print(f\"\\nThese {TOP_N_LEAST_PLAYED} openings represent {percentage_of_total:.2f}% of all games in the database\")\n",
    "else:\n",
    "    print(f\"Database file not found at {db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053833e5",
   "metadata": {},
   "source": [
    "## Opening Distribution and Percentile Analysis\n",
    "\n",
    "Let's analyze the overall distribution of games across all openings to understand the data landscape. This includes percentile breakdowns and distribution statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5db61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution analysis and percentiles for opening popularity\n",
    "if db_path.exists():\n",
    "    with get_db_connection(db_path) as con:\n",
    "        print(\"=== OPENING DISTRIBUTION ANALYSIS ===\\n\")\n",
    "        \n",
    "        # Get distribution statistics for all openings\n",
    "        distribution_stats = con.execute(\"\"\"\n",
    "            SELECT \n",
    "                COUNT(*) as total_openings,\n",
    "                MIN(total_games) as min_games,\n",
    "                MAX(total_games) as max_games,\n",
    "                ROUND(AVG(total_games), 1) as avg_games,\n",
    "                ROUND(MEDIAN(total_games), 1) as median_games,\n",
    "                ROUND(STDDEV(total_games), 1) as stddev_games,\n",
    "                MIN(unique_players) as min_players,\n",
    "                MAX(unique_players) as max_players,\n",
    "                ROUND(AVG(unique_players), 1) as avg_players,\n",
    "                ROUND(MEDIAN(unique_players), 1) as median_players,\n",
    "                ROUND(STDDEV(unique_players), 1) as stddev_players,\n",
    "                SUM(total_games) as all_games\n",
    "            FROM (\n",
    "                SELECT \n",
    "                    o.id,\n",
    "                    SUM(pos.num_wins + pos.num_draws + pos.num_losses) as total_games,\n",
    "                    COUNT(DISTINCT pos.player_id) as unique_players\n",
    "                FROM opening o\n",
    "                JOIN player_opening_stats pos ON o.id = pos.opening_id\n",
    "                GROUP BY o.id\n",
    "            ) stats\n",
    "        \"\"\").fetchone()\n",
    "        \n",
    "        print(\"--- Overall Opening Statistics ---\")\n",
    "        print(f\"Total Openings: {distribution_stats[0]:,}\")\n",
    "        print(f\"\\nGames per Opening:\")\n",
    "        print(f\"  Min: {distribution_stats[1]:,}\")\n",
    "        print(f\"  Max: {distribution_stats[2]:,}\")\n",
    "        print(f\"  Average: {distribution_stats[3]:,}\")\n",
    "        print(f\"  Median: {distribution_stats[4]:,}\")\n",
    "        print(f\"  Std Dev: {distribution_stats[5]:,}\")\n",
    "        print(f\"\\nPlayers per Opening:\")\n",
    "        print(f\"  Min: {distribution_stats[6]:,}\")\n",
    "        print(f\"  Max: {distribution_stats[7]:,}\")\n",
    "        print(f\"  Average: {distribution_stats[8]:,}\")\n",
    "        print(f\"  Median: {distribution_stats[9]:,}\")\n",
    "        print(f\"  Std Dev: {distribution_stats[10]:,}\")\n",
    "        print(f\"\\nTotal Games Across All Openings: {distribution_stats[11]:,}\")\n",
    "        \n",
    "        # Percentile analysis for games\n",
    "        print(\"\\n--- Games per Opening Percentiles ---\")\n",
    "        games_percentiles = con.execute(\"\"\"\n",
    "            SELECT \n",
    "                ROUND(PERCENTILE_CONT(0.05) WITHIN GROUP (ORDER BY total_games), 1) as p05,\n",
    "                ROUND(PERCENTILE_CONT(0.10) WITHIN GROUP (ORDER BY total_games), 1) as p10,\n",
    "                ROUND(PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY total_games), 1) as p25,\n",
    "                ROUND(PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY total_games), 1) as p50,\n",
    "                ROUND(PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY total_games), 1) as p75,\n",
    "                ROUND(PERCENTILE_CONT(0.90) WITHIN GROUP (ORDER BY total_games), 1) as p90,\n",
    "                ROUND(PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY total_games), 1) as p95,\n",
    "                ROUND(PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY total_games), 1) as p99\n",
    "            FROM (\n",
    "                SELECT SUM(pos.num_wins + pos.num_draws + pos.num_losses) as total_games\n",
    "                FROM opening o\n",
    "                JOIN player_opening_stats pos ON o.id = pos.opening_id\n",
    "                GROUP BY o.id\n",
    "            ) stats\n",
    "        \"\"\").fetchone()\n",
    "        \n",
    "        percentile_labels = ['5th', '10th', '25th', '50th (Median)', '75th', '90th', '95th', '99th']\n",
    "        for i, label in enumerate(percentile_labels):\n",
    "            print(f\"  {label:15s}: {games_percentiles[i]:>12,.0f} games\")\n",
    "        \n",
    "        # Percentile analysis for players\n",
    "        print(\"\\n--- Players per Opening Percentiles ---\")\n",
    "        players_percentiles = con.execute(\"\"\"\n",
    "            SELECT \n",
    "                ROUND(PERCENTILE_CONT(0.05) WITHIN GROUP (ORDER BY unique_players), 1) as p05,\n",
    "                ROUND(PERCENTILE_CONT(0.10) WITHIN GROUP (ORDER BY unique_players), 1) as p10,\n",
    "                ROUND(PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY unique_players), 1) as p25,\n",
    "                ROUND(PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY unique_players), 1) as p50,\n",
    "                ROUND(PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY unique_players), 1) as p75,\n",
    "                ROUND(PERCENTILE_CONT(0.90) WITHIN GROUP (ORDER BY unique_players), 1) as p90,\n",
    "                ROUND(PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY unique_players), 1) as p95,\n",
    "                ROUND(PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY unique_players), 1) as p99\n",
    "            FROM (\n",
    "                SELECT COUNT(DISTINCT pos.player_id) as unique_players\n",
    "                FROM opening o\n",
    "                JOIN player_opening_stats pos ON o.id = pos.opening_id\n",
    "                GROUP BY o.id\n",
    "            ) stats\n",
    "        \"\"\").fetchone()\n",
    "        \n",
    "        for i, label in enumerate(percentile_labels):\n",
    "            print(f\"  {label:15s}: {players_percentiles[i]:>12,.0f} players\")\n",
    "        \n",
    "        # Count openings by game thresholds\n",
    "        print(\"\\n--- Openings by Game Count Thresholds ---\")\n",
    "        game_thresholds = [10, 50, 100, 500, 1000, 5000, 10000, 50000]\n",
    "        \n",
    "        threshold_data = []\n",
    "        for threshold in game_thresholds:\n",
    "            count_below = con.execute(f\"\"\"\n",
    "                SELECT COUNT(*)\n",
    "                FROM (\n",
    "                    SELECT SUM(pos.num_wins + pos.num_draws + pos.num_losses) as total_games\n",
    "                    FROM opening o\n",
    "                    JOIN player_opening_stats pos ON o.id = pos.opening_id\n",
    "                    GROUP BY o.id\n",
    "                    HAVING total_games < {threshold}\n",
    "                ) stats\n",
    "            \"\"\").fetchone()[0]\n",
    "            \n",
    "            count_above = distribution_stats[0] - count_below\n",
    "            percentage_below = (count_below / distribution_stats[0]) * 100\n",
    "            percentage_above = (count_above / distribution_stats[0]) * 100\n",
    "            \n",
    "            threshold_data.append({\n",
    "                'threshold': threshold,\n",
    "                'below': count_below,\n",
    "                'below_pct': percentage_below,\n",
    "                'above': count_above,\n",
    "                'above_pct': percentage_above\n",
    "            })\n",
    "        \n",
    "        threshold_df = pd.DataFrame(threshold_data)\n",
    "        \n",
    "        print(f\"{'Threshold':<15} {'< Threshold':<20} {'≥ Threshold':<20}\")\n",
    "        print(\"-\" * 55)\n",
    "        for _, row in threshold_df.iterrows():\n",
    "            print(f\"{row['threshold']:>10,} games: {row['below']:>6,} ({row['below_pct']:>5.1f}%)  {row['above']:>6,} ({row['above_pct']:>5.1f}%)\")\n",
    "        \n",
    "        # Count openings by player thresholds\n",
    "        print(\"\\n--- Openings by Player Count Thresholds ---\")\n",
    "        player_thresholds = [5, 10, 25, 50, 100, 500, 1000, 5000]\n",
    "        \n",
    "        threshold_data = []\n",
    "        for threshold in player_thresholds:\n",
    "            count_below = con.execute(f\"\"\"\n",
    "                SELECT COUNT(*)\n",
    "                FROM (\n",
    "                    SELECT COUNT(DISTINCT pos.player_id) as unique_players\n",
    "                    FROM opening o\n",
    "                    JOIN player_opening_stats pos ON o.id = pos.opening_id\n",
    "                    GROUP BY o.id\n",
    "                    HAVING unique_players < {threshold}\n",
    "                ) stats\n",
    "            \"\"\").fetchone()[0]\n",
    "            \n",
    "            count_above = distribution_stats[0] - count_below\n",
    "            percentage_below = (count_below / distribution_stats[0]) * 100\n",
    "            percentage_above = (count_above / distribution_stats[0]) * 100\n",
    "            \n",
    "            threshold_data.append({\n",
    "                'threshold': threshold,\n",
    "                'below': count_below,\n",
    "                'below_pct': percentage_below,\n",
    "                'above': count_above,\n",
    "                'above_pct': percentage_above\n",
    "            })\n",
    "        \n",
    "        threshold_df = pd.DataFrame(threshold_data)\n",
    "        \n",
    "        print(f\"{'Threshold':<15} {'< Threshold':<20} {'≥ Threshold':<20}\")\n",
    "        print(\"-\" * 55)\n",
    "        for _, row in threshold_df.iterrows():\n",
    "            print(f\"{row['threshold']:>10,} players: {row['below']:>6,} ({row['below_pct']:>5.1f}%)  {row['above']:>6,} ({row['above_pct']:>5.1f}%)\")\n",
    "        \n",
    "        # Data quality insights\n",
    "        print(\"\\n--- Data Quality Insights ---\")\n",
    "        \n",
    "        # Openings with less than minimum threshold\n",
    "        low_data_count = con.execute(f\"\"\"\n",
    "            SELECT COUNT(*)\n",
    "            FROM (\n",
    "                SELECT SUM(pos.num_wins + pos.num_draws + pos.num_losses) as total_games\n",
    "                FROM opening o\n",
    "                JOIN player_opening_stats pos ON o.id = pos.opening_id\n",
    "                GROUP BY o.id\n",
    "                HAVING total_games < {MIN_GAMES_FOR_PERCENTILE}\n",
    "            ) stats\n",
    "        \"\"\").fetchone()[0]\n",
    "        \n",
    "        low_data_pct = (low_data_count / distribution_stats[0]) * 100\n",
    "        high_quality_count = distribution_stats[0] - low_data_count\n",
    "        high_quality_pct = 100 - low_data_pct\n",
    "        \n",
    "        print(f\"Openings with < {MIN_GAMES_FOR_PERCENTILE} games (low confidence): {low_data_count:,} ({low_data_pct:.1f}%)\")\n",
    "        print(f\"Openings with ≥ {MIN_GAMES_FOR_PERCENTILE} games (high confidence): {high_quality_count:,} ({high_quality_pct:.1f}%)\")\n",
    "        \n",
    "        # Concentration analysis\n",
    "        games_in_top_10_pct = con.execute(\"\"\"\n",
    "            WITH ranked_openings AS (\n",
    "                SELECT \n",
    "                    SUM(pos.num_wins + pos.num_draws + pos.num_losses) as total_games,\n",
    "                    ROW_NUMBER() OVER (ORDER BY SUM(pos.num_wins + pos.num_draws + pos.num_losses) DESC) as rank,\n",
    "                    COUNT(*) OVER () as total_count\n",
    "                FROM opening o\n",
    "                JOIN player_opening_stats pos ON o.id = pos.opening_id\n",
    "                GROUP BY o.id\n",
    "            )\n",
    "            SELECT SUM(total_games)\n",
    "            FROM ranked_openings\n",
    "            WHERE rank <= CAST(total_count * 0.10 AS INTEGER)\n",
    "        \"\"\").fetchone()[0]\n",
    "        \n",
    "        concentration_pct = (games_in_top_10_pct / distribution_stats[11] * 100) if distribution_stats[11] > 0 else 0\n",
    "        \n",
    "        print(f\"\\nTop 10% of openings account for: {games_in_top_10_pct:,} games ({concentration_pct:.1f}% of total)\")\n",
    "        print(f\"This indicates {'high' if concentration_pct > 50 else 'moderate' if concentration_pct > 30 else 'low'} concentration in popular openings\")\n",
    "        \n",
    "else:\n",
    "    print(f\"Database file not found at {db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4be1ab0",
   "metadata": {},
   "source": [
    "## Opening Popularity Visualization\n",
    "\n",
    "Let's create visual charts to better understand the distribution of opening popularity. These charts will show:\n",
    "- Distribution of games across openings\n",
    "- Top openings by games and players\n",
    "- Comparison between most and least popular openings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dd05b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize opening popularity with charts\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "if db_path.exists():\n",
    "    with get_db_connection(db_path) as con:\n",
    "        print(\"=== GENERATING OPENING POPULARITY VISUALIZATIONS ===\\n\")\n",
    "        \n",
    "        # Get data for most-played openings\n",
    "        most_played_viz = con.execute(f\"\"\"\n",
    "            SELECT \n",
    "                o.eco || ': ' || SUBSTRING(o.name, 1, 30) || \n",
    "                    CASE WHEN LENGTH(o.name) > 30 THEN '...' ELSE '' END as opening_label,\n",
    "                SUM(pos.num_wins + pos.num_draws + pos.num_losses) as total_games,\n",
    "                COUNT(DISTINCT pos.player_id) as unique_players\n",
    "            FROM opening o\n",
    "            JOIN player_opening_stats pos ON o.id = pos.opening_id\n",
    "            GROUP BY o.id, o.eco, o.name\n",
    "            ORDER BY total_games DESC\n",
    "            LIMIT {TOP_N_MOST_PLAYED}\n",
    "        \"\"\").fetchdf()\n",
    "        \n",
    "        # Get data for least-played openings\n",
    "        least_played_viz = con.execute(f\"\"\"\n",
    "            SELECT \n",
    "                o.eco || ': ' || SUBSTRING(o.name, 1, 30) || \n",
    "                    CASE WHEN LENGTH(o.name) > 30 THEN '...' ELSE '' END as opening_label,\n",
    "                SUM(pos.num_wins + pos.num_draws + pos.num_losses) as total_games,\n",
    "                COUNT(DISTINCT pos.player_id) as unique_players\n",
    "            FROM opening o\n",
    "            JOIN player_opening_stats pos ON o.id = pos.opening_id\n",
    "            GROUP BY o.id, o.eco, o.name\n",
    "            ORDER BY total_games ASC\n",
    "            LIMIT {TOP_N_LEAST_PLAYED}\n",
    "        \"\"\").fetchdf()\n",
    "        \n",
    "        # Create a figure with multiple subplots\n",
    "        fig = plt.figure(figsize=(16, 12))\n",
    "        \n",
    "        # 1. Top Most-Played Openings by Games\n",
    "        ax1 = plt.subplot(2, 2, 1)\n",
    "        y_pos = np.arange(min(15, len(most_played_viz)))\n",
    "        bars1 = ax1.barh(y_pos, most_played_viz['total_games'].head(15), color='#2E86AB')\n",
    "        ax1.set_yticks(y_pos)\n",
    "        ax1.set_yticklabels(most_played_viz['opening_label'].head(15), fontsize=8)\n",
    "        ax1.invert_yaxis()\n",
    "        ax1.set_xlabel('Total Games', fontsize=10, fontweight='bold')\n",
    "        ax1.set_title(f'Top 15 Most-Played Openings by Total Games', fontsize=11, fontweight='bold', pad=10)\n",
    "        ax1.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, (bar, games) in enumerate(zip(bars1, most_played_viz['total_games'].head(15))):\n",
    "            ax1.text(bar.get_width(), bar.get_y() + bar.get_height()/2, \n",
    "                    f' {games:,.0f}', va='center', fontsize=7)\n",
    "        \n",
    "        # 2. Top Most-Played Openings by Players\n",
    "        ax2 = plt.subplot(2, 2, 2)\n",
    "        y_pos = np.arange(min(15, len(most_played_viz)))\n",
    "        bars2 = ax2.barh(y_pos, most_played_viz['unique_players'].head(15), color='#A23B72')\n",
    "        ax2.set_yticks(y_pos)\n",
    "        ax2.set_yticklabels(most_played_viz['opening_label'].head(15), fontsize=8)\n",
    "        ax2.invert_yaxis()\n",
    "        ax2.set_xlabel('Unique Players', fontsize=10, fontweight='bold')\n",
    "        ax2.set_title(f'Top 15 Most-Played Openings by Unique Players', fontsize=11, fontweight='bold', pad=10)\n",
    "        ax2.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, (bar, players) in enumerate(zip(bars2, most_played_viz['unique_players'].head(15))):\n",
    "            ax2.text(bar.get_width(), bar.get_y() + bar.get_height()/2, \n",
    "                    f' {players:,.0f}', va='center', fontsize=7)\n",
    "        \n",
    "        # 3. Least-Played Openings by Games\n",
    "        ax3 = plt.subplot(2, 2, 3)\n",
    "        y_pos = np.arange(min(15, len(least_played_viz)))\n",
    "        bars3 = ax3.barh(y_pos, least_played_viz['total_games'].head(15), color='#F18F01')\n",
    "        ax3.set_yticks(y_pos)\n",
    "        ax3.set_yticklabels(least_played_viz['opening_label'].head(15), fontsize=8)\n",
    "        ax3.invert_yaxis()\n",
    "        ax3.set_xlabel('Total Games', fontsize=10, fontweight='bold')\n",
    "        ax3.set_title(f'Top 15 Least-Played Openings by Total Games', fontsize=11, fontweight='bold', pad=10)\n",
    "        ax3.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, (bar, games) in enumerate(zip(bars3, least_played_viz['total_games'].head(15))):\n",
    "            ax3.text(bar.get_width(), bar.get_y() + bar.get_height()/2, \n",
    "                    f' {games:,.0f}', va='center', fontsize=7)\n",
    "        \n",
    "        # 4. Distribution histogram - all openings\n",
    "        all_games = con.execute(\"\"\"\n",
    "            SELECT SUM(pos.num_wins + pos.num_draws + pos.num_losses) as total_games\n",
    "            FROM opening o\n",
    "            JOIN player_opening_stats pos ON o.id = pos.opening_id\n",
    "            GROUP BY o.id\n",
    "        \"\"\").fetchdf()\n",
    "        \n",
    "        ax4 = plt.subplot(2, 2, 4)\n",
    "        # Use log scale for better visualization of the distribution\n",
    "        bins = np.logspace(np.log10(all_games['total_games'].min()), \n",
    "                          np.log10(all_games['total_games'].max()), \n",
    "                          50)\n",
    "        ax4.hist(all_games['total_games'], bins=bins, color='#06A77D', alpha=0.7, edgecolor='black')\n",
    "        ax4.set_xscale('log')\n",
    "        ax4.set_xlabel('Total Games (log scale)', fontsize=10, fontweight='bold')\n",
    "        ax4.set_ylabel('Number of Openings', fontsize=10, fontweight='bold')\n",
    "        ax4.set_title('Distribution of Games Across All Openings', fontsize=11, fontweight='bold', pad=10)\n",
    "        ax4.grid(axis='both', alpha=0.3, linestyle='--')\n",
    "        \n",
    "        # Add percentile lines\n",
    "        percentiles = [25, 50, 75, 95]\n",
    "        percentile_values = [all_games['total_games'].quantile(p/100) for p in percentiles]\n",
    "        colors_p = ['blue', 'green', 'orange', 'red']\n",
    "        \n",
    "        for p, val, color in zip(percentiles, percentile_values, colors_p):\n",
    "            ax4.axvline(val, color=color, linestyle='--', linewidth=1.5, alpha=0.7, \n",
    "                       label=f'{p}th: {val:,.0f}')\n",
    "        \n",
    "        ax4.legend(fontsize=8, loc='upper right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(project_root / 'notebooks' / 'opening_popularity_analysis.png', \n",
    "                   dpi=150, bbox_inches='tight')\n",
    "        print(\"✓ Chart saved to: notebooks/opening_popularity_analysis.png\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Create a second figure for games vs players scatter plot\n",
    "        fig2 = plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Get data for all openings\n",
    "        all_openings = con.execute(\"\"\"\n",
    "            SELECT \n",
    "                o.eco,\n",
    "                o.name,\n",
    "                SUM(pos.num_wins + pos.num_draws + pos.num_losses) as total_games,\n",
    "                COUNT(DISTINCT pos.player_id) as unique_players\n",
    "            FROM opening o\n",
    "            JOIN player_opening_stats pos ON o.id = pos.opening_id\n",
    "            GROUP BY o.id, o.eco, o.name\n",
    "        \"\"\").fetchdf()\n",
    "        \n",
    "        ax = plt.subplot(1, 1, 1)\n",
    "        scatter = ax.scatter(all_openings['total_games'], \n",
    "                           all_openings['unique_players'],\n",
    "                           alpha=0.5, s=20, c='#2E86AB', edgecolors='black', linewidth=0.5)\n",
    "        \n",
    "        ax.set_xlabel('Total Games', fontsize=11, fontweight='bold')\n",
    "        ax.set_ylabel('Unique Players', fontsize=11, fontweight='bold')\n",
    "        ax.set_title('Relationship Between Games and Players Across All Openings', \n",
    "                    fontsize=12, fontweight='bold', pad=15)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_yscale('log')\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        \n",
    "        # Add reference line (games = players)\n",
    "        min_val = min(all_openings['total_games'].min(), all_openings['unique_players'].min())\n",
    "        max_val = max(all_openings['total_games'].max(), all_openings['unique_players'].max())\n",
    "        ax.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.5, linewidth=2, \n",
    "               label='Games = Players')\n",
    "        \n",
    "        ax.legend(fontsize=10)\n",
    "        \n",
    "        # Add text annotation\n",
    "        avg_games_per_player = all_openings['total_games'].sum() / all_openings['unique_players'].sum()\n",
    "        ax.text(0.05, 0.95, f'Average games per player: {avg_games_per_player:.1f}',\n",
    "               transform=ax.transAxes, fontsize=10, verticalalignment='top',\n",
    "               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(project_root / 'notebooks' / 'opening_games_vs_players.png', \n",
    "                   dpi=150, bbox_inches='tight')\n",
    "        print(\"✓ Chart saved to: notebooks/opening_games_vs_players.png\")\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\n✅ All visualizations generated successfully!\")\n",
    "        \n",
    "else:\n",
    "    print(f\"Database file not found at {db_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
