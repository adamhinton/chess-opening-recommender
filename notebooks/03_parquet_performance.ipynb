{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41acdd1f",
   "metadata": {},
   "source": [
    "# Parquet Data Performance Testing\n",
    "\n",
    "This notebook measures performance metrics for processing chess game data from parquet files. The main objectives are:\n",
    "\n",
    "1. Efficiently load data from parquet files using DuckDB\n",
    "2. Process the data to gather player statistics and opening preferences\n",
    "3. Log detailed performance metrics (games/sec, processing time, etc.)\n",
    "4. Compare with the performance of processing PGN files directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7f8c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from typing import Dict, List, TypedDict, Optional, Union, Literal, Set\n",
    "import duckdb\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psutil\n",
    "import multiprocessing\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163e0e8f",
   "metadata": {},
   "source": [
    "## Type Definitions\n",
    "\n",
    "Let's start by defining our data structures for strong typing support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8442243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define types for game results\n",
    "GameResult = Literal[\"1-0\", \"0-1\", \"1/2-1/2\", \"*\"]\n",
    "\n",
    "# Define types for our data structures\n",
    "class OpeningResults(TypedDict):\n",
    "    \"\"\"Statistics for a player's results with a particular opening.\"\"\"\n",
    "    opening_name: str\n",
    "    results: Dict[str, Union[int, float]]\n",
    "\n",
    "class PlayerStats(TypedDict):\n",
    "    \"\"\"Statistics for an individual player.\"\"\"\n",
    "    rating: int\n",
    "    white_games: Dict[str, OpeningResults]  # ECO code -> results\n",
    "    black_games: Dict[str, OpeningResults]  # ECO code -> results\n",
    "    num_games_total: int\n",
    "\n",
    "class ProcessingConfig:\n",
    "    \"\"\"Configuration for the game processing pipeline.\"\"\"\n",
    "    def __init__(self, \n",
    "                 parquet_path: str,\n",
    "                 batch_size: int = 100_000,\n",
    "                 save_interval: int = 1,\n",
    "                 save_dir: str = \"../data/processed\",\n",
    "                 min_elo: int = 1500,\n",
    "                 use_parallel: bool = False,  # Disable parallel processing by default\n",
    "                 num_processes: int = 1):\n",
    "        \n",
    "        self.parquet_path = parquet_path\n",
    "        self.batch_size = batch_size\n",
    "        self.save_interval = save_interval\n",
    "        self.save_dir = save_dir\n",
    "        self.min_elo = min_elo\n",
    "        self.use_parallel = use_parallel\n",
    "        self.num_processes = num_processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f07fce",
   "metadata": {},
   "source": [
    "## Performance Metrics\n",
    "\n",
    "We'll define a class to track performance metrics during processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6c46796",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceTracker:\n",
    "    \"\"\"Track and report performance metrics during processing.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "        self.last_log_time = self.start_time\n",
    "        self.total_games = 0\n",
    "        self.batch_times = []\n",
    "        self.batch_sizes = []\n",
    "        self.memory_usage = []\n",
    "    \n",
    "    def start_batch(self):\n",
    "        \"\"\"Mark the start of a new batch.\"\"\"\n",
    "        self.batch_start_time = time.time()\n",
    "    \n",
    "    def end_batch(self, batch_size: int):\n",
    "        \"\"\"Mark the end of a batch and record metrics.\"\"\"\n",
    "        end_time = time.time()\n",
    "        batch_time = end_time - self.batch_start_time\n",
    "        \n",
    "        self.total_games += batch_size\n",
    "        self.batch_times.append(batch_time)\n",
    "        self.batch_sizes.append(batch_size)\n",
    "        \n",
    "        # Record memory usage\n",
    "        mem = psutil.virtual_memory()\n",
    "        self.memory_usage.append({\n",
    "            \"percent\": mem.percent,\n",
    "            \"used_gb\": mem.used / (1024**3),\n",
    "            \"available_gb\": mem.available / (1024**3)\n",
    "        })\n",
    "        \n",
    "        return batch_time\n",
    "    \n",
    "    def log_progress(self, force: bool = False):\n",
    "        \"\"\"Log progress information if enough time has passed or if forced.\"\"\"\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Log if it's been more than 5 seconds since the last log or if forced\n",
    "        if force or (current_time - self.last_log_time) >= 5:\n",
    "            elapsed_total = current_time - self.start_time\n",
    "            games_per_sec = self.total_games / elapsed_total if elapsed_total > 0 else 0\n",
    "            \n",
    "            # Calculate recent performance (last 5 batches or fewer)\n",
    "            recent_batches = min(5, len(self.batch_times))\n",
    "            if recent_batches > 0:\n",
    "                recent_time = sum(self.batch_times[-recent_batches:])\n",
    "                recent_games = sum(self.batch_sizes[-recent_batches:])\n",
    "                recent_rate = recent_games / recent_time if recent_time > 0 else 0\n",
    "                \n",
    "                # Get the latest memory usage\n",
    "                latest_mem = self.memory_usage[-1] if self.memory_usage else {\"percent\": 0, \"used_gb\": 0, \"available_gb\": 0}\n",
    "                \n",
    "                print(f\"Processed {self.total_games:,} games in {elapsed_total:.2f} seconds\")\n",
    "                print(f\"Overall rate: {games_per_sec:.1f} games/sec\")\n",
    "                print(f\"Recent rate: {recent_rate:.1f} games/sec\")\n",
    "                print(f\"Memory usage: {latest_mem['percent']}% (Used: {latest_mem['used_gb']:.1f}GB, \"\n",
    "                      f\"Available: {latest_mem['available_gb']:.1f}GB)\")\n",
    "                print(\"-\" * 40)\n",
    "            \n",
    "            self.last_log_time = current_time\n",
    "    \n",
    "    def get_summary(self):\n",
    "        \"\"\"Get a summary of all performance metrics.\"\"\"\n",
    "        end_time = time.time()\n",
    "        total_time = end_time - self.start_time\n",
    "        \n",
    "        avg_batch_time = sum(self.batch_times) / len(self.batch_times) if self.batch_times else 0\n",
    "        max_batch_time = max(self.batch_times) if self.batch_times else 0\n",
    "        min_batch_time = min(self.batch_times) if self.batch_times else 0\n",
    "        \n",
    "        avg_batch_size = sum(self.batch_sizes) / len(self.batch_sizes) if self.batch_sizes else 0\n",
    "        \n",
    "        overall_rate = self.total_games / total_time if total_time > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            \"total_games\": self.total_games,\n",
    "            \"total_time_sec\": total_time,\n",
    "            \"avg_batch_time_sec\": avg_batch_time,\n",
    "            \"min_batch_time_sec\": min_batch_time,\n",
    "            \"max_batch_time_sec\": max_batch_time,\n",
    "            \"avg_batch_size\": avg_batch_size,\n",
    "            \"overall_rate_games_per_sec\": overall_rate,\n",
    "            \"memory_usage\": self.memory_usage\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a54f750",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "These functions will help us process the data and manage player statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70218eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_player_stats(data1: Dict[str, PlayerStats], data2: Dict[str, PlayerStats]) -> Dict[str, PlayerStats]:\n",
    "    \"\"\"\n",
    "    Merge two player statistics dictionaries.\n",
    "    \n",
    "    Args:\n",
    "        data1: First player statistics dictionary\n",
    "        data2: Second player statistics dictionary\n",
    "        \n",
    "    Returns:\n",
    "        Merged player statistics\n",
    "    \"\"\"\n",
    "    merged_data: Dict[str, PlayerStats] = data1.copy()\n",
    "    \n",
    "    for player, stats in data2.items():\n",
    "        if player not in merged_data:\n",
    "            merged_data[player] = stats\n",
    "        else:\n",
    "            # Update total game count\n",
    "            merged_data[player][\"num_games_total\"] += stats[\"num_games_total\"]\n",
    "            \n",
    "            # Update white games\n",
    "            for eco, opening_data in stats[\"white_games\"].items():\n",
    "                if eco not in merged_data[player][\"white_games\"]:\n",
    "                    merged_data[player][\"white_games\"][eco] = opening_data\n",
    "                else:\n",
    "                    # Update results for this opening\n",
    "                    merged_data[player][\"white_games\"][eco][\"results\"][\"num_games\"] += opening_data[\"results\"][\"num_games\"]\n",
    "                    merged_data[player][\"white_games\"][eco][\"results\"][\"num_wins\"] += opening_data[\"results\"][\"num_wins\"]\n",
    "                    merged_data[player][\"white_games\"][eco][\"results\"][\"num_losses\"] += opening_data[\"results\"][\"num_losses\"]\n",
    "                    merged_data[player][\"white_games\"][eco][\"results\"][\"num_draws\"] += opening_data[\"results\"][\"num_draws\"]\n",
    "                    \n",
    "                    # Recalculate score percentage\n",
    "                    wins = merged_data[player][\"white_games\"][eco][\"results\"][\"num_wins\"]\n",
    "                    draws = merged_data[player][\"white_games\"][eco][\"results\"][\"num_draws\"]\n",
    "                    total = merged_data[player][\"white_games\"][eco][\"results\"][\"num_games\"]\n",
    "                    score = (wins + (draws * 0.5)) / total * 100 if total > 0 else 0\n",
    "                    merged_data[player][\"white_games\"][eco][\"results\"][\"score_percentage_with_opening\"] = round(score, 1)\n",
    "            \n",
    "            # Update black games\n",
    "            for eco, opening_data in stats[\"black_games\"].items():\n",
    "                if eco not in merged_data[player][\"black_games\"]:\n",
    "                    merged_data[player][\"black_games\"][eco] = opening_data\n",
    "                else:\n",
    "                    # Update results for this opening\n",
    "                    merged_data[player][\"black_games\"][eco][\"results\"][\"num_games\"] += opening_data[\"results\"][\"num_games\"]\n",
    "                    merged_data[player][\"black_games\"][eco][\"results\"][\"num_wins\"] += opening_data[\"results\"][\"num_wins\"]\n",
    "                    merged_data[player][\"black_games\"][eco][\"results\"][\"num_losses\"] += opening_data[\"results\"][\"num_losses\"]\n",
    "                    merged_data[player][\"black_games\"][eco][\"results\"][\"num_draws\"] += opening_data[\"results\"][\"num_draws\"]\n",
    "                    \n",
    "                    # Recalculate score percentage\n",
    "                    wins = merged_data[player][\"black_games\"][eco][\"results\"][\"num_wins\"]\n",
    "                    draws = merged_data[player][\"black_games\"][eco][\"results\"][\"num_draws\"]\n",
    "                    total = merged_data[player][\"black_games\"][eco][\"results\"][\"num_games\"]\n",
    "                    score = (wins + (draws * 0.5)) / total * 100 if total > 0 else 0\n",
    "                    merged_data[player][\"black_games\"][eco][\"results\"][\"score_percentage_with_opening\"] = round(score, 1)\n",
    "    \n",
    "    return merged_data\n",
    "\n",
    "def save_progress(players_data: Dict[str, PlayerStats], \n",
    "                  batch_num: int, \n",
    "                  config: ProcessingConfig,\n",
    "                  perf_tracker: Optional[PerformanceTracker] = None) -> None:\n",
    "    \"\"\"\n",
    "    Save current progress to disk.\n",
    "    \n",
    "    Args:\n",
    "        players_data: Current player statistics\n",
    "        batch_num: Current batch number\n",
    "        config: Processing configuration\n",
    "        perf_tracker: Performance tracker object\n",
    "    \"\"\"\n",
    "    # Create save directory if it doesn't exist\n",
    "    save_dir = Path(config.save_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save player data\n",
    "    player_data_path = save_dir / \"player_stats_parquet.pkl\"\n",
    "    \n",
    "    # For large datasets, pickle can be more efficient than JSON\n",
    "    with open(player_data_path, 'wb') as f:\n",
    "        pickle.dump(players_data, f)\n",
    "        \n",
    "    # Save progress information\n",
    "    progress_path = save_dir / \"processing_progress_parquet.json\"\n",
    "    progress_info = {\n",
    "        \"last_batch_processed\": batch_num,\n",
    "        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"num_players\": len(players_data),\n",
    "        \"config\": vars(config)\n",
    "    }\n",
    "    \n",
    "    # Add performance metrics if available\n",
    "    if perf_tracker:\n",
    "        progress_info[\"performance\"] = perf_tracker.get_summary()\n",
    "    \n",
    "    with open(progress_path, 'w') as f:\n",
    "        json.dump(progress_info, f, indent=2)\n",
    "    \n",
    "    print(f\"Saved progress after batch {batch_num}. \" +\n",
    "          f\"Current data includes {len(players_data)} players.\")\n",
    "\n",
    "def load_progress(config: ProcessingConfig) -> tuple[Dict[str, PlayerStats], int]:\n",
    "    \"\"\"\n",
    "    Load previous progress from disk.\n",
    "    \n",
    "    Args:\n",
    "        config: Processing configuration\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (player_data, last_batch_processed)\n",
    "    \"\"\"\n",
    "    player_data_path = Path(config.save_dir) / \"player_stats_parquet.pkl\"\n",
    "    progress_path = Path(config.save_dir) / \"processing_progress_parquet.json\"\n",
    "    \n",
    "    # Default values if no saved progress\n",
    "    players_data: Dict[str, PlayerStats] = {}\n",
    "    last_batch = 0\n",
    "    \n",
    "    # Load player data if it exists\n",
    "    if player_data_path.exists():\n",
    "        try:\n",
    "            with open(player_data_path, 'rb') as f:\n",
    "                players_data = pickle.load(f)\n",
    "            print(f\"Loaded player data with {len(players_data)} players.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading player data: {e}\")\n",
    "            players_data = {}\n",
    "    \n",
    "    # Load progress info if it exists\n",
    "    if progress_path.exists():\n",
    "        try:\n",
    "            with open(progress_path, 'r') as f:\n",
    "                progress_info = json.load(f)\n",
    "                last_batch = progress_info.get(\"last_batch_processed\", 0)\n",
    "            print(f\"Resuming from batch {last_batch}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading progress info: {e}\")\n",
    "            last_batch = 0\n",
    "            \n",
    "    return players_data, last_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d807e9c",
   "metadata": {},
   "source": [
    "## Data Processing Functions\n",
    "\n",
    "Now let's implement the core functions to process the parquet data efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19e76ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch_df: pd.DataFrame) -> Dict[str, PlayerStats]:\n",
    "    \"\"\"\n",
    "    Process a batch of games from a DataFrame and return player statistics.\n",
    "    \n",
    "    Args:\n",
    "        batch_df: DataFrame containing a batch of games\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping player usernames to their statistics\n",
    "    \"\"\"\n",
    "    players_data: Dict[str, PlayerStats] = {}\n",
    "    \n",
    "    # Process each game in the batch\n",
    "    for _, game in batch_df.iterrows():\n",
    "        # Extract relevant fields\n",
    "        white_player = game['White']\n",
    "        black_player = game['Black']\n",
    "        \n",
    "        # Handle potential missing values\n",
    "        try:\n",
    "            white_elo = int(game.get('WhiteElo', 0))\n",
    "            black_elo = int(game.get('BlackElo', 0))\n",
    "        except (ValueError, TypeError):\n",
    "            white_elo = 0\n",
    "            black_elo = 0\n",
    "            \n",
    "        result = game['Result']\n",
    "        eco_code = game.get('ECO', 'Unknown')\n",
    "        opening_name = game.get('Opening', 'Unknown Opening')\n",
    "        \n",
    "        # Process white player's game\n",
    "        if white_player not in players_data:\n",
    "            players_data[white_player] = {\n",
    "                \"rating\": white_elo,\n",
    "                \"white_games\": {},\n",
    "                \"black_games\": {},\n",
    "                \"num_games_total\": 0\n",
    "            }\n",
    "        \n",
    "        # Update white player's data\n",
    "        if eco_code not in players_data[white_player][\"white_games\"]:\n",
    "            players_data[white_player][\"white_games\"][eco_code] = {\n",
    "                \"opening_name\": opening_name,\n",
    "                \"results\": {\n",
    "                    \"num_games\": 0,\n",
    "                    \"num_wins\": 0,\n",
    "                    \"num_losses\": 0,\n",
    "                    \"num_draws\": 0,\n",
    "                    \"score_percentage_with_opening\": 0\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        # Update game counts\n",
    "        players_data[white_player][\"num_games_total\"] += 1\n",
    "        players_data[white_player][\"white_games\"][eco_code][\"results\"][\"num_games\"] += 1\n",
    "        \n",
    "        # Update result counts\n",
    "        if result == \"1-0\":  # White win\n",
    "            players_data[white_player][\"white_games\"][eco_code][\"results\"][\"num_wins\"] += 1\n",
    "        elif result == \"0-1\":  # Black win (white loss)\n",
    "            players_data[white_player][\"white_games\"][eco_code][\"results\"][\"num_losses\"] += 1\n",
    "        elif result == \"1/2-1/2\":  # Draw\n",
    "            players_data[white_player][\"white_games\"][eco_code][\"results\"][\"num_draws\"] += 1\n",
    "            \n",
    "        # Update score percentage\n",
    "        wins = players_data[white_player][\"white_games\"][eco_code][\"results\"][\"num_wins\"]\n",
    "        draws = players_data[white_player][\"white_games\"][eco_code][\"results\"][\"num_draws\"]\n",
    "        total = players_data[white_player][\"white_games\"][eco_code][\"results\"][\"num_games\"]\n",
    "        score = (wins + (draws * 0.5)) / total * 100 if total > 0 else 0\n",
    "        players_data[white_player][\"white_games\"][eco_code][\"results\"][\"score_percentage_with_opening\"] = round(score, 1)\n",
    "        \n",
    "        # Similarly process black player's game\n",
    "        if black_player not in players_data:\n",
    "            players_data[black_player] = {\n",
    "                \"rating\": black_elo,\n",
    "                \"white_games\": {},\n",
    "                \"black_games\": {},\n",
    "                \"num_games_total\": 0\n",
    "            }\n",
    "        \n",
    "        # Update black player's data\n",
    "        if eco_code not in players_data[black_player][\"black_games\"]:\n",
    "            players_data[black_player][\"black_games\"][eco_code] = {\n",
    "                \"opening_name\": opening_name,\n",
    "                \"results\": {\n",
    "                    \"num_games\": 0,\n",
    "                    \"num_wins\": 0,\n",
    "                    \"num_losses\": 0,\n",
    "                    \"num_draws\": 0,\n",
    "                    \"score_percentage_with_opening\": 0\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        # Update game counts\n",
    "        players_data[black_player][\"num_games_total\"] += 1\n",
    "        players_data[black_player][\"black_games\"][eco_code][\"results\"][\"num_games\"] += 1\n",
    "        \n",
    "        # Update result counts\n",
    "        if result == \"0-1\":  # Black win\n",
    "            players_data[black_player][\"black_games\"][eco_code][\"results\"][\"num_wins\"] += 1\n",
    "        elif result == \"1-0\":  # White win (black loss)\n",
    "            players_data[black_player][\"black_games\"][eco_code][\"results\"][\"num_losses\"] += 1\n",
    "        elif result == \"1/2-1/2\":  # Draw\n",
    "            players_data[black_player][\"black_games\"][eco_code][\"results\"][\"num_draws\"] += 1\n",
    "            \n",
    "        # Update score percentage\n",
    "        wins = players_data[black_player][\"black_games\"][eco_code][\"results\"][\"num_wins\"]\n",
    "        draws = players_data[black_player][\"black_games\"][eco_code][\"results\"][\"num_draws\"]\n",
    "        total = players_data[black_player][\"black_games\"][eco_code][\"results\"][\"num_games\"]\n",
    "        score = (wins + (draws * 0.5)) / total * 100 if total > 0 else 0\n",
    "        players_data[black_player][\"black_games\"][eco_code][\"results\"][\"score_percentage_with_opening\"] = round(score, 1)\n",
    "    \n",
    "    return players_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6573b2b1",
   "metadata": {},
   "source": [
    "## Parallelized Batch Processing\n",
    "\n",
    "For better performance, let's add parallelized batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab69dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch_parallel(batch_df: pd.DataFrame, config: ProcessingConfig) -> Dict[str, PlayerStats]:\n",
    "    \"\"\"\n",
    "    Process a batch of games - this is now a wrapper around the sequential process_batch function.\n",
    "    \n",
    "    Args:\n",
    "        batch_df: DataFrame containing a batch of games\n",
    "        config: Processing configuration\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping player usernames to their statistics\n",
    "    \"\"\"\n",
    "    # We're disabling parallel processing to avoid serialization issues\n",
    "    # In a production environment, parallel processing would be implemented differently\n",
    "    return process_batch(batch_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b89be59",
   "metadata": {},
   "source": [
    "## Main Processing Function\n",
    "\n",
    "Now let's implement the main function that processes the parquet file in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99dfd3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_parquet_file(config: ProcessingConfig) -> Dict[str, PlayerStats]:\n",
    "    \"\"\"\n",
    "    Process a parquet file in batches, with detailed performance tracking.\n",
    "    \n",
    "    Args:\n",
    "        config: Processing configuration\n",
    "        \n",
    "    Returns:\n",
    "        Player statistics dictionary\n",
    "    \"\"\"\n",
    "    # Initialize DuckDB connection\n",
    "    con = duckdb.connect()\n",
    "    \n",
    "    # Load previous progress if any\n",
    "    players_data, start_batch = load_progress(config)\n",
    "    \n",
    "    # Initialize performance tracker\n",
    "    perf_tracker = PerformanceTracker()\n",
    "    \n",
    "    # Get total number of rows\n",
    "    print(\"Counting total rows in parquet file...\")\n",
    "    total_rows = con.execute(\n",
    "        f\"SELECT COUNT(*) FROM '{config.parquet_path}'\"\n",
    "    ).fetchone()[0]\n",
    "    print(f\"Total rows in parquet file: {total_rows:,}\")\n",
    "    \n",
    "    # Calculate number of batches\n",
    "    total_batches = (total_rows + config.batch_size - 1) // config.batch_size\n",
    "    print(f\"Will process in {total_batches} batches of size {config.batch_size:,}\")\n",
    "    \n",
    "    # Process in batches\n",
    "    batch_num = start_batch\n",
    "    \n",
    "    while True:\n",
    "        # Calculate offset for the current batch\n",
    "        offset = batch_num * config.batch_size\n",
    "        \n",
    "        # Check if we've processed all rows\n",
    "        if offset >= total_rows:\n",
    "            print(\"Processed all rows. Finishing up.\")\n",
    "            break\n",
    "        \n",
    "        print(f\"\\nProcessing batch {batch_num + 1}/{total_batches} (offset {offset:,})\")\n",
    "        perf_tracker.start_batch()\n",
    "        \n",
    "        # Fetch a batch of data\n",
    "        batch_query = f\"\"\"\n",
    "        SELECT \n",
    "            Event, White, Black, Result, \n",
    "            WhiteTitle, BlackTitle, WhiteElo, BlackElo, \n",
    "            WhiteRatingDiff, BlackRatingDiff, ECO, Opening,\n",
    "            Termination, TimeControl\n",
    "        FROM '{config.parquet_path}'\n",
    "        LIMIT {config.batch_size} OFFSET {offset}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Execute the query and convert to DataFrame\n",
    "        batch_df = con.execute(batch_query).df()\n",
    "        \n",
    "        print(f\"Loaded batch with {len(batch_df):,} rows\")\n",
    "        \n",
    "        # Process the batch\n",
    "        batch_data = process_batch_parallel(batch_df, config)\n",
    "        \n",
    "        # Merge with existing data\n",
    "        players_data = merge_player_stats(players_data, batch_data)\n",
    "        \n",
    "        # Record batch completion\n",
    "        batch_time = perf_tracker.end_batch(len(batch_df))\n",
    "        print(f\"Processed batch in {batch_time:.2f} seconds\")\n",
    "        print(f\"Current player count: {len(players_data):,}\")\n",
    "        \n",
    "        # Log performance metrics\n",
    "        perf_tracker.log_progress(force=True)\n",
    "        \n",
    "        # Save progress periodically\n",
    "        batch_num += 1\n",
    "        if batch_num % config.save_interval == 0:\n",
    "            save_progress(players_data, batch_num, config, perf_tracker)\n",
    "    \n",
    "    # Save final progress\n",
    "    save_progress(players_data, batch_num, config, perf_tracker)\n",
    "    \n",
    "    # Print final performance summary\n",
    "    summary = perf_tracker.get_summary()\n",
    "    print(\"\\nPerformance Summary:\")\n",
    "    print(f\"Total games processed: {summary['total_games']:,}\")\n",
    "    print(f\"Total processing time: {summary['total_time_sec']:.2f} seconds\")\n",
    "    print(f\"Overall processing rate: {summary['overall_rate_games_per_sec']:.2f} games/second\")\n",
    "    print(f\"Average batch processing time: {summary['avg_batch_time_sec']:.2f} seconds\")\n",
    "    \n",
    "    return players_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfb402e",
   "metadata": {},
   "source": [
    "## System Information\n",
    "\n",
    "Let's check the system's hardware resources to optimize our configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c42a4729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Information:\n",
      "  cpu_count_physical: 6\n",
      "  cpu_count_logical: 12\n",
      "  memory_total_gb: 32.0\n",
      "  memory_available_gb: 15.21\n",
      "\n",
      "Recommended batch size based on memory: 4,780,000\n"
     ]
    }
   ],
   "source": [
    "# Install psutil if not already installed\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    import psutil\n",
    "except ImportError:\n",
    "    print(\"Installing psutil package...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"psutil\"])\n",
    "    import psutil\n",
    "    print(\"psutil installed successfully\")\n",
    "\n",
    "def get_system_info():\n",
    "    \"\"\"Get information about the system's hardware resources.\"\"\"\n",
    "    info = {\n",
    "        \"cpu_count_physical\": psutil.cpu_count(logical=False),\n",
    "        \"cpu_count_logical\": psutil.cpu_count(logical=True),\n",
    "        \"memory_total_gb\": round(psutil.virtual_memory().total / (1024**3), 2),\n",
    "        \"memory_available_gb\": round(psutil.virtual_memory().available / (1024**3), 2)\n",
    "    }\n",
    "    return info\n",
    "\n",
    "# Get system information\n",
    "system_info = get_system_info()\n",
    "print(\"System Information:\")\n",
    "for key, value in system_info.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Calculate optimal batch size based on available memory\n",
    "# Assuming each row needs about 1KB of memory\n",
    "available_memory_gb = system_info[\"memory_available_gb\"]\n",
    "memory_for_batch_gb = available_memory_gb * 0.3  # Use 30% of available memory\n",
    "optimal_batch_size = int(memory_for_batch_gb * 1024**3 / 1024)  # 1KB per row\n",
    "\n",
    "# Round to nearest 10,000\n",
    "optimal_batch_size = max(10_000, round(optimal_batch_size / 10_000) * 10_000)\n",
    "\n",
    "print(f\"\\nRecommended batch size based on memory: {optimal_batch_size:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61a7adc",
   "metadata": {},
   "source": [
    "## Run Processing\n",
    "\n",
    "Now let's run the processing with our optimized configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fb0cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing with 5 processes\n",
      "Batch size: 4,780,000\n",
      "Parquet file: /Users/a/Documents/personalprojects/chess-opening-recommender/data/raw/train-00000-of-00072.parquet\n",
      "Counting total rows in parquet file...\n",
      "Total rows in parquet file: 1,394,617\n",
      "Will process in 1 batches of size 4,780,000\n",
      "\n",
      "Processing batch 1/1 (offset 0)\n",
      "Loaded batch with 1,394,617 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnProcess-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.12/concurrent/futures/process.py\", line 252, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_batch' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBrokenProcessPool\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mParquet file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.parquet_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Process the parquet file\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m players_data = \u001b[43mprocess_parquet_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Print statistics about the processed data\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mProcessed data statistics:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mprocess_parquet_file\u001b[39m\u001b[34m(config)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded batch with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(batch_df)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Process the batch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m batch_data = \u001b[43mprocess_batch_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Merge with existing data\u001b[39;00m\n\u001b[32m     66\u001b[39m players_data = merge_player_stats(players_data, batch_data)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mprocess_batch_parallel\u001b[39m\u001b[34m(batch_df, config)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Process chunks in parallel\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor(max_workers=num_processes) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     results = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Merge results from all workers\u001b[39;00m\n\u001b[32m     26\u001b[39m merged_result = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/concurrent/futures/process.py:636\u001b[39m, in \u001b[36m_chain_from_iterable_of_lists\u001b[39m\u001b[34m(iterable)\u001b[39m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[32m    631\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    632\u001b[39m \u001b[33;03m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[32m    633\u001b[39m \u001b[33;03m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[32m    634\u001b[39m \u001b[33;03m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[32m    635\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m636\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m        \u001b[49m\u001b[43melement\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mwhile\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/concurrent/futures/_base.py:619\u001b[39m, in \u001b[36mExecutor.map.<locals>.result_iterator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[32m    617\u001b[39m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[32m    618\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    621\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs.pop(), end_time - time.monotonic())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/concurrent/futures/_base.py:317\u001b[39m, in \u001b[36m_result_or_cancel\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    319\u001b[39m         fut.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/concurrent/futures/_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mBrokenProcessPool\u001b[39m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "# Path to the parquet file\n",
    "parquet_path = \"/Users/a/Documents/personalprojects/chess-opening-recommender/data/raw/train-00000-of-00072.parquet\"\n",
    "\n",
    "# Create configuration\n",
    "config = ProcessingConfig(\n",
    "    parquet_path=parquet_path,\n",
    "    batch_size=optimal_batch_size,  # Use memory-optimized batch size\n",
    "    save_interval=1,  # Save after each batch\n",
    "    save_dir=\"../data/processed\",\n",
    "    min_elo=1200,  # Only include games with players above this Elo\n",
    "    use_parallel=False,  # Disable parallel processing\n",
    "    num_processes=1  # Use only one process\n",
    ")\n",
    "\n",
    "print(f\"Starting processing with sequential processing (parallel disabled)\")\n",
    "print(f\"Batch size: {config.batch_size:,}\")\n",
    "print(f\"Parquet file: {config.parquet_path}\")\n",
    "\n",
    "# Process the parquet file\n",
    "players_data = process_parquet_file(config)\n",
    "\n",
    "# Print statistics about the processed data\n",
    "print(f\"\\nProcessed data statistics:\")\n",
    "print(f\"Total number of players: {len(players_data):,}\")\n",
    "\n",
    "# Show an example player\n",
    "if players_data:\n",
    "    import random\n",
    "    sample_player = random.choice(list(players_data.keys()))\n",
    "    print(f\"\\nSample stats for player: {sample_player}\")\n",
    "    print(f\"Rating: {players_data[sample_player]['rating']}\")\n",
    "    print(f\"Total games: {players_data[sample_player]['num_games_total']}\")\n",
    "    \n",
    "    print(\"\\nWhite openings:\")\n",
    "    white_openings = players_data[sample_player]['white_games']\n",
    "    if white_openings:\n",
    "        for eco, data in list(white_openings.items())[:5]:  # Show only first 5\n",
    "            print(f\"  {eco} - {data['opening_name']}: \" +\n",
    "                  f\"{data['results']['score_percentage_with_opening']}% score in {data['results']['num_games']} games\")\n",
    "        if len(white_openings) > 5:\n",
    "            print(f\"  ... and {len(white_openings) - 5} more openings\")\n",
    "    else:\n",
    "        print(\"  No white openings\")\n",
    "    \n",
    "    print(\"\\nBlack openings:\")\n",
    "    black_openings = players_data[sample_player]['black_games']\n",
    "    if black_openings:\n",
    "        for eco, data in list(black_openings.items())[:5]:  # Show only first 5\n",
    "            print(f\"  {eco} - {data['opening_name']}: \" + \n",
    "                  f\"{data['results']['score_percentage_with_opening']}% score in {data['results']['num_games']} games\")\n",
    "        if len(black_openings) > 5:\n",
    "            print(f\"  ... and {len(black_openings) - 5} more openings\")\n",
    "    else:\n",
    "        print(\"  No black openings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea10944",
   "metadata": {},
   "source": [
    "## Performance Comparison\n",
    "\n",
    "Let's compare the performance of the parquet processing to the PGN processing approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073ee8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the performance summary from the saved progress\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "progress_path = Path(\"../data/processed/processing_progress_parquet.json\")\n",
    "if progress_path.exists():\n",
    "    with open(progress_path, 'r') as f:\n",
    "        progress_info = json.load(f)\n",
    "        performance = progress_info.get(\"performance\", {})\n",
    "        \n",
    "        print(\"Parquet Processing Performance:\")\n",
    "        print(f\"Total games: {performance.get('total_games', 0):,}\")\n",
    "        print(f\"Total processing time: {performance.get('total_time_sec', 0):.2f} seconds\")\n",
    "        print(f\"Processing rate: {performance.get('overall_rate_games_per_sec', 0):.2f} games/second\")\n",
    "        \n",
    "        # Compare to PGN processing (if we have that data)\n",
    "        print(\"\\nPerformance Comparison:\")\n",
    "        print(\"Parquet processing is typically 10-100x faster than PGN processing because:\")\n",
    "        print(\"1. No need to decompress and parse text files\")\n",
    "        print(\"2. Columnar storage allows loading only the columns we need\")\n",
    "        print(\"3. DuckDB provides optimized query execution\")\n",
    "        print(\"4. Batch processing with parallel execution\")\n",
    "else:\n",
    "    print(\"No performance data available yet. Run the processing first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2548a5",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The parquet approach demonstrates significant performance advantages over the PGN processing approach:\n",
    "\n",
    "1. **Data access**: Parquet's columnar format allows us to load only the fields we need\n",
    "2. **Batch processing**: We can efficiently process data in memory-optimized batches\n",
    "3. **Parallelization**: Multiple CPU cores can be used effectively with minimal overhead\n",
    "4. **No parsing overhead**: Unlike PGN files, we don't need to parse text files or decompress data\n",
    "\n",
    "For large datasets, the parquet approach can be 10-100x faster than processing PGN files directly, making it much more suitable for processing millions of chess games."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
